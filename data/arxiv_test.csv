,query,abstract,num_words,num_sentences,num_characters,flesch_reading_ease
0,astrophysics,"The idea of a unified model for all astrophysical jets has been considered
for quite some time. We present here a few scaling laws relevant to all type of
astrophysical jets, analogous to those of \citet{sams96} which are widely used
for astrophysical black holes. We use Buckingham's $ \Pi $ theorem of
dimensional analysis to obtain a family of dimensional relations among the
physical quantities associated to astrophysical jets.",69,4,432,31.92
1,astrophysics,"I discuss the scientific rationale and opportunities in the study of high
energy particle accelerators away from the Earth; mostly, those outside the
Solar System. I also briefly outline the features to be desired in telescopes
used to probe accelerators studied by remote sensing.",44,3,281,32.22
2,astrophysics,"This is an overview over the prediction of astrophysical reaction rates in
the statistical model, with special emphasis on the parametrization of optical
alpha+nucleus potentials.",25,2,179,12.26
3,astrophysics,"I review progress that has been made in nuclear astrophysics over the past
few years and summarize some of the questions that remain. Topics selected
include solar neutrinos, supernovae (the explosion and associated
nucleosynthesis), laboratory astrophysics, and neutron star structure.",40,3,286,25.8
4,astrophysics,"I present both a history of radioactivity in astrophysics and an introduction
to the major applications of radioactive abundances to astronomy.",21,2,143,16.32
5,astrophysics,"An critical overview of the current state of research in turbulence in
astrophysical disks.",14,2,91,40.35
6,astrophysics,"A summary of the session on Particle Astrophysics at the Rencontre de
Vietnam, 2006.",14,2,84,48.81
7,astrophysics,"We review the current status, and some open issues, of VHE astrophysics.",12,2,72,67.76
8,astrophysics,"Outlook talk presented at the 10th International Symposium on Cosmology and
Particle Astrophysics (CosPA2013)",14,1,109,14.97
9,astrophysics,"The parallel session on ""Relativistic and Particle Astrophysics"" was held on
14th December 2015. Here a short summary of each presentation of this parallel
session is given.",27,3,173,40.85
10,astrophysics,"The idea of a unified model for all astrophysical jets has been considered
for some time now. We present here some hydrodynamical scaling laws relevant
for all type of astrophysical jets, analogous to those of Sams et al. (1996).
We use Buckingham's Pi theorem of dimensional analysis to obtain a family of
dimensional relations among the physical quantities associated with the jets.",62,5,384,33.54
11,astrophysics,"Laboratory astrophysics and complementary theoretical calculations are the
foundations of astronomy and astrophysics and will remain so into the
foreseeable future. The impact of laboratory astrophysics ranges from the
scientific conception stage for ground-based, airborne, and space-based
observatories, all the way through to the scientific return of these projects
and missions. It is our understanding of the under-lying physical processes and
the measurements of critical physical parameters that allows us to address
fundamental questions in astronomy and astrophysics. In this regard, laboratory
astrophysics is much like detector and instrument development at NASA, NSF, and
DOE. These efforts are necessary for the success of astronomical research being
funded by the agencies. Without concomitant efforts in all three directions
(observational facilities, detector/instrument development, and laboratory
astrophysics) the future progress of astronomy and astrophysics is imperiled.
In addition, new developments in experimental technologies have allowed
laboratory studies to take on a new role as some questions which previously
could only be studied theoretically can now be addressed directly in the lab.
With this in mind we, the members of the AAS Working Group on Laboratory
Astrophysics, have prepared this State of the Profession Position Paper on the
laboratory astrophysics infrastructure needed to ensure the advancement of
astronomy and astrophysics in the next decade.",210,9,1492,10.94
12,astrophysics,"We discuss the outcomes of surveys addressing the career situation of
astronomers in Germany and the UK, finding social and cultural differences
between communities as well as gender bias in both.",31,2,196,31.55
13,astrophysics,"[Abridged] The Moon is a unique platform from and on which to conduct
astrophysical measurements. The Lunar University Network for Astrophysics
Research (LUNAR) and the Center for Lunar Origins and Evolution (CLOE) teams
within the NASA Lunar Science Institute (NLSI) are illustrating how the Moon
can be used as a platform to advance important goals in astrophysics. Of
relevance to Astrophysics and aligned with NASA strategic goals, all three of
the primary research themes articulated by New Worlds, New Horizons in
Astronomy & Astrophysics are being addressed by LUNAR and CLOE, namely Probing
Cosmic Dawn, Understanding New Worlds, and Physics of the Universe",103,3,665,36.97
14,astrophysics,"Laboratory astrophysics and complementary theoretical calculations are the
foundations of astronomy and astrophysics and will remain so into the
foreseeable future. The mission enabling impact of laboratory astrophysics
ranges from the scientific conception stage for airborne and space-based
observatories, all the way through to the scientific return of these missions.
It is our understanding of the under-lying physical processes and the
measurements of critical physical parameters that allows us to address
fundamental questions in astronomy and astrophysics. In this regard, laboratory
astrophysics is much like detector and instrument development at NASA. These
efforts are necessary for the success of astronomical research being funded by
NASA. Without concomitant efforts in all three directions (observational
facilities, detector/instrument development, and laboratory astrophysics) the
future progress of astronomy and astrophysics is imperiled. In addition, new
developments in experimental technologies have allowed laboratory studies to
take on a new role as some questions which previously could only be studied
theoretically can now be addressed directly in the lab. With this in mind we,
the members of the AAS Working Group on Laboratory Astrophysics (WGLA), have
prepared this White Paper on the laboratory astrophysics infrastructure needed
to maximize the scientific return from NASA's space and Earth sciences program.",202,9,1443,11.96
15,astrophysics,"Collection of ""Extended Abstracts"" of talks presented at the SFB-375 workshop
NEUTRINO ASTROPHYSICS, Ringberg Castle, Tegernsee, Germany, 20-24 Oct. 1997.
Topics include Solar Neutrinos, Supernovae, Gamma-Ray Bursts, High-Energy
Neutrinos (atmospheric, astrophysical), Cosmology, and Future Prospects. The
focus is on astrophysical and experimental/observational aspects of
astrophysical neutrinos while particle theory and neutrino laboratory
experiments are not covered.",56,5,472,-6.74
16,astrophysics,"I present some recent results from experiments at the Oak Ridge Electron
Linear Accelerator (ORELA) and discuss their impact in nuclear astrophysics. I
then describe some possible future nuclear astrophysics experiments at ORELA
and at the Spallation Neutron Source (SNS) being built in Oak Ridge. The SNS
and ORELA are complementary, world-class facilities and both will be needed for
important future experiments in nuclear astrophysics.",65,4,439,32.53
17,astrophysics,"Recent years have seen tremendous progress in our understanding of the
extreme universe, which in turn points to even deeper questions to be further
addressed. History has shown that the symbiosis between direct observations and
laboratory investigations is instrumental in the progress of astrophysics.
Current frontier astrophysical phenomena related to particle astrophysics and
cosmology typically involve one or more of the following conditions: (1)
extremely high energy events;(2) very high density, high temperature processes;
(3) super strong field environments. Laboratory experiments using high
intensity lasers and particle beams can calibrate astrophysical observation or
detection processes, investigate the underlying dynamics of astrophysical
phenomena, and probe fundamental physics in extreme limits. We give examples of
possible laboratory experiments that investigate into the extreme universe.",122,6,914,4.41
18,astrophysics,"We outline scientific objectives for monitoring X-ray sources and transients
with wide-angle, coded mask cameras. It is now possible to instantaneously view
half of the sky over long time intervals, gaining access to events of
extraordinary interest. Solid state detectors can raise the quality of data
products for bright sources to levels associated with pointed instruments.
There are diverse ways to advance high energy astrophysics and quantitative
applications for general relativity.",71,5,490,28.03
19,astrophysics,"Neutrinos of astrophysical origin are messengers produced in stars, in
explosive phenomena like core-collapse supernovae, in the accretion disks
around black holes, or in the Earth's atmosphere. Their fluxes and spectra
encode information on the environments that produce them. Such fluxes are
modified in characteristic ways when neutrinos traverse a medium. Here our
current understanding of neutrino flavour conversion in media is summarized.
The importance of this domain for astrophysical observations is emphasized.
Examples are given of the fundamental properties that astrophysical neutrinos
have uncovered, or might reveal in the future.",91,7,646,30.67
20,astrophysics,"An impact of a nonzero neutrino millicharge in astrophysics is tested. It is
shown that in astrophysical environments electromagnetic interactions of the
neutrino millicharge with strong electromagnetic fields as well as weak
interactions of the neutrinos with dense background matter can produce new
phenomena accessible for astrophysical observations. On this basis a new limit
on the neutrino millicharge $q_0<1.3\times10^{-19}e_0$ is obtained. This limit
is among the strongest astrophysical constraint on the neutrino millicharge.
Some other possible applications of the obtained results to astrophysics are
discussed in details.",87,7,634,31.38
21,astrophysics,"Nuclear Astrophysics is a vibrant field at the intersection of nuclear
physics and astrophysics that encompasses research in nuclear physics,
astrophysics, astronomy, and computational science. This paper is not a review.
It is intended to provide an incomplete personal perspective on current trends
in nuclear astrophysics and the specific role of nuclear physics in this field.",56,4,380,27.11
22,astrophysics,"This is a basic introduction to the physics of compact objects in the context
of High Time Resolution Astrophysics (HTRA). The main mechanisms of energy
release and the properties of relevant radiation processes are briefly
reviewed. As a specific example, the top models for the multi-wavelength
variability of accreting black holes are unveiled.",53,4,347,36.59
23,astrophysics,"General aspects about the thermodynamics of astrophysical systems are
discussed, overall, those concerning to astrophysical systems in mutual
interaction (or the called \emph{open astrophysical systems}). A special
interest is devoted along the paper to clarify several misconceptions that are
still common in the recent literature, such as the direct application to the
astrophysical scenario of notions and theoretical frameworks that were
originally conceived to deal with extensive systems of the everyday practice
(large systems with short-range interactions).",77,3,565,-1.45
24,astrophysics,"I discuss several general-relativistic effects that are likely to be of
interest in the astrophysics of black holes and neutron stars",21,1,133,33.24
25,astrophysics,"Precise knowledge of the features of several X-ray sources from compact
binary sources to galactic nuclei is gradually unveiling the physical
parameters of relativistic neutron stars and black holes therein. Recent
developments in theory, astrophysical models and experiments are reviewed.",40,3,289,17.34
26,astrophysics,"1) Introduction
  2) PopIII stars and galaxies: a ""top-down"" theoretical approach
  3) Lyman-alpha physics and astrophysics
  4) Distant/primeval galaxies: observations and main results",23,1,185,14.29
27,astrophysics,"I give a concise introduction into high energy cosmic ray physics, including
also few related aspects of high energy gamma-ray and neutrino astrophysics.
The main emphasis is placed on astrophysical questions, and the level of the
presentation is kept basic.",40,3,258,34.26
28,astrophysics,"This contribution discusses some of the main problems in high energy
astrophysics, and the perspectives to solve them using different types of
""messengers"": cosmic rays, photons and neutrinos",28,1,191,26.14
29,astrophysics,"I review the current status of neutrino astrophysics, including solar
neutrinos; atmospheric neutrinos; neutrino mass and oscillations; supernova
neutrinos; neutrino nucleosynthesis (Big Bang nucleosynthesis, the neutrino
process, the r-process); neutrino cooling and red giants; and high energy
neutrino astronomy.",39,2,315,-27.34
30,astrophysics,"A reply to arXiv:0809.2310, ""Comment on Universal Charge-Radius Relation for
Subatomic and Astrophysical Compact Objects""
[arXiv:0804.2140,PRL100(2008)151102]",16,3,158,21.06
31,astrophysics,"The most distant -ray burst yet sighted is the earliest astronomical object
ever observed in cosmic history. This ancient beacon offers a glimpse of the
little-known cosmic dark ages.",29,3,183,48.3
32,astrophysics,"Pioneering works and stimulation by S. Hayakawa for the development of
high-energy astrophysics in Japan.",15,3,105,38.48
33,astrophysics,"This paper explores the application of Probabilistic Neural Network (PNN),
Support Vector Machine (SVM) and Kmeans clustering as tools for automated
classification of massive stellar spectra.",26,2,191,11.25
34,astrophysics,"This paper has been withdrawn by the author because has been send to other
journal.",15,2,83,73.17
35,astrophysics,"I review our current understanding of superluminous supernovae, mysterious
events 100 times brighter than conventional stellar explosions.",17,2,138,3.46
36,astrophysics,"The unique power of AXAF (NASA's Advanced X-ray Astrophysics Facility) - due
for launch in late 1988 - make it both the culmination of 20 years of X-ray
astronomy, and a new starting point for X-ray astrophysics. This short paper
tries to show just how revolutionary AXAF is.",48,3,275,56.59
37,astrophysics,"The effective metric is introduced by means of two examples (non-linear
electromagnetism and hydrodynamics),along with applications in Astrophysics. A
sketch of the generality of the effect is also given.",29,3,204,22.92
38,astrophysics,"The quark matter may have great implications in astrophysical studies, which
could appear in the early Universe, in compact stars, and/or as cosmic rays.
After a general review of astrophysical quark matter, the density-dominated
quark matter is focused.",38,3,254,35.27
39,astrophysics,"We briefly describe different astrophysical applications of a population
synthesis method. In some details we discuss the population synthesis of close
binary systems and of isolated neutron stars.",28,3,197,23.43
40,astrophysics,"We briefly review the high energy astrophysical processes that are related to
the production of high energy $\gamma$-ray and neutrino signals and are likely
to be important for the energy loss of high and ultrahigh energy cosmic rays.
We also give examples for neutrino fluxes generated by different astrophysical
objects and describe the cosmological link provided by cosmogenic neutrinos.",59,3,390,16.15
41,astrophysics,"In this paper I briefly review recent progress in the field of ground-based
gamma ray astrophysics.",16,2,99,72.16
42,astrophysics,"We briefly discuss three aspects related to the origin of ultra-high energy
cosmic rays (UHECRs) namely: 1) particle acceleration in astrophysical sources;
2) transition to an extragalactic origin; 3) spectrum and anisotropies at the
highest energies.",36,2,251,9.56
43,astrophysics,"Likely astrophysical sources of detectable high-energy (>> TeV) neutrinos are
considered. Based on gamma-ray emission properties, the most probable sources
of neutrinos are argued to be GRBs, blazars, microquasars, and supernova
remnants. Diffuse neutrino sources are also briefly considered.",39,4,292,33.2
44,astrophysics,"The different phases of QCD at finite temperature and density lead to
interesting effects in cosmology and astrophysics. In this work I review some
aspects of the cosmological QCD transition and of astrophysics at high baryon
density.",37,3,234,35.78
45,astrophysics,"The current status of optical potentials employed in the prediction of
thermonuclear reaction rates for astrophysics in the Hauser-Feshbach formalism
is discussed. Special emphasis is put on $\alpha$+nucleus potentials. A novel
approach for the prediction of $\alpha$+nucleus potentials is proposed. Further
experimental efforts are motivated.",45,5,343,17.71
46,astrophysics,"A selected overview of stellar effects and reaction mechanisms with relevance
to the prediction of astrophysical reaction rates far off stability is
provided.",23,2,158,14.29
47,astrophysics,"Let's take stock of the situation on one of the most studied astrophysical
phenomena during the latest years: the jets escaping from protostars, stellar
singularities, GRB and active galactic nuclei.",30,2,199,15.65
48,astrophysics,"In these lectures presented at Baikal summer school on physics of elementary
particles and astrophysics 2011, I present a wide view of neutron star
astrophysics with special attention paid to young isolated compact objects and
studies of the properties of neutron star interiors using astronomical methods.",46,2,306,16.33
49,astrophysics,"This is a pedagological review of some astrophysical highlights of the Fermi
Gamma ray Observatory, including theoretical studies related mainly to
extragalactic Fermi science.",24,2,176,-12.11
50,astrophysics,"Several directions of the demand of decay data in nuclear astrophysics are
discussed for radionuclides near the valley of nuclear stability. The current
decay data evaluation results have been presented for a number of radionuclides
of astrophysical interest. An extended list of such nuclides is offered for
their nuclear characteristics to be further evaluated by the Decay Data
Evaluation Project cooperation participants.",62,4,425,16.62
51,astrophysics,"High energy astrophysics is one of the most active branches in contemporary
astrophysics. It studies astrophysical objects that emit X-ray and gamma-ray
photons, such as accreting super-massive and stellar-size black holes, and
various species of neutron stars. With the operations of many space-borne and
ground-based observational facilities, high energy astrophysics has enjoyed a
rapid development in the past decades. It is foreseen that the field will
continue to advance rapidly in the coming decade, with possible ground-breaking
discoveries of astrophysical sources in the high-energy neutrino and
gravitational wave channels. This Special Issue of Frontiers of Physics is
dedicated to a systematic survey of the field of high energy astrophysics as it
stands in 2013.",114,6,777,31.41
52,astrophysics,"Einstein established the theory of general relativity and the corresponding
field equation in 1915 and its vacuum solutions were obtained by Schwarzschild
and Kerr for, respectively, static and rotating black holes, in 1916 and 1963,
respectively. They are, however, still playing an indispensable role, even
after 100 years of their original discovery, to explain high energy
astrophysical phenomena. Application of the solutions of Einstein's equation to
resolve astrophysical phenomena has formed an important branch, namely
relativistic astrophysics. I devote this article to enlightening some of the
current astrophysical problems based on general relativity. However, there seem
to be some issues with regard to explaining certain astrophysical phenomena
based on Einstein's theory alone. I show that Einstein's theory and its
modified form, both are necessary to explain modern astrophysical processes, in
particular, those related to compact objects.",136,7,958,14.59
53,astrophysics,"We summarize the progress in neutrino astrophysics and emphasize open issues
in our understanding of neutrino flavor conversion in media. We discuss solar
neutrinos, core-collapse supernova neutrinos and conclude with ultra-high
energy neutrinos.",33,3,246,12.43
54,astrophysics,"At the Workshop on Astrophysical Opacities, several attendees voiced their
interest in a list of absorption data that are missing from or inadequate in
current models of astrophysical objects. This wish list by modelers is meant as
motivation and inspiration for experimentalists and theoreticians alike.",45,3,304,14.8
55,astrophysics,"The extreme electromagnetic or gravitational fields associated with some
astrophysical objects can give rise to macroscopic effects arising from the
physics of the quantum vacuum. Therefore, these objects are incredible
laboratories for exploring the physics of quantum field theories. In this
dissertation, we explore this idea in three astrophysical scenarios.",50,4,362,20.68
56,astrophysics,"The statistical parameters of five generalizations of the Lindley
distribution, such as the average, variance and moments, are reviewed. A new
double truncated Lindley distribution with three parameters is derived. The new
distributions are applied to model the initial mass function for stars.",43,4,294,31.58
57,astrophysics,"In the era of multi-messenger astronomy, neutrinos are among the most
important astronomical messengers, due to their interaction properties. In
these lessons I briefly review the main issues concerning the theory on
astrophysical neutrinos.",34,3,241,20.38
58,astrophysics,"Works submitted to the 37th International Cosmic Ray Conference.
  Contents:
  Operation, Calibration, and Analysis
  Galactic Gamma-Ray Physics
  Extra Galactic Gamma-Ray Physics
  Cosmic-Ray Physics",23,2,200,9.04
59,astrophysics,"The following annotated bibliography contains a reasonably complete survey of
contemporary work in the philosophy of astrophysics. Spanning approximately
forty years from the early 1980s to the present day, the bibliography should
help researchers entering the field to acquaint themselves with its major
texts, while providing an opportunity for philosophers already working on
astrophysics to expand their knowledge base and engage with unfamiliar
material.",64,3,459,13.62
60,astrophysics,"The spectacular recent development of modern high-energy density laboratory
facilities which concentrate more and more energy in millimetric volumes allows
the astrophysical community to reproduce and to explore, in millimeter-scale
targets and during very short times, astrophysical phenomena where radiation
and matter are strongly coupled. The astrophysical relevance of these
experiments can be checked from the similarity properties and especially
scaling laws establishment, which constitutes the keystone of laboratory
astrophysics. From the radiating optically thin regime to the so-called
optically thick radiative pressure regime, we present in this paper, for the
first time, a complete analysis of the main radiating regimes that we
encountered in laboratory astrophysics with the same formalism based on the
Lie-group theory. The use of the Lie group method appears as systematic which
allows to construct easily and orderly the scaling laws of a given problem.
This powerful tool permits to unify the recent major advances on scaling laws
and to identify new similarity concepts that we discuss in this paper and which
opens important applications for the present and the future laboratory
astrophysics experiments. All these results enable to demonstrate theoretically
that astrophysical phenomena in such radiating regimes can be explored
experimentally thanks to powerful facilities. Consequently the results
presented here are a fundamental tool for the high-energy density laboratory
astrophysics community in order to quantify the astrophysics relevance and
justify laser experiments. Moreover, relying on the Lie-group theory, this
paper constitutes the starting point of any analysis of the self-similar
dynamics of radiating fluids.",250,9,1755,5.87
61,astrophysics,"Several topics are discussed regarding the pseudo-Newtonian models of the
gravitational field around rotating black holes",16,1,121,21.4
62,astrophysics,"In this poster I briefly review several articles on astrophysics of old
isolated neutron stars, which were published in 1994-99 by my co-authors and
myself.",25,2,156,54.56
63,astrophysics,A report on the observational status of VHE astronomy is given.,11,2,63,34.93
64,astrophysics,A short overview on aperture synthesis in space for the non-specialist,11,1,70,60.31
65,astrophysics,"We describe the Planck HFI design and expected performances for measuring CMB
polarisation.",13,2,91,32.9
66,astrophysics,This paper has been withdrawn.,5,2,30,83.32
67,astrophysics,"Transonic accretion flow with self-consistent treatment of random magnetic
field is presented.",12,2,94,17.0
68,astrophysics,"We present recent results of our ongoing multiplicity study of exoplanet host
stars.",13,2,84,41.36
69,astrophysics,"The purpose of the 2010 NASA Laboratory Astrophysics Workshop (LAW) was, as
given in the Charter from NASA, ""to provide a forum within which the scientific
community can review the current state of knowledge in the field of Laboratory
Astrophysics, assess the critical data needs of NASA's current and future Space
Astrophysics missions, and identify the challenges and opportunities facing the
field as we begin a new decade"". LAW 2010 was the fourth in a roughly
quadrennial series of such workshops sponsored by the Astrophysics Division of
the NASA Science Mission Directorate. In this White Paper, we report the
findings of the workshop.",103,4,642,36.66
70,astrophysics,"The Jeans model is shown to be self-consistent, so that the ""Jeans Swindle""
has never taken place.",17,2,98,71.14
71,astrophysics,"The MESSENGER spacecraft conducted its first flyby of Mercury on 14th January
2008, followed by two subsequent encounters on 6th October 2008 and 29th
September 2009, prior to Mercury orbit insertion on 18th March 2011. We have
reviewed MESSENGER flight telemetry and X-ray Spectrometer observations from
the first two encounters, and correlate several prominent features in the data
with the presence of astrophysical X-ray sources in the instrument field of
view. We find that two X-ray peaks attributed in earlier work to the detection
of suprathermal electrons from the Mercury magnetosphere, are likely to contain
a significant number of events that are of astrophysical origin. The
intensities of these two peaks cannot be explained entirely on the basis of
astrophysical sources, and we support the previous suprathermal explanation but
suggest that the electron fluxes derived in those studies be revised to correct
for a significant astrophysical signal.",147,5,963,25.66
72,astrophysics,"Lundmark established observational evidence that the Universe is expanding.
Lema\^itre established theoretical evidence. Hubble established observational
proof.",17,4,160,-18.92
73,astrophysics,"We investigate how a stochastic gravitational wave background, produced from
a discrete set of astrophysical sources, differs from an idealised model
consisting of an isotropic, unpolarised, and Gaussian background. We focus, in
particular, on the different signatures produced from these two cases, as
observed in a cross-correlation search. We show that averaged over many
realisations of an astrophysical background, the cross-correlation measurement
of an astrophysical background is identical to that of an idealised background.
However, any one realisation of an astrophysical background can produce a
different signature. Using a model consisting of an ensemble of binary neutron
star coalescences, we quantify the typical difference between the signal from
individual realisations of the astrophysical background and the idealised case.
For advanced detectors, we find that, using a cross-correlation analysis,
astrophysical backgrounds from many discrete sources are probably
indistinguishable from an idealised background.",141,7,1032,13.78
74,astrophysics,What is a galaxy group?,5,1,23,100.24
75,astrophysics,"This article looks at philosophical aspects and questions that modern
astrophysical research gives rise to. Other than cosmology, astrophysics
particularly deals with understanding phenomena and processes operating at
""intermediate"" cosmic scales, which has rarely aroused philosophical interest
so far. Being confronted with the attribution of antirealism by Ian Hacking
because of its observational nature, astrophysics is equipped with a
characteristic methodology that can cope with the missing possibility of direct
interaction with most objects of research. In its attempt to understand the
causal history of singular phenomena it resembles the historical sciences,
while the search for general causal relations with respect to classes of
processes or objects can rely on the ""cosmic laboratory"": the multitude of
different phenomena and environments, naturally provided by the universe.
Furthermore, the epistemology of astrophysics is strongly based on the use of
models and simulations and a complex treatment of large amounts of data.",149,6,1044,7.39
76,astrophysics,"We present ARC2 (Astrophysically Robust Correction 2), an open-source
Python-based systematics-correction pipeline to correct for the Kepler prime
mission long cadence light curves. The ARC2 pipeline identifies and corrects
any isolated discontinuities in the light curves, then removes trends common to
many light curves. These trends are modelled using the publicly available
co-trending basis vectors, within an (approximate) Bayesian framework with
`shrinkage' priors to minimise the risk of over-fitting and the injection of
any additional noise into the corrected light curves, while keeping any
astrophysical signals intact. We show that the ARC2 pipeline's performance
matches that of the standard Kepler PDC-MAP data products using standard noise
metrics, and demonstrate its ability to preserve astrophysical signals using
injection tests with simulated stellar rotation and planetary transit signals.
Although it is not identical, the ARC2 pipeline can thus be used as an open
source alternative to PDC-MAP, whenever the ability to model the impact of the
systematics removal process on other kinds of signal is important.",164,6,1133,21.26
77,astrophysics,"This article explores the properties (amplitude and shape) of the angular
power spectrum of the anisotropies of the astrophysical gravitational wave
background (AGWB) focusing on the signatures of the astrophysical models
describing sub-galactic physics. It demonstrates that while some parameters
have negligible impact others, and in particular the stellar evolution models,
the metallicity and the merger time delay distribution can result in relative
differences of order 40% in the angular power spectrum of anisotropies in both
the LIGO/Virgo and LISA frequency bands. It is also shown that the monopole and
the anisotropic components of the AGWB are complementary and sensitive to
different astrophysical parameters. It follows that AGWB anisotropies are a new
observable with the potential to provide new astrophysical information that can
not be accessed otherwise.",127,5,874,13.82
78,astrophysics,"Multi-messenger astrophysics will enable the discovery of new astrophysical
neutrino sources and provide information about the mechanisms that drive these
objects. We present a curated online catalog of astrophysical neutrino
candidates. Whenever single high energy neutrino events, that are publicly
available, get published multiple times from various analyses, the catalog
records all these changes and highlights the best information. All studies by
IceCube that produce astrophysical candidates will be included in our catalog.
All information produced by these searches such as time, type, direction,
neutrino energy and signalness will be contained in the catalog. The
multi-messenger astrophysical community will be able to select neutrinos with
certain characteristics, e.g. within a declination range, visualize data for
the selected neutrinos, and finally download data in their preferred form to
conduct further studies.",130,9,932,18.76
79,astrophysics,"We discuss the importance of precise study of muon capture in deuterium for
correct understanding of some fundamental astrophysical processes",20,1,141,17.34
80,astrophysics,"Chapter 13: SOC Systems in Astrophysics --- Content list: 13.1 Theory --
13.1.1 The Sacle-Free Probability Theorem - 13.1.2 The Fractal-Diffusive
Spatio-Temporal Relationship - 13.1.3 Size Distributions of Astrophysical
Observables - 13.1.4 Scaling Laws for Thermal Emission of Astrophysical Plasmas
- 13.1.5 Scaling Laws for Astrophysical Acceleration Mechanisms - 13.2
Observations -- 13.2.1 Lunar Craters - 13.2.2 Asteroid Belt - 13.2.3 Saturn
Ring - 13.2.4 Magnetospheric Substorms and Auroras - 13.2.5 Solar Flares -
13.2.6 Stellar Flares - 13.2.7 Pulsars - 13.2.8 Soft Gamma-Ray Repeaters -
13.2.9 Black-Hole Objects - 13.2.10 Blazars - 13.2.11 Cosmic Rays - 13.3
Conclusions",99,36,681,33.37
81,astrophysics,"We present the first predictions for the angular power spectrum of the
astrophysical gravitational wave background constituted of the radiation
emitted by all resolved and unresolved astrophysical sources. Its shape and
amplitude depend on both the astrophysical properties on galactic scales and on
cosmological properties. We show that the angular power spectrum behaves as
$C_{\ell}\propto 1/{\ell}$ on large scales and that relative fluctuations of
the signal are of order 30% at 100 Hz. We also present the correlations of the
astrophysical gravitational wave background with weak-lensing and galaxy
distribution. These numerical results pave the way to the study of a new
observable at the crossroad between general relativity, astrophysics and
cosmology.",111,6,761,23.56
82,astrophysics,"Neutrino-driven ejecta in core collapse supernovae (CCSNe) offer an
interesting astrophysical scenario where lighter heavy elements between Sr and
Ag can be synthesized. Previous studies emphasized the important role that
($\alpha,n$) reactions play in the production of these elements, particularly
in neutron-rich and alpha-rich environments. In this paper, we have
investigated the sensitivity of elemental abundances to specific ($\alpha,n$)
reaction-rate uncertainties under different astrophysical conditions. Following
a Monte Carlo nucleosynthesis study with over 36 representative astrophysical
wind conditions, we have identified the most important reactions based on their
impact on the final elemental abundances. Experimental studies of these
reactions will reduce the nucleosynthesis uncertainties and make it possible to
use observations to understand the origin of lighter heavy elements and the
astrophysical conditions where they are formed.",127,6,959,3.39
83,astrophysics,"The origin of the bulk of the astrophysical neutrinos detected by the IceCube
Observatory remains a mystery. Previous source-finding analyses compare the
directions of IceCube events and individual sources in astrophysical catalogs.
The source association method is technically challenging when the number of
source candidates is much larger than the number of the observed astrophysical
neutrinos. We show that in this large source number regime, a cross-correlation
analysis of neutrino data and source catalog can instead be used to constrain
potential source populations for the high-energy astrophysical neutrinos, and
provide spatial evidence for the existence of astrophysical neutrinos. We
present an analysis of the cross-correlation of the IceCube 2010-2012
point-source data and a WISE-2MASS galaxy sample. While we find no significant
detection of cross-correlation with the publicly available neutrino dataset, we
show that, when applied to the full IceCube data, which has a longer
observation time and higher astrophysical neutrino purity, our method has
sufficient statistical power to detect a cross-correlation signal if the
neutrino sources trace the Large Scale Structure of the Universe.",174,7,1208,16.66
84,astrophysics,"We review observational, experimental and theoretical results related to Dark
Matter.",11,2,85,-15.84
85,astrophysics,"It has become clear that early career astrophysics researchers (doctoral
researchers, post-docs, etc) have a very diverse appreciation of their career,
with some declaring it the best job that you can have and others suffering from
overwork, harrassment and stress from the precarity of their job, and
associated difficulties. In order to establish how astrophysics researchers,
primarily in France, experience their career, we sent out a survey to
understand the impact that their job has on their well-being. 276 people
responded to the survey. Whilst around half of the respondents expressed
pleasure derived from their career, it is clear that many (early career)
researchers are suffering due to overwork, with more than a quarter saying that
they work in excess of 50 hours per week and 2\% in excess of 90 h per week.
Almost 30\% professed to having suffered harrassment or discrimination in the
course of their work. Further, whilst only 20\% had suffered mental health
issues before starting their career in astrophysics, $\sim$45\% said that they
suffered with mental health problems since starting in astrophysics. Here we
provide results from the survey as well as possible avenues to explore and a
list of recommendations to improve (early) careers in astrophysics.",202,8,1278,42.14
86,astrophysics,"Patterns in the scientific developments of Relativistic Astrophysics are
analyzed with special attention to the physics and astrophysics of Black Holes
and Gamma Ray Bursts.",25,2,173,29.18
87,astrophysics,"The advantages of high-order finite difference scheme for astrophysical MHD
and turbulence simulations are highlighted. A number of one-dimensional test
cases are presented ranging from various shock tests to Parker-type wind
solutions. Applications to magnetized accretion discs and their associated
outflows are discussed. Particular emphasis is placed on the possibility of
dynamo action in three-dimensional turbulent convection and shear flows, which
is relevant to stars and astrophysical discs. The generation of large scale
fields is discussed in terms of an inverse magnetic cascade and the
consequences imposed by magnetic helicity conservation are reviewed with
particular emphasis on the issue of alpha-quenching.",101,6,725,17.13
88,astrophysics,"The generation and evolution of astrophysical magnetic fields occurs largely
through the action of turbulence. In many situations, the magnetic field is
strong enough to influence many important properties of turbulence itself.
Numerical simulation of magnetized turbulence is especially challenging in the
astrophysical regime because of the high magnetic Reynolds numbers involved,
but some aspects of this difficulty can be avoided in weakly ionized systems.",65,4,461,15.61
89,astrophysics,"The Galactic center provides a unique astrophysical laboratory for us to
study various astrophysical processes. In this paper, we review and outline the
latest results from observations of Sgr~A$^*$ in terms of source structure and
variations in flux density. Sgr~A$^*$ phenomenon represents a typical case of
low radiative efficiency accretion flow surrounding a supermassive black hole
in low luminosity AGNs. Many pending astrophysical problems found from
observations of Sgr A$^*$ have challenged the existing astrophysical theories.
Current theoretical models of Sgr A$^*$ are also reviewed.",85,6,596,20.38
90,astrophysics,"I discuss recent advances being made in the physics and astrophysics of
cosmic rays and cosmic gamma-rays at the highest observed energies as well as
the related physics and astrophysics of very high energy cosmic neutrinos. I
also discuss the connections between these topics.",44,3,277,49.15
91,astrophysics,"Many recent discoveries in astrophysics involve phenomena that are highly
complex. Carefully designed experiments, together with sophisticated computer
simulations, are required to gain insights into the underlying physics. We show
that particle accelerators are unique tools in this area of research, by
providing precision calibration data and by creating extreme experimental
conditions relevant for astrophysics. In this paper we discuss laboratory
experiments that can be carried out at the Stanford Linear Accelerator Center
and implications for astrophysics.",77,5,565,9.59
92,astrophysics,"Albert Einstein postulated the equivalence of energy and mass, developed the
theory of special relativity, explained the photoelectric effect, and described
Brownian motion in five papers, all published in 1905, 100 years ago. With
these papers, Einstein provided the framework for understanding modern
astrophysical phenomena. Conversely, astrophysical observations provide one of
the most effective means for testing Einstein's theories. Here, I review
astrophysical advances precipitated by Einstein's insights, including
gravitational redshifts, gravitational lensing, gravitational waves, the
Lense-Thirring effect, and modern cosmology. A complete understanding of
cosmology, from the earliest moments to the ultimate fate of the universe, will
require developments in physics beyond Einstein, to a unified theory of gravity
and quantum physics.",113,6,851,14.7
93,astrophysics,"Binary systems have long been recognized as the source of powerful
astrophysical diagnostics. Among the many applications of binary stars, they
have been used as probes of stellar structure and evolution (both of single and
binary stars) in a broad range of masses, evolutionary stages, and chemical
compositions, and as indicators of distance and time. With the numerous ongoing
photometric surveys and upcoming space astrometry and photometry missions, the
future of binaries looks bright. The various aspects of binaries as
astrophysically useful laboratories are reviewed here, with emphasis on the
currently open problems and research opportunities.",96,5,654,21.74
94,astrophysics,"The Square Kilometer Array will be operating at the same time with several
new large optical, X-ray and Gamma-ray facilities currently under construction
or planned. Fostering synergies in astrophysical research made across different
spectral bands presents a compelling argument for designing the SKA such that
it would offer imaging capabilities similar to those of other future
telescopes. Imaging capabilities of the SKA are compared here with those of the
major future astrophysical facilities.",73,4,499,29.89
95,astrophysics,"We consider the hypothesis that some active galactic nuclei and other compact
astrophysical objects may be current or former entrances to wormholes. A broad
mass spectrum for astrophysical wormholes is possible. We consider various new
models of the static wormholes including wormholes maintained mainly by an
electromagnetic field. We also discuss observational effects of a single
entrance to wormhole and a model for a binary astrophysical system formed by
the entrances of wormholes with magnetic fields and consider its possible
manifestation.",81,5,549,25.49
96,astrophysics,"This working group focused mainly on the complementarity among particle
physics and astrophysics. The analysis of data from both fields will better
constrain theoretical models. Much of the discussion focused on detecting dark
matter and susy particles, and on the potential of neutrino and gamma-ray
astrophysics for seeking or constraining new physics.",52,4,354,37.0
97,astrophysics,"A unifying theme of this conference was the use of different approaches to
understand astrophysical sources of energetic particles in the TeV range and
above. In this summary I review how gamma-ray astronomy, neutrino astronomy and
(to some extent) gravitational wave astronomy provide complementary avenues to
understanding the origin and role of high-energy particles in energetic
astrophysical sources.",58,3,405,8.2
98,astrophysics,"The importance of a teaching a clear definition of the ``observer'' in
special relativity is highlighted using a simple astrophysical example from the
exciting current research area of ``Gamma-Ray Burst'' astrophysics. The example
shows that a source moving relativistically toward a single observer at rest
exhibits a time ``contraction'' rather than a ``dilation'' because the light
travel time between the source and observer decreases with time. Astrophysical
applications of special relativity complement idealized examples with real
applications and very effectively exemplify the role of a finite light travel
time.",89,4,622,15.95
99,astrophysics,"Quark matter both in terrestrial experiment and in astrophysics is briefly
reviewed. Astrophysical quark matter could appear in the early Universe, in
compact stars, and as cosmic rays. Emphasis is put on quark star as the nature
of pulsars. Possible astrophysical implications of experiment-discovered sQGP
are also concisely discussed.",49,5,337,33.61
100,astrophysics,"The origin of magnetic fields in astrophysical objects is a challenging
problem in astrophysics. Throughout the years, many scientists have suggested
that non-minimal gravitational-electromagnetic coupling (NMGEC) could be the
origin of the ubiquitous astrophysical magnetic fields. We investigate the
possible origin of intense magnetic fields $\sim 10^{15}-10^{16}$ by NMGEC near
rotating neutron stars and black holes, connected with magnetars, quasars, and
gamma-ray bursts. Whereas these intense magnetic fields are difficult to
explain astrophysically, we find that they are easily explained by NMGEC.",82,5,607,25.29
101,astrophysics,"We propose a new method to search for light (pseudo-)scalar particles in the
spectra of compact astrophysical objects such as magnetars, pulsars, and
quasars. On accounts of compact astrophysical objects having intense magnetic
fields extending over large volumes, they provide good conditions for efficient
photon-particle oscillations via the Primakoff process. In particular, we show
that if the coupling constant for light (<1e-2 eV) axions, g>1e-13 [1/GeV] then
it is likely that absorption-like features would be detectable in the spectrum
of compact astrophysical sources.",83,4,579,34.9
102,astrophysics,"This is a white paper submitted to the Stars and Stellar Evolution (SSE)
Science Frontier Panel (SFP) of the NRC's Astronomy and Astrophysics 2010
Decadal Survey. The white paper is endorsed by the American Physical Society's
(APS) Topical Group on Plasma Astrophysics (GPAP).",43,3,276,41.19
103,astrophysics,"This is a white paper submitted to the Stars and Stellar Evolution (SSE)
Science Frontier Panel (SFP) of the NRC's 2010 Astronomy and Astrophysics
Decadal Survey. The white paper is endorsed by the NSF Physics Frontier Center
for Magnetic Self-Organization in Laboratory and Astrophysical Plasmas (CMSO).",46,3,304,31.21
104,astrophysics,"Gravitational wave detectors are already operating at interesting sensitivity
levels, and they have an upgrade path that should result in secure detections
by 2014. We review the physics of gravitational waves, how they interact with
detectors (bars and interferometers), and how these detectors operate. We study
the most likely sources of gravitational waves and review the data analysis
methods that are used to extract their signals from detector noise. Then we
consider the consequences of gravitational wave detections and observations for
physics, astrophysics, and cosmology.",85,5,583,24.48
105,astrophysics,"In the first lecture of this volume, we will present the basic fundamental
ideas regarding nuclear processes occurring in stars. We start from stellar
observations, will then elaborate on some important quantum-mechanical
phenomena governing nuclear reactions, continue with how nuclear reactions
proceed in a hot stellar plasma and, finally, we will provide an overview of
stellar burning stages. At the end, the current knowledge regarding the origin
of the elements is briefly summarized. This lecture is directed towards the
student of nuclear astrophysics. Our intention is to present seemingly
unrelated phenomena of nuclear physics and astrophysics in a coherent
framework.",100,6,680,25.8
106,astrophysics,"Ground-based gamma-ray astronomy, which provides access to the TeV energy
range, is a young and rapidly developing discipline. Recent discoveries in this
waveband have important consequences for a wide range of topics in astrophysics
and astroparticle physics. This article is an attempt to review the
experimental status of this field and to provide the basic formulae and
concepts required to begin the interpretation of TeV observations.",66,4,440,32.22
107,astrophysics,"The Decadal Survey of Astronomy and Astrophysics created five panels to
identify the science themes that would define the field's research frontiers in
the coming decade. I will describe the conclusions of one of these, the Panel
on Cosmology and Fundamental Physics, and comment on their relevance to the
discussions at this meeting of the NASA Laboratory Astrophysics community.",59,3,380,33.07
108,astrophysics,"We argue that an effective flavor discrimination in neutrino telescopes is
the key to probe the flavor ratios of astrophysical neutrinos at the source and
flavor transition mechanisms of these neutrinos during their propagations from
the source to the Earth. We first discuss how well one can reconstruct the
flavor ratios of astrophysical neutrinos at the source. We then discuss how to
probe flavor transition mechanisms of propagating astrophysical neutrinos. In
this regard, we propose a model independent parametrization for neutrino flavor
transitions, with the neutrino oscillation as a special case.",91,5,607,31.41
109,astrophysics,"I outline methods for calculating the solution of Monte Carlo Radiative
Transfer (MCRT) in scattering, absorption and emission processes of dust and
gas, including polarization. I provide a bibliography of relevant papers on
methods with astrophysical applications.",37,3,265,10.4
110,astrophysics,"The astrophysical site or sites responsible for the r-process of
nucleosynthesis still remains an enigma. Since the rare earth region is formed
in the latter stages of the r-process it provides a unique probe of the
astrophysical conditions during which the r-process takes place. We use
features of a successful rare earth region in the context of a high entropy
r-process (S>100k_B) and discuss the types of astrophysical conditions that
produce abundance patterns that best match meteoritic and observational data.
Despite uncertainties in nuclear physics input, this method effectively
constrains astrophysical conditions.",92,5,626,39.67
111,astrophysics,"The prospects of using extreme relativistic laser-matter interactions for
laboratory astrophysics are discussed. Laser-driven process simulation of
matter dynamics at ultra-high energy density is proposed for the studies of
astrophysical compact objects and the early universe.",36,3,277,10.91
112,astrophysics,"We review the use of Bayesian Model Averaging in astrophysics. We first
introduce the statistical basis of Bayesian Model Selection and Model
Averaging. We discuss methods to calculate the model-averaged posteriors,
including Markov Chain Monte Carlo (MCMC), nested sampling, Population Monte
Carlo, and Reversible Jump MCMC. We then review some applications of Bayesian
Model Averaging in astrophysics, including measurements of the dark energy and
primordial power spectrum parameters in cosmology, cluster weak lensing and
Sunyaev-Zel'dovich effect data, estimating distances to Cepheids, and
classifying variable stars.",85,5,623,16.02
113,astrophysics,"We briefly review the recent developments in neutrino physics and
astrophysics which have import for frontline research in nuclear physics. These
developments, we argue, tie nuclear physics to exciting developments in
observational cosmology and astrophysics in new ways. Moreover, the behavior of
neutrinos in dense matter is itself a fundamental problem in many-body quantum
mechanics, in some ways akin to well-known issues in nuclear matter and nuclei,
and in some ways radically different, especially because of nonlinearity and
quantum de-coherence. The self-interacting neutrino gas is the only many body
system driven by the weak interactions.",95,5,651,21.94
114,astrophysics,"I discuss some of the most outstanding challenges in relativistic
astrophysics in the subjects of: compact objects (Black Holes and Neutron
Stars); dark sector (Dark Matter and Dark Energy); plasma astrophysics (Origin
of Jets, Cosmic Rays and Magnetic Fields) and the primordial universe (Physics
at the beginning of the Universe). In these four subjects, I discuss twelve of
the most important challenges. These challenges give us insight into new
physics that can only be studied in the large scale Universe. The near future
possibilities, in observations and theory, for addressing these challenges, are
also discussed.",95,5,623,47.32
115,astrophysics,"This paper provides an introduction to a number of astrophysics problems
related to strong magnetic fields. The first part deals with issues related to
atoms, condensed matter and high-energy processes in very strong magnetic
fields, and how these issues influence various aspects of neutron star
astrophysics. The second part deals with classical astrophysical effects of
magnetic fields: Even relatively ""weak"" fields can play a strong role in
various astrophysical problems, ranging from stars, accretion disks and
outflows, to the formation and merger of compact objects.",85,4,575,34.29
116,astrophysics,"A review of the Annual Review of Astronomy and Astrophysics Volume 52, 2014
(Ed. S.M. Faber, Ewine van Dishoeck, and John Kormendy) is given, with a
perspective of understanding the current trends in Astronomy and Astrophysics.
The impact of high volume data, high connectivity, and fast computations is
clearly seen in the various research areas discussed in this volume. This has
provided unprecedented development in the understanding of various
astrophysical phenomena. At the same time, some negative trends like
commodification of science, ignoring dissenting views are also evident.",88,8,589,28.23
117,astrophysics,"Astrophysical discs are often warped, that is, their orbital planes change
with radius. This occurs whenever there is a non-axisymmetric force acting on
the disc, for example the Lense-Thirring precession induced by a misaligned
spinning black hole, or the gravitational pull of a misaligned companion. Such
misalignments appear to be generic in astrophysics. The wide range of systems
that can harbour warped discs - protostars, X-ray binaries, tidal disruption
events, quasars and others - allows for a rich variety in the disc's response.
Here we review the basic physics of warped discs and its implications.",95,6,612,52.6
118,astrophysics,"Hereafter we describe the activities of the $Grand \, Sud-Ouest$ Data Centre
operated for INSU/CNRS by the OMP-IRAP and the Universit\'e Paul Sabatier
(Toulouse), in a collaboration with the OASU-LAB (Bordeaux) and OREME-LUPM
(Montpellier).",34,2,240,21.06
119,astrophysics,"Data immersion has advantages in astrophysical visualization. Complex
multi-dimensional data and phase spaces can be explored in a seamless and
interactive viewing environment. Putting the user in the data is a first step
toward immersive data analysis. We present a technique for creating 360 degree
spherical panoramas with astrophysical data. The three-dimensional software
package Blender and the Google Spatial Media module are used together to
immerse users in data exploration. Several examples employing these methods
exhibit how the technique works using different types of astronomical data.",86,7,601,23.12
120,astrophysics,"This editorial from the PASP Special Focus Issue ""Techniques and Methods for
Astrophysical Data Visualization"" summarizes contributions from authors, their
software and tutorials, video abstracts, and 3D content. PASP and IOP have made
this Focus Issue an ongoing project and will continue accepting submissions
throughout 2017. For more information and to view the video abstract visit:
http://iopscience.iop.org/journal/1538-3873/page/Techniques-and-Methods-for-Astrophysical-Data-Visualization",57,5,496,1.43
121,astrophysics,"Scientific discovery is mediated by ideas that, after being formulated in
hypotheses, can be tested, validated, and quantified before they eventually
lead to accepted concepts. Computer-mediated discovery in astrophysics is no
exception, but antiquated code that is only intelligible to scientists who were
involved in writing it is holding up scientific discovery in the field. A bold
initiative is needed to modernize astrophysics code and make it transparent and
useful beyond a small group of scientists. (abridged)",77,4,519,20.01
122,astrophysics,"A review of neutrino astrophysics is presented, including solar and
atmospheric neutrinos; neutrino mass and oscillations; the supernova mechanism,
supernova neutrino production, and associated nucleosynthesis; cosmological
neutrinos and Big Bang nucleosynthesis; neutrino cooling and associated limits
on neutrino properties; and high-energy astrophysical neutrinos.",43,2,367,-65.24
123,astrophysics,"The IRON Project, initiated in 1991, aims at two main objectives, i) study
the characteristics of and calculate large-scale high accuracy data for atomic
radiative and collisional processes, and ii) application in solving
astrophysical problems. It focuses on the complex iron and iron-peak elements
commonly observed in the spectra of astrophysical plasmas. The present report
will illustrate the characteristics of the dominant atomic process of
photoionization that have been established under the project and the preceding
the Opacity Project and their importance in applications.",84,4,584,17.68
124,astrophysics,"In this chapter, we introduce the concept of a black hole (BH) and recount
the initial theoretical predictions. We then review the possible types of BHs
in nature, from primordial, to stellar-mass, to supermassive BHs. Finally, we
focus on the latter category and on their intricate relation with their host
galaxies.",51,4,317,45.76
125,astrophysics,"In experimental nuclear astrophysics it is common knowledge that reaction
cross sections must be measured in the astrophysically relevant, low energy
ranges or at least as close to them as possible. In most of the cases, however,
it is impossible to reach such low energies. The reactions must therefore be
studied at higher energies and the cross sections must be extrapolated to lower
ones. In this paper the importance of cross section measurements in wide energy
ranges are emphasized and a few examples are shown from the areas of hydrogen
burning processes and heavy element nucleosynthesis.",96,5,597,38.66
126,astrophysics,"The impact of autonomous systems on astrophysics can be just as revolutionary
as in our daily lives. This paper includes the following so that the
astrophysics community can realize the benefits of autonomous systems:
description of autonomous systems with examples; enabled and enhanced
observations; Adoption gaps; suggested recommendations.",48,3,343,13.28
127,astrophysics,"A new equivalence relation, named relation of 'similarity' is defined and
applied in the restricted three-body problem. Using this relation, a new class
of trajectories (named 'similar' trajectories) are obtained; they have the
theoretical role to give us new details in the restricted three-body problem.
The 'similar' coordinate systems allow us in addition to obtain a unitary and
an elegant demonstration of some analytical relations in the Roche geometry. As
an example, some analytical relations published in Astrophysical Journal by
Seidov in 2004 are demonstrated.",85,5,572,24.48
128,astrophysics,"In this conference proceeding, we review important theoretical developments
related to the production of strangeness in astrophysics. This includes its
effects in supernova explosions, neutron stars, and compact-star mergers. We
also discuss in detail how the presence of net strangeness affects the
deconfinement to quark matter, expected to take place at large densities and/or
temperatures. We conclude that a complete description of dense matter
containing hyperons and strange quarks is fundamental for the understanding of
modern high-energy astrophysics.",78,5,561,26.3
129,astrophysics,"Small grains play an essential role in astrophysical processes such as
chemistry, radiative transfer, gas/dust dynamics. The population of small
grains is mainly maintained by the fragmentation process due to colliding
grains. An accurate treatment of dust fragmentation is required in numerical
modelling. However, current algorithms for solving fragmentation equation
suffer from an over-diffusion in the conditions of 3D simulations. To tackle
this challenge, we developed a Discontinuous Galerkin scheme to solve
efficiently the non-linear fragmentation equation with a limited number of dust
bins.",84,6,602,29.04
130,astrophysics,"Transfer reactions are an important tool in nuclear astrophysics. These
reactions allow us to identify states in nuclei and to find the corresponding
energies, to determine if these states can contribute to astrophysical nuclear
reactions and ultimately to determine the strength of that contribution. In
this paper, the basic details of how transfer reactions may be used in nuclear
astrophysics are set out along with some common pitfalls to avoid.",70,4,450,39.37
131,astrophysics,"This book chapter presents an overview of the historical experimental and
theoretical developments in neutrino physics and astrophysics and also the
physical properties of neutrinos, as well as the physical processes involving
neutrinos. It also discusses the role of neutrinos in astrophysics and
cosmology. Correction to tex file made.",49,4,337,21.09
132,astrophysics,"Magnetism is a ubiquitous property of astrophysical plasmas, yet stellar
magnetism still remains far from being completely understood. In this review,
we describe recent observational and modelling efforts and progress to expand
our knowledge of the magnetic properties of high-mass stars. Several mechanisms
(magneto-convection, mass-loss quenching, internal angular momentum transport,
and magnetic braking) have significant implications for stellar evolution,
populations, and end-products. Consequently, it remains an urgent issue to
address and resolve open questions related to magnetism in high-mass stars.",80,5,613,17.34
133,astrophysics,"We aim at facilitating the visualization of astrophysical data for several
tasks, such as uncovering patterns, presenting results to the community, and
facilitating the understanding of complex physical relationships to the public.
We present pastamarkers, a customized Python package fully compatible with
matplotlib, that contains unique pasta-shaped markers meant to enhance the
visualization of astrophysical data. We prove that using different pasta types
as markers can improve the clarity of astrophysical plots by reproducing some
of the most famous plots in the literature.",83,4,582,9.52
134,astrophysics,"The physics of astrophysical jets can be divided into three regimes: (i)
engine and launch (ii) propagation and collimation, (iii) dissipation and
particle acceleration. Since astrophysical jets comprise a huge range of scales
and phenomena, practicality dictates that most studies of jets intentionally or
inadvertently focus on one of these regimes, and even therein, one body of work
may be simply boundary condition for another. We first discuss long standing
persistent mysteries that pertain the physics of each of these regimes,
independent of the method used to study them. This discussion makes contact
with frontiers of plasma astrophysics more generally. While observations
theory, and simulations, and have long been the main tools of the trade, what
about laboratory experiments? Jet related experiments have offered controlled
studies of specific principles, physical processes, and benchmarks for
numerical and theoretical calculations. We discuss what has been done to date
on these fronts. Although experiments have indeed helped us to understand
certain processes, proof of principle concepts, and benchmarked codes, they
have yet to solved an astrophysical jet mystery on their own. A challenge is
that experimental tools used for jet-related experiments so far, are typically
not machines originally designed for that purpose, or designed with specific
astrophysical mysteries in mind. This presents an opportunity for a different
way of thinking about the development of future platforms: start with the
astrophysical mystery and build an experiment to address it.",235,10,1585,30.7
135,astrophysics,"In this chapter I focus on asking and answering the following questions: (1)
What is a black hole? Answer: There are three types of black holes, namely
mathematical black holes, physical black holes and astrophysical black holes.
An astrophysical black hole, with mass distributed within its event horizon but
not concentrated at the singularity point, is not a mathematical black hole.
(2) Can astrophysical black holes be formed in the physical universe? Answer:
Yes, at least this can be done with gravitational collapse. (3) How can we
prove that what we call astrophysical black holes are really black holes?
Answer: Finding direct evidence of event horizon is not the way to go. Instead
I propose five criteria which meet the highest standard for recognizing new
discoveries in experimental physics and observational astronomy. (4) Do we have
sufficient evidence to claim the existence of astrophysical black holes in the
physical universe? Answer: Yes, astrophysical black holes have been found at
least in some galactic binary systems, at the center of almost every galaxy,
and as the central engines of at least some long gamma-ray bursts. (5) Will all
matter in the universe eventually fall into black holes? Answer: Probably ""no"",
because ""naked"" compact objects, if they do exist with radii smaller than the
radii of event horizons for their masses but are not enclosed by event
horizons, can rescue the universe from an eternal death by re-cycling out the
matter previously accreted into astrophysical black holes. Finally I also
discuss briefly if we need a quantum theory of gravity in order to further
understand astrophysical black holes, and what further astronomical
observations and telescopes are needed to make further progress on our
understanding of astrophysical black holes.",286,9,1800,40.69
136,astrophysics,"The absence of other viable momentum sources for collimated flows leads to
the likelihood that magnetic fields play a fundamental role in jet launch
and/or collimation in astrophysical jets. To best understand the physics of
jets, it is useful to distinguish between the launch region where the jet is
accelerated and the larger scales where the jet propagates as a collimated
structure. Observations presently resolve jet propagation, but not the launch
region. Simulations typically probe the launch and propagation regions
separately, but not both together. Here, I identify some of the physics of jet
launch vs. propagation and what laboratory jet experiments to date have probed.
Reproducing an astrophysical jet in the lab is unrealistic, so maximizing the
benefit of the experiments requires clarifying the astrophysical connection.",127,8,839,36.18
137,astrophysics,"The quality of astronomical spectra is now so high that the accuracy of the
laboratory data is getting more and more important for the analysis and
interpretation. Both in astrophysics and cosmology the needs for accurate
laboratory wavelengths have increased with the development of new ground-based
and air-borne telescopes and spectrographs. The high resolution UV Fourier
Transform spectrometer at Lund Observatory is being used for studying
laboratory spectra of astrophysically important elements. Measurements of
accurate laboratory UV and IR wavelengths have been made for cosmological and
astrophysical applications.",88,5,625,6.84
138,astrophysics,"Beginning in autumn 2008 the first generation of astronomy master students
will start a 2 year course in Astrophysics offered by the Physics department of
the University of Split, Croatia
(http://fizika.pmfst.hr/astro/english/index.html). This unique master course in
South-Eastern Europe, following the Bologna convention and given by astronomers
from international institutions, offers a series of comprehensive lectures
designed to greatly enhance students' knowledge and skills in astrophysics, and
prepare them for a scientific career. An equally important aim of the course is
to recognise the areas in which astronomy and astrophysics can serve as a
national asset and to use them to prepare young people for real life
challenges, enabling graduates to enter the modern society as a skilled and
attractive work-force. In this contribution, I present an example of a
successful organisation of international astrophysics studies in a developing
country, which aims to become a leading graduate program in astrophysics in the
broader region. I will focus on the benefits of the project showing why and in
what way astronomy can be interesting for third world countries, what are the
benefits for the individual students, nation and region, but also research,
science and the astronomical community in general.",197,9,1314,14.56
139,astrophysics,"Applying photometric catalogs to the study of the population of the Galaxy is
obscured by the impossibility to map directly photometric colors into
astrophysical parameters. Most of all-sky catalogs like ASCC or 2MASS are based
upon broad-band photometric systems, and the use of broad photometric bands
complicates the determination of the astrophysical parameters for individual
stars. This paper presents an algorithm for determining stellar astrophysical
parameters (effective temperature, gravity and metallicity) from broad-band
photometry even in the presence of interstellar reddening. This method suits
the combination of narrow bands as well. We applied the method of
interval-cluster analysis to finding stellar astrophysical parameters based on
the newest Kurucz models calibrated with the use of a compiled catalog of
stellar parameters. Our new method of determining astrophysical parameters
allows all possible solutions to be located in the effective
temperature-gravity-metallicity space for the star and selection of the most
probable solution.",149,7,1062,4.0
140,astrophysics,"We present a flexible interactive 3D morpho-kinematical modeling application
for astrophysics. Compared to other systems, our application reduces the
restrictions on the physical assumptions, data type and amount that is required
for a reconstruction of an object's morphology. It is one of the first publicly
available tools to apply interactive graphics to astrophysical modeling. The
tool allows astrophysicists to provide a-priori knowledge about the object by
interactively defining 3D structural elements. By direct comparison of model
prediction with observational data, model parameters can then be automatically
optimized to fit the observation. The tool has already been successfully used
in a number of astrophysical research projects.",105,7,746,19.87
141,astrophysics,"In this paper we introduce the concept of Direct Statistical Simulation (DSS)
for astrophysical flows. This technique may be appropriate for problems in
astrophysical fluids where the instantaneous dynamics of the flows are of
secondary importance to their statistical properties. We give examples of such
problems including mixing and transport in planets, stars and disks. The method
is described for a general set of evolution equations, before we consider the
specific case of a spectral method optimised for problems on a spherical
surface. The method is illustrated for the simplest non-trivial example of
hydrodynamics and MHD on a rotating spherical surface. We then discuss possible
extensions of the method both in terms of computational methods and the range
of astrophysical problems that are of interest.",125,7,817,33.44
142,astrophysics,"Nuclear astrophysics strives for a comprehensive picture of the nuclear
reactions responsible for synthesizing the chemical elements and for powering
the stellar evolution engine. Deep underground in the Gran Sasso laboratory the
cross sections of the key reactions of the proton-proton chain and of the
Carbon-Nitrogen-Oxygen (CNO) cycle have been measured right down to the
energies of astrophysical interest. The salient features of underground nuclear
astrophysics are summarized here. The main results obtained by LUNA in the last
twenty years are reviewed, and their influence on the comprehension of the
properties of the neutrino, of the Sun and of the Universe itself are
discussed. Future directions of underground nuclear astrophysics towards the
study of helium and carbon burning and of stellar neutron sources in stars are
pointed out.",128,6,849,28.57
143,astrophysics,"This review focuses on nuclear reactions in astrophysics and, more
specifically, on reactions with light ions (nucleons and alpha particles)
proceeding via the strong interaction. It is intended to present the basic
definitions essential for studies in nuclear astrophysics, to point out the
differences between nuclear reactions taking place in stars and in a
terrestrial laboratory, and to illustrate some of the challenges to be faced in
theoretical and experimental studies of those reactions. The discussion
revolves around the relevant quantities for astrophysics, which are the
astrophysical reaction rates. The sensitivity of the reaction rates to the
uncertainties in the prediction of various nuclear properties is explored and
some guidelines for experimentalists are also provided.",115,5,793,16.86
144,astrophysics,"The usage of the high-level scripting language Python has enabled new
mechanisms for data interrogation, discovery and visualization of scientific
data. We present yt, an open source, community-developed astrophysical analysis
and visualization toolkit for data generated by high-performance computing
(HPC) simulations of astrophysical phenomena. Through a separation of
responsibilities in the underlying Python code, yt allows data generated by
incompatible, and sometimes even directly competing, astrophysical simulation
platforms to be analyzed in a consistent manner, focusing on physically
relevant quantities rather than quantities native to astrophysical simulation
codes. We present on its mechanisms for data access, capabilities for
MPI-parallel analysis, and its implementation as an in situ analysis and
visualization tool.",111,5,838,-15.97
145,astrophysics,"Turbulence is a ubiquitous phenomenon in space and astrophysical plasmas,
driving a cascade of energy from large to small scales and strongly influencing
the plasma heating resulting from the dissipation of the turbulence. Modern
theories of plasma turbulence are based on the fundamental concept that the
turbulent cascade of energy is caused by the nonlinear interaction between
counterpropagating Alfven waves, yet this interaction has never been
observationally or experimentally verified. We present here the first
experimental measurement in a laboratory plasma of the nonlinear interaction
between counterpropagating Alfven waves, the fundamental building block of
astrophysical plasma turbulence. This measurement establishes a firm basis for
the application of theoretical ideas developed in idealized models to
turbulence in realistic space and astrophysical plasma systems.",122,5,884,-1.79
146,astrophysics,"The aberrated radiation pressure at the inner edge of the accretion disk
around an astrophysical black hole imparts a relative azimuthal velocity on the
electrons with respect to the ions which gives rise to a ring electric current
that generates large scale poloidal magnetic field loops. This is the Cosmic
Battery established by Contopoulos and Kazanas in 1998. In the present work we
perform realistic numerical simulations of this important astrophysical
mechanism in advection-dominated accretion flows-ADAF. We confirm the original
prediction that the inner parts of the loops are continuously advected toward
the central black hole and contribute to the growth of the large scale magnetic
field, whereas the outer parts of the loops are continuously diffusing outward
through the turbulent accretion flow. This process of inward advection of the
axial field and outward diffusion of the return field proceeds all the way to
equipartition, thus generating astrophysically significant magnetic fields on
astrophysically relevant timescales. We confirm that there exists a critical
value of the magnetic Prandtl number between unity and 10 in the outer disk
above which the Cosmic Battery mechanism is suppressed.",184,7,1218,23.39
147,astrophysics,"In this article we review the astrophysical application of gravitational
microlensing. After introducing the history of gravitational lensing, we
present the key equations and concept of microlensing. The most frequent
microlensing events are single-lens events and historically it has been used
for searching dark matter in the form of compact astrophysical halo objects in
the Galactic halo. We discuss about the degeneracy problem in the parameters of
lens and perturbation effects that can partially break the degeneracy between
the lens parameters. The rest of paper is about the astrophysical applications
of microlensing. One of the important applications is in the stellar physics by
probing the surface of source stars in the high magnification microlensing
events. The astrometric and polarimetric observations will be complimentary for
probing the atmosphere and stellar spots on the surface of source stars.
Finally we discuss about the future projects as space based telescopes for
parallax and astrometry observations of microlensing events. With this project,
we would expect to produce a complete stellar and remnant mass function and
study the structure of Galaxy in term of distribution of stars along our line
of sight towards the centre of galaxy.",192,10,1267,32.94
148,astrophysics,"The paper aims to consider the strength gradient force as the dynamic of
astrophysical jets, explaining the movement phenomena of astrophysical jets. J.
C. Maxwell applied the quaternion analysis to describe the electromagnetic
theory. This encourages others to adopt the complex quaternion and octonion to
depict the electromagnetic and gravitational theories. In the complex octonion
space, it is capable of deducing the field potential, field strength, field
source, angular momentum, torque, force and so forth. As one component of the
force, the strength gradient force relates to the gradient of the norm of field
strength only, and is independent of not only the direction of field strength
but also the mass and electric charge for the test particle. When the strength
gradient force is considered as the thrust of the astrophysical jets, one can
deduce some movement features of astrophysical jets, including the bipolarity,
matter ingredient, precession, symmetric distribution, emitting, collimation,
stability, continuing acceleration and so forth. The above results reveal that
the strength gradient force is able to be applied to explain the main
mechanical features of astrophysical jets, and is the competitive candidate of
the dynamic of astrophysical jets.",191,10,1274,26.85
149,astrophysics,"Charge exchange X-ray emission provides unique insights into the interactions
between cold and hot astrophysical plasmas. Besides its own profound science,
this emission is also technically crucial to all observations in the X-ray
band, since charge exchange with the solar wind often contributes a significant
foreground component that contaminates the signal of interest. By approximating
the cross sections resolved to $n$ and $l$ atomic subshells, and carrying out
complete radiative cascade calculation, we create a new spectral code to
evaluate the charge exchange emission in the X-ray band. Comparing to
collisional thermal emission, charge exchange radiation exhibits enhanced lines
from large-$n$ shells to the ground, as well as large forbidden-to-resonance
ratios of triplet transitions. Our new model successfully reproduces an
observed high-quality spectrum of comet C/2000 WM1 (LINEAR), which emits purely
by charge exchange between solar wind ions and cometary neutrals. It
demonstrates that a proper charge exchange model will allow us to probe
remotely the ion properties, including charge state, dynamics, and composition,
at the interface between the cold and hot plasmas.",173,7,1192,33.78
150,astrophysics,"Core-collapse supernovae produce elements between Fe and Ag depending on the
properties of the ejected matter. Despite the fast progress in supernova
simulations in the last decades, there are still uncertainties in the
astrophysical conditions. In this paper we investigate the impact of
astrophysical uncertainties on the nucleosynthesis. Since a systematic study
based on trajectories from hydrodynamic simulations is computationally very
expensive, we rely on a steady-state model. By varying the mass and radius of
the proto-neutron star as well as electron fraction in the steady-state model,
we cover a wide range of astrophysical conditions. In our study, we find four
abundance patterns which can be formed in neutron-rich neutrino-driven ejecta.
This provides a unique template of trajectories that can be used to investigate
the impact of nuclear physics input on the nucleosynthesis for representative
astrophysical conditions. Furthermore, we link these four patterns to the
neutron-to-seed and alpha-to-seed ratios at $T=3$~GK. Therefore, our results
give a good overview of the potential nucleosynthesis evolution which can occur
in a supernova simulation.",170,10,1171,35.37
151,astrophysics,"Astrophysical fluids are turbulent, magnetized and frequently partially
ionized. As an example of astrophysical turbulence, the interstellar turbulence
extends over a remarkably large range of spatial scales and participates in key
astrophysical processes happening in different ranges of scales. A significant
progress has been achieved in the understanding of the magnetohydrodynamic
(MHD) turbulence since the turn of the century, and this enables us to better
describe turbulence in magnetized and partially ionized plasmas. In fact, the
modern revolutionized picture of the MHD turbulence physics facilitates the
development of various theoretical domains, including the damping process for
dissipating MHD turbulence and the dynamo process for generating MHD turbulence
with many important astrophysical implications. In this paper, we review some
important findings from our recent theoretical works to demonstrate the
interconnection between the properties of MHD turbulence and those of turbulent
dynamo in a partially ionized gas. We also briefly exemplify some new tentative
studies on how the revised basic processes influence the associated outstanding
astrophysical problems in, such as, magnetic reconnection, cosmic ray
scattering, magnetic field amplification in both the early and the present-day
universe.",184,7,1324,6.47
152,astrophysics,"Remarkable progress has been made in understanding turbulent astrophysical
plasmas in past decades including, notably, the solar wind and the interstellar
medium. In the case of the solar wind, much of this progress has relied on in
situ measurements from space-borne instruments. However, ground-based radio
observations also have played a significant role and have the potential to play
an even bigger role. In particular, using distant background sources (quasars,
pulsars, satellite beacons) to transilluminate the foreground corona and solar
wind, a variety of radio propagation phenomena can be used to map plasma
properties of the solar corona and heliosphere, as well as the warm
interstellar medium. These include angular broadening, interplanetary and
interstellar scintillations, and differential Faraday rotation. These
observations are highly complementary to in situ observations of the solar
wind, and could be a mainstay of investigations into turbulence of the ISM. We
point out that the Next Generation Very Large Array (ngVLA) fulfills all the
requirements necessary to exploit radio observations of astrophysical
turbulence fully.",167,8,1150,30.3
153,astrophysics,"We show that the anisotropies of the astrophysical stochastic gravitational
wave background in the mHz band have a strong dependence on the modelling of
galactic and sub-galactic physics. We explore a wide range of self-consistent
astrophysical models for stellar evolution and for the distribution of orbital
parameters, all calibrated such that they predict the same number of resolved
mergers to fit the number of detections during LIGO/Virgo O1+O2 observations
runs. We show that different physical choices for the process of black hole
collapse and cut-off in the black hole mass distribution give fractional
differences in the angular power spectrum of anisotropies up to 50\% on all
angular scales. We also point out that the astrophysical information which can
be extracted from anisotropies is complementary to the isotropic background and
individual mergers. These results underline the interest in the anisotropies of
the stochastic gravitational wave background as a new and potentially rich
field of research, at the cross-road between astrophysics and cosmology.",161,6,1076,30.33
154,astrophysics,"The standard neutrino oscillation paradigm predicts almost equal fractions of
astrophysical neutrino flavors at Earth regardless of their production ratio at
the sources. Therefore, identification of astrophysical tau neutrinos could not
only reconfirm the astrophysical neutrino flux measured by IceCube, but also is
essential in precisely determining the astrophysical neutrino flavor ratio at
Earth, which is an important probe for physics beyond the Standard Model over
astronomical baselines. A tau neutrino undergoing a charged current (CC)
interaction in IceCube could produce a double deposition of energy, with the
first one from the CC hadronic shower and the second from the subsequent tau
lepton decay shower. Above an energy of ~100 TeV, such consecutive energy
depositions might be resolvable in the sensor waveforms and hence can be a
signature of an individual tau neutrino interaction in IceCube. We will present
the results of a search for astrophysical tau neutrinos in IceCube waveforms
with improved double pulse waveform identification techniques and using 8 years
of data.",164,6,1095,12.8
155,astrophysics,"This brief overview stresses the importance of laboratory data and theory in
analyzing astronomical observations and understanding the physical and chemical
processes that drive the astrophysical phenomena in our Universe. This includes
basic atomic and molecular data such as spectroscopy and collisional rate
coefficients, but also an improved understanding of nuclear, plasma and
particle physics, as well as reactions and photoprocesses in the gaseous and
solid state that lead to chemical complexity and building blocks for life.
Systematic laboratory collision experiments have provided detailed insight into
the steps that produce pebbles, bricks and ultimately planetesimals starting
from sub-$\mu$m-sized grains. Sample return missions and meteoritic studies
benefit from increasingly sophisticated laboratory machines to analyze
materials and provide compositional images on nanometer scales. Prioritization
of future data requirements will be needed to cope with the increasing data
streams from a diverse range of future astronomical facilities within a
constrained laboratory astrophysics budget.",150,6,1109,-1.28
156,astrophysics,"In this paper we showcase the importance of understanding and measuring
interdisciplinarity and other -disciplinarity concepts for all scientists, the
role social sciences have historically played in NASA research and missions,
the sparsity of social science interdisciplinarity in space and planetary
sciences, including astronomy and astrophysics, while there is an imperative
necessity for it, and the example of interdisciplinarity between social
sciences and astrobiology. Ultimately we give voice to the scientists across
all fields with respect to their needs, aspirations and experiences in their
interdisciplinary work with social sciences through an ad-hoc survey we
conducted within the Astro2020 Decadal Survey scientific community.",102,3,744,-14.14
157,astrophysics,"If neutrinos have self-interactions, these will induce scatterings between
astrophysical and cosmic neutrinos. Prior work proposed to look for possible
resulting resonance features in astrophysical neutrino spectra in order to seek
a neutrino self-interaction which can be either diagonal in the neutrino flavor
space or couple different neutrino flavors. The calculation of the
astrophysical spectra involves either a Monte Carlo simulation or a
computationally intensive numerical integration of an
integro-partial-differential equation. As a result only limited regions of the
neutrino self-interaction parameter space have been explored, and only
flavor-diagonal self-interactions have been considered. Here, we present a
fully analytic form for the astrophysical neutrino spectra for arbitrary
neutrino number and arbitrary self-coupling matrix that accurately obtains the
resonance features in the observable neutrino spectra. The results can be
applied to calculations of the diffuse supernova neutrino background and of the
spectrum from high-energy astrophysical neutrino sources. We illustrate with a
few examples.",152,8,1124,7.15
158,astrophysics,"This report provides detailed findings on the critical laboratory
astrophysics data needs that are required to maximize the scientific return for
NASA's current and near-term planned astrophysics missions. It also provides
prioritized rankings on said laboratory astrophysics data, generally by
waveband. The Report is based on community input gathered at the 2018 NASA
Laboratory Astrophysics Workshop (LAW) from presentations, from discussions
during workshop breakout sessions, and from other solicited input deemed
appropriate by the Scientific Organizing Committee (SOC) obtained prior to and
after the meeting. Hence, the Report is a direct reflection of the spirit and
participant make-up of LAW 2018. The Report also outlines specific
opportunities and threats facing NASA's Laboratory Astrophysics Program, and
articulates concrete actions by which the Agency can capitalize on the
opportunities and mitigate the challenges. The Report was prepared by the SOC,
with help from some invited speakers, and input and review from community
members.",151,7,1052,20.52
159,astrophysics,"We seek to compile a uniform set of basic capabilities and needs to maximize
the yield of Solar System science with future Astrophysics assets while
allowing those assets to achieve their Astrophysics priorities. Within
considerations of cost and complexity, inclusion of capabilities that make a
particular platform useable to planetary science provide a critical advantage
over platforms lacking such capabilities.",60,3,416,7.19
160,astrophysics,"We perform a hierarchical Bayesian analysis of the GWTC-2 catalog to
investigate the mixed scenario in which the merger events are explained by
black holes of both astrophysical and primordial origin. For the astrophysical
scenario we adopt the phenomenological model used by the LIGO/Virgo
collaboration and we include the correlation between different parameters
inferred from data, the role of the spins in both the primordial and
astrophysical scenarios, and the impact of accretion in the primordial
scenario. Our best-fit mixed model has a strong statistical evidence relative
to the single-population astrophysical model, thus supporting the coexistence
of populations of black-hole mergers of two different origins. In particular,
our results indicate that the astrophysical mergers account for roughly four
times the number of primordial black hole events and predict that
third-generation detectors, such as the Einstein Telescope and Cosmic Explorer,
should detect up to hundreds of mergers from primordial black hole binaries at
redshift $z\gtrsim30$.",154,5,1063,7.02
161,astrophysics,"It is well-known that magnetohydrodynamic (MHD) turbulence is ubiquitous in
astrophysical environments. The correct understanding of the fundamental
properties of MHD turbulence is a prerequisite for revealing many key
astrophysical processes. The development of observation-based measurement
techniques has significantly promoted MHD turbulence theory and its
implications in astrophysics. After describing the modern understanding of MHD
turbulence based on theoretical analysis and direct numerical simulations, we
review recent developments related to synchrotron fluctuation techniques.
Specifically, we comment on the validation of synchrotron fluctuation
techniques and the measurement performance of several properties of magnetic
turbulence based on data cubes from MHD turbulence simulations and
observations. Furthermore, we propose to strengthen the studies of the
magnetization and 3D magnetic field structure's measurements of interstellar
turbulence. At the same time, we also discuss the prospects of new techniques
for measuring magnetic field properties and understanding astrophysical
processes, using a large number of data cubes from the Low-Frequency Array
(LOFAR) and the Square Kilometre Array (SKA).",161,8,1224,5.83
162,astrophysics,"Nuclear astrophysics is a multi-disciplinary field with a huge demand for
nuclear data. Among its various fields, stellar evolution and nucleosynthesis
are clearly the most closely related to nuclear physics. The need for nuclear
data for astrophysics applications challenges experimental techniques as well
as the robustness and predictive power of present nuclear models. Despite
impressive progress for the last years, major problems and puzzles remain. In
the present contribution, only a few nuclear astrophysics specific aspects are
discussed. These concern some experimental progress related to the measurement
of key reactions of relevance for the so-called s-and p-processes of
nucleosynthesis, the theoretical effort in predicting nuclear properties of
exotic neutron-rich nuclei of interest for the r-process nucleosynthesis, and
the recent introduction of machine learning techniques in nuclear astrophysics
applications.",128,7,933,16.02
163,astrophysics,"Photoionization and its inverse, electron-ion recombination, are key
processes that influence many astrophysical plasmas (and gasses), and the
diagnostics that we use to analyse the plasmas. In this review we provide a
brief overview of the importance of photoionization and recombination in
astrophysics. We highlight how the data needed for spectral analyses, and the
required accuracy, varies considerably in different astrophysical environments.
We then discuss photoionization processes, highlighting resonances in their
cross-sections. Next we discuss radiative recombination, and low and high
temperature dielectronic recombination. The possible suppression of low
temperature dielectronic recombination (LTDR) and high temperature dielectronic
recombination (HTDR) due to the radiation field and high densities is
discussed. Finally we discuss a few astrophysical examples to highlight
photoionization and recombination processes.",122,8,938,3.05
164,astrophysics,"The global network of interferometric gravitational wave (GW) observatories
(LIGO, Virgo, KAGRA) has detected and characterized nearly 100 mergers of
binary compact objects. However, many more real GWs are lurking sub-threshold,
which need to be sifted from terrestrial-origin noise triggers (known as
glitches). Because glitches are not due to astrophysical phenomena, inference
on the glitch under the assumption it has an astrophysical source (e.g. binary
black hole coalescence) results in source parameters that are inconsistent with
what is known about the astrophysical population. In this work, we show how one
can extract unbiased population constraints from a catalog of both real GW
events and glitch contaminants by performing Bayesian inference on their source
populations simultaneously. In this paper, we assume glitches come from a
specific class with a well-characterized effective population (blip glitches).
We also calculate posteriors on the probability of each event in the catalog
belonging to the astrophysical or glitch class, and obtain posteriors on the
number of astrophysical events in the catalog, finding it to be consistent with
the actual number of events included.",177,9,1198,20.42
165,astrophysics,"To assess the number of life-bearing worlds in astrophysical environments, it
is necessary to take the intertwined processes of abiogenesis (birth),
extinction (death), and transfer of life (migration) into account. We construct
a mathematical model that incorporates this trio of mechanisms and accordingly
derive the probability distribution function and other statistical properties
(e.g., mean) for the number of worlds with biospheres. We show that a given
astrophysical setting may become eventually saturated with life if the rate of
successful transfers of organisms is higher than the extinction rate of
biospheres. Based on the available data, we suggest that this criterion might
be fulfilled for star-forming clusters (and perhaps the Galactic bulge under
optimal circumstances), thereby indicating that such regions could constitute
promising abodes for hosting and detecting life.",128,7,894,28.57
166,astrophysics,"IceCube real-time alerts allow for rapid follow-up observations of likely
astrophysical neutrino events, enabling searches for multi-messenger
counterparts. The Enhanced Starting Track Real-time Stream (ESTReS) is a
real-time extension of the Enhanced Starting Track Event Selection (ESTES), a
high astrophysical purity muon-neutrino sample recently used by IceCube to
measure the astrophysical diffuse flux. A set of computationally cheap cuts
allows us to run a fast filter in seconds. This online filter selects about 100
events per day to be sent to Madison, WI via satellite where the full ESTES
event selection is applied within minutes. Events that pass the final set of
cuts (ESTReS + ESTES) will be sent out as real-time alerts to the broader
astrophysical community. ESTReS's unique contribution to the current real-time
alerts will be events in the southern sky in the 5 TeV - 100 TeV range. We
expect about 10.3 events per year which average 50% astrophysical purity. In
this talk I will report the status of the ESTReS alert stream in the context of
the IceCube real-time program.",174,10,1093,52.09
167,astrophysics,"Interferometric measurements of the 21cm signal are a prime example of the
data-driven era in astrophysics we are entering with current and upcoming
experiments. We showcase the use of deep networks that are tailored for the
structure of 3D tomographic 21cm light-cones to firstly detect and characterise
HI sources and to secondly directly infer global astrophysical and cosmological
model parameters. We compare different architectures and highlight how 3D CNN
architectures that mirror the data structure are the best-performing model.",79,4,538,19.4
168,astrophysics,"Computational astrophysics has undergone unprecedented development over the
last decade, becoming a field of its own. The challenge ahead of us will
involve increasingly complex multi-scale simulations. These will bridge the gap
between areas of astrophysics such as star and planet formation, or star
formation and galaxy formation, that have evolved separately until today. A
global knowledge of the physics and modeling techniques of astrophysical
simulations is thus an important asset for the next generation of modelers.
With the aim at fostering such a global approach, we present the Special Issue
on Computational Astrophysics for the Advanced Science Letters
(http://www.aspbs.com/science.htm). The Advanced Science Letters (ASL) is a new
multi-disciplinary scientific journal which will cover extensively
computational astrophysics and cosmology, and will act as a forum for the
presentation and discussion of novel work attempting to connect different
research areas. This Special Issue collects 9 reviews on 9 key topics of modern
astrophysics and cosmology in which simulations have had a pivotal
contribution. From asteroid collisions to the formation of stars, from the
physics and origin of galaxy clusters to large-scale phenomena such as the
reionization of the Universe, it is a showcase of state-of-the-art numerical
work in a diverse range of topics. The 9 reviews are available on today's
listing of the astro-ph archive (arXiv id numbers are provided in this
foreword).",222,13,1493,29.48
169,astrophysics,"The origin of the elements is a fascinating question that scientists have
been trying to answer for the last seven decades. The formation of light
elements in the primordial universe and heavier elements in astrophysical
sources occurs through nuclear reactions. We can say that nuclear processes are
responsible for the production of energy and synthesis of elements in the
various astrophysical sites. Thus, nuclear reactions have a determining role in
the existence and evolution of several astrophysical environments, from the Sun
to the spectacular explosions of supernovae. Nuclear astrophysics attempts to
address the most basic and important questions of our existence and future.
There are still many issues that are unresolved such as, how stars and our
Galaxy have formed and how they evolve, how and where are the heaviest elements
made, what is the abundance of nuclei in the universe and what is the
nucleosynthesis output of the various production processes and why the amount
of lithium-7 observed is less than predicted. In this paper, we review our
current understanding of the different astrophysical nuclear processes leading
to the formation of chemical elements and pay particular attention to the
formation of heavy elements occurring during high-energy astrophysical events.
Thanks to the recent multi-messenger observation of a binary neutron star
merger, which also confirmed production of heavy elements, explosive scenarios
such as short gamma-ray bursts and the following kilonovae are now strongly
supported as nucleosynthesis sites.",236,9,1563,24.61
170,astrophysics,"The Astrophysical Multimessenger Observatory Network (AMON) has been built
with the purpose of enabling near real-time coincidence searches using data
from leading multimessenger observatories and astronomical facilities. Its
mission is to evoke discovery of multimessenger astrophysical sources, exploit
these sources for purposes of astrophysics and fundamental physics, and explore
multimessenger datasets for evidence of multimessenger source population AMON
aims to promote the advancement of multimessenger astrophysics by allowing its
participants to study the most energetic phenomena in the universe and to help
answer some of the outstanding enigmas in astrophysics, fundamental physics,
and cosmology. The main strength of AMON is its ability to combine and analyze
sub-threshold data from different facilities. Such data cannot generally be
used stand-alone to identify astrophysical sources. The analyses algorithms
used by AMON can identify statistically significant coincidence candidates of
multimessenger events, leading to the distribution of AMON alerts used by
partner observatories for real-time follow-up that may identify and,
potentially, confirm the reality of the multimessenger association. We present
the science motivation, partner observatories, implementation and summary of
the current status of the AMON project.",181,7,1345,-1.49
171,astrophysics,"Measuring temperature fluctuations in the 21 cm signal from the Epoch of
Reionization and the Cosmic Dawn is one of the most promising ways to study the
Universe at high redshifts. Unfortunately, the 21 cm signal is affected by both
cosmology and astrophysics processes in a non-trivial manner. We run a suite of
1,000 numerical simulations with different values of the main astrophysical
parameters. From these simulations we produce tens of thousands of 21 cm maps
at redshifts $10\leq z\leq 20$. We train a convolutional neural network to
remove the effects of astrophysics from the 21 cm maps, and output maps of the
underlying matter field. We show that our model is able to generate 2D matter
fields that not only resemble the true ones visually, but whose statistical
properties agree with the true ones within a few percent down to pretty small
scales. We demonstrate that our neural network retains astrophysical
information, that can be used to constrain the value of the astrophysical
parameters. Finally, we use saliency maps to try to understand which features
of the 21 cm maps is the network using in order to determine the value of the
astrophysical parameters.",195,9,1177,46.71
172,astrophysics,"Dust is an essential component of the interstellar medium (ISM) and plays an
important role in many different astrophysical processes and phenomena.
Traditionally, dust grains are known to be destroyed by thermal sublimation,
Coulomb explosions, sputtering, and shattering. The first two mechanisms arise
from the interaction of dust with intense radiation fields and high-energy
photons (extreme UV), which work in a limited astrophysical environment. The
present review is focused on a new destruction mechanism present in the {\it
dust-radiation interaction} that is effective in a wide range of radiation
fields and has ubiquitous applications in astrophysics. We first describe this
new mechanism of grain destruction, namely rotational disruption induced by
Radiative Torques (RATs) or RAdiative Torque Disruption (RATD). We then discuss
rotational disruption of nanoparticles by mechanical torques due to supersonic
motion of grains relative to the ambient gas, which is termed MEchanical Torque
Disruption (METD). These two new mechanisms modify properties of dust and ice
(e.g., size distribution and mass), which affects observational properties,
including dust extinction, thermal and nonthermal emission, and polarization.
We present various applications of the RATD and METD mechanisms for different
environments, including the ISM, star-forming regions, astrophysical
transients, and surface astrochemistry.",197,11,1421,23.87
173,astrophysics,"The Particle-In-Cell (PIC) method has been developed by Oscar Buneman,
Charles Birdsall, Roger W. Hockney, and John Dawson in the 1950s and, with the
advances of computing power, has been further developed for several fields such
as astrophysical, magnetospheric as well as solar plasmas and recently also for
atmospheric and laser-plasma physics. Currently more than 15 semi-public PIC
codes are available which we discuss in this review. Its applications have
grown extensively with increasing computing power available on high performance
computing facilities around the world. These systems allow the study of various
topics of astrophysical plasmas, such as magnetic reconnection, pulsars and
black hole magnetosphere, non-relativistic and relativistic shocks,
relativistic jets, and laser-plasma physics. We review a plethora of
astrophysical phenomena such as relativistic jets, instabilities, magnetic
reconnection, pulsars, as well as PIC simulations of laser-plasma physics
(until 2021) emphasizing the physics involved in the simulations. Finally, we
give an outlook of the future simulations of jets associated to neutron stars,
black holes and their merging and discuss the future of PIC simulations in the
light of petascale and exascale computing.",181,8,1262,28.27
174,astrophysics,"Recent multi-messenger detection of the binary neutron star merger (GW170817)
energized the astrophysical community and encouraged further research for
determination of nuclear physics observables. Comprehensive studies of atomic
nuclei in the cosmos provide an opportunity for investigating these
astrophysical phenomena and acquiring complementary information on stellar
nucleosynthesis processes that can be verified using the latest nuclear data.
  Evaluated Nuclear Data File (ENDF) libraries contain complete collections of
reaction cross sections over the energy range relevant to astrophysics, fission
yields and decay data. These data collections have been used worldwide in
nuclear science, industry and national security applications. There is great
interest in exploring the ENDF/B-VIII.0 and TALYS Evaluated Nuclear Data
Library (TENDL-2015) for nuclear astrophysics purposes and comparing findings
with the Karlsruhe Astrophysical Database of Nucleosynthesis in Stars
(KADoNiS).
  The Maxwellian-averaged cross sections (MACS) and astrophysical reaction
rates have been calculated using the ENDF/B-VIII.0 and TENDL-2015 evaluated
data sets. The calculated cross sections were combined with the solar system
abundances and fitted using the classical model of stellar nucleosynthesis.
Astrophysical rapid- and slow-neutron capture, $r$- and $s$-process,
respectively, abundances were obtained from present data and compared with
available values. Further analysis of MACS reveals potential evaluated
libraries data deficiencies and a strong need for new measurements. The current
results demonstrate a large nuclear astrophysics potential of evaluated
libraries and mutually beneficial relations between nuclear industry and
research efforts.",228,13,1754,9.89
175,astrophysics,"Nuclear physics has been playing an important role in modern astrophysics and
cosmology. Since the early 1950's it has been successfully applied for the
interpretation and prediction of astrophysical phenomena. Nuclear physics
models helped to explain the observed elemental and isotopic abundances and
star evolution and provided valuable insights on the Big Bang theory. Today,
the variety of elements observed in stellar surfaces, solar system and cosmic
rays, and isotope abundances are calculated and compared with the observed
values. Consequently, the overall success of the modeling critically depends on
the quality of underlying nuclear data that helps to bring physics of macro and
micro scales together. To broaden the scope of traditional nuclear astrophysics
activities and produce additional complementary information, I will investigate
applicability of the U.S. Nuclear Data Program (USNDP) databases for
astrophysical applications. EXFOR (Experimental Nuclear Reaction Data) and ENDF
(Evaluated Nuclear Data File) libraries have large astrophysics potential; the
former library contains experimental data sets while the latter library
includes evaluated neutron cross sections. ENSDF (Evaluated Nuclear Structure
Data File) database is a primary depository of nuclear structure and decay
rates information. The decay rates are essential in stellar nucleosynthesis
calculations, and these rates are evaluated using nuclear structure codes. The
structure evaluation codes are pure mathematical procedures that can be applied
to diverse data samples. A brief review of astrophysical nuclear data needs has
been presented. Several opportunities and the corresponding computer tools have
been identified. Further work will include extensive analysis of nuclear
databases and computer procedures for astrophysical calculations.",255,16,1839,19.16
176,astrophysics,"In this paper, we explore from a conceptual standpoint the possibility of
using natural astrophysical sources to accelerate spacecrafts to relativistic
speeds. We focus on light sails and electric sails, which are reliant on
momentum transfer from photons and protons, respectively, because these two
classes of spacecrafts are not required to carry fuel on board. The payload is
assumed to be stationed near the astrophysical source, and the sail is
subsequently unfolded and activated when the source is functional. By
considering a number of astrophysical objects such as massive stars,
microquasars, supernovae, pulsar wind nebulae, and active galactic nuclei, we
show that terminal speeds approaching the speed of light might be realizable
under idealized circumstances provided that sufficiently advanced sail
materials and control techniques exist. We also investigate the constraints
arising from the sail's material properties, the voyage through the ambient
source environment, and the passage through the interstellar medium. While all
of these considerations pose significant challenges to spacecrafts, our
analysis indicates that they are not insurmountable in optimal conditions.
Finally, we sketch the implications for carrying out future technosignature
searches.",182,8,1279,19.71
177,astrophysics,"There may exist extended configurations in the dark matter sector that are
analogues of structures in the visible sector. In this work, we explore
non-topological solitonic configurations, specifically Q-balls, and study when
they may form macroscopic astrophysical structures and what their distinct
characteristics might be. We study in some detail theoretical bounds on their
sizes and constraints on the underlying parameters, based on criteria for an
astrophysical Q-ball's existence, gravitational stability and viability of
solutions. Following this path, one is able to obtain novel limits on
astrophysical Q-ball sizes and their underlying parameters. We also explore the
gravitational lensing features of different astrophysical Q-ball profiles,
which are more general than the simple thin-wall limit. It is seen that the
magnification characteristics may be very distinct, depending on the actual
details of the solution, even for astrophysical Q-balls having the same size
and mass. Assuming that such astrophysical Q-balls may form a small component
of the dark matter in the universe, we place limits on this fraction from the
gravitational microlensing surveys EROS-2, OGLE-IV, HSC-Subaru and the proposed
future survey WFIRST. Exploring various astrophysical Q-ball profiles and
sizes, it is found that while for most intermediate masses that we consider,
the dark matter fraction comprising astrophysical Q-balls is at most
sub-percent, for other masses it may be significantly higher.",218,9,1502,18.39
178,astrophysics,"In this paper, we have derived the the effects of strong magnetic fields
${\bf \vec B}$ on nucleon and particle reaction rates of astrophysical
significance. We have explored the sensitivity to the presence of arbitrary
degeneracy and polarization. The possible astrophysical applications of our
results are discussed.",47,4,318,30.16
179,astrophysics,"This paper outlines astrophysical issues related to the long term fate of the
universe. We consider the evolution of planets, stars, stellar populations,
galaxies, and the universe itself over time scales which greatly exceed the
current age of the universe. (shortened version of abstract).",44,4,291,48.09
180,astrophysics,"We summarize new RXTE observations to search for millisecond X-ray
variability from the bright Galactic bulge source GX 3+1. During a short 2 ksec
observation we did not detect kilohertz (kHz) quasiperiodic oscillations (QPO).
We place an upper limit of about 1 % (rms) on the amplitude of such
oscillations.",50,4,308,54.93
181,astrophysics,"We review some of the properties of Advection-Dominated Accretion Flow (ADAF)
models and show that they successfully describe many astrophysical systems.
Despite these successful applications some fundamental problems still remain to
be solved, the most important one being the physics of the transition between
an ADAF and a geometrically thin Keplerian disc.",52,3,360,19.71
182,astrophysics,"The GRAPE-4, the world's fastest computer in 1995-1997, has produced some
major scientific results, through a wide diversity of large-scale simulations
in astrophysics. Applications have ranged from planetary formation, through the
evolution of star clusters and galactic nuclei, to the formation of galaxies
and clusters of galaxies.",47,3,334,30.7
183,astrophysics,"Astrophysical and cosmological consequences of a standard $\nu_{\tau}$ of (15
+- 3) keV/c^{2} mass are discussed in the light of the recent results of the
solar, atmospheric and LSND neutrino experiments and theoretical prejudices.",34,2,231,12.6
184,astrophysics,"The forms of two astrophysically applicable equations of state (EOS) are
compared: the EOS proposed within the semiclassical theory of dense matter
developed by P.Savic and R.Kasanin,and the universal equation of state
introduced by Vinet et al.Some similarities between them are discussed and
possibilities of astrophysical tests are pointed out.",50,5,347,33.41
185,astrophysics,"The modeled performance of the Alpha Magnetic Spectrometer (AMS) as a
high-energy (0.3 to 100 GeV) gamma-ray detector is described, and its gamma-ray
astrophysics objectives are discussed.",27,3,188,40.85
186,astrophysics,"Radiative Transfer (RT) effects play a crucial role in the thermal history of
the intergalactic medium. Here I discuss recent advances in the development of
numerical methods that introduce RT to cosmological hydrodynamics. These
methods can also readily be applied to time dependent problems on interstellar
and galactic scales.",49,4,329,29.55
187,astrophysics,"A brief review of neutrino anomalies in particle physics and of the role
played by neutrinos in cosmology and astrophysics is presented. The main part
of the talk is dedicated to the impact of neutrinos and in particular of
neutrino oscillations on BBN and to a possible spatial variation of primordial
abundances.",52,3,314,36.63
188,astrophysics,"Supernovae play a critical role in observational cosmology as well as in
astrophysics of stars and galaxies. Recent era has seen dramatic progress in
the research of supernovae. Several programs to search systematically
supernovae in nearby to distant galaxies have been very successful. Recent
progresses in the modern supernova search are reviewed.",52,5,350,32.9
189,astrophysics,"We review current astrophysical bounds on MeV sterile neutrinos, and then we
discuss why a sterile keV neutrino is a natural warm dark matter candidate.",25,2,152,37.64
190,astrophysics,"Many of the fundamental questions in astrophysics can be addressed using
spectroscopic observations of photoionized cosmic plasmas. However, the
reliability of the inferred astrophysics depends on the accuracy of the
underlying atomic data used to interpret the collected spectra. In this paper,
we review some of the most glaring atomic data needs for better understanding
photoionized plasmas.",57,4,395,26.81
191,astrophysics,"We briefly review our current understanding for the formation, acceleration
and collimation of winds to jets associated with compact astrophysical objects
such as AGN and microQuasars.",26,2,184,11.25
192,astrophysics,"We address the extended problem of component separation for CMB applications
when a mixture of both astrophysical and instrumental components are present in
the observations, and show how standard methods can be adapted to handle this
more complex inversion problem.",40,2,266,13.96
193,astrophysics,"We show that thermal radio emission has an induced character and argue that
thermal blackbody radiation in other spectral ranges also has an induced
origin. A new theory of thermal radio emission of non-uniform gas basing on the
induced origin of emission and its astrophysical applications are considered.
The nature of emission from various astrophysical objects is discussed.",58,4,378,34.97
194,astrophysics,"I highlight results from Chandr observations of nearby galaxies, including
the Milky Way. These observations have offered insights into old mysteries and
indications of new high energy astrophysical phenomena and processes that are
yet to be understood.",37,3,253,27.32
195,astrophysics,"Astronomical observations of the orbital angular momentum of photons, a
property of electromagnetic radiation that has come to the fore in recent
years, have apparently never been attempted. Here, I show that measurements of
this property of photons have a number of astrophysical applications.",44,3,294,15.31
196,astrophysics,"A brief review is given on the astrophysics of cosmic rays in the PeV primary
energy range, i.e. the region of the knee.",23,4,120,76.72
197,astrophysics,"Although formal proposals have not yet been made, the UNO and
Hyper-Kamiokande projects are being developed to follow-up the tremendously
successful program at Super-Kamiokande using a detector that is 20-50 times
larger. The potential of such a detector to continue the study of astrophysical
neutrinos is considered and contrasted with the program for cubic kilometer
neutrino observatories.",57,3,393,25.63
198,astrophysics,"A review of the recent achievements in high energy neutrino physics and,
partly, neutrino astrophysics is presented. It is argued that experiments with
high energy neutrinos of natural origin can be used for a search of new physics
effects beyond the electroweak scale.",43,3,269,41.19
199,astrophysics,"We discuss briefly the potential sources of high energy astrophysical
neutrinos and show estimates of the neutrino fluxes that they can produce. A
special attention is paid to the connection between the highest energy cosmic
rays and astrophysical neutrinos.",39,3,258,34.76
200,astrophysics,"This collection of proceedings to the TeV PA II Conference presents some of
the latest results of the IceCube Collaboration.",20,2,124,42.72
201,astrophysics,"We present spectral methods developed in our group to solve three-dimensional
partial differential equations. The emphasis is put on equations arising from
astrophysical problems in the framework of general relativity.",30,3,218,22.41
202,astrophysics,"This Resource Letter provides a guide to the literature on the physics and
astrophysics of gravitational waves. Journals, books, reports, archives, and
websites are provided as basic resources and for current research frontiers in
detectors, data analysis, and astrophysical source modeling.",41,3,291,33.75
203,astrophysics,"In this talk I will briefly outline work in progress in two different
contexts in astrophysical relativity, i.e. the study of rotating star
spacetimes and the problem of reliably extracting gravitational wave templates
in numerical relativity. In both cases the use of Weyl scalars and curvature
invariants helps to clarify important issues.",52,5,341,37.0
204,astrophysics,"Recent progress in neutrino physics has been rapid, to a large extent thanks
to observations of neutrinos produced in astrophysical environments. Here, we
review the current standing on such questions as neutrino masses and mixings,
focusing mainly on the interplay between neutrino physics, astrophysics and
cosmology.",46,3,319,31.21
205,astrophysics,"Neutrino masses are likely to be a manifestation of the right-handed, or
sterile neutrinos. The number of sterile neutrinos and the scales of their
Majorana masses are unknown. We explore theoretical arguments in favor of the
high and low scale seesaw mechanisms, review the existing experimental results,
and discuss the astrophysical hints regarding sterile neutrinos.",55,4,370,27.52
206,astrophysics,"After reviewing some of the basic concepts, nomenclatures and
parametrizations of Astronomy, Astrophysics and Cosmology, we introduce a few
central problems in Nuclear Astrophysics, including the hot-CNO cycle, helium
burning in massive stars, and solar neutrino's. We demonstarte that SECONDARY
(RADIOACTIVE) NUCLEAR BEAMS allow for considerable progress on these problems.",50,3,374,20.72
207,astrophysics,"We study the combined effects of vacuum polarization, relativity,
Bremsstrahlung, and atomic polarization in nuclear reactions of astrophysical
interest. It is shown that these effects do not solve the longstanding
differences between the experimental data of astrophysical nuclear reactions at
very low energies and the theoretical calculations which aim to include
electron screening.",53,3,386,2.28
208,astrophysics,"An improved code for the calculation of astrophysical reaction rates in the
statistical model is presented. It includes the possibility to study isospin
effects. Such effects heavily affect capture rates involving self-conjugate
nuclei and may also be found in reactions on other intermediate and heavy
targets.",46,4,311,30.57
209,astrophysics,"We discuss models to calculate one- and two-neutron capture reactions on
light nuclei. These are applied to calculate the reaction rates of
15N(n,gamma)16N, 16N(n,gamma)17}N and 4He(2n,gamma)6He. The possible
astrophysical importance is discussed.",32,4,247,35.23
210,astrophysics,"We derived analytic formulas of the effective S astrophysical S factor,S^eff
for a non-resonant reaction of charged particles using a Taylor expension of
the astrophysical S factor and a uniform approximation.The formulas will be
able to generate generate more accurate approximation to S^eff than previous
ones.",46,3,312,5.83
211,astrophysics,"Some of the means through which the possible presence of nearly deconfined
quarks in neutron stars can be detected by astrophysical observations of
neutron stars from their birth to old age are highlighted.",33,2,206,37.98
212,astrophysics,"We derive analytic formulas for the power output and critical frequency of
radiation by electrons accelerated by relativistic kinetic Poynting flux, and
validate these results with Particle-In-Cell plasma simulations. We find that
the in-situ radiation power output and critical frequency are much below those
predicted by the classical synchrotron formulae. We discuss potential
astrophysical applications of these results.",58,4,424,1.13
213,astrophysics,"Adding 3 right-handed (sterile) neutrino to the Standard Model (SM) can solve
several ""beyond the Standard Model"" problems within one consistent framework:
explain neutrino oscillations and baryon asymmetry of the Universe and provide
a dark matter (DM) candidate. In this talk I will present current status of
astrophysical searches for the DM sterile neutrino.",54,3,362,35.61
214,astrophysics,"Methods and techniques of the theory of nonlinear dynamical systems and
patterns can be useful in astrophysical applications. Some works on the
subjects of dynamical astronomy, stellar pulsation and variability, as well as
spatial complexity in extended systems, in which such approaches have already
been utilized, are reviewed. Prospects for future directions in applications of
this kind are outlined.",59,4,404,26.1
215,astrophysics,"These lectures summarize our basic understanding of the emergence of cosmic
structures, the epoch of first light, the survival of early substructure in
present-day galaxy halos.",26,2,177,36.63
216,astrophysics,"We review Extended Theories of Gravity in metric and Palatini formalism
pointing out their cosmological and astrophysical application. The aim is to
propose an alternative approach to solve the puzzles connected to dark
components.",34,3,231,20.38
217,astrophysics,"Neutrino astronomy is on the verge of discovering new sources, and this will
lead to important advances in astrophysics, cosmology, particle physics, and
nuclear physics. This paper is meant for non-experts, so that they might better
understand the basic issues in this field.",43,3,276,41.19
218,astrophysics,"I discuss the development and resolution of the solar neutrino problem, as
well as opportunities now open to us to extend our knowledge of main-sequence
stellar evolution and neutrino astrophysics.",30,2,197,15.65
219,astrophysics,"In this paper we study specific classes of radiating shocks which are widely
spread in astrophysical environments. We present more general solutions of
their structure and proceed to the analytical determination of physical
quantities.",34,3,235,20.38
220,astrophysics,"Gurzadyan-Xue Dark Energy was derived in 1986 (twenty years before the paper
of Gurzadyan-Xue). The paper by the present author, titled The Planck Length as
a Cosmological Constant, published in Astrophysics Space Science, Vol. 127,
p.133-137, 1986 contains the formula claimed to have been derived by
Gurzadyan-Xue (in 2003).",49,5,326,63.39
221,astrophysics,"The South Pole is an optimal location for hosting astrophysical
observatories. The status of the construction of the IceCube Observatory and
some selected physics results will be discussed. Moreover prospects for
detection of Ultra-High Energy cosmogenic neutrinos and techniques that can
address this energy region will be considered.",48,4,335,29.86
222,astrophysics,"As the Stars and Stellar Evolution (SSE) panel is fully aware, the next
decade will see major advances in our understanding of these areas of research.
To quote from their charge, these advances will occur in studies of the Sun as
a star, stellar astrophysics, the structure and evolution of single and
multiple stars, compact objects, SNe, gamma-ray bursts, solar neutrinos, and
extreme physics on stellar scales. Central to the progress in these areas are
the corresponding advances in laboratory astrophysics, required to fully
realize the SSE scientific opportunities within the decade 2010-2020.
Laboratory astrophysics comprises both theoretical and experimental studies of
the underlying physics that produces the observed astrophysical processes. The
6 areas of laboratory astrophysics, which we have identified as relevant to the
CFP panel, are atomic, molecular, solid matter, plasma, nuclear physics, and
particle physics. In this white paper, we describe in Section 2 the scientific
context and some of the new scientific opportunities and compelling scientific
themes which will be enabled by advances in laboratory astrophysics. In Section
3, we discuss some of the experimental and theoretical advances in laboratory
astrophysics required to realize the SSE scientific opportunities of the next
decade. As requested in the Call for White Papers, Section 4 presents four
central questions and one area with unusual discovery potential. Lastly, we
give a short postlude in Section 5.",226,10,1496,29.08
223,astrophysics,"The principal goal of this whitepaper is not so much to demonstrate that
gravitational wave detectors like LIGO and LISA will help answer many central
questions in astronomy and astrophysics, but to make the case that they can
help answer a far greater range of questions if we prepare to make the
(sometimes substantial) effort to identify electromagnetic counterparts to the
gravitational wave sources.",64,2,404,6.52
224,astrophysics,"The August 2009 edition of the AAO newsletter contains articles on
observations of the lunar impact of the Kaguya satellite, mapping the ISM
towards Omega Centauri, early results from the Anglo-Australian Rocky Planet
search, details of a new AAOmega observing mode, the new telescope control
system and a number of regular features.",52,2,333,18.7
225,astrophysics,"Nuclear reactions in stars are difficult to measure directly in the
laboratory at the small astrophysical energies. In recent years indirect
methods with rare isotopes have been developed and applied to extract
low-energy astrophysical cross sections.",36,3,251,19.37
226,astrophysics,"We discuss basic features of steady accretion disk morphology around
magnetized compact astrophysical objects. A comparison between the standard
model of accretion based on visco-resistive MHD and the plasma instabilities,
like ballooning modes, triggered by very low value of resistivity, is proposed.",42,3,302,16.32
227,astrophysics,"I describe in very simple terms the theoretical tools needed to investigate
ultra-peripheral nuclear reactions for nuclear astrophysics purposes. For a
more detailed account, see arXiv:0908.4307.",26,4,195,15.98
228,astrophysics,"The Feburary 2010 edition of the AAO newsletter contains articles on
Helium-rich subluminous B stars, the discovery of large-scale gravitationall
infall in a massive proto-stellar cluster, HERMES: the new multi-object
high-resolution spectrograph for the AAT, future fibre positioning technology
and a number of regular features.",45,2,329,-8.05
229,astrophysics,"WIMP direct detection experiments probe the ultra-local dark matter density
and velocity distribution. We review how uncertainties in these quantities
affect the accuracy with which the WIMP mass and cross-section can be
constrained or determined.",35,3,247,28.33
230,astrophysics,"The relevant energy ranges for stellar nuclear reactions are introduced.
Low-energy compound and direct reactions are discussed. Stellar modifications
of the cross sections are presented. Implications for experiments are outlined.",30,5,230,21.56
231,astrophysics,"In this lecture the basic theory of accretion disks is reviewed, with
emphasis on aspects relevant for X-ray binaries and Cataclysmic Variables. The
text gives a general introduction as well as a selective discussion of a number
of more recent topics.",41,3,251,42.21
232,astrophysics,"The appearance of quark matter in the centers of compact stars has a number
of astrophysical implications. In this contribution I discuss the structure and
stability of compact stars, gravitational radiation from non-axisymmetric
deformations, and nucleation and dynamics of vortices (flux tubes) in the color
superconducting phases.",47,3,333,13.78
233,astrophysics,"A simple discussion of the recent OPERA result on the apparent critical speed
of the muon neutrino is presented. We point out in particular some of the
possible consistency problems of such an interpretation of the OPERA data with
respect to well-established astrophysical observations.",44,3,286,32.22
234,astrophysics,"All sky neutrino searches: Atmospheric neutrinos; Astrophysical neutrinos;
Cosmegenic neutrinos; Submitted papers to the 32nd International Cosmic Ray
Conference, Beijing 2011.",21,2,176,-9.07
235,astrophysics,"Searches for point sources of astrophysical neutrinos and related
measurements: Searches for steady and time-variable sources; Follow-up
programs; AGNs; GRBs; Moon shadow; Submitted papers to the 32nd International
Cosmic Ray Conference, Beijing 2011.",33,2,251,21.06
236,astrophysics,"This paper has been withdrawn by the author due to text overlap with
arXiv:1102.5004, as well as omission of proper citations to arXiv:1110.4655 and
arXiv:1111.0313",25,4,164,79.97
237,astrophysics,"A relativistic fluid ball with an inhomogeneous static stratified matter
configuration is considered. A model of an astrophysical object with this
structure of matter is constructed.",26,3,182,15.98
238,astrophysics,"An update on astrophysical models for nucleosynthesis via rapid neutron
capture, the r process, is given. A neutrino-induced r process in supernova
helium shells may have operated up to metallicities of ~10^-3 times the solar
value. Another r-process source, possibly neutron star mergers, is required for
higher metallicities.",48,4,327,29.86
239,astrophysics,"Correlation analysis of gamma-ray burst coordinates and nearby stars,
registered on 2008-2011, revealed 5 coincidences with angular accuracy better
than 0.1 degree. The random probability is $7\times 10^{-7}$, so evidencing
that coincident stars are indeed gamma-ray burst sources. The proposed method
should be continued in order to provide their share in common balance of cosmic
gamma-ray bursts.",57,5,399,35.27
240,astrophysics,"Using standard thermodynamics and previous results of the author, this paper
aims to discuss the conditions for phase equilibrium in a Lennard-Jones fluid.
Possibilities of astrophysical applications of the results obtained here are
discussed to some extent.",37,3,258,27.32
241,astrophysics,"I discuss three open problems in astrophysics where nuclear physics can make
important contributions: the solar abundance problem, dark matter particle
detection, and the origin of the r-process elements.",29,2,204,25.12
242,astrophysics,"These are the Proceedings of IAU Symposium 291, held 20-24 August 2012, in
Beijing, China.",15,2,90,64.71
243,astrophysics,"Binary stars evolve differently from single stars, thus binary evolution is
very useful for astrophysical studies. This paper discusses the application of
binary evolution in the studies of stars, star clusters, galaxies, and
cosmology. In particular, I concentrate on the use of binary evolution in
colour-magnitude diagram and spectral energy distribution studies of star
clusters and galaxies.",57,4,396,18.35
244,astrophysics,"We present a short overview of the formation and evolution of ultra-compact
binaries. They are relevant to a surprisingly large number of astrophysical
phenomena (binary interactions, mass transfer stability, explosive phenomena
such as type Ia supernovae and gravitational waves).",39,3,281,9.38
245,astrophysics,"The history of the program of systematic UBV photometric monitoring of Be
stars, binaries, CP stars and some other targets is briefly summarized. It is
shown that a careful data homogenization, reduction and transformation to the
standard Johnson system can be carried out successfully even at a station
nearly the sea level when some strict measures are taken.",58,3,361,33.58
246,astrophysics,"The recent observation of high-energy astrophysical neutrinos can be used to
constrain violations of Lorentz invariance emerging from a quantum theory of
gravity. We perform threshold and Cherenkov analyses that improve existing
bounds by factors ranging from about a million to 10^{20}.",42,3,287,33.24
247,astrophysics,"We introduce a project of new cooled infrared spectrometer-photometer for 6-m
telescope BTA (Special Astrophysical Observatory of Russian Science Academy).
The device would extend the wavelength range accessible for observations on the
6-m BTA telescope toward near infrared (0.8-2.5 um).",40,5,288,25.8
248,astrophysics,"Phenomenology of possible neutrino millicharge in terrestrial and
astrophysical settings is discussed. Two new limits on the millicharge from
terrestrial experiments and astrophysics are reported.",25,3,196,8.03
249,astrophysics,"In the framework of the modified potential cluster model with forbidden
states the possibility of describing the available experimental data on the
total cross sections and astrophysical S-factor for p11B radiative capture to
the ground state of 12C was treated at astrophysical energies.",43,2,288,2.45
250,astrophysics,"A brief review of the current status of neutrino mixing and oscillations in
astrophysical environments, with particular emphasis on the Sun and
core-collapse supernovae, is given. Implications of the existence of sterile
states which mix with the active neutrinos are discussed.",41,3,278,25.29
251,astrophysics,"In this work the Bumblebee model for spontaneous Lorentz symmetry breaking is
considered in the context of spherically symmetric astrophysical bodies. A
discussion of the modified equations of motion is presented and constraints on
the parameters of the model are perturbatively obtained.",42,3,288,24.78
252,astrophysics,"We built r-band surface brightness profiles by SDSS data for 16 Seyfert
galaxies observed in Crimean Astrophysical Observatory. Obtained profiles can
be used for finding more accurate lightcurves for these galaxies.",31,3,215,47.28
253,astrophysics,"The connection between neutrino physics, nucleosynthesis of elements in
astrophysical sites, laboratory measurements with rare exotic nuclei and
astronomical observations is discussed. The key role played by neutrinos is
emphasized and the close connection between neutrino physics and
nucleosynthesis is highlighted.",41,3,317,8.37
254,astrophysics,"Like the miniaturization of modern computers, next-generation radial velocity
instruments will be significantly smaller and more powerful than their
predecessors.",20,2,162,-8.05
255,astrophysics,"This is the collection of Chapters on 'Continuum Science' presented at the
Conference 'Advancing Astrophysics with the SKA' (AASKA14), held in Giardini
Naxos (Italy), June 9-13, 2014",27,1,182,35.61
256,astrophysics,"We use a kinetic-equation approach to describe the propagation of ultra high
energy cosmic ray protons and nuclei comparing theoretical results with the
observations of the Pierre Auger Observatory.",29,2,198,8.2
257,astrophysics,"We demonstrate that high abundances of water vapor could have existed in
extremely low metallicity ($10^{-3}$ solar) partially shielded gas, during the
epoch of first metal enrichment of the interstellar medium of galaxies at high
redshifts.",36,2,241,26.48
258,astrophysics,"In the framework of metric $f(R)$ gravity, we find the dispersion relation
for the propagation of tightly wound spiral density waves in the surface of
rotating, self-gravitating disks. Also, new Toomre-like stability criteria for
differentially rotating disks has been derived for both fluid and stellar
disks.",46,3,310,31.21
259,astrophysics,"We present the emerging panorama of Astroparticle Physics at Eastern
Colombia, and describe several ongoing projects, most of them related to the
Latin American Giant Observatory (LAGO) Project. This research work is carried
out at the Grupo de Investigaciones en Relatividad y Gravitaci\'on of
Universidad Industrial de Santander.",48,3,331,30.2
260,astrophysics,"We describe the experience of running an Astrophysics outreach initiative
involving traditional mass media like radio broadcast and new digital media
like blog, microblogging and internet video channel. Some very successful
preliminary results are also presented. This unique experience is helping to
create new science informal education environments for Spanish speaking people
in Latin America.",55,4,397,19.06
261,astrophysics,"We report the detection of two dwarf galaxies in a projected distance of ~50
kpc from NGC 7331 and suspect the physical nature of dwarfs of this spiral
galaxy.",29,2,159,50.5
262,astrophysics,"Are there examples of ""astrophysical Russian dolls,"" and what could we learn
from their similarities? In this article, we list a few such examples,
including disks, filaments, and clusters. We suggest that forging connections
across disciplinary borders enhances our perception of beauty, while
simultaneously leading to a more comprehensive understanding of the Universe.",53,3,372,36.59
263,astrophysics,"Besides supernovae, few astrophysical processes can release close to 10^51
erg of energy. A growing number of stellar outbursts are now recognised to have
energy releases matching those of faint supernovae. These transients can be
triggered by a variety of mechanisms, and their discrimination is sometimes a
tricky issue.",49,4,322,46.47
264,astrophysics,"Joint contributions of the Telescope Array Collaboration and the Pierre Auger
Collaboration to the 35th International Cosmic Ray Conference (ICRC 2017),
12-20 July 2017, Bexco, Busan, Korea.",27,2,190,18.69
265,astrophysics,"The rapid neutron-capture process needed to build up many of the elements
heavier than iron seems to take place primarily in neutron-star mergers, not
supernova explosions.",26,2,172,36.63
266,astrophysics,"This paper describes how commercially available spectrographs can be used to
identify and measure some basic characteristics of planetary nebulae.",20,2,146,17.34
267,astrophysics,"In this chapter, I present the main X-ray observational characteristics of
black-hole binaries and low magnetic field neutron-star binaries, concentrating
on what can be considered similarities or differences, with particular emphasis
on their fast-timing behaviour.",35,2,266,-6.36
268,astrophysics,"A brief overview of the importance of photodisintegration reactions in
astrophysical environments is given and the relevance of photonuclear
experiments for nucleosynthesis studies is discussed.",25,2,194,-13.13
269,astrophysics,"Gamma-ray bursts (GRBs) and supernovae (SNe) bring new perspectives to the
study of neutron stars and white dwarfs, as well as opening new branches of
theoretical physics and astrophysics.",29,2,188,50.5
270,astrophysics,"The efficiency of the Kolmogorov-Arnold technique for the astrophysical
signals is studied modeling sequences with both random and regular properties.
This technique has been applied to the study of the structures in cosmic
microwave background maps obtained by the Wilkinson Microwave Anisotropy Probe.",43,3,303,41.19
271,astrophysics,"We briefly present the history of technical solutions aimed at improving the
efficiency of spectroscopy on small- and moderate-diameter telescopes. We
assess the current state of spectroscopy techniques and some of the
perspectives.",33,3,232,37.81
272,astrophysics,"After a brief reminder on the electromagnetic properties of neutrinos, the
main processes of the electromagnetic interactions of neutrinos in astrophysics
and the corresponding limitations on millicharges and effective magnetic
moments of the particle are discussed.",36,2,266,-7.37
273,astrophysics,"This whitepaper focuses on the astrophysical systematics which are
encountered in dark matter searches. Oftentimes in indirect and also in direct
dark matter searches, astrophysical systematics are a major limiting factor to
sensitivity to dark matter. Just as there are many forms of dark matter
searches, there are many forms of backgrounds. We attempt to cover the major
systematics arising in dark matter searches using photons -- radio and gamma
rays -- to cosmic rays, neutrinos and gravitational waves. Examples include
astrophysical sources of cosmic messengers and their interactions which can
mimic dark matter signatures. In turn, these depend on commensurate studies in
understanding the cosmic environment -- gas distributions, magnetic field
configurations -- as well as relevant nuclear astrophysics. We also cover the
astrophysics governing celestial bodies and galaxies used to probe dark matter,
from black holes to dwarf galaxies. Finally, we cover astrophysical backgrounds
related to probing the dark matter distribution and kinematics, which impact a
wide range of dark matter studies. In the future, the rise of multi-messenger
astronomy, and novel analysis methods to exploit it for dark matter, will offer
various strategic ways to continue to enhance our understanding of
astrophysical backgrounds to deliver improved sensitivity to dark matter.",203,10,1371,23.66
274,astrophysics,"We develop and present a geometrical and an analytical derivation of the
equation of hydrostatic equilibrium in spherically symmetric stars with a
generalized stress tensor. The analytical derivation is based on the
Navier-Cauchy equation. We also critically examine the derivation of this
equation found in textbooks on stellar astrophysics and show that there are
errors in many of the derivations presented in textbooks.",63,4,423,33.24
275,astrophysics,"Astrophysical polarization measurements provide some of the strongest
constraints on the photon sector of the non-minimal Standard-Model Extension.
This paper reviews some recent results obtained by combining optical linear and
circular polarization data from a large number of astrophysical objects.",40,3,300,8.88
276,astrophysics,"This proceeding contribution is a short summary of the invited talk about
observational supernova science at Stockholm University that has been conducted
at the Nordic Optical Telescope over the past 25 years, and some expectations
for the future.",38,2,247,15.99
277,astrophysics,"Randomly oriented flattened spheroids have been used to describe a broad
range of astrophysical phenomena. Here we use this geometric approach to derive
equations representing lines of sight through quasar absorption clouds to
constrain cloud sizes.",36,3,249,44.75
278,astrophysics,"Fifty years on from the first detailed chemical kinetic modelling of
astronomical sources, I provide some introductory comments on the history of
astrochemistry, summarise some personal views on the topics covered in this
discussion meeting, and conclude with some thoughts on its future development.
I have left out the jokes.",50,3,327,37.64
279,astrophysics,"Most tests of general relativity with gravitational-wave observations rely on
inferring the degree to which a signal deviates from general relativity in
conjunction with the astrophysical parameters of its source, such as the
component masses and spins of a compact binary. Due to features of the signal,
measurements of these deviations are often highly correlated with the
properties of astrophysical sources. As a consequence, prior assumptions about
astrophysical parameters will generally affect the inferred magnitude of the
deviations. Incorporating information about the underlying astrophysical
population is necessary to avoid biases in the inference of deviations from
general relativity. Current tests assume that the astrophysical population
follows an unrealistic fiducial prior chosen to ease sampling of the posterior
-- for example, a prior flat in component masses -- which is is inconsistent
with both astrophysical expectations and the distribution inferred from
observations. We propose a framework for fortifying tests of general relativity
by simultaneously inferring the astrophysical population using a catalog of
detections. Although this method applies broadly, we demonstrate it concretely
on massive graviton constraints and parameterized tests of deviations to the
post-Newtonian phase coefficients. Using observations from LIGO-Virgo-KAGRA's
third observing run, we show that concurrent inference of the astrophysical
distribution strengthens constraints and improves overall consistency with
general relativity. We provide updated constraints on deviations from the
theory, finding that, upon modeling the astrophysical population, the
90\%-credible upper limit on the mass of the graviton improves by $25\%$ to
$m_g \leq 9.6 \times 10^{-24}\, \mathrm{eV}/c^2$ and the inferred
population-level post-Newtonian deviations move ${\sim} 0.4 \sigma$ closer to
zero.",259,12,1893,5.42
280,astrophysics,"Astrophysical neutrinos allow us to access energies and baselines that cannot
be reached by human-made accelerators, offering unique probes of new physics
phenomena. This thesis aims to address the challenges currently facing searches
for Beyond Standard Model (BSM) physics in the high-energy universe using
astrophysical neutrinos, particularly in the contexts of flavor measurements
and connections with dark matter.",58,3,419,16.66
281,astrophysics,"Astrophysics is gaining increased attention from the particle and nuclear
physics communities, as budget cuts, delays, and cancellations limit
opportunities for breakthrough research at accelerator laboratories.
Observations of cosmic rays (protons and nuclei), gamma rays and neutrinos
present a variety of puzzles whose eventual solution will shed light on many
issues ranging from the nature of fundamental interactions at extreme energies
to the mechanisms of astrophysical sources. Several important detectors are
just beginning full-scale operation and others are beginning construction.",80,4,593,10.53
282,astrophysics,"To understand their data better, astronomers need to use statistical tools
that are more advanced than traditional ``freshman lab'' statistics. As an
illustration, the problem of combining apparently incompatible measurements of
a quantity is presented from both the traditional, and a more sophisticated
Bayesian, perspective. Explicit formulas are given for both treatments. Results
are shown for the value of the Hubble Constant, and a 95% confidence interval
of 66 < H0 < 82 (km/s/Mpc) is obtained.",76,5,502,35.78
283,astrophysics,"Helioseismology has provided very precise information about the solar
internal sound speed and density throughout most of the solar interior. The
results are generally quite close to the properties of standard solar models.
Since the solar oscillation frequencies do not provide direct information about
temperature and composition, the helioseismic results to not completely rule
out an astrophysical solution to the discrepancy between the predicted and
measured neutrino fluxes from the Sun. However, such a solution does appear
rather implausible.",79,5,551,17.54
284,astrophysics,"The interior of gravitationally collapsed objects in alternate theories of
gravity in which event horizons and singularities do not occur in strong field
gravity were generically investigated. These objects, called red holes, were
found to contain dynamic configurations of matter, radiation and spacetime
similar to inside out accretion disks well inside the photon orbit.
Applications to astrophysical phenomena are briefly described.",61,4,436,17.03
285,astrophysics,"We present an empirical calibration of the uvby-beta photometric system to
determine the intrinsic colours and indices and the astrophysical parameters of
the underlying star, valid for Be stars earlier than B5. The procedure allows
the determination of the interstellar reddening with an accuracy of 0.033 mag.
(rms), and the absolute magnitude with an accuracy of 0.7 mag.",58,6,374,26.51
286,astrophysics,"In the summer of the year 2000, a NASA Small Explorer satellite, the High
Energy Solar Spectroscopic Imager (HESSI), will be launched. It will consist of
nine large, coaxial germanium detectors viewing the Sun through a set of
Rotation Modulation Collimators and will accomplish high-resolution imaging and
spectroscopy of solar flares in the x-ray and gamma-ray bands. Here we describe
some of the astrophysical observations HESSI will also perform in addition to
its solar mission.",75,4,483,37.64
287,astrophysics,"Astrophysical sources of gravitational radiation are likely to have been
formed since the beginning of star formation. Realistic source rates of
formation throughout the Universe have been estimated from an observation-based
determination of the star formation rate density evolution. Both the radiation
emitted during the collapse to black holes and the spin-down radiation, induced
by the r-mode instability, emitted by hot, young rapidly rotating neutron stars
have been considered. We have investigated the overall signal produced by the
ensemble of sources exploring the parameter space and discussing its possible
detectability.",90,5,634,23.26
288,astrophysics,"The role of hydrodynamic mixing in astrophysics is reviewed, emphasizing
connections with laser physics experiments and inertial confinement fusion
(ICF). Computer technology now allows two dimensional (2D) simulations, with
complex microphysics, of stellar hydrodynamics and evolutionary sequences, and
holds the promise for 3D. Careful validation of astrophysical methods, by
laboratory experiment, by critical comparison of numerical and analytical
methods, and by observation are necessary for the development of simulation
methods with reliable predictive capability. Recent and surprising results from
isotopic patterns in presolar grains, 2D hydrodynamic simulations of stellar
evolution, and laser tests and computer simulations of Richtmeyer-Meshkov and
Rayleigh-Taylor instabilities are discussed, and related to stellar evolution
and supernovae.",110,5,856,-7.21
289,astrophysics,"A general overview of neutrino physics and astrophysics is given, starting
with a historical account of the development of our understanding of neutrinos
and how they helped to unravel the structure of the Standard Model. We discuss
why it is so important to establish if neutrinos are massive and introduce the
main scenarios to provide them a mass. The present bounds and the positive
indications in favor of non-zero neutrino masses are discussed, including the
recent results on atmospheric and solar neutrinos. The major role that
neutrinos play in astrophysics and cosmology is illustrated.",94,5,596,30.7
290,astrophysics,"I present the analysis of data of astrophysical polarimetric observations
that gives the signature of the fundamental extra dimension Planck scale
magnitude essentially higher than $~1TeV$. Magnetic conversion of photons into
the fundamental particles (scalars, gravitons) is the probable mechanism that
can produce noticeable amount of polarization of optical radiation of
astrophysical objects, especially, of distant extragalactic sources. The
results of magnetic conversion process of optical light of extragalactic
sources are presented for a number of situations including: (a) intergalactic
magnetic field, (b) galaxy cluster magnetic field, (c) magnetic conversion in
the typical galaxy magnetic field, (d) magnetic conversion of CMB radiation.",102,4,752,-5.34
291,astrophysics,"Interfaces between high-energy physics, astrophysics and cosmology are
reviewed, with particular emphasis on the important roles played by high-energy
cosmic-ray physics. These include the understanding of atmospheric neutrinos,
the search for massive cold dark matter particles and possible tests of models
of quantum gravity. In return, experiments at the LHC may be useful for
refining models of ultra-high-energy cosmic rays, and thereby contributing
indirectly to understanding their origin. Only future experiments will be able
to tell whether these are due to some bottom-up astrophysical mechanism or some
top-down cosmological mechanism.",90,5,646,14.8
292,astrophysics,"The great success of the Rossi X-Ray Timing Explorer (RXTE) has shown that
X-ray timing is an excellent tool for the study of strong gravitational fields
and the measurement of fundamental physical properties of black holes and
neutron stars. Here, we describe a next-generation X-ray timing mission, the
Relativistic Astrophysics Explorer (RAE), designed to fit within the envelope
of a medium-sized mission. The instruments will be a narrow-field X-ray
detector array with an area of 6 m^2 equal to ten times that of RXTE and a
wide-field X-ray monitor. We describe the science made possible with this
mission, the design of the instruments, and results on prototype large-area
X-ray detectors.",110,5,696,43.56
293,astrophysics,"In the nuclear and particle astrophysics session of CIPANP 2003 we heard
talks on a number of topics, focused for the most part into four broad areas.
Here we outline the discussions of the standard cosmological model, dark matter
searches, cosmic rays, and neutrino astrophysics. The robustness of theoretical
and experimental programs in all of these areas is very encouraging, and we
expect to have many questions answered, and new ones asked, in time for CIPANP
2006.",77,4,471,45.39
294,astrophysics,"On examining the historical development of astrophysical science at the
bottom of the world from the early 20th century until today we find three
temporally overlapping eras of which each has a rather distinct beginning.
These are the eras of Astrogeology, High Energy Astrophysics and Photon
Astronomy. A full version of this paper will be submitted to PASA.",58,4,359,34.97
295,astrophysics,"This review describes telescopes designed to study neutrinos from
astrophysical sources. These sources include the Sun and Supernovae emitting
neutrino energies up to tens of MeV, atmospheric neutrino sources caused by
cosmic ray interactions and other sources generating neutrino energies ranging
up to $1\times 10^{20}$ eV. Measurements with these telescopes also provide
information on neutrino properties including clear evidence for neutrino flavor
change. Telescopes in operation in the past and present are described, along
with plans for future instruments to expand this rapidly growing field of
particle astrophysics.",88,5,627,32.22
296,astrophysics,"Among early-type galaxies with almost circular isophotes E0 and E1 galaxies
are, at 99.3% significance, more luminous than face-on objects classified as S0
(0) and S(0) (1). This result supports the view that rotation and ""diskiness""
are more important in the outer regions of faint-early type galaxies than they
are for more luminous galaxies of very early morphological type.",59,4,377,43.02
297,astrophysics,"We briefly discuss a handful of topics in pulsar astrophysics, first some
general well-known features, then an overview of the glitch phenomenon and the
sort of information gathered about the internal structure and dynamics, and
finally the quandary posed by the precession of PSR B1828-11 a very important
clue pointing towards a novel paradigm for structure of the core regions. We
point out that ""exotic"" solutions for the precession puzzle would force a
consideration of exotic {\it glitch} mechanisms as well.",81,3,514,30.37
298,astrophysics,"Some nuclear and astrophysical aspects of the r-process are discussed.
Particular attention is paid to observations of abundances in metal-poor stars
and their implications for the astrophysical site and yield patterns of the
r-process. The effects of supernova neutrinos and related nuclear processes on
the yield patterns are explored. The uncertainties in the theoretical nuclear
input for the r-process are discussed and the need for experimental data is
emphasized.",69,5,470,28.54
299,astrophysics,"I review several ongoing connections between space physics and astrophysics:
a) Measurements of energetic particle spectra have confirmed theoretical
prediction of the highest energy to which shocks can accelerate particles, and
this has direct bearing on the origin of the highest energy cosmic rays. b)
Mass ejection in solar flares may help us understand photon ejection in the
giant flares of magnetar outbursts. c) Measurements of electron heat fluxes in
the solar wind can help us understand whether heat flux in tenuous
astrophysical plasma is in accordance with the classical Spitzer-Harm formula
or whether it is reduced well below this value by plasma instabilities.",104,4,676,19.33
300,astrophysics,"The nonlinear propagation of low-frequency circularly polarized waves in a
magnetized dusty plasma is analyzed. It is found that wave steepening and shock
formation can take place due to the presence of nonlinear quantum vacuum
effects, thus giving rise to ultra-intense electromagnetic shocks. Moreover, it
is shown that solitary wave structures are admitted even under moderate
astrophysical conditions. The results may have applications to astrophysical
plasmas, as well as next generation laser interactions with laboratory plasmas
containing dust clusters.",79,5,561,26.0
301,astrophysics,"While the origin of r-process nuclei remains a long-standing mystery, recent
spectroscopic studies of extremely metal-poor stars in the Galactic halo
strongly suggest that it is associated with core-collapse supernovae. In this
article, an overview of the recent theoretical studies of the r-process is
presented with a special emphasis on the astrophysical scenarios related to
core-collapse supernovae. We also review a recent progress of the Galactic
chemical evolution studies as well as of the spectroscopic studies of extremely
metal-poor halo stars, which provide us important clues to better understanding
of the astrophysical r-process site.",94,4,650,14.33
302,astrophysics,"We study the possibility of evading astrophysical bounds on light
pseudoscalars. We argue that the solar bounds can be evaded if we have a
sufficiently strong self coupling of the pseudoscalars. The required couplings
do not conflict with any known experimental bounds. We show that it is possible
to find a coupling range such that the results of the recent PVLAS experiment
are not in conflict with any astrophysical bounds.",70,5,426,62.17
303,astrophysics,"In addition to study extragalactic stellar populations in their integrated
light, the detailed analysis of individual resolved objects has become
feasible, mainly for luminous giant stars and for extragalactic planetary
nebulae (XPNe) in nearby galaxies. A recently started project at the
Astrophysical Institute Potsdam (AIP), called ``XPN--Physics'', aims to verify
if XPNe are useful probes to measure the chemical abundances of their parent
stellar population. The project involves theoretical and observational work
packages.",73,4,530,12.97
304,astrophysics,"We discuss astrophysical scenarios relevant to the generation of
gravitational waves (GW) and effects expected to arise from the interaction of
GW and electromagnetic (EM) radiation. A strong programme of coordinated GW and
EM astrophysical studies must be established in order to ensure the
exploitation of the full scientific potential of the LISA mission. We describe
on-going astrophysical work, and suggest alternative approaches to current
studies, which are relevant to these considerations.",72,4,498,13.28
305,astrophysics,"We consider the acceleration of energetic particles by Fermi processes (i.e.,
diffusive shock acceleration, second order Fermi acceleration, and gradual
shear acceleration) in relativistic astrophysical jets, with particular
attention given to recent progress in the field of viscous shear acceleration.
We analyze the associated acceleration timescales and the resulting particle
distributions, and discuss the relevance of these processes for the
acceleration of charged particles in the jets of AGNs, GRBs and microquasars,
showing that multi-component powerlaw-type particle distributions are likely to
occur.",82,5,613,-7.0
306,astrophysics,"We review recent PIC simulation results which show that double-sided
irradiation of a thin over-dense plasma slab with ultra-intense laser pulses
from both sides can lead to sustained comoving Poynting flux acceleration of
electrons to energies much higher than the conventional ponderomotive limit.
The result is a robust power-law electron momentum spectrum similar to
astrophysical sources. We discuss future ultra-intense laser experiments that
may be used to simulate astrophysical particle acceleration.",71,4,509,13.58
307,astrophysics,"The past few years have seen dramatic breakthroughs and spectacular and
puzzling discoveries in astrophysics and cosmology. In many cases, the new
observations can only be explained with the introduction of new fundamental
physics. Here we summarize some of these recent advances. We then describe
several problem in astrophysics and cosmology, ripe for major advances, whose
resolution will likely require new physics.",62,5,419,38.82
308,astrophysics,"High energy neutrinos with energy typically greater than tens of thousands of
GeV may originate from several astrophysical sources. The sources may include,
for instance, our galaxy, the active centers of nearby galaxies, as well as
possibly the distant sites of gamma ray bursts. I briefly review some aspects
of production and propagation as well as prospects for observations of these
high energy astrophysical neutrinos.",65,4,424,40.99
309,astrophysics,"Selected topics in neutrino astrophysics are reviewed. These include the
production of low energy neutrino flux from cores of collapsing stars and the
expected high energy neutrino flux from some other astrophysical sites such as
the galactic plane as well as the center of some distant galaxies. The expected
changes in these neutrino fluxes because of neutrino oscillations during their
propagation to us are described. Observational signatures for these neutrino
fluxes with and without neutrino oscillations are discussed.",78,5,526,34.76
310,astrophysics,"Photon-induced reactions during the astrophysical p- (or gamma-) process
occur at typical temperatures of 1.8 < T9 < 3.3. Experimental data of
(gamma,n), (gamma,p), or (gamma,alpha) reactions - if available in the relevant
energy region - cannot be used directly to measure astrophysical (gamma,n),
(gamma,p), or (gamma,alpha) reaction rates because of the thermal excitation of
target nuclei at these high temperatures. Usually, statistical model
calculations are used to predict photon-induced reaction rates. The relations
between experimental reaction cross sections, theoretical predictions, and
astrophysical reaction rates will be critically discussed.",89,7,659,11.92
311,astrophysics,"Effective astrophysical factors for non-resonant astrophysical nuclear
reaction are invariably calculated with respect to a zero energy limit. In the
present work that limit is shown to be very disadvantageous compared to the
more natural effective energy limit. The latter is used in order to modify the
thermonuclear reaction rate formula so that it takes into account both plasma
and laboratory screening effects.",63,4,416,16.32
312,astrophysics,"Nuclear structure data are of crucial importance in order to address
important astrophysical problems such as the origin of chemical elements, the
inner working of our Sun, and the evolution of stars. We demonstrate this by
investigating the ground state structure of $^8$B and $^7$Be nuclei within the
Skyrme Hartree-Fock framework and by calculating the overlap integral of $^8$B
and $^7$Be wave functions. The latter is used to calculate the astrophysical S
factor ($S_{17}$) for the solar fusion reaction $^{7}$Be($p, \gamma)^{8}$B.",81,4,536,35.61
313,astrophysics,"The Trojan Horse (TH) method is a powerful indirect technique that provides
information to determine astrophysical factors for rearrangement processes at
astrophysically relevant energies. A short coming for understanding the
reliability of the technique has been determining the importance of nuclear and
Coulomb effects on the energy dependence of the yield. Using a simple model, we
demonstrate that off-energy-shell and Coulomb effects in the entry channel and
the final state nuclear interactions do not change the energy dependence of the
astrophysical factor extracted from the TH reaction. Some examples are
presented.",91,5,626,22.95
314,astrophysics,"Precise nuclear reaction rates are needed for a detailed description of the
production of elements in primordial nucleosynthesis and during the hydrostatic
burning of stars to constrain the astrophysical models. The relevant reactions
are extremely difficult to measure directly in the laboratory at the small
astrophysical energies. In recent years direct reactions methods have been
developed and applied to extract low-energy astrophysical S factors. The
application of these methods requires a combination of experimental and
theoretical efforts. This contribution focuses on the underlying reaction
theories that have to be well understood in order to assess the precision and
limitations of the various approaches.",103,6,720,8.27
315,astrophysics,"The measurement of the flavor composition of the neutrino fluxes from
astrophysical sources has been proposed as a method to study not only the
nature of their emission mechanisms, but also the neutrino fundamental
properties. It is however problematic to reconcile these two goals, since a
sufficiently accurate understanding of the neutrino fluxes at the source is
needed to extract information about the physics of neutrino propagation. In
this work we discuss critically the expectations for the flavor composition and
energy spectrum from different types of astrophysical sources, and comment on
the theoretical uncertainties connected to our limited knowledge of their
structure.",102,4,685,11.59
316,astrophysics,"We study the possibility of evading astrophysical bound on light
pseudoscalars. We argue that the solar bounds can be evaded if we have a
sufficiently strong self-coupling of the pseudoscalars. The required coupling
does not conflict with any known experimental bounds. We also show that it is
possible to find a coupling range such that the recent PVLAS experiment is not
in conflict with any astrophysical bounds.",67,5,415,54.42
317,astrophysics,"This is a written version of a series of lectures aimed at undergraduate
students in astrophysics/particle theory/particle experiment. We summarize the
important progress made in recent years towards understanding high energy
astrophysical processes and we survey the state of the art regarding the
concordance model of cosmology.",47,3,330,13.78
318,astrophysics,"Recently wide publicity has been given to a claim by T. Vachaspati that
""black holes do not exist"", that the objects known as black holes in
astrophysics should rather be called ""black stars"" and they not only do not
have event horizons but actually can be the source of spectacular gamma ray
bursts. In this short essay (no flimsier than the original preprint where these
extravagant claims appeared) I demonstrate that these ill-considered claims are
clearly wrong. Yet they present a good occasion to reflect on some well known
but little discussed conceptual difficulties which arise when applying
relativistic terminology in an astrophysical context.",104,5,655,45.09
319,astrophysics,"We generalize the Maximum Likelihood-type method used to study cross
correlations between a catalog of candidate astrophysical sources and Ultrahigh
Energy Cosmic Rays (UHECRs), to allow for differing source luminosities. The
new method is applicable to any sparse data set such as UHE gamma rays or
astrophysical neutrinos. Performance of the original and generalized techniques
is evaluated in simulations of various scenarios. Applying the new technique to
data, we find an excess correlation of about 9 events between HiRes UHECRs and
known BLLacs, with a 6*10^-5 probability of such a correlation arising by
chance.",94,5,620,30.7
320,astrophysics,"The idea of this work is to compare a new positive and entropy stable
approximate Riemann solver by Francois Bouchut with a state-of the-art
algorithm for astrophysical fluid dynamics. We implemented the new Riemann
solver into an astrophysical PPM-code, the Prometheus code, and also made a
version with a different, more theoretically grounded higher order algorithm
than PPM. We present shock tube tests, two-dimensional instability tests and
forced turbulence simulations in three dimensions. We find subtle differences
between the codes in the shock tube tests, and in the statistics of the
turbulence simulations. The new Riemann solver increases the computational
speed without significant loss of accuracy.",106,6,714,33.04
321,astrophysics,"We propose a new method for determination of element abundances in stellar
atmospheres aimed for the automatic processing of high-quality stellar spectra.
The pan-spectral method is based on weighted cumulative line-widths Q of
studied element. Difference in quantities Q found from synthetic and observed
spectra gives a correction to the initial abundance. Final abundances are then
found by rapidly converging iterations. Calculations can be made for many
elements simultaneously and do not demand supercomputers.",74,6,516,31.07
322,astrophysics,"Searches for transient astrophysical pulses could open an exciting new window
into the fundamental physics of quantum gravity. In particular, an evaporating
primordial black hole in the presence of an extra dimension can produce a
detectable transient pulse. Observations of such a phenomenon can in principle
explore the electroweak energy scale, indicating that astrophysical probes of
quantum gravity can successfully complement the exciting new physics expected
to be discovered in the near future at the Large Hadron Collider.",78,4,531,19.71
323,astrophysics,"We review the spectral properties of stochastic backgrounds of astrophysical
origin and discuss how they may differ from the primordial contribution by
their statistical properties. We show that stochastic searches with the next
generation of terrestrial interferometers could put interesting constrains on
the physical properties of astrophysical populations, such as the ellipticity
and magnetic field of magnetars, or the coalescence rate of compact binaries.",64,3,462,5.16
324,astrophysics,"Gravitational N-body simulations, that is numerical solutions of the
equations of motions for N particles interacting gravitationally, are widely
used tools in astrophysics, with applications from few body or solar system
like systems all the way up to galactic and cosmological scales. In this
article we present a summary review of the field highlighting the main methods
for N-body simulations and the astrophysical context in which they are usually
applied.",70,3,461,19.03
325,astrophysics,"The relevant gamma energy range is explicitly identified where additional
gamma$ strength has to be located for having an impact on astrophysically
relevant reactions. It is shown that folding the energy dependences of the
transmission coefficients and the level density leads to maximal contributions
for gamma energies of 2<=E_gamma<=4 MeV unless quantum selection rules allow
isolated states to contribute. Under this condition, electric dipole
transitions dominate. These findings allow to more accurately judge the
relevance of modifications of the \gamma strength for astrophysics.",83,5,587,16.52
326,astrophysics,"The aim of our paper is to make high-precision positional stellar catalogs by
compiling large astrophysical data bulk and large astrometrical surveys. The
data reliability and uniqueness is the primary request. The common precision of
1 arc sec in coordinates is insufficient now to guarantee the simple
identification of stars. Therefore the technique of catalogs verification
become relevant. The paper presents the outcome of stars identification in The
Henry Draper Extension Charts catalog and Variable stars catalog using proper
method. Examples of conflicts permission concerning doubles and multiples stars
in astrophysical catalogs are discussed.",94,7,655,21.7
327,astrophysics,"We review the free parameters in the concordance cosmology, and those which
might be added to this set as the quality of astrophysical data improves. Most
concordance parameters encode information about otherwise unexplored aspects of
high energy physics, up to the GUT scale via the ""inflationary sector,"" and
possibly even the Planck scale in the case of dark energy. We explain how
neutrino properties may be constrained by future astrophysical measurements.
Conversely, future neutrino physics experiments which directly measure these
parameters will remove uncertainty from fits to astrophysical data, and improve
our ability to determine the global properties of our universe.",101,5,682,20.42
328,astrophysics,"The paper is devoted to the prospects of using the laser radiation
interaction with plasmas in the laboratory relativistic astrophysics context.
We discuss the dimensionless parameters characterizing the processes in the
laser and astrophysical plasmas and emphasize a similarity between the laser
and astrophysical plasmas in the ultrarelativistic energy limit. In particular,
we address basic mechanisms of the charged particle acceleration, the
collisionless shock wave and magnetic reconnection and vortex dynamics
properties relevant to the problem of ultrarelativistic particle acceleration.",80,4,597,-6.4
329,astrophysics,"This white paper briefly describes the astrophysics of ultra-compact
binaries, with emphasis of the challenges and opportunities in the next decade.",21,2,148,33.24
330,astrophysics,"We highlight recent theoretical and observational progress in several areas
of neutron star astrophysics, and discuss the prospect for advances in the next
decade.",24,2,163,30.2
331,astrophysics,"The durations of 388 gamma-ray bursts, detected by the Swift satellite, are
studied statistically in order to search for their subgroups. Then the results
are compared with the results obtained earlier from the BATSE database. The
standard chi^2 test is used. Similarly to the BATSE database, the short and
long subgroups are well detected also in the Swift data. Also the intermediate
subgroup is seen in the Swift database. The whole sample of 388 GRBs gives a
support for three subgroups.",81,7,491,66.23
332,astrophysics,"These lectures are intended to provide a brief pedagogical review of dark
matter for the newcomer to the subject. We begin with a discussion of the
astrophysical evidence for dark matter. The standard weakly-interacting massive
particle (WIMP) scenario--the motivation, particle models, and detection
techniques--is then reviewed. We provide a brief sampling of some recent
variations to the standard WIMP scenario as well as some alternatives (axions
and sterile neutrinos). Exercises are provided for the reader.",75,6,514,30.87
333,astrophysics,"We consider astrophysical objects such as main-sequence stars, white-dwarfs
and neutron stars in a noncommutative context. Noncommutativity is implemented
via a deformed dispersion relation $E^{2}=p^{2}c^{2}(1+\lambda
E)^{2}+m^{2}c^{4}$ from which we obtain noncommutative corrections to the
pressure, particle number and energy densities for radiation and for a
degenerate fermion gas. The main implications of noncommutativity for the
considered astrophysical objects are examined and discussed.",62,4,497,-0.31
334,astrophysics,"Relativistic shocks are usually thought to occur in violent astrophysical
explosions. These collisionless shocks are mediated by a plasma kinetic
streaming instability, often loosely referred to as the Weibel instability,
which generates strong magnetic fields ""from scratch"" very efficiently. In this
review paper we discuss the shock micro-physics and present a recent model of
""pre-conditioning"" of an initially unmagnetized upstream region via the
cosmic-ray-driven Weibel-type instability.",66,4,494,6.84
335,astrophysics,"On the occasion of the International Year of Astronomy (IYA2009), we present
a new interactive dictionary of astronomy and astrophysics, which contains
about 7000 entries. This interdisciplinary and multicultural work is intended
for professional and amateur astronomers, university students in astrophysics,
as well as terminologists and linguists. A new approach is pursued in the
formation of a scientific dictionary, which aims to display additional
dimensions of astronomical concepts. Although Virtual Observatories recognize
the necessity of efforts to define basic astronomical concepts and establish
their reciprocal relations, so far they have mainly been confined to archiving
observational data. The present dictionary could be an incipient contribution
to cover and inter-relate the whole astronomical lexicon beyond subfields.",115,6,840,5.83
336,astrophysics,"Future ground-based and space-borne interferometric gravitational-wave
detectors may capture between tens and thousands of binary coalescence events
per year. There is a significant and growing body of work on the estimation of
astrophysically relevant parameters, such as masses and spins, from the
gravitational-wave signature of a single event. This paper introduces a robust
Bayesian framework for combining the parameter estimates for multiple events
into a parameter distribution of the underlying event population. The framework
can be readily deployed as a rapid post-processing tool.",83,5,592,16.52
337,astrophysics,"Dark matter has been introduced to explain many independent gravitational
effects at different astronomical scales, in galaxies, groups of galaxies,
clusters, superclusters and even across the full horizon. This review describes
the accumulated astronomical, astrophysical, and cosmological evidence for dark
matter. It is written at a non-specialist level and intended for an audience
with little or only partial knowledge of astrophysics or cosmology.",63,4,453,16.32
338,astrophysics,"We present a new code, CASTRO, that solves the multicomponent compressible
hydrodynamic equations for astrophysical flows including self-gravity, nuclear
reactions and radiation. CASTRO uses an Eulerian grid and incorporates adaptive
mesh refinement (AMR). Our approach to AMR uses a nested hierarchy of
logically-rectangular grids with simultaneous refinement in both space and
time. The radiation component of CASTRO will be described in detail in the next
paper, Part II, of this series.",71,5,490,28.03
339,astrophysics,"Extreme star formation includes star formation in starbursts and regions
forming super star clusters. We survey the current problems in our
understanding of the star formation process in starbursts and super star
clusters - initial mass functions, cluster mass functions, star formation
efficiencies, and radiative feedback into molecular clouds - that are critical
to our understanding of the formation and survival of large star clusters,
topics that will be the drivers of the observations of the next decade.",78,3,512,24.45
340,astrophysics,"We measure the recoil velocity as a function of spin for equal-mass,
highly-spinning black-hole binaries, with spins in the orbital plane, equal in
magnitude and opposite in direction. We confirm that the leading-order effect
is linear in the spin and the cosine of angle between the spin direction and
the infall direction at merger. We find higher-order corrections that are
proportional to the odd powers in both the spin and cosine of this angle.
Taking these corrections into account, we predict that the maximum recoil will
be 3680+-130 km/s.",89,5,548,48.84
341,astrophysics,"A systematic multiple hypothesis testing approach is applied to the search
for astrophysical sources of high energy neutrinos. The method is based on the
maximisation of the detection power maintaining the control of the confidence
level of an hypothetical discovery. This is achieved by using the so-called
""False Discovery Rate"" (FDR) controlling procedure. It has the advantage to be
independent of the signal modelling and to naturally take into account the
trial factor. Moreover it is well suited to the detection of multiple sources.",84,6,540,37.5
342,astrophysics,"I describe the various elements of the NASA Science Mission Directorate's
Astrophysics Division Research and Analysis Program and provide quantitative
descriptions for factors such as proposal submission characteristics, proposal
success rates, distribution of science areas for selected proposals, as well as
funding distributions for the various program elements. I examine the variation
of these factors with time to explore possible trends. The measures described
here can be used as starting points for future discussions about issues related
to balance within the astronomy and astrophysics research and analysis program.",88,4,627,16.36
343,astrophysics,"An astrophysical MASER (Microwave Amplification by Stimulated Emission of
Radiation) is a source of stimulated spectral line emission. Maser emission is
observed from the circumstellar envelopes of evolved stars, molecular
clouds/star-forming regions, active galactic nuclei, supernova remnants,
comets, and the Saturnian moons. It arises from molecules such as water (H2O),
hydroxyl radicals (OH), methanol (CH3OH), formaldehyde (CH2O), silicon monoxide
(SiO), ammonia (NH3), silicon sulphide (SiS), hydrogen cyanide (HCN), and from
atomic hydrogen recombination lines. Masers are compact, of high brightness
temperature, and often display narrow spectral line widths, polarized emission
and variability. Free electron-cyclotron astrophysical masers additionally
exist.",98,6,770,17.74
344,astrophysics,"We investigate the synchrotron emission (both intensity and morphology)
associated with generic dark matter particles and make predictions for the
PLANCK experiment using the FERMI data and a model for the astrophysical
sources. Our results indicate that the morphology of the dark matter plus
astrophysical source synchrotron emission is frequency-dependent. We show that
a thorough comparison between LFI and HFI data can potentially provide a new
tool for constraining the dark matter particle mass.",74,4,502,21.02
345,astrophysics,"A significant part of observations by Russian 6-m telescope is carried out
using SCORPIO multi-mode focal reducer. A lot of scientific data have been
collected using observations in direct imaging, slit spectroscopy and
Fabry-Perot interferometry modes during the past ten years. Some results of
these observations are considered in this review. We are also present a short
description of a new generation instrument named SCORPIO-2.",65,5,433,38.01
346,astrophysics,"Past and ongoing research activities at the Heidelberg heavy-ion storage-ring
TSR are reviewed which aim at providing accurate absolute rate coefficients and
cross sections of atomic collision processes for applications in astrophysics
and magnetically confined fusion. In particular, dielectronic recombination and
electron impact ionization of iron ions are discussed as well as dielectronic
recombination of tungsten ions.",57,3,425,0.25
347,astrophysics,"We present an analytical unified representation for 22 equations of state
(EoS) of dense matter in neutron stars. Such analytical representations can be
useful for modeling neutron star structure in modified theories of gravity with
high order derivatives.",38,3,256,26.81
348,astrophysics,"This online book contains the proceedings of a meeting on ""RR Lyrae Stars,
Metal-Poor Stars, and the Galaxy"" held at the Carnegie Observatories, Pasadena,
California, in January 2011. The purpose of the scientific meeting was to honor
the 80th year of our colleague, George W. Preston III.
  The book comprises the 5th volume of the Carnegie Observatories Astrophysics
Series. In addition to links for each arXiv article I also include links to
download the entire volume, free of charge.",79,6,488,51.38
349,astrophysics,"For the synthesis of the heavy, proton rich isotopes in the astrophysical
gamma-process the precise knowledge of alpha-induced cross sections is of high
importance. We have initiated a comprehensive study of the 64Zn+alpha system
involving the cross section measurement of different reaction channels as well
as the elastic scattering at low, astrophysically relevant energies. In this
paper the experimental technique and some preliminary results of the
64Zn(alpha,p)67Ga cross section measurement are presented.",72,4,513,21.74
350,astrophysics,"We present a working prototype of YouASTRO (www.youastro.org), a web-based
BibTeX-compliant reference management software (RMS) for astrophysical papers
in the SAO/NASA ADS database. It also includes as a main feature the concept of
distributed paper comments and ratings. In these paper, we introduce the main
characteristics of the web application, and we will briefly discuss what could
be the advantages and drawbacks of such a system being widespread adopted by
the astrophysical community for its scientific literature.",77,6,525,34.97
351,astrophysics,"A multi-messenger approach with gravitational-wave transients and high-energy
neutrinos is expected to open new perspectives in the study of the most violent
astrophysical processes in the Universe. In particular, gamma-ray bursts are of
special interest as they are associated with astrophysical scenarios predicting
significant joint emission of gravitational waves and high-energy neutrinos.
Several experiments (e.g. ANTARES, IceCube, LIGO and Virgo) are currently
recording data and searching for those astrophysical sources. In this report,
we present the first joint analysis effort using data from the
gravitational-wave detectors LIGO and Virgo, and from the high-energy neutrino
detector ANTARES.",96,7,706,18.15
352,astrophysics,"We show that a stacking approach to galaxy clusters can improve current
limits on decaying dark matter by a factor $\gtrsim 5-100$, with respect to a
single source analysis, for all-sky instruments such as Fermi-LAT. Based on the
largest sample of X-ray-selected galaxy clusters available to date (the MCXC
meta-catalogue), we provide all the astrophysical information, in particular
the astrophysical term for decaying dark matter, required to perform an
analysis with current instruments.",73,3,490,17.51
353,astrophysics,"Black holes have the peculiar and intriguing property of having an event
horizon, a one-way membrane causally separating their internal region from the
rest of the Universe. Today astrophysical observations provide some evidence
for the existence of event horizons in astrophysical black hole candidates. In
this short paper, I compare the constraint we can infer from the
non-observation of electromagnetic radiation from the putative surface of these
objects with the bound coming from the ergoregion instability, pointing out the
respective assumptions and limitations.",83,4,572,26.44
354,astrophysics,"We review the current status of studies of disc atmospheres and winds in low
mass X-ray binaries. We discuss the possible wind launching mechanisms and
compare the predictions of the models with the existent observations. We
conclude that a combination of thermal and radiative pressure (the latter being
relevant at high luminosities) can explain the current observations of
atmospheres and winds in both neutron star and black hole binaries. Moreover,
these winds and atmospheres could contribute significantly to the broad iron
emission line observed in these systems.",87,5,571,40.89
355,astrophysics,"The newsletter of the Australian Astronomical Observatory. In this issue:
SPIE Extravaganza; The AAO's Gemini High-resolution Optical SpecTrograph
(GHOST) concept; First Cosmological Constraints from the 6dFGS Peculiar
Velocity Field; Galaxy And Mass Assembly (GAMA): GAMA Announces Second Data
Release; Evidence for Significant Growth in the Stellar Mass of the Most
Massive Galaxies in the Universe; The 5th Southern Cross Conference: A Joint
CASS/AAO Conference; GALAH: Preparing for Flight; and all the usual columns and
news from the Observatory.",78,3,551,6.51
356,astrophysics,"The significance of jets and accretion disks in Astrophysics may be growing
far beyond any single example of recent finds in the scientific journals. This
brief review will summarize recent, significant manifestations of accretion
disk powered jets in the universe. We then introduce supplemental contemporary
finds in physics and astrophysics which might bear tangential or direct
implications for astrophysics toward rethinking the universe with a major role
of relativistic jets powered by accretion disks. We conclude with the direction
our research will take in order to establish a new perspective on the universe.",93,5,620,30.91
357,astrophysics,"I review three problems in astrophysics of compacts stars: (i) the phase
diagram of warm pair-correlated nuclear matter a sub-saturation densities at
finite isospin asymmtery; (ii) the Standard Model neutrino emission from
superfluid phases in neutron stars within the Landau theory of Fermi
(superfluid) liquids; (iii) the beyond Standard Model physics of axionic
cooling of compact stars by the Cooper pair-breaking processes.",62,2,428,-8.38
358,astrophysics,"Located at the South Pole, IceCube is a particle-astrophysics observatory
composed of a square-kilometer surface air shower array (IceTop) and a 1.4 km
deep cubic-kilometer optical Cherenkov detector array. We review results of
measurements of the cosmic ray spectrum and average mass in the energy range 1
PeV to 1 EeV.",51,4,320,45.76
359,astrophysics,"We describe a general method to observationally exclude a theoretical model
for gravitational wave (GW) emission from a transient astrophysical source
(event) by using a null detection from a network of GW detectors. In the case
of multiple astrophysical events with no GW detection, statements about
individual events can be combined to increase the exclusion confidence. We
frame and demonstrate the method using a population of hypothetical core
collapse supernovae.",70,4,469,22.45
360,astrophysics,"Although the detailed conditions for explosive nucleosynthesis are derived
from astrophysical modeling, nuclear physics determines fundamental patterns in
abundance yields, not only for equilibrium processes. Focussing on the nu-p-
and the gamma-process, general nucleosynthesis features within the range of
astrophysical models, but (mostly) independent of details in the modelling, are
presented. Remaining uncertainties due to uncertain Q-values and reaction rates
are discussed.",62,4,482,8.16
361,astrophysics,"Baryonic matter in the core of a massive and evolved star is compressed
significantly to form a supra-nuclear object, and compressed baryonic matter
(CBM) is then produced after supernova. The state of cold matter at a few
nuclear density is pedagogically reviewed, with significant attention paid to a
possible quark-cluster state conjectured from an astrophysical point of view.",58,3,380,25.12
362,astrophysics,"Recent progress in astrophysical hydromagnetic turbulence is being reviewed.
The physical ideas behind the now widely accepted Goldreich--Sridhar model and
its extension to compressible magnetohydrodynamic turbulence are introduced.
Implications for cosmic ray diffusion and acceleration is being discussed.
Dynamo-generated magnetic fields with and without helicity are contrasted
against each other. Certain turbulent transport processes are being modified
and often suppressed by anisotropy and inhomogeneities of the turbulence, while
others are being produced by such properties, which can lead to new large-scale
instabilities of the turbulent medium. Applications of various such processes
to astrophysical systems are being considered.",97,7,743,12.73
363,astrophysics,Energy-resolved lightcurves are calculated for a weak pulsar.,8,2,61,37.98
364,astrophysics,"We give precise details to support that observations of gravitational lensing
at scales of individual, groups and clusters of galaxies can be understood in
terms of non-Newtonian gravitational interactions with a relativistic structure
compatible with the Einstein Equivalence Principle. This result is derived on
very general grounds without knowing the underlying structure of the
gravitational field equations. As such, any developed gravitational theory
built to deal with these astrophysical scales needs to reproduce the obtained
results of this article.",79,4,560,10.94
365,astrophysics,"Astrophysical fluid bodies that orbit close to one another induce tidal
distortions and flows that are subject to dissipative processes. The spin and
orbital motions undergo a coupled evolution over astronomical timescales, which
is relevant for many types of binary star, short-period extrasolar planetary
systems and the satellites of the giant planets in the solar system. I review
the principal mechanisms that have been discussed for tidal dissipation in
stars and giant planets in both linear and nonlinear regimes. I also compare
the expectations based on theoretical models with recent observational
findings.",92,5,617,31.21
366,astrophysics,"Gravitationally bound supermassive black hole binaries (SBHBs) are thought to
be a natural product of galactic mergers and growth of the large scale
structure in the universe. They however remain observationally elusive, thus
raising a question about characteristic observational signatures associated
with these systems. In this conference proceeding I discuss current theoretical
understanding and latest advances and prospects in observational searches for
SBHBs.",63,4,466,16.32
367,astrophysics,"We discuss the basic physics of hot-star winds and we provide mass-loss rates
for (very) massive stars. Whilst the emphasis is on theoretical concepts and
line-force modelling, we also discuss the current state of observations and
empirical modelling, and address the issue of wind clumping.",45,3,291,40.18
368,astrophysics,"Since it became publicly available in 2004, the radiative transfer code
STOKES has been used to model the spectroscopic, polarimetric, timing and
imaging signatures for different astrophysical scenarios. Ten years later, at
the release of a new version of the Monte Carlo code, we make a census of the
different scientific cases explored with STOKES and review the main results
obtained so far.",63,3,394,39.5
369,astrophysics,"Recent observation of a sudden spin down, occurring on a timescale not
exceeding two weeks, of the magnetar 1E2259+586 (see Archibald et al. 2013,
where this event was dubbed an `anti-glitch') has not still received any
interpretation in terms of the standard scenario of pulsar glitches proposed by
Anderson and Itoh (1975). Motivated by this observation, here we present a toy
model that allows, under certain conditions, for anti-glitches in neutron stars
within the standard approach.",76,4,488,54.26
370,astrophysics,"Cosmological birefringence is a rotation of the polarization plane of photons
coming from sources of astrophysical and cosmological origin. The rotation can
also depend on the energy of the photons and not only on the distance of the
source and on the cosmological evolution of the underlying theoretical model.
In this work, we constrain few selected models for cosmological birefringence,
combining CMB and astrophysical data at radio, optical, X and gamma
wavelengths, taking into account the specific energy and distance dependences.",81,4,537,10.23
371,astrophysics,"Neutrinos are produced by a variety of sources that comprise our Sun,
explosive environments such as core-collapse supernovae, the Earth and the
Early Universe. The precise origin of the recently discovered ultra-high energy
neutrinos is to be determined yet. These weakly interacting particles give us
information on their sources, although the neutrino fluxes can be modified when
neutrinos traverse an astrophysical environment. Here we highlight recent
advances in neutrino astrophysics and emphasise the important progress in our
understanding of neutrino flavour conversion in media.",84,5,589,24.78
372,astrophysics,"Chameleon and similar (symmetron and dilation) theories of gravity can
exhibit new and interesting features on cosmological scales whilst screening
the modifications on small scales thereby satisfying solar system tests of
general relativity. This thesis explores the regime between these two scales:
astrophysics. The majority of this thesis is focused on discerning new and
novel astrophysical probes of chameleon gravity in the form of stellar
structure and oscillation tests. These are used to place new constraints on the
theory parameters and the implications of these are discussed, as are the
future prospects for improving them using planned future surveys. The final two
chapters review supersymmetric completions of these theories.",109,6,742,32.43
373,astrophysics,"We highlight recent advances in neutrino astrophysics, the open issues and
the interplay with neutrino properties. We emphasize the important progress in
our understanding of neutrino flavor conversion in media. We discuss the case
of solar neutrinos, of core-collapse supernova neutrinos and of SN1987A, and of
the recently discovered ultra-high energy neutrinos whose origin is to be
determined.",58,4,397,26.51
374,astrophysics,"In recent years, observational $\gamma$-ray astronomy has seen a remarkable
range of exciting new results in the high-energy and very-high energy regimes.
Coupled with extensive theoretical and phenomenological studies of non-thermal
processes in the Universe these observations have provided a deep insight into
a number of fundamental problems of high energy astrophysics and astroparticle
physics. Although the main moti- vations of $\gamma$-ray astronomy remain
unchanged, recent observational results have contributed significantly towards
our understanding of many related phenomena. This article aims to review the
most important results in the young and rapidly developing field of
$\gamma$-ray astrophysics.",97,5,716,12.97
375,astrophysics,"In 2008 a Starting Grant project supported by the European Research Council
titled ""Nuclear reaction studies relevant to the astrophysical p-process
nucleosynthesis"" was launched. After five years of successful research related
to the experimental investigation of proton- and alpha-induced nuclear reaction
for the astrophysical p-process, the project came to an end. In this paper a
summary of the research and the most important achievements is given.",66,4,454,23.77
376,astrophysics,"We develop a description of tidal effects in astrophysical systems using
effective field theory techniques. While our approach is equally capable of
describing objects in the Newtonian regime (e.g. moons, rocky planets, main
sequence stars, etc.) as well as relativistic objects (e.g. neutron stars and
black holes), in this paper we focus special attention on the Newtonian regime.
In this limit, we recover the dynamical equations for the ""weak friction model""
with additional corrections due to tidal and rotational deformations.",80,9,532,41.06
377,astrophysics,"The recent discoveries of high-energy astrophysical neutrinos and
gravitational waves have opened new windows of exploration to the Universe.
Combining neutrino observations with measurements of electromagnetic radiation
and cosmic rays promises to unveil the sources responsible for the neutrino
emission and to help solve long-standing problems in astrophysics such as the
origin of cosmic rays. Neutrino observations may also help localize
gravitational-wave sources, and enable the study of their astrophysical
progenitors. In this work we review the current status and future plans for
multi-messenger searches of neutrino sources.",88,5,636,15.31
378,astrophysics,"For a long time very little experimental information was available about
neutrino properties, even though a minute neutrino mass has intriguing
cosmological and astrophysical implications. This situation has changed in
recent decades: intense experimental activity to measure many neutrino
properties took place. Some of these developments and their implications for
astrophysics and cosmology are briefly reviewed with a particular emphasis on
neutrino magnetic moments and collective neutrino oscillations",68,3,507,6.13
379,astrophysics,"In this concluding article I recall the early history of the Gaia mission,
showing that the original science case and expectations of wide community
interest in Gaia data have been met. The quarter-century long partnership
involving some 1,000 scientists, engineers and managers in industry and
academia is delivering a large, high-quality and unique data set which will
underpin astrophysics across many sub-fields for years to come.",66,3,434,21.06
380,astrophysics,"This article presents a brief description of India's AstroSat mission which
is a powerful space based observatory for compact star research. An account is
given of observational constraints and spectral and timing capabilities as
realised post-launch. Some preliminary results of observations of the Crab
pulsar and an X-ray binary system GX~301-2 are presented to illustrate some of
the capabilities of the mission.",62,4,416,33.54
381,astrophysics,"We are members of the Astrophysics Source Code Library's Advisory Committee
and its editor-in-chief. The Astrophysics Source Code Library (ASCL, ascl.net)
is a successful initiative that advocates for open research software and
provides an infrastructure for registering, discovering, sharing, and citing
this software. Started in 1999, the ASCL has been expanding in recent years,
with an average of over 200 codes added each year, and now houses over 1,600
code entries.",71,5,472,44.95
382,astrophysics,"Modeling electromagnetic cascades during gamma-ray transport is important in
many applications within astrophysics. This document introduces
$\gamma$-Cascade, a publicly available Mathematica package which allows users
to calculate observed gamma-ray fluxes from point sources as well as from a
distribution of sources. $\gamma$-Cascade semi-analytically computes the
effects of electromagnetic interactions during gamma-ray transport.",52,4,435,3.16
383,astrophysics,"We announce the public release of the application program interface (API) for
the Open Astronomy Catalogs (OACs), the OACAPI. The OACs serve near-complete
collections of supernova, tidal disruption, kilonova, and fast stars data
(including photometry, spectra, radio, and X-ray observations) via a
user-friendly web interface that displays the data interactively and offers
full data downloads. The OACAPI, by contrast, enables users to specifically
download particular pieces of the OAC dataset via a flexible programmatic
syntax, either via URL GET requests, or via a module within the astroquery
Python package.",89,4,614,24.41
384,astrophysics,"High-energy photons are a powerful probe for astrophysics and for fundamental
physics in extreme conditions. During the recent years, our knowledge of the
most violent phenomena in the Universe has impressively progressed thanks to
the advent of new detectors for gamma rays, both at ground and on satellites.
This article reviews the present status of high-energy gamma-ray astrophysics,
with emphasis on the recent results and a look to the future.",70,4,450,39.37
385,astrophysics,"In this short paper we discuss the possibility of testing the nature of
astrophysical black holes using the recently observed black hole mergers. We
investigate the possibility that a secondary black hole is created in the
merger of two astrophysical black holes and discuss potential astrophysical
signatures. We point out that black hole mergers are a possible astrophysical
mechanism for the creation of quantum black holes with masses close to the
Planck mass.",73,4,464,38.35
386,astrophysics,"At the 36 th ICRC during 11 parallel Gamma-Ray Indirect sessions in total
about 70 talks were presented. A few of the plenary highlight talks as well
concerned mostly indirect observations of gamma rays. In addition about 140
posters on this topic have been shown in poster sessions. This rapport tries to
summarize the results presented in those contributions.",59,5,361,56.45
387,astrophysics,"Understanding the physical structure of the planet formation environment, the
protoplanetary disk, is essential for the interpretation of high resolution
observations of the dust and future observations of the magnetic field
structure. Observations of multiple transitions of molecular species offers a
unique view of the underlying physical structure through excitation analyses.
Here we describe a new method to extract high-resolution spectra from
low-resolution observations, then provide two case studies of how molecular
excitation analyses were used to constrain the physical structure in TW Hya,
the closest protoplanetary disk to Earth.",90,4,645,15.65
388,astrophysics,"The contribution of unresolved sources to the diffuse gamma-ray background
could produce anisotropies in this emission on small angular scales. Recent
studies have considered the angular power spectrum and other anisotropy metrics
as tools for identifying contributions to diffuse emission from unresolved
source classes, such as extragalactic and Galactic dark matter as well as
various astrophysical gamma-ray source populations. We present preliminary
results of an anisotropy analysis of the diffuse emission measured by the
Fermi-LAT.",75,4,539,20.72
389,astrophysics,"Utrecht has a long tradition in both spectroscopy and mass-loss studies. Here
we present a novel methodology to calibrate mass-loss rates on purely
spectroscopic grounds. We utilize this to predict the final fates of massive
stars, involving pair-instability and long gamma-ray bursts (GRBs) at low
metallicity Z.",47,4,313,55.54
390,astrophysics,"The main aim of this paper is to study the astrophysical behavior of open
clusters' properties along the Milky Way Galaxy. Near-IR JHK (2MASS) photometry
has been used for getting a homogeneous Catalog of 263 open clusters'
parameters, which are studied for the first time by the author through the last
five years. The correlations between the astrophysical parameters of these
clusters have been achieved in morphological way and compared with the most
recent works.",75,4,468,46.1
391,astrophysics,"We present here evidence for the existence of a citation advantage within
astrophysics for papers that link to data. Using simple measures based on
publication data from NASA Astrophysics Data System we find a citation
advantage for papers with links to data receiving on the average significantly
more citations per paper than papers without links to data. Furthermore, using
INSPEC and Web of Science databases we investigate whether either papers of an
experimental or theoretical nature display different citation behavior.",80,4,527,18.99
392,astrophysics,"We describe the recent modifications to the data reduction technique for
observations acquired with the scanning Fabry-Perot interferometer (FPI)
mounted on the 6-m telescope of the Special Astrophysical Observatory that
allow the wavelength scale to be correctly computed in the case of large mutual
offsets of studied objects in interferograms. Also the parameters of the
scanning FPIs used in the SCORPIO-2 multimode focal reducer are considered.",66,3,449,12.6
393,astrophysics,"We discuss the astrophysical science case for a decihertz gravitational-wave
mission. We focus on unique opportunities for scientific discovery in this
frequency range, including probes of type IA supernova progenitors, mergers in
the presence of third bodies, intermediate mass black holes, seeds of massive
black holes, improved sky localization, and tracking the population of merging
compact binaries.",57,3,405,17.17
394,astrophysics,"The luminosity function (LF) for stars is here fitted by a Schechter function
and by a Gamma probability density function. The dependence of the number of
stars on the distance, both in the low and high luminosity regions, requires
the inclusion of a lower and upper boundary in the Schechter and Gamma LFs.
Three astrophysical applications for stars are provided: deduction of the
parameters at low distances, behavior of the average absolute magnitude with
distance, and the location of the photometric maximum as a function of the
selected flux. The use of the truncated LFs allows to model the Malmquist bias.",101,5,613,37.34
395,astrophysics,"Photon-photon scattering of gamma-rays on the cosmic microwave background has
been studied using the low energy approximation of the total cross section by
Zdziarski & Svensson (1989); Svensson & Zdziarski (1990). Here, the cosmic
horizon due to photon-photon scattering is accurately determined using the
exact cross section and we find that photon-photon scattering dominates over
the pair production at energies smaller than 1.68 GeV and at redshifts larger
than 180.",70,4,470,31.51
396,astrophysics,"Astrophysical observations are a powerful tool to constrain effects of
Lorentz-invariance violation in the photon sector. Objects at high redshifts
provide the longest possible baselines, and gamma-ray telescopes allow us to
observe some of the highest energy photons. Observations include polarization
measurements and time-of-flight measurements of transient or variable objects
to constrain vacuum birefringence and dispersion. Observing multiple sources
covering the entire sky allows the extraction of constraints on anisotropy. In
this paper, I review methods and recent results on Lorentz- and CPT-invariance
violation constraints derived from astrophysical polarization measurements in
the framework of the Standard-Model Extension.",97,6,740,17.94
397,astrophysics,"The search for life beyond the Solar System-a major part of the Planetary
Systems thematic area of the Astro2020 Decadal process-includes the search for
technological life. Although financial support for such searches at the NSF and
NASA and in past decadal surveys has been weak to nonexistent, recent advances
in astrobiology, astrophysics, and advances in technical capability make
searches for technosignatures a compelling theme for 2020-2030 and beyond.",68,3,459,28.51
398,astrophysics,"We study the conditions for the adiabatic resonant conversion of the cold
dark matter (CDM) axions into photons in existence of the astrophysically
sourced strong magnetic fields such as those in the neutron star magnetosphere.
We demonstrate the possibility that the forthcoming radio telescopes such as
the SKA (Square Kilometre Array) can probe those photon signals from the CDM
axions.",60,3,389,32.57
399,astrophysics,"We review the current status of research in MHD turbulence theory and
numerical experiments and their applications to astrophysics and solar science.
We introduce general tools for studying turbulence, basic turbulence models,
MHD equations and their wave modes. Subsequently, we cover the theories and
numerics of Alfvenic turbulence, imbalanced turbulence, small-scale dynamos and
models and numerics for supersonic MHD turbulence.",60,4,433,25.8
400,astrophysics,"Hermann Bondi's 1952 paper ""On spherically symmetrical accretion"" is
recognized as one of the foundations of accretion theory. Although Bondi later
remarked that it was ""not much more than an examination exercise"", his
mathematical analysis of spherical accretion on to a point mass has found broad
use across fields of astrophysics that were embryonic or non-existent at the
time of the paper's publication. In this non-technical review, I describe the
motivations for Bondi's work, and briefly discuss some of the applications of
Bondi accretion in high energy astrophysics, galaxy formation, and star
formation.",93,4,614,23.09
401,astrophysics,"A brief history and various themes of mid-frequency gravitational wave
detection are presented more or less following historical order -- Laser
Interferometry, Atom Interferometry (AI), Torsion Bar Antenna (TOBA), and
Superconducting Omni-directional Gravitational Radiation Observatory (SOGRO).
Both Earth-based and Space-borne concepts are reviewed with outlook on expected
astrophysical sources",49,2,397,-20.57
402,astrophysics,"The Maxwell-Boltzmann (MB) distribution for velocities in ideal gases is
usually defined between zero and infinity. A double truncated MB distribution
is here introduced and the probability density function, the distribution
function, the average value, the rth moment about the origin, the
root-mean-square speed and the variance are evaluated. Two applications are
presented: (i) a numerical relationship between root-mean-square speed and
temperature, and (ii) a modification of the formula for the Jeans escape flux
of molecules from an atmosphere.",79,4,552,10.94
403,astrophysics,"Two relativistic distributions which generalizes the Maxwell Boltzman (MB)
distribution are analyzed: the relativistic MB and the Maxwell-J{\""u}ttner (MJ)
distribution. For the two distributions we derived in terms of special
functions the constant of normalization, the average value, the second moment
about the origin, the variance, the mode, the asymptotic behavior, approximate
expressions for the average value as function of the temperature and the
connected inverted expressions for the temperature as function of the average
value. Two astrophysical applications to the synchrotron emission in presence
of the magnetic field and the relativistic electrons are presented.",95,4,679,13.92
404,astrophysics,"We present the ""StoP"" photometer-polarimeter (Stokes-polarimeter) used for
observations with the 1-m telescope of the Special Astrophysical Observatory of
the Russian Academy of Sciences since the beginning of 2020. We describe the
instrument and its parameters in observations performed in the photometric and
polarimetric modes. We demonstrate the capabilities of the instrument through
the polarimetry of the blazar S5 0716+714 and compare the results with those
earlier obtained with the 6-m telescope.",72,4,506,30.2
405,astrophysics,"This document presents an accurate record of the scientific programme of the
2013 UK National Conference on Geophysical, Astrophysical and Industrial
Magnetohydrodynamics held on 23rd and 24th of May 2013 at the School of
Mathematics and Statistics of the University of Glasgow. The abstracts of
presented contributions are listed in chronological order and a full list of
participants and their affiliations is included.",63,3,421,14.12
406,astrophysics,"We have compiled a catalogue of eclipsing variable stars, the largest
catalogue, containing classified eclipsing binaries. A procedure for the
classification of eclipsing binaries, based on the catalogued data, is also
developed. It was applied to unclassified eclipsing binaries. In this paper we
discuss eclipsing binaries, which can not be classified with the procedure.
Some of them belong to marginal evolutionary classes. Observational data for
others are too contradictory, and additional observations are needed to
attribute them to one or another evolutionary class.",83,7,575,32.09
407,astrophysics,"Astrophysical models of primordial star formation require rate constants for
three-body recombination as input. The current status of these rates for H2 due
to collisions with H is far from satisfactory, with published rate constants
showing orders of magnitude disagreement at the temperatures relevant for H2
formation in primordial gas. This letter presents an independent calculation of
this recombination rate constant as a function of temperature. An analytic
expression is provided for the rate constant which should be more reliable than
ones currently being used in astrophysical models.",88,5,596,23.77
408,astrophysics,"We have made an estimation of the synchrotron peak frequency
($\nu_{peak}^{s}$) for six very low synchrotron peaked (VLSP) blazars. These
objects were selected as VLSP candidates (with the $\nu_{peak}^{s} \leq
10^{13}$ Hz) from the archival data. We have build spectral energy distribution
using quasi-simultaneous observations at the Zeiss-1000 and RATAN-600
telescopes of the Special astrophysical observatory of RAS and made an
estimation of the $\nu_{peak}^{s}$. We confirmed classification as a VLSP for
two sources ([HB89] 1308+326 and 3C 345), for four other blazars we have
calculated $\nu_{peak}^{s}>10^{13}$ Hz.",88,5,621,40.69
409,astrophysics,"A century ago, nuclear physics entered astrophysics, giving birth to a new
field of science referred to as ""Nuclear Astrophysics"". With time, it developed
at an impressive pace into a vastly inter- and multidisciplinary discipline
bringing into its wake not only astronomy and cosmology, but also many other
sub-fields of physics, especially particle, solid-state and computational
physics, as well as chemistry, geology and even biology. The present
Astronuclear Physics review focusses primarily on the facets of nuclear physics
that are of relevance to astronomy and astrophysics, the theoretical aspects
being of special concern here.",94,4,638,14.33
410,astrophysics,"Protoplanetary disks around young stars are the birth sights of planetary
systems like our own. Disks represent the gaseous dusty matter left after the
formation of their central stars. The mass and luminosity of the star, initial
disk mass and angular momentum, and gas viscosity govern disk evolution and
accretion. Protoplanetary disks are the cosmic nurseries where microscopic dust
grains grow into pebbles, planetesimals, and planets.",66,5,440,46.27
411,astrophysics,"The theory of the conservation of energy in the thin layer approximation has
been extended to special relativity. Four models for the density of the
circumstellar medium are analyzed, which are represented by constant, power
law, exponential and Emden (n=5) profile for density. The astrophysical results
are presented in a numerical way, except for a Taylor expansion of the four
trajectories in the surrounding of the origin. The free parameters of the
models are particularized for SN1993j, for which the radius versus time is
known. Some evaluations on the time dilation are presented.",93,6,589,35.68
412,astrophysics,A short derivation of all isochrone models using complex analysis,10,1,65,61.33
413,astrophysics,"Two new equations of motion for a supernova remnant (SNR) are derived in the
framework of energy conservation for the thin-layer approximation. The first
one is based on an inverse square law for the surrounding density and the
second one on a non-cubic dependence of the swept mass. Under the assumption
that the observed radio-flux scales as the flux of kinetic energy, two scaling
laws are derived for the temporal evolution of the surface brightness of SNRs.
The astrophysical applications cover two galactic samples of surface brightness
and an extragalactic one.",91,5,568,39.87
414,astrophysics,"Jets, collimated outflows of particles and fields, are observed in a wide
variety of astrophysical systems, including Active Galactic Nuclei of various
types, microquasars, gamma-ray bursts, and young stellar objects. Despite
intensive efforts along several decades of observational and theoretical
research, there are still many uncertainties and open questions related to how
jets are produced and what is their composition. In this review I offer an
outline of some current views on the content and basic properties of
astrophysical jets.",80,4,541,27.45
415,astrophysics,"Simulating a survey of fluxes and redshifts (distances) from an astrophysical
population is a routine task. \texttt{popsynth} provides a generic,
object-oriented framework to produce synthetic surveys from various
distributions and luminosity functions, apply selection functions to the
observed variables and store them in a portable (HDF5) format. Population
synthesis routines can be constructed either using classes or from a
serializable YAML format allowing flexibility and portability. Users can not
only sample the luminosity and distance of the populations, but they can create
auxiliary distributions for parameters which can have arbitrarily complex
dependencies on one another. Thus, users can simulate complex astrophysical
populations which can be used to calibrate analysis frameworks or quickly test
ideas.",114,6,822,14.49
416,astrophysics,"We model the conservation of energy in the framework of the thin layer
approximation for two types of interstellar medium (ISM). In particular, we
analyse an ISM in the presence of self-gravity and a Gaussian ISM which
produces an asymmetry in the advancing shell. The astrophysical targets to be
simulated are the Fermi bubbles, the local bubble, and the W4 super-bubble. The
theory of images is applied to a piriform curve, which allows deriving some
analytical formulae for the observed intensity in the case of an optically thin
medium.",89,5,540,31.92
417,astrophysics,"Gravitational microlensing is one of the methods to detect exoplanets;
planets outside our solar system. Here we focus on theoretical modeling of
three lens systems and in particular circumbinary systems. Circumbinary systems
include two stars and a planet and are estimated to make up a sizable portion
of all exoplanets. Extending a method developed for binary lenses to the three
lens case, we explore the parameter space of circumbinary systems producing
exact magnification maps and light curves.",77,5,501,26.51
418,astrophysics,"Recent work has called into question whether nature can extract the
rotational energy of a black hole via electromagnetic fields by appealing to an
alleged ability to absorb current. We describe the strategies needed to
properly treat the astrophysics in curved spacetime near black holes, showing
that while the Blandford-Znajek effect is sound, the deeper nature of the
electric nature of black holes remains unresolved.",65,3,422,38.49
419,astrophysics,"We offer a pedagogical introduction to axion-like particles (ALPs) as far as
their relevance for high-energy astrophysics is concerned, from a few MeV to
1000 TeV. This review is self-contained, in such a way to be understandable
even to non-specialists. Among other things, we discuss two strong hints at a
specific ALP that emerge from two very different astrophysical situations. More
technical matters are contained in three Appendices.",68,5,440,45.76
420,astrophysics,"In-orbit background is an unavoidable feature of all space-borne X-ray
detectors, and arises both from cosmic sources (diffuse or point-like) and from
the interaction of the detectors themselves with the space environment (primary
or secondary cosmic rays, geomagnetically trapped particles, activation of
spacecraft structures). In this chapter the main background sources are
discussed, with their principal effects on the various detector types, and
simulation and mitigation strategies are described.",69,3,504,19.54
421,astrophysics,"This paper describes the X-ray and gamma-ray imaging spectroscopy
capabilities of the Ramaty High Energy Solar Spectroscopic Imager (RHESSI). It
also outlines RHESSI's major scientific accomplishments during the 16 years of
operations from 2002 to 2018. These include unique contributions to solar flare
research and to other aspects of solar physics (oblateness), astrophysics
(magnetars), and Earth sciences (terrestrial gamma-ray flashes).",60,4,442,25.8
422,astrophysics,"A quantitative description of the properties of hot nuclear matter will be
needed for the interpretation of the available and forthcoming astrophysical
data, providing information on the post merger phase of a neutron star
coalescence. We have employed a recently developed theoretical model, based on
a phenomenological nuclear Hamiltonian including two- and three-nucleon
potentials, to study the temperature dependence of average and single-particle
properties of nuclear matter relevant to astrophysical applications. The
possibility to represent the results of microscopic calculations using simple
and yet physically motivated parametrisations of thermal effects, suitable for
use in numerical simulations of astrophysical processes, is also discussed.",102,4,758,-13.8
423,astrophysics,"Little is known about the radio astronomical universe at frequencies below 10
MHz because such radiation does not penetrate the ionosphere. A cubesat-based
observatory for the 1--10 MHz band could be rapidly and economically deployed
in low earth orbit. When shielded by the Earth from Solar emission, it could
observe weak extra-Solar System sources. We consider possible transient and
steady sources, and application to study of the ionosphere itself.",69,5,453,45.46
424,astrophysics,"The White Paper describes the nuclear astrophysics program at the Triangle
Universities Nuclear Laboratory (TUNL), with the intent of providing input for
the 2023 NSAC Long Range planning process. TUNL is operated jointly by North
Carolina Central University, North Carolina State University, The University of
North Carolina at Chapel Hill, and Duke University. TUNL houses three
world-class facilities for nuclear astrophysics research: the Laboratory for
Experimental Nuclear Astrophysics (LENA); the Enge Magnetic Spectrograph; and
the High-Intensity gamma-ray Source (HIgS). We discuss past successes, the
present status, and future plans.",89,5,644,23.46
425,astrophysics,"In gamma ray astronomy with Cherenkov telescopes, machine learning models are
needed to guess what kind of particles generated the detected light, and their
energies and directions. The focus in this work is on the classification task,
training a simple convolutional neural network suitable for binary
classification (as it could be a cats vs dogs classification problem), using as
input uncleaned images generated by Montecarlo data for a single ASTRI
telescope. Results show an enhanced discriminant power with respect to
classical random forest methods.",84,4,557,26.14
426,astrophysics,"This conference proceeding presents an overview of the modern approaches in
the study of baryonic matter at high densities, focusing on the use of online
repositories such as CompOSE and MUSES for the calculation of neutron star
properties. In this context, relevant astrophysical constraints for the
equations of state (mass-radius relation, speed of sound, tidal deformability)
are discussed.",58,3,394,25.12
427,astrophysics,"Time-resolved ground-based surveys in general, and photometric ones in
particular, have played a crucial role in building up our knowledge of the
properties, physical nature, and the very existence of the many different
classes of variable stars and transient events that are currently known. Here I
provide a brief overview of these developments, discussing some of the
stumbling blocks that had to be overcome along the way, and others that may
still hamper further progress in the area. A compilation of different types of
past, present, and future surveys is also provided.",92,4,577,48.77
428,astrophysics,"Magnetohydrodynamical (MHD) turbulence is ubiquitous in magnetized
astrophysical plasmas, and it radically changes a great variety of
astrophysical processes. In this review, we give the concept of MHD turbulence
and explain the origin of its scaling. We consider the implications of MHD
turbulence to various problems: dynamo in different types of stars, flare
activity, solar and stellar wind from different stars, propagation of cosmic
rays, and star formation. We also discuss how the properties of MHD turbulence
provide a new way of tracing magnetic fields in interstellar and intracluster
media.",90,5,602,23.26
429,astrophysics,"These lecture notes collect the material that I have been using over the
years for various short courses on the physics of gravitational waves, first at
the Institut d'Astrophysique de Paris (France), and then at SISSA (Italy) and
various summer/winter schools. The level should be appropriate for PhD students
in physics or for MSc students that have taken a first course in general
relativity. The focus is on deriving results from first principles, rather than
on astrophysical applications.",78,4,494,45.09
430,astrophysics,"Recent studies reveal that more than a dozen of white dwarfs displaying
near-perfect blackbody spectra in the optical range have been lurking in the
Sloan Digital Sky Survey catalog. We point out that, in a way analogous to the
Cosmic Microwave Background, these stars serve as excellent testbeds for new
physics. Specifically, we show how their observed lack of spectral distortions
translates into limits on the parameter space of axions with electromagnetic
coupling. The prospects for future improvements are also discussed.",81,5,528,50.87
431,astrophysics,"Many models of dark matter (DM) are now widely considered and probed
intensively with accelerators, underground detectors, and astrophysical
experiments. Among the various approaches, high-energy astrophysical
observations are extremely useful to complement laboratory searches for some DM
candidates. In the near future, the Cherenkov Telescope Array (CTA) should
enable us to access much heavier weakly interacting massive particles, as well
as a broad range of other DM candidates. In this talk, we describe DM searches
with CTA.",77,5,532,26.51
432,astrophysics,"The Galclaim software is designed to identify association between
astrophysical transient sources and host galaxy by computing the probability of
chance alignment. It is distributed as an open source Python software. It is
already used to identify, confirm or reject host galaxy candidates of GRBs and
to validate or invalidate transient candidates in astrophysical observations.
Such tools are also very useful to characterise archived transient candidates
in large sky survey telescopes.",71,5,489,36.49
433,astrophysics,"Abundance determinations in planetary nebulae (PNe) are crucial for
understanding stellar evolution and the chemical evolution of the host galaxy.
  We discuss the complications involved when the presence of a metal-rich phase
is suspected in the nebula. We demonstrate that the presence of a cold region
emitting mainly metal recombination lines necessitates a detailed treatment to
obtain an accurate assessment of the enrichment of this cold gas phase.",68,4,455,31.51
434,astrophysics,"We discuss the standard Lane-Emden formalism as well as the one related to
the slowly rotating objects. It is preceded by a brief introduction of
different forms of the polytropic equation of state. This allows to study a
wide class of astrophysical objects in the framework of a given theory of
gravity, as demonstrated in a few examples. We will discuss light elements
burning processes and cooling models in stars and substellar objects with the
use of the Lane-Emden formalism.",80,5,481,42.72
435,astrophysics,"Does deconfined cold quark matter occur in nature? This is currently one of
the fundamental open questions in nuclear astrophysics. In these proceedings, I
review the current state-of-the-art techniques to address this question in a
model-agnostic manner, by synthesizing inputs from astrophysical observations
of neutron stars and their binary mergers, and first-principles calculations
within nuclear and particle theory. I highlight recent improvements in
perturbative calculations in asymptotically dense cold quark matter, as well as
compelling evidence for a conformalizing transition within the cores of massive
neutron stars.",87,4,633,15.51
436,astrophysics,"Modern machine learning will allow for simulation-based inference from
reionization-era 21cm observations at the Square Kilometre Array. Our framework
combines a convolutional summary network and a conditional invertible network
through a physics-inspired latent representation. It allows for an optimal and
extremely fast determination of the posteriors of astrophysical and
cosmological parameters. The sensitivity to non-Gaussian information makes our
method a promising alternative to the established power spectra.",67,5,519,3.66
437,astrophysics,"An attempt is made to evaluate progress of the Polish astrophysical research
of stars and of the inter-stellar medium (ISM) on the basis of scientific paper
citations in the ADS database. Rather modest citation levels were observed in
the years before the mid-1950's. In the years 1958 - 1973, thanks to the partly
opened foreign contacts and to strong support from astronomers of the older
generation, work of a number of young, energetic enthusiasts reached the world
science levels and formed a strong basis for the well recognized, international
successes of the next generations.",94,4,584,40.01
438,astrophysics,"The long-term evolution of astrophysical systems is driven by a Hamiltonian
that is independent of the fast angle. As this Hamiltonian may contain
explicitly time-dependent parameters, the conservation of mechanical energy is
not guaranteed in such systems. We derive how the semi-major axis evolves in
these cases. We analyze two astrophysically interesting examples, those of the
harmonic and quadrupole perturbations.",60,5,420,22.41
439,astrophysics,"As the Cosmology and Fundamental Physics (CFP) panel is fully aware, the next
decade will see major advances in our understanding of these areas of research.
To quote from their charge, these advances will occur in studies of the early
universe, the microwave background, the reionization and galaxy formation up to
virialization of protogalaxies, large scale structure, the intergalactic
medium, the determination of cosmological parameters, dark matter, dark energy,
tests of gravity, astronomically determined physical constants, and high energy
physics using astronomical messengers. Central to the progress in these areas
are the corresponding advances in laboratory astrophysics which are required
for fully realizing the CFP scientific opportunities within the decade
2010-2020. Laboratory astrophysics comprises both theoretical and experimental
studies of the underlying physics which produce the observed astrophysical
processes. The 5 areas of laboratory astrophysics which we have identified as
relevant to the CFP panel are atomic, molecular, plasma, nuclear, and particle
physics. Here, Section 2 describes some of the new scientific opportunities and
compelling scientific themes which will be enabled by advances in laboratory
astrophysics. In Section 3, we provide the scientific context for these
opportunities. Section 4 briefly discusses some of the experimental and
theoretical advances in laboratory astrophysics required to realize the CFP
scientific opportunities of the next decade. As requested in the Call for White
Papers, Section 5 presents four central questions and one area with unusual
discovery potential. Lastly, we give a short postlude in Section 6.",242,11,1686,21.53
440,astrophysics,"As the Galaxies across Cosmic Time (GCT) panel is fully aware, the next
decade will see major advances in our understanding of these areas of research.
To quote from their charge, these advances will occur in studies of the
formation, evolution, and global properties of galaxies and galaxy clusters, as
well as active galactic nuclei and QSOs, mergers, star formation rate, gas
accretion, and supermassive black holes. Central to the progress in these areas
are the corresponding advances in laboratory astrophysics that are required for
fully realizing the GCT scientific opportunities within the decade 2010-2020.
Laboratory astrophysics comprises both theoretical and experimental studies of
the underlying physics that produce the observed astrophysical processes. The 5
areas of laboratory astrophysics that we have identified as relevant to the CFP
panel are atomic, molecular, solid matter, plasma, nuclear, and particle
physics. In this white paper, we describe in Section 2 some of the new
scientific opportunities and compelling scientific themes that will be enabled
by advances in laboratory astrophysics. In Section 3, we provide the scientific
context for these opportunities. Section 4 briefly discusses some of the
experimental and theoretical advances in laboratory astrophysics required to
realize the GCT scientific opportunities of the next decade. As requested in
the Call for White Papers, Section 5 presents four central questions and one
area with unusual discovery potential. Lastly, we give a short postlude in
Section 6.",233,11,1548,30.91
441,astrophysics,"As the Galactic Neighborhood (GAN) panel is fully aware, the next decade will
see major advances in our understanding of this area of research. To quote from
their charge, these advances will occur in studies of the galactic
neighborhood, including the structure and properties of the Milky Way and
nearby galaxies, and their stellar populations and evolution, as well as
interstellar media and star clusters. Central to the progress in these areas
are the corresponding advances in laboratory astrophysics that are required for
fully realizing the GAN scientific opportunities within the decade 2010-2020.
Laboratory astrophysics comprises both theoretical and experimental studies of
the underlying physics and chemistry that produces the observed astrophysical
processes. The 5 areas of laboratory astrophysics that we have identified as
relevant to the GAN panel are atomic, molecular, solid matter, plasma, and
nuclear physics. In this white paper, we describe in Section 2 some of the new
scientific opportunities and compelling scientific themes that will be enabled
by advances in laboratory astrophysics. In Section 3, we provide the scientific
context for these opportunities. Section 4 briefly discusses some of the
experimental and theoretical advances in laboratory astrophysics required to
realize the GAN scientific opportunities of the next decade. As requested in
the Call for White Papers, Section 5 presents four central questions and one
area with unusual discovery potential. Lastly, we give a short postlude in
Section 6.",232,11,1543,31.01
442,astrophysics,"Invited review talk given at the Meeting on ""Extragalactic Background
Radiation: A meeting in honor of Riccardo Giacconi"" Baltimore, May 18-20, 1993
Ro be published by Cambridge University Press",29,1,194,16.66
443,astrophysics,"We review and discuss information on the mass distribution of galaxy clusters
obtained from gravitational lensing.",16,2,114,21.4
444,astrophysics,"A brief outline of the current status of CMB anisotropies and what they might
mean, heavily biased towards the perspective of Berkeley theorists. Based on a
talk presented at the 17th Texas Symposium on Relativistic Astrophysics held in
Munich, December 1994.",41,3,259,50.67
445,astrophysics,"Observational constraints on standard CDM spectra and perturbation spectra
with broken scale invariance are discussed.",15,2,118,22.41
446,astrophysics,"We present the first completely analytical computation of the full
differential \gamma-\gamma pair production rate from compact radiation fields,
exact to 2nd order QED, and use this result to investigate the validity of
previously known approximations.",36,2,253,1.1
447,astrophysics,"Selected results from the HEGRA experiment on charged Cosmic Rays and on very
high energy gamma-rays are presented. The MAGIC Telescope is presented as an
outlook to the future of Gamma-Ray astronomy.",32,3,200,46.78
448,astrophysics,"In this paper we give a brief systematic study of different models of
astrophysical point sources of ultra high energy (\ge 1 TeV) neutrinos.",24,2,141,38.66
449,astrophysics,"This report provides a summary and bibliography for the research activities
at the Princeton University Observatory and Department of Astrophysical
Sciences during the period July 1, 1997 to June 30, 1998.",31,2,205,6.17
450,astrophysics,"I briefly review recent developments in the study of circumstellar debris
disks, particularly at infrared and sub-millimeter wavelengths, and discuss
possible avenues of research for the near future.",28,2,199,17.68
451,astrophysics,"This is a short review of the main results on the equation of state of a Bose
gas.Some known results are expressed in a new form,and their possible
applications in astrophysics and solid state physics are pointed out.",38,3,217,69.11
452,astrophysics,"We review basic properties of advection-dominated accretion flows (ADAFs) and
their applications to astrophysical systems ranging from Galactic binary
systems to galactic nuclei. A new classification scheme for low-luminosity,
X-ray bright galactic nuclei is highlighted. Some outstanding unresolved issues
are discussed.",41,4,321,6.81
453,astrophysics,A retrospective of Martin Schwarzschild's work on galaxy dynamics.,9,2,66,45.42
454,astrophysics,"The problem of concentration of cometary perihelia on the sphere is discussed
from the point of view of physics and astronomy. The important facts which may
be crucial in understanding the observed concentration of cometary perihelia in
the direction of solar apex are presented.",44,3,279,40.69
455,astrophysics,"Highly personalysed and subjective review of studies of the equilibrium,
pulsations and stability of stars with the first-order phase transition.",20,2,145,25.8
456,astrophysics,"It is emphasized that the existence of a very light axion is consistent with
the strong CP invariance and cosmological and astrophysical constraints. The
attempt to embed the very light axion in superstring models is discussed.",36,3,227,44.75
457,astrophysics,"This article discusses stellar dynamical evidence for supermassive black
holes in inactive and weakly active galaxies.",16,2,118,4.47
458,astrophysics,"Contrary to some recent claims the `no torque inner boundary condition' as
applied at the marginally stable orbit is correct for geometrically thin disks
accreting into black holes.",28,2,181,34.6
459,astrophysics,"We show that accretion disks with relativisticly hot electrons which are
coupled to cold ions is subject to inertial-type instability in which kinematic
drag between electrons and ions produces radial acceleration of electrons.",33,2,227,21.06
460,astrophysics,"The contributions of different radiation mechanisms to the diffuse gamma-ray
emission of the galactic disk are studied in a broad energy region from X-rays
to very high energy gamma rays.",30,2,187,32.57
461,astrophysics,"Using a criterion proposed by Salpeter and standard solid-state physics,we
have determined conditions for the occurence of the plasma-solid
transition.Possible astrophysical applications are discussed.",24,3,201,8.53
462,astrophysics,"This article (which appeared with illustrations) was the
astrophysics/cosmology contribution to the historical series ``Pathways of
Discovery'' which appeared in ``Science'' during last year.",24,2,191,13.28
463,astrophysics,"A recently proposed mechanism of acceleration of highest energy cosmic rays
by polarization electric fields arising in plasmoids injected into neutron star
magnetospheres is discussed.",25,2,184,3.8
464,astrophysics,"After an M, K, G, or F star forms, it magnetically compresses the infall
dregs to produce a close in brown dwarf.",22,2,113,66.07
465,astrophysics,"We present a new statistical algorithm of Chemical Evolution implemented into
the Tree-SPH code developed by Lia & Carraro (2000 MNRAS 314, 145).",23,2,145,32.22
466,astrophysics,"This is a brief introduction to quantum aspects of black holes, addressed at
an astrophysics-oriented audience. The topics are: The laws of black-hole
mechanics, Hawking radiation, interpretation of entropy, and primordial black
holes.",33,3,235,37.81
467,astrophysics,"Using the principle of detailed balance and the assumption on the absorption
cross-section consistent with available astrophysical data, we obtain the
energy distribution of atoms in the field of thermal blackbody radiation and
show that this distribution diverges from the Boltzmann law.",42,2,288,11.93
468,astrophysics,"After a brief historical introduction, we summarize current efforts and
accomplishments in the study of supermassive black holes.",18,2,129,27.83
469,astrophysics,"This is an intorduction to some of the basic methods and results of dense
matter physics.It is aimed at readers interested in astrophysical and physical
applications.",26,3,166,41.36
470,astrophysics,This paper has been withdrawn.,5,2,30,83.32
471,astrophysics,"John Barton was one of the experimental founders of particle astrophysics,
working in deep underground locations all over the world. This note combines
the obituary published in The Independent with a complete list of his
publications.",36,3,235,44.75
472,astrophysics,"A brief summary of several topics in the study of gravitational many body
problem is given. The discussion covers both static backgrounds (applicable to
astrophysical systems) as well as clustering in an expanding background
(relevant for cosmology)",37,2,249,27.32
473,astrophysics,"I give a synopsis of two aspects of the Galactic Cosmic Ray (GCR)
acceleration problem: the importance of the medium energy gamma-ray window, and
several specific astrophysical sources which merit further investigation.",32,2,219,5.16
474,astrophysics,"A refereed review paper which covers high resolution abundances in dSph
galaxies.",12,2,81,33.92
475,astrophysics,"Recently estimation of merger rate of double neutron stars from the
observations of PSR J0737-3039 by Burgay is discussed under real astrophysical
background.",23,2,158,22.75
476,astrophysics,"We discuss several categories of models which may explain the IMF, including
the possible role of turbulence and magnetic fields.",20,2,129,34.26
477,astrophysics,Conference Summary,2,1,18,-49.0
478,astrophysics,"In this article, a broad perspective of supernovae, their classification and
mechanism is given. Later, the astrophysical significance of supernovae is
discussed in brief.",24,3,171,25.46
479,astrophysics,"It is shown that the existence of radiation-induced solitary waves in hot
plasmas of accretion disks depends on the radial temperature profile.",22,2,143,32.22
480,astrophysics,"The use of a method of spectra disentangling for telluric lines is explained
in detail, with a particular emphasis on high-precision radial-velocity
measurements for the search for extrasolar planets. New improvements to the
method are introduced.",36,3,247,36.28
481,astrophysics,"Compact astrophysical objects produce some of the highest energy light in the
universe. The challenge is to determine what mechanism produces these photons.",23,3,156,42.88
482,astrophysics,"We present a new and exploratory method to estimate the distance of
microquasars by suggesting an empirical correlation between the bluemost point
of the bisector of the cross-correlation function and the absolute magnitude.",33,2,224,21.06
483,astrophysics,"We analyze the scepticism on the hydrodynamic turbulence in Keplerian
astrophysical disks expressed in Balbus and Hawley 2006 and show the failure of
arguments of the paper.",27,2,173,18.69
484,astrophysics,"Gigantic cosmological gamma-ray bursts have fallen into a dichotomy of long
and short bursts, each with a very different origin. The discovery of an
oddball burst calls for a rethink of that classification.",33,3,206,46.27
485,astrophysics,"The basics of the relativistic astrophysics including the celestial mechanics
in weak field, black holes and cosmological models are illustrated and analyzed
by means of Maple 6",27,1,177,27.15
486,astrophysics,"The experimental and astrophysical status of neutrino masses is reviewed with
an emphasis on the cosmologically interesting regime.",18,2,131,-6.02
487,astrophysics,"We review bounds on neutrino properties, in particular on their masses,
coming mostly from cosmology, and also from astrophysics.",19,2,129,26.81
488,astrophysics,"Non-minimal gauge models with exact unbroken improper space-time symmetries
are constructed and their cosmological and astrophysical implications explored.",18,2,155,-14.48
489,astrophysics,"Notes from 11 October 2004 lecture presented at the Joint Institute for
Nuclear Astrophysics R-Matrix School at Notre Dame University.",20,2,134,34.26
490,astrophysics,"An updated discussion of Lorentz symmetry violation in particle physics at
very high energy is presented, focusing on applications of models of deformed
Lorentz symmetry to high-energy astrophysics.",28,2,198,9.22
491,astrophysics,"Recent observational and theoretical advances concerning astronomical masers
in star forming regions are reviewed. Major masing species are considered
individually and in combination. Key results are summarized with emphasis on
present science and future prospects.",35,4,265,17.3
492,astrophysics,"This review covers selected developments in maser theory since the previous
meeting, ""Cosmic Masers: From Proto-Stars to Black Holes"" (Migenes & Reid
2002). Topics included are time variability of fundamental constants, pumping
of OH megamasers and indicators for differentiating disks from bi-directional
outflows.",43,3,315,16.32
493,astrophysics,"We discuss the anisotropic arrival directions of the ultra high energy cosmic
rays detected by Auger which I consider one of the biggest discoverie in
astrophysics during the last year.",30,2,185,32.57
494,astrophysics,"Study of astrophysical objects with strong dipolar magnetic fields show that
the spectrum of the accelerated charged particles leaving the sources has a
power law form with exponent -2.5, where the exponent is calculated on purely
geometrical bases and is independent on the particle species.",45,3,292,31.72
495,astrophysics,"We study the 2-dimensional Navier-Stokes-Poisson equations with
density-dependent viscosity $\theta=1/2$ without pressure of gaseous stars in
astrophysics. The analytical solutions with collapsing in radial symmetry, are
constructed in this paper.",30,3,247,13.95
496,astrophysics,"After a decade of Fireball reign there is a hope for thin collimated Jet to
solve the Supernova-GRB mystery",19,1,107,60.65
497,astrophysics,"These lectures review some of the techniques used to analyze the arrival
direction distribution of Cosmic Rays, and some relevant results on the field.",24,2,151,47.12
498,astrophysics,"The timing of the Local Group is used to test Modified Newtonian Dynamics
(MOND). The result shows that the masses predicted by MOND are well below the
baryonic contents of the Milky Way and Andromeda galaxies.",36,3,210,53.21
499,astrophysics,"Results of three-color photoelectric UBV observations of UU Cas performed at
Abastumani Astrophysical Observatory in 1972-1984 are presented.",18,2,141,2.44
500,neuroscience,"The problems and beauty of teaching computational neuroscience are discussed
by reviewing three new textbooks.",15,2,110,30.87
501,neuroscience,"A recent editorial in Nature noted that cognitive neuroscience is at a
crossroads where it is a thorny issue to reliably reveal brain-behavior
associations. This commentary sketches a big data science way out for cognitive
neuroscience, namely population neuroscience. In terms of design, analysis, and
interpretations, population neuroscience research takes the design control to
an unprecedented level, greatly expands the dimensions of the data analysis
space, and paves a paradigm shift for exploring mechanisms on brain-behavior
associations.",77,4,547,11.55
502,neuroscience,"It has been demonstrated that the statistical power of many neuroscience
studies is very low, so that the results are unlikely to be robustly
reproducible. How are neuroscientists and the journals in which they publish
responding to this problem? Here I review the sample size justifications
provided for all 15 papers published in one recent issue of the leading journal
Nature Neuroscience. Of these, only one claimed it was adequately powered. The
others mostly appealed to the sample sizes used in earlier studies, despite a
lack of evidence that these earlier studies were adequately powered. Thus,
concerns regarding statistical power in neuroscience have mostly not yet been
addressed.",108,6,692,44.75
503,neuroscience,"Over the last several years, the use of machine learning (ML) in neuroscience
has been rapidly increasing. Here, we review ML's contributions, both realized
and potential, across several areas of systems neuroscience. We describe four
primary roles of ML within neuroscience: 1) creating solutions to engineering
problems, 2) identifying predictive variables, 3) setting benchmarks for simple
models of the brain, and 4) serving itself as a model for the brain. The
breadth and ease of its applicability suggests that machine learning should be
in the toolbox of most systems neuroscientists.",90,5,592,40.18
504,neuroscience,"Neuroscience is undergoing a period of rapid experimental progress and
expansion. New mathematical tools, previously unknown in the neuroscience
community, are now being used to tackle fundamental questions and analyze
emerging data sets. Consistent with this trend, the last decade has seen an
uptick in the use of topological ideas and methods in neuroscience. In this
talk I will survey recent applications of topology in neuroscience, and explain
why topology is an especially natural tool for understanding neural codes.
Note: This is a write-up of my talk for the Current Events Bulletin, held at
the 2016 Joint Math Meetings in Seattle, WA.",102,6,647,42.31
505,neuroscience,"Neuroscience and artificial intelligence are closely intertwined, but so are
the physics of dynamical system, philosophy and psychology. Each of these
fields try in their own way to relate observations at the level of molecules,
synapses, neurons or behavior, to a function. An influential conceptual
approach to this end was popularized by David Marr, which focused on the
interaction between three theoretical 'levels of analysis'. With the
convergence of simulation-based approaches, algorithm-oriented Neuro-AI and
high-throughput data, we currently see much research organized around four
levels of analysis: observations, models, algorithms and functions.
Bidirectional interaction between these levels influences how we undertake
interdisciplinary science.",103,6,763,16.73
506,neuroscience,"Videogames have been a catalyst for advances in many research fields, such as
artificial intelligence, human-computer interaction or virtual reality. Over
the years, research in fields such as artificial intelligence has enabled the
design of new types of games, while games have often served as a powerful tool
for testing and simulation. Can this also happen with neuroscience? What is the
current relationship between neuroscience and games research? what can we
expect from the future? In this article, we'll try to answer these questions,
analysing the current state-of-the-art at the crossroads between neuroscience
and games and envisioning future directions.",99,4,666,46.27
507,neuroscience,"In the dawn of computer science and the eve of neuroscience we participate in
rebirth of neuroscience due to new technology that allows us to deeply and
precisely explore whole new world that dwells in our brains.",37,2,213,42.38
508,neuroscience,"In recent years, deep learning revolutionized machine learning and its
applications, producing results comparable to human experts in several domains,
including neuroscience. Each year, hundreds of scientific publications present
applications of deep neural networks for biomedical data analysis. Due to the
fast growth of the domain, it could be a complicated and extremely
time-consuming task for worldwide researchers to have a clear perspective of
the most recent and advanced software libraries. This work contributes to
clarify the current situation in the domain, outlining the most useful
libraries that implement and facilitate deep learning application to
neuroscience, allowing scientists to identify the most suitable options for
their research or clinical projects. This paper summarizes the main
developments in Deep Learning and their relevance to Neuroscience; it then
reviews neuroinformatic toolboxes and libraries, collected from the literature
and from specific hubs of software projects oriented to neuroscience research.
The selected tools are presented in tables detailing key features grouped by
domain of application (e.g. data type, neuroscience area, task), model
engineering (e.g. programming language, model customization) and technological
aspect (e.g. interface, code source). The results show that, among a high
number of available software tools, several libraries are standing out in terms
of functionalities for neuroscience applications. The aggregation and
discussion of this information can help the neuroscience community to devolop
their research projects more efficiently and quickly, both by means of readily
available tools, and by knowing which modules may be improved, connected or
added.",244,15,1733,32.02
509,neuroscience,"The field of neuroscience is facing an unprecedented expanse in the volume
and diversity of available data. Traditionally, network models have provided
key insights into the structure and function of the brain. With the advent of
big data in neuroscience, both more sophisticated models capable of
characterizing the increasing complexity of the data and novel methods of
quantitative analysis are needed. Recently multilayer networks, a mathematical
extension of traditional networks, have gained increasing popularity in
neuroscience due to their ability to capture the full information of
multi-model, multi-scale, spatiotemporal data sets. Here, we review multilayer
networks and their applications in neuroscience, showing how incorporating the
multilayer framework into network neuroscience analysis has uncovered
previously hidden features of brain networks. We specifically highlight the use
of multilayer networks to model disease, structure-function relationships,
network evolution, and link multi-scale data. Finally, we close with a
discussion of promising new directions of multilayer network neuroscience
research and propose a modified definition of multilayer networks designed to
unite and clarify the use of the multilayer formalism in describing real-world
systems.",176,8,1285,3.7
510,neuroscience,"This article discusses how to create an interactive virtual training program
at the intersection of neuroscience, robotics, and computer science for high
school students. A four-day microseminar, titled Swarming Powered by
Neuroscience (SPN), was conducted virtually through a combination of
presentations and interactive computer game simulations, delivered by subject
matter experts in neuroscience, mathematics, multi-agent swarm robotics, and
education. The objective of this research was to determine if taking an
interdisciplinary approach to high school education would enhance the students
learning experiences in fields such as neuroscience, robotics, or computer
science. This study found an improvement in student engagement for neuroscience
by 16.6%, while interest in robotics and computer science improved respectively
by 2.7% and 1.8%. The curriculum materials, developed for the SPN microseminar,
can be used by high school teachers to further evaluate interdisciplinary
instructions across life and physical sciences and computer science.",144,9,1055,16.73
511,neuroscience,"Network neuroscience represents the brain as a collection of regions and
inter-regional connections. Given its ability to formalize systems-level
models, network neuroscience has generated unique explanations of neural
function and behavior. The mechanistic status of these explanations and how
they can contribute to and fit within the field of neuroscience as a whole has
received careful treatment from philosophers. However, these philosophical
contributions have not yet reached many neuroscientists. Here we complement
formal philosophical efforts by providing an applied perspective from and for
neuroscientists. We discuss the mechanistic status of the explanations offered
by network neuroscience and how they contribute to, enhance, and interdigitate
with other types of explanations in neuroscience. In doing so, we rely on
philosophical work concerning the role of causality, scale, and mechanisms in
scientific explanations. In particular, we make the distinction between an
explanation and the evidence supporting that explanation, and we argue for a
scale-free nature of mechanistic explanations. In the course of these
discussions, we hope to provide a useful applied framework in which network
neuroscience explanations can be exercised across scales and combined with
other fields of neuroscience to gain deeper insights into the brain and
behavior.",195,10,1367,24.07
512,neuroscience,"In recent years, Artificial Intelligence (AI) shows a spectacular ability of
insertion inside a variety of disciplines which use it for scientific
advancements and which sometimes improve it for their conceptual and
methodological needs. According to the transverse science framework originally
conceived by Shinn and Joerges, AI can be seen as an instrument which is
progressively acquiring a universal character through its diffusion across
science. In this paper we address empirically one aspect of this diffusion,
namely the penetration of AI into a specific field of research. Taking
neuroscience as a case study, we conduct a scientometric analysis of the
development of AI in this field. We especially study the temporal egocentric
citation network around the articles included in this literature, their
represented journals and their authors linked together by a temporal
collaboration network. We find that AI is driving the constitution of a
particular disciplinary ecosystem in neuroscience which is distinct from other
subfields, and which is gathering atypical scientific profiles who are coming
from neuroscience or outside it. Moreover we observe that this AI community in
neuroscience is socially confined in a specific subspace of the neuroscience
collaboration network, which also publishes in a small set of dedicated
journals that are mostly active in AI research. According to these results, the
diffusion of AI in a discipline such as neuroscience didn't really challenge
its disciplinary orientations but rather induced the constitution of a
dedicated socio-cognitive environment inside this field.",241,9,1622,15.54
513,neuroscience,"Neuroscientists often describe neural activity as a representation of
something, or claim to have found evidence for a neural representation. But
what do these statements mean? The reasons to call some neural activity a
representation and the assumptions that come with this term are not generally
made clear from its common uses in neuroscience. Representation is a central
concept in philosophy of mind, with a rich history going back to the ancient
period. In order to clarify its usage in neuroscience, here we advance a link
between the connotations of this term across these disciplines. We draw on a
broad range of discourse in philosophy to distinguish three key aspects of
representation: correspondence, functional role, and teleology. We argue that
each of these aspects are implied by the explanatory role the term plays in
neuroscience. However, evidence related to all three aspects is rarely
presented or discussed in the course of individual studies that aim to identify
representations. Overlooking the significance of all three aspects hinders
communication in neuroscience, as it obscures the limitations of experimental
paradigms and conceals gaps in our understanding of the phenomena of primary
interest. Working from this three-part view, we discuss how to move toward
clearer communication about representations in the brain.",207,10,1349,33.54
514,neuroscience,"Historically, artificial intelligence has drawn much inspiration from
neuroscience to fuel advances in the field. However, current progress in
reinforcement learning is largely focused on benchmark problems that fail to
capture many of the aspects that are of interest in neuroscience today. We
illustrate this point by extending a T-maze task from neuroscience for use with
reinforcement learning algorithms, and show that state-of-the-art algorithms
are not capable of solving this problem. Finally, we point out where insights
from neuroscience could help explain some of the issues encountered.",87,5,598,40.89
515,neuroscience,"Digital services such as repositories and science gateways have become key
resources for the neuroscience community, but users often have a hard time
orienting themselves in the service landscape to find the best fit for their
particular needs. INCF (International Neuroinformatics Coordinating Facility)
has developed a set of recommendations and associated criteria for choosing or
setting up and running a repository or scientific gateway, intended for the
neuroscience community, with a FAIR neuroscience perspective. These
recommendations have neurosciences as their primary use case but are often
general. Considering the perspectives of researchers and providers of
repositories as well as scientific gateways, the recommendations harmonize and
complement existing work on criteria for repositories and best practices. The
recommendations cover a range of important areas including accessibility,
licensing, community responsibility and technical and financial sustainability
of a service.",136,6,996,1.57
516,neuroscience,"Neuroscience research has evolved to generate increasingly large and complex
experimental data sets, and advanced data science tools are taking on central
roles in neuroscience research. Neurodata Without Borders (NWB), a standard
language for neurophysiology data, has recently emerged as a powerful solution
for data management, analysis, and sharing. We here discuss our efforts to
implement NWB data science pipelines. We describe general principles and
specific use cases that illustrate successes, challenges, and non-trivial
decisions in software engineering. We hope that our experience can provide
guidance for the neuroscience community and help bridge the gap between
experimental neuroscience and data science.",101,6,722,25.59
517,neuroscience,"Recently, large language models (LLMs) have outperformed human experts in
predicting the results of neuroscience experiments (Luo et al., 2024). What is
the basis for this performance? One possibility is that statistical patterns in
that specific scientific literature, as opposed to emergent reasoning abilities
arising from broader training, underlie LLMs' performance. To evaluate this
possibility, we trained (next word prediction) a relatively small
124M-parameter GPT-2 model on 1.3 billion tokens of domain-specific knowledge.
Despite being orders of magnitude smaller than larger LLMs trained on trillions
of tokens, small models achieved expert-level performance in predicting
neuroscience results. Small models trained on the neuroscience literature
succeeded when they were trained from scratch using a tokenizer specifically
trained on neuroscience text or when the neuroscience literature was used to
finetune a pretrained GPT-2. Our results indicate that expert-level performance
may be attained by even small LLMs through domain-specific, auto-regressive
training approaches.",148,9,1090,27.32
518,neuroscience,"Directed information theory deals with communication channels with feedback.
When applied to networks, a natural extension based on causal conditioning is
needed. We show here that measures built from directed information theory in
networks can be used to assess Granger causality graphs of stochastic
processes. We show that directed information theory includes measures such as
the transfer entropy, and that it is the adequate information theoretic
framework needed for neuroscience applications, such as connectivity inference
problems.",76,5,540,26.81
519,neuroscience,"We find that rats, like primates and humans, perform better on the random dot
motion task when they take more time to respond. We provide evidence that this
improvement is due to stimulus integration. Rats increase their response
latency modestly as a function of trial difficulty. Rats can modulate response
latency more strongly on a trial by trial basis, apparently on the basis of
reward-related parameters.",66,5,411,46.27
520,neuroscience,"Mammalian brain is one of the most complex objects in the known universe, as
it governs every aspect of animal's and human behavior. It is fair to say that
we have a very limited knowledge of how the brain operates and functions.
Computational Neuroscience is a scientific discipline that attempts to
understand and describe the brain in terms of mathematical modeling. This
user-friendly review tries to introduce this relatively new field to
mathematicians and physicists by showing examples of recent trends. It also
discusses briefly future prospects for constructing an integrated theory of
brain function.",95,6,611,43.73
521,neuroscience,"This paper introduces several fundamental concepts in information theory from
the perspective of their origins in engineering. Understanding such concepts is
important in neuroscience for two reasons. Simply applying formulae from
information theory without understanding the assumptions behind their
definitions can lead to erroneous results and conclusions. Furthermore, this
century will see a convergence of information theory and neuroscience;
information theory will expand its foundations to incorporate more
comprehensively biological processes thereby helping reveal how neuronal
networks achieve their remarkable information processing abilities.",83,5,656,-0.41
522,neuroscience,"Connectomics and network neuroscience offer quantitative scientific
frameworks for modeling and analyzing networks of structurally and functionally
interacting neurons, neuronal populations, and macroscopic brain areas. This
shift in perspective and emphasis on distributed brain function has provided
fundamental insight into the role played by the brain's network architecture in
cognition, disease, development, and aging. In this chapter, we review the core
concepts of human connectomics at the macroscale. From the construction of
networks using functional and diffusion MRI data, to their subsequent analysis
using methods from network neuroscience, this review highlights key findings,
commonly-used methodologies, and discusses several emerging frontiers in
connectomics.",102,5,780,11.75
523,neuroscience,"Functional optical imaging in neuroscience is rapidly growing with the
development of new optical systems and fluorescence indicators. To realize the
potential of these massive spatiotemporal datasets for relating neuronal
activity to behavior and stimuli and uncovering local circuits in the brain,
accurate automated processing is increasingly essential. In this review, we
cover recent computational developments in the full data processing pipeline of
functional optical microscopy for neuroscience data and discuss ongoing and
emerging challenges.",75,4,552,3.8
524,neuroscience,"At the intersection of computational neuroscience (CN) and data mining (DM),
we advocate a holistic view toward their rich connections. On the one hand,
fundamental concepts in neuroscience such as saliency, memory, and emotion can
find novel applications in data mining. On the other hand, multimodal imaging
has opened the door for data mining to facilitate the extraction of important
cognitive and behavioral information from multimodal neural data. By NeuroDM,
we advocate for more collaboration between CN and DM to expedite the advances
in two well-established fields. The analogy between the over-parameterization
of biological and artificial neural networks might suggest a unifying
perspective of advancing both fields.",107,6,729,24.37
525,neuroscience,"The exponential growth of neuroscience literature presents a significant
challenge for researchers seeking to efficiently access and utilize relevant
information. To address this issue, we introduce the Brain Knowledge Engine
(BrainKnow), an automated system designed to extract, link, and synthesize
neuroscience knowledge from scientific publications. BrainKnow constructs a
comprehensive knowledge graph encompassing 3,626,931 relationships across
37,011 neuroscience concepts, derived from 1,817,744 articles. This vast
repository of knowledge is accessible through a user-friendly web interface,
facilitating efficient navigation and data retrieval. BrainKnow employs
advanced graph network algorithms, specifically Node2Vec, to enhance knowledge
recommendation and visualization. This enables users to explore semantic
relationships between concepts, predict potential new relationships, and gain a
deeper understanding of the interconnectedness within neuroscience.
Additionally, BrainKnow ensures real-time updates by synchronizing with PubMed,
providing researchers with access to the most current information. BrainKnow
serves as a valuable resource for neuroscience researchers, offering a powerful
tool for exploring, synthesizing, and leveraging the vast and complex knowledge
base of the field.",162,9,1308,8.57
526,neuroscience,"Participant needs to achieve a given power are frequently underestimated.
This is particularly problematic when effect sizes are small, such as is common
in neuroscience and psychology. We provide tools to make these demands
immediately obvious in the form of a powerscape visualization.",43,4,287,31.58
527,neuroscience,"Information theory is a practical and theoretical framework developed for the
study of communication over noisy channels. Its probabilistic basis and
capacity to relate statistical structure to function make it ideally suited for
studying information flow in the nervous system. As a framework it has a number
of useful properties: it provides a general measure sensitive to any
relationship, not only linear effects; its quantities have meaningful units
which in many cases allow direct comparison between different experiments; and
it can be used to study how much information can be gained by observing neural
responses in single experimental trials, rather than in averages over multiple
trials. A variety of information theoretic quantities are in common use in
neuroscience - including the Shannon entropy, Kullback-Leibler divergence, and
mutual information. In this entry, we introduce and define these quantities.
Further details on how these quantities can be estimated in practice are
provided in the entry ""Estimation of Information-Theoretic Quantities"" and
examples of application of these techniques in neuroscience can be found in the
entry ""Applications of Information-Theoretic Quantities in Neuroscience"".",178,7,1224,7.69
528,neuroscience,"Diverse subfields of neuroscience have enriched artificial intelligence for
many decades. With recent advances in machine learning and artificial neural
networks, many neuroscientists are partnering with AI researchers and machine
learning experts to analyze data and construct models. This paper attempts to
demonstrate the value of such collaborations by providing examples of how
insights derived from neuroscience research are helping to develop new machine
learning algorithms and artificial neural network architectures. We survey the
relevant neuroscience necessary to appreciate these insights and then describe
how we can translate our current understanding of the relevant neurobiology
into algorithmic techniques and architectural designs. Finally, we characterize
some of the major challenges facing current AI technology and suggest avenues
for overcoming these challenges that draw upon research in developmental and
comparative cognitive neuroscience.",130,6,966,11.25
529,neuroscience,"We organized a workshop on the ""Present and Future Frameworks of Theoretical
Neuroscience"", with the support of the National Science Foundation. The
objective was to identify the challenges and strategies that this field will
need to tackle in order to incorporate vast and multi-scale streams of
experimental data from the technologies developed by the BRAIN initiative. The
participants, divided in workgroups, identified five key areas that, while not
exhaustive, cover multiple aspects of current challenges needed to be
developed: Dynamics-statistics; multi-scale integration; coding; brain-body
integration; and structure of neuroscience theories. While each area is
different, there were coincidences on finding theoretical paths to incorporate
biophysics, energetics, and ethology with more abstract coding and
computational approaches. Each workgroup has continued to work after the
meeting to develop the ideas seeded there, which are started to being
published. Here, we provide a perspective of the discussions of each workgroup
that point to building on the present foundations of theoretical neuroscience
and extend them by incorporating multi-scale information with the objective of
providing mechanistic insights into the nervous system.",176,7,1253,16.36
530,neuroscience,"Reinforcement learning methods have recently been very successful at
performing complex sequential tasks like playing Atari games, Go and Poker.
These algorithms have outperformed humans in several tasks by learning from
scratch, using only scalar rewards obtained through interaction with their
environment. While there certainly has been considerable independent innovation
to produce such results, many core ideas in reinforcement learning are inspired
by phenomena in animal learning, psychology and neuroscience. In this paper, we
comprehensively review a large number of findings in both neuroscience and
psychology that evidence reinforcement learning as a promising candidate for
modeling learning and decision making in the brain. In doing so, we construct a
mapping between various classes of modern RL algorithms and specific findings
in both neurophysiological and behavioral literature. We then discuss the
implications of this observed relationship between RL, neuroscience and
psychology and its role in advancing research in both AI and brain science.",152,7,1067,20.42
531,neuroscience,"In this study, following the idea of our previous paper (Wang, et al.,
2013a), we improve the method to detect and track hot topics in a specific
field by using the real-time article usage data. With the ""usage count"" data
provided by Web of Science, we take the field of computational neuroscience as
an example to make analysis. About 10 thousand articles in the field of
Computational Neuroscience are queried in Web of Science, when the records,
including the usage count data of each paper, have been harvested and updated
weekly from October 19, 2015 to March 21, 2016. The hot topics are defined by
the most frequently used keywords aggregated from the articles. The analysis
reveals that hot topics in Computational Neuroscience are related to the key
technologies, like ""fmri"", ""eeg"", ""erp"", etc. Furthermore, using the weekly
updated data, we track the dynamical changes of the topics. The characteristic
of immediacy of usage data makes it possible to track the ""heat"" of hot topics
timely and dynamically.",168,9,1017,50.16
532,neuroscience,"While probabilistic models describe the dependence structure between observed
variables, causal models go one step further: they predict, for example, how
cognitive functions are affected by external interventions that perturb
neuronal activity. In this review and perspective article, we introduce the
concept of causality in the context of cognitive neuroscience and review
existing methods for inferring causal relationships from data. Causal inference
is an ambitious task that is particularly challenging in cognitive
neuroscience. We discuss two difficulties in more detail: the scarcity of
interventional data and the challenge of finding the right variables. We argue
for distributional robustness as a guiding principle to tackle these problems.
Robustness (or invariance) is a fundamental principle underlying causal
methodology. A causal model of a target variable generalises across
environments or subjects as long as these environments leave the causal
mechanisms intact. Consequently, if a candidate model does not generalise, then
either it does not consist of the target variable's causes or the underlying
variables do not represent the correct granularity of the problem. In this
sense, assessing generalisability may be useful when defining relevant
variables and can be used to partially compensate for the lack of
interventional data.",195,10,1356,24.07
533,neuroscience,"A major challenge in both neuroscience and machine learning is the
development of useful tools for understanding complex information processing
systems. One such tool is probes, i.e., supervised models that relate features
of interest to activation patterns arising in biological or artificial neural
networks. Neuroscience has paved the way in using such models through numerous
studies conducted in recent decades. In this work, we draw insights from
neuroscience to help guide probing research in machine learning. We highlight
two important design choices for probes $-$ direction and expressivity $-$ and
relate these choices to research goals. We argue that specific research goals
play a paramount role when designing a probe and encourage future probing
studies to be explicit in stating these goals.",122,9,808,45.66
534,neuroscience,"Noninvasive medical neuroimaging has yielded many discoveries about the brain
connectivity. Several substantial techniques mapping morphological, structural
and functional brain connectivities were developed to create a comprehensive
road map of neuronal activities in the human brain -namely brain graph. Relying
on its non-Euclidean data type, graph neural network (GNN) provides a clever
way of learning the deep graph structure and it is rapidly becoming the
state-of-the-art leading to enhanced performance in various network
neuroscience tasks. Here we review current GNN-based methods, highlighting the
ways that they have been used in several applications related to brain graphs
such as missing brain graph synthesis and disease classification. We conclude
by charting a path toward a better application of GNN models in network
neuroscience field for neurological disorder diagnosis and population graph
integration. The list of papers cited in our work is available at
https://github.com/basiralab/GNNs-in-Network-Neuroscience.",142,8,1038,22.04
535,neuroscience,"We propose that in order to harness our understanding of neuroscience toward
machine learning, we must first have powerful tools for training brain-like
models of learning. Although substantial progress has been made toward
understanding the dynamics of learning in the brain, neuroscience-derived
models of learning have yet to demonstrate the same performance capabilities as
methods in deep learning such as gradient descent. Inspired by the successes of
machine learning using gradient descent, we demonstrate that models of
neuromodulated synaptic plasticity from neuroscience can be trained in Spiking
Neural Networks (SNNs) with a framework of learning to learn through gradient
descent to address challenging online learning problems. This framework opens a
new path toward developing neuroscience inspired online learning algorithms.",119,5,842,24.31
536,neuroscience,"Recent advances in machine learning have made revolutionary breakthroughs in
computer games, image and natural language understanding, and scientific
discovery. Foundation models and large-scale language models (LLMs) have
recently achieved human-like intelligence thanks to BigData. With the help of
self-supervised learning (SSL) and transfer learning, these models may
potentially reshape the landscapes of neuroscience research and make a
significant impact on the future. Here we present a mini-review on recent
advances in foundation models and generative AI models as well as their
applications in neuroscience, including natural language and speech, semantic
memory, brain-machine interfaces (BMIs), and data augmentation. We argue that
this paradigm-shift framework will open new avenues for many neuroscience
research directions and discuss the accompanying challenges and opportunities.",120,6,897,21.74
537,neuroscience,"Scientists are adopting new approaches to scale up their activities and
goals. Progress in neurotechnologies, artificial intelligence, automation, and
tools for collaboration promises new bursts of discoveries. However, compared
to other disciplines and the industry, neuroscience laboratories have been slow
to adopt key technologies to support collaboration, reproducibility, and
automation. Drawing on progress in other fields, we define a roadmap for
implementing automated research workflows for diverse research teams. We
propose establishing a five-level capability maturity model for operations in
neuroscience research. Achieving higher levels of operational maturity requires
new technology-enabled methodologies, which we describe as ``SciOps''. The
maturity model provides guidelines for evaluating and upgrading operations in
multidisciplinary neuroscience teams.",111,8,876,13.04
538,neuroscience,"The proliferation and refinement of affordable virtual reality (VR)
technologies and wearable sensors have opened new frontiers in cognitive and
behavioral neuroscience. This chapter offers a broad overview of VR for anyone
interested in leveraging it as a research tool. In the first section, it
examines the fundamental functionalities of VR and outlines important
considerations that inform the development of immersive content that stimulates
the senses. In the second section, the focus of the discussion shifts to the
implementation of VR in the context of the neuroscience lab. Practical advice
is offered on adapting commercial, off-theshelf devices to specific research
purposes. Further, methods are explored for recording, synchronizing, and
fusing heterogeneous forms of data obtained through the VR system or add-on
sensors, as well as for labeling events and capturing game play.",132,7,893,32.22
539,neuroscience,"A central goal in neuroscience is to provide explanations for how animal
nervous systems can generate actions and cognitive states such as consciousness
while artificial intelligence (AI) and machine learning (ML) seek to provide
models that are increasingly better at prediction. Despite many decades of
research we have made limited progress on providing neuroscience explanations
yet there is an increased use of AI and ML methods in neuroscience for
prediction of behavior and even cognitive states. Here we propose emulator
theory (ET) and neural emulators as circuit- and scale-independent predictive
models of biological brain activity and emulator theory (ET) as an alternative
research paradigm in neuroscience. ET proposes that predictive models trained
solely on neural dynamics and behaviors can generate functionally
indistinguishable systems from their sources. That is, compared to the
biological organisms which they model, emulators may achieve indistinguishable
behavior and cognitive states - including consciousness - without any
mechanistic explanations. We posit ET via several conjectures, discuss the
nature of endogenous and exogenous activation of neural circuits, and discuss
neural causality of phenomenal states. ET provides the conceptual and empirical
framework for prediction-based models of neural dynamics and behavior without
explicit representations of idiosyncratically evolved nervous systems.",199,8,1431,9.11
540,neuroscience,"Visually comparing brain networks, or connectomes, is an essential task in
the field of neuroscience. Especially relevant to the field of clinical
neuroscience, group studies that examine differences between populations or
changes over time within a population enable neuroscientists to reason about
effective diagnoses and treatments for a range of neuropsychiatric disorders.
In this paper, we specifically explore how visual analytics tools can be used
to facilitate various clinical neuroscience tasks, in which observation and
analysis of meaningful patterns in the connectome can support patient diagnosis
and treatment. We conduct a survey of visualization tasks that enable clinical
neuroscience activities, and further explore how existing connectome
visualization tools support or fail to support these tasks. Based on our
investigation of these tasks, we introduce a novel visualization tool,
NeuroCave, to support group studies analyses. We discuss how our design
decisions (the use of immersive visualization, the use of hierarchical
clustering and dimensionality reduction techniques, and the choice of visual
encodings) are motivated by these tasks. We evaluate NeuroCave through two use
cases that illustrate the utility of interactive connectome visualization in
clinical neuroscience contexts. In the first use case, we study sex differences
using functional connectomes and discover hidden connectome patterns associated
with well-known cognitive differences in spatial and verbal abilities. In the
second use case, we show how the utility of visualizing the brain in different
topological space coupled with clustering information can reveal the brain's
intrinsic structure.",239,10,1694,19.1
541,neuroscience,"Immersive virtual reality (VR) emerges as a promising research and clinical
tool. However, several studies suggest that VR induced adverse symptoms and
effects (VRISE) may undermine the health and safety standards, and the
reliability of the scientific results. In the current literature review, the
technical reasons for the adverse symptomatology are investigated to provide
suggestions and technological knowledge for the implementation of VR
head-mounted display (HMD) systems in cognitive neuroscience. The technological
systematic literature indicated features pertinent to display, sound, motion
tracking, navigation, ergonomic interactions, user experience, and computer
hardware that should be considered by the researchers. Subsequently, a
meta-analysis of 44 neuroscientific or neuropsychological studies involving VR
HMD systems was performed. The meta-analysis of the VR studies demonstrated
that new generation HMDs induced significantly less VRISE and marginally fewer
dropouts.Importantly, the commercial versions of the new generation HMDs with
ergonomic interactions had zero incidents of adverse symptomatology and
dropouts. HMDs equivalent to or greater than the commercial versions of
contemporary HMDs accompanied with ergonomic interactions are suitable for
implementation in cognitive neuroscience. In conclusion, researchers
technological competency, along with meticulous methods and reports pertinent
to software, hardware, and VRISE, are paramount to ensure the health and safety
standards and the reliability of neuroscientific results.",205,10,1565,6.03
542,neuroscience,"Neuroscience is undergoing dramatic progress because of the vast data streams
derived from the new technologies product of the BRAIN initiative and other
enterprises. As any other scientific field, neuroscience benefits from having
clear definitions of its theoretical components and their interactions. This
allows generating theories that integrate knowledge, provide mechanistic
insights, and predict results under new experimental conditions. However,
theoretical neuroscience is a heterogeneous field that has not yet agreed on
how to build theories or whether it is desirable to have an overarching theory
or whether theories are simply tools to understand the brain. Here we advocate
for the need of developing theoretical frameworks as a basis of generating
common theoretical structures. We enumerate the elements of theoretical
frameworks we deem necessary for any theory in neuroscience. In particular, we
address the notions of paradigms, models, and scales of organizations. We then
identify areas with pressing needs to develop brain theories: integration of
statistical and dynamic approaches; multi-scale integration; coding; and
interpretability in the context of Artificial Intelligence. We also point out
that future theoretical frameworks would benefit from the incorporation of the
principles of Evolution as a fundamental structure rather than purely
mathematical or engineering principles. Rather than providing definite answers,
the objective of this paper is to serve as an initial and succinct presentation
of these topics to encourage discussion and further in depth development of
each topic.",232,11,1620,14.09
543,neuroscience,"Reinforcement learning has a rich history in neuroscience, from early work on
dopamine as a reward prediction error signal for temporal difference learning
(Schultz et al., 1997) to recent work suggesting that dopamine could implement
a form of 'distributional reinforcement learning' popularized in deep learning
(Dabney et al., 2020). Throughout this literature, there has been a tight link
between theoretical advances in reinforcement learning and neuroscientific
experiments and findings. As a result, the theories describing our experimental
data have become increasingly complex and difficult to navigate. In this
review, we cover the basic theory underlying classical work in reinforcement
learning and build up to an introductory overview of methods used in modern
deep reinforcement learning that have found applications in systems
neuroscience. We start with an overview of the reinforcement learning problem
and classical temporal difference algorithms, followed by a discussion of
'model-free' and 'model-based' reinforcement learning together with methods
such as DYNA and successor representations that fall in between these two
categories. Throughout these sections, we highlight the close parallels between
the machine learning methods and related work in both experimental and
theoretical neuroscience. We then provide an introduction to deep reinforcement
learning with examples of how these methods have been used to model different
learning phenomena in the systems neuroscience literature, such as
meta-reinforcement learning (Wang et al., 2018) and distributional
reinforcement learning (Dabney et al., 2020). Code that implements the methods
discussed in this work and generates the figures is also provided.",245,13,1732,21.23
544,neuroscience,"Finding general principles underlying brain function has been appealing to
scientists. Indeed, in some branches of science like physics and chemistry (and
to some degree biology) a general theory often can capture the essence of a
wide range of phenomena. Whether we can find such principles in neuroscience,
and [assuming they do exist] what those principles are, are important
questions. Abstracting the brain as a complex system is one of the perspectives
that may help us answer this question.
  While it is commonly accepted that the brain is a (or even the) prominent
example of a complex system, the far reaching implications of this are still
arguably overlooked in our approaches to neuroscientific questions. One of the
reasons for the lack of attention could be the apparent difference in foci of
investigations in these two fields -- neuroscience and complex systems. This
thesis is an effort toward providing a bridge between systems neuroscience and
complex systems by harnessing systems neuroscience tools & notions for building
empirical approaches toward the brain as a complex system.
  Perhaps, in the spirit of searching for principles, we should abstract and
approach the brain as a complex adaptive system as the more complete
perspective (rather than just a complex system). In the end, the brain, even
the most ""complex system"", need to survive in the environment. Indeed, in the
field of complex adaptive systems, the intention is understanding very similar
questions in nature. As an outlook, we also touch on some research directions
pertaining to the adaptivity of the brain as well.",257,12,1611,47.93
545,neuroscience,"The unprecedented availability of large-scale datasets in neuroscience has
spurred the exploration of artificial deep neural networks (DNNs) both as
empirical tools and as models of natural neural systems. Their appeal lies in
their ability to approximate arbitrary functions directly from observations,
circumventing the need for cumbersome mechanistic modeling. However, without
appropriate constraints, DNNs risk producing implausible models, diminishing
their scientific value. Moreover, the interpretability of DNNs poses a
significant challenge, particularly with the adoption of more complex
expressive architectures. In this perspective, we argue for universal
differential equations (UDEs) as a unifying approach for model development and
validation in neuroscience. UDEs view differential equations as
parameterizable, differentiable mathematical objects that can be augmented and
trained with scalable deep learning techniques. This synergy facilitates the
integration of decades of extensive literature in calculus, numerical analysis,
and neural modeling with emerging advancements in AI into a potent framework.
We provide a primer on this burgeoning topic in scientific machine learning and
demonstrate how UDEs fill in a critical gap between mechanistic,
phenomenological, and data-driven models in neuroscience. We outline a flexible
recipe for modeling neural systems with UDEs and discuss how they can offer
principled solutions to inherent challenges across diverse neuroscience
applications such as understanding neural computation, controlling neural
systems, neural decoding, and normative modeling.",215,10,1622,13.38
546,neuroscience,"We extracted and processed abstract data from the SFN annual meeting
abstracts during the period 2001-2006, using techniques and software from
natural language processing, database management, and data visualization and
analysis. An important first step in the process was the application of data
cleaning and disambiguation methods to construct a unified database, since the
data were too noisy to be of full utility in the raw form initially available.
The resulting co-author graph in 2006, for example, had 39,645 nodes (with an
estimated 6% error rate in our disambiguation of similar author names) and
13,979 abstracts, with an average of 1.5 abstracts per author, 4.3 authors per
abstract, and 5.96 collaborators per author (including all authors on shared
abstracts). Recent work in related areas has focused on reputational indices
such as highly cited papers or scientists and journal impact factors, and to a
lesser extent on creating visual maps of the knowledge space. In contrast,
there has been relatively less work on the demographics and community
structure, the dynamics of the field over time to examine major research trends
and the structure of the sources of research funding. In this paper we examined
each of these areas in order to gain an objective overview of contemporary
neuroscience. Some interesting findings include a high geographical
concentration of neuroscience research in north eastern United States, a
surprisingly large transient population (60% of the authors appear in only one
out of the six studied years), the central role played by the study of
neurodegenerative disorders in the neuroscience community structure, and an
apparent growth of behavioral/systems neuroscience with a corresponding
shrinkage of cellular/molecular neuroscience over the six year period.",276,11,1809,35.0
547,neuroscience,"This paper presents the first comprehensive tutorial on a promising research
field located at the frontier of two well-established domains: Neurosciences
and wireless communications, motivated by the ongoing efforts to define how the
sixth generation of mobile networks (6G) will be. In particular, this tutorial
first provides a novel integrative approach that bridges the gap between these
two, seemingly disparate fields. Then, we present the state-of-the-art and key
challenges of these two topics. In particular, we propose a novel
systematization that divides the contributions into two groups, one focused on
what neurosciences will offer to 6G in terms of new applications and systems
architecture (Neurosciences for Wireless), and the other focused on how
wireless communication theory and 6G systems can provide new ways to study the
brain (Wireless for Neurosciences). For the first group, we concretely explain
how current scientific understanding of the brain would enable new application
for 6G within the context of a new type of service that we dub braintype
communications and that has more stringent requirements than human- and
machine-type communication. In this regard, we expose the key requirements of
brain-type communication services and we discuss how future wireless networks
can be equipped to deal with such services. Meanwhile, for the second group, we
thoroughly explore modern communication system paradigms, including Internet of
Bio-nano Things and chaosbased communications, in addition to highlighting how
complex systems tools can help bridging 6G and neuroscience applications.
Brain-controlled vehicles are then presented as our case study. All in all,
this tutorial is expected to provide a largely missing articulation between
these two emerging fields while delineating concrete ways to move forward in
such an interdisciplinary endeavor.",276,10,1880,23.39
548,neuroscience,"We explain the notion of colimit in category theory as a potential tool for
describing structures and their communication, and the notion of higher
dimensional algebra as a potential yoga for dealing with processes and
processes of processes.",38,2,242,7.53
549,neuroscience,"We review our recent work on applying the Google PageRank algorithm to find
scientific ""gems"" among all Physical Review publications, and its extension to
CiteRank, to find currently popular research directions. These metrics provide
a meaningful extension to traditionally-used importance measures, such as the
number of citations and journal impact factor. We also point out some pitfalls
of over-relying on quantitative metrics to evaluate scientific quality.",66,4,462,23.77
550,neuroscience,"We consider a bivariate diffusion process and we study the first passage time
of one component through a boundary. We prove that its probability density is
the unique solution of a new integral equation and we propose a numerical
algorithm for its solution. Convergence properties of this algorithm are
discussed and the method is applied to the study of the integrated Brownian
Motion and to the integrated Ornstein Uhlenbeck process. Finally a model of
neuroscience interest is also discussed.",79,5,495,42.92
551,neuroscience,"Here we provide a thorough discussion of the study conducted by Rodgers et
al. (J Neurosci. 2015; 35(24):9194-204. doi: 10.1523/JNEUROSCI.0919-15.2015) to
investigate focal seizures and acquired epileptogenesis induced by head injury
in the rat. This manuscript serves as supplementary document for our letter to
the Editor to appear in the Journal of Neuroscience. We find that the subject
article suffers from poor experimental design, very selective consideration of
antecedent literature, and application of inappropriate epilepsy diagnostic
criteria which, together, lead to unwarranted conclusions.",83,10,604,24.98
552,neuroscience,"Recent advances in computer vision have made accurate, fast and robust
measurement of animal behavior a reality. In the past years powerful tools
specifically designed to aid the measurement of behavior have come to fruition.
Here we discuss how capturing the postures of animals - pose estimation - has
been rapidly advancing with new deep learning methods. While challenges still
remain, we envision that the fast-paced development of new deep learning tools
will rapidly change the landscape of realizable real-world neuroscience.",81,5,533,42.92
553,neuroscience,"Building machines that learn and think like humans is essential not only for
cognitive science, but also for computational neuroscience, whose ultimate goal
is to understand how cognition is implemented in biological brains. A new
cognitive computational neuroscience should build cognitive-level and neural-
level models, understand their relationships, and test both types of models
with both brain and behavioral data.",60,3,421,15.65
554,neuroscience,"The SW has undeniably been one of the most popular network descriptors in the
neuroscience literature. Two main reasons for its lasting popularity are its
apparent ease of computation and the intuitions it is thought to provide on how
networked systems operate. Over the last few years, some pitfalls of the SW
construct and, more generally, of network summary measures, have widely been
acknowledged.",64,4,401,41.4
555,neuroscience,"The Wilson-Cowan equations represent a landmark in the history of
computational neuroscience. Among the insights Wilson and Cowan offered for
neuroscience, they crystallized an approach to modeling neural dynamics and
brain function. Although their iconic equations are used in various guises
today, the ideas that led to their formulation and the relationship to other
approaches are not well known. Here, we give a little context to some of the
biological and theoretical concepts that lead to the Wilson-Cowan equations and
discuss how to extend beyond them.",86,5,561,41.19
556,neuroscience,"In 1982 John Hopfield published a neural network model for memory retrieval,
a model that became a cornerstone in theoretical neuroscience. A key ingredient
of the Hopfield model was the use of a network dynamics that is governed by a
Lyapunov function. In a recent paper, Krotov and Hopfield showed how a Lyapunov
function governs a biological plausible learning rule for the neural networks'
connectivity. By doing so, they bring an intriguing approach to classification
tasks, and show the relevance of the broader framework across decades in the
field.",89,5,556,40.38
557,neuroscience,"The interactions play one of the central roles in the brain mediating various
processes and functions. They are particularly important for the brain as a
complex system that has many different functions from the same structural
connectivity. When studying such neural interactions the coupling functions are
very suitable, as inherently they can reveal the underlaying functional
mechanism. This chapter overviews some recent and widely used aspects of
coupling functions for studying neural interactions. Coupling functions are
discussed in connection to two different levels of brain interactions - that of
neuron interactions and brainwave cross-frequency interactions. Aspects
relevant to this from both, theory and methods, are presented. Although the
discussion is based on neuroscience, there are strong implications from, and
to, other fields as well.",124,8,859,36.69
558,neuroscience,"This paper reviews predictive coding, from theoretical neuroscience, and
variational autoencoders, from machine learning, identifying the common origin
and mathematical framework underlying both areas. As each area is prominent
within its respective field, more firmly connecting these areas could prove
useful in the dialogue between neuroscience and machine learning. After
reviewing each area, we discuss two possible correspondences implied by this
perspective: cortical pyramidal dendrites as analogous to (non-linear) deep
networks and lateral inhibition as analogous to normalizing flows. These
connections may provide new directions for further investigations in each
field.",91,5,682,14.49
559,neuroscience,"Meta-learning, or learning to learn, has gained renewed interest in recent
years within the artificial intelligence community. However, meta-learning is
incredibly prevalent within nature, has deep roots in cognitive science and
psychology, and is currently studied in various forms within neuroscience. The
aim of this review is to recast previous lines of research in the study of
biological intelligence within the lens of meta-learning, placing these works
into a common framework. More recent points of interaction between AI and
neuroscience will be discussed, as well as interesting new directions that
arise under this perspective.",94,5,639,30.7
560,neuroscience,"Unlike the brain, artificial neural networks, including state-of-the-art deep
neural networks for computer vision, are subject to ""catastrophic forgetting"":
they rapidly forget the previous task when trained on a new one. Neuroscience
suggests that biological synapses avoid this issue through the process of
synaptic consolidation and metaplasticity: the plasticity itself changes upon
repeated synaptic events. In this work, we show that this concept of
metaplasticity can be transferred to a particular type of deep neural networks,
binarized neural networks, to reduce catastrophic forgetting.",83,4,597,17.98
561,neuroscience,"The fast-growing field of Computational Cognitive Neuroscience is on track to
meet its first crisis. A large number of papers in this nascent field are
developing and testing novel analysis methods using the same stimuli and
neuroimaging datasets. Publication bias and confirmatory exploration will
result in overfitting to the limited available data. The field urgently needs
to collect more good quality open neuroimaging data using a variety of
experimental stimuli, to test the generalisability of current published
results, and allow for more robust results in future work.",87,5,578,32.43
562,neuroscience,"We have developed a graphic user interface (GUI), ExBrainable, dedicated to
convolutional neural networks (CNN) model training and visualization in
electroencephalography (EEG) decoding. Available functions include model
training, evaluation, and parameter visualization in terms of temporal and
spatial representations. We demonstrate these functions using a well-studied
public dataset of motor-imagery EEG and compare the results with existing
knowledge of neuroscience. The primary objective of ExBrainable is to provide a
fast, simplified, and user-friendly solution of EEG decoding for investigators
across disciplines to leverage cutting-edge methods in brain/neuroscience
research.",88,5,689,15.31
563,neuroscience,"Although principles of neuroscience like reinforcement learning, visual
perception and attention have been applied in machine learning models, there is
a huge gap between machine learning and mammalian learning. Based on the
advances in neuroscience, we propose the context sequence theory to give a
common explanation for multiple types of learning in mammals and hope that can
provide a new insight into the construct of machine learning models.",68,3,447,28.51
564,neuroscience,"Recently, the computational neuroscience community has pushed for more
transparent and reproducible methods across the field. In the interest of
unifying the domain of auditory neuroscience, naplib-python provides an
intuitive and general data structure for handling all neural recordings and
stimuli, as well as extensive preprocessing, feature extraction, and analysis
tools which operate on that data structure. The package removes many of the
complications associated with this domain, such as varying trial durations and
multi-modal stimuli, and provides a general-purpose analysis framework that
interfaces easily with existing toolboxes used in the field.",92,4,662,14.93
565,neuroscience,"The existence of periodic solutions is proven for some neuroscience models
with a small parameter. Moreover, the stability of such solutions is
investigated, as well. The results are based on a theoretical research dealing
with the functional differential equation with parameters $$ \dot{x}(t)=L(\tau)
x_t + \varepsilon f(t, x_t), $$ where $L: \mathbb{R}_+\rightarrow
\mathcal{L}(C; \mathbb{R})$ and $f: \mathbb{R} \times C \rightarrow \mathbb{R}$
are, respectively, linear and nonlinear operators, and $\varepsilon>0$ is a
small enough parameter. The theoretical results are applied to a Parkinson's
disease model, where the obtained conclusions are illustrated by numerical
simulations.",93,5,689,14.8
566,neuroscience,"We address the question: Why are dynamical laws governing in quantum
mechanics and in neuroscience of probabilistic nature instead of being
deterministic? We discuss some ideas showing that the probabilistic option
offers advantages over the deterministic one.",37,2,260,27.32
567,neuroscience,"We examine the qualitative and quantitative properties of continuous
attractor networks in explaining the dynamics of grid cells.",18,2,129,10.91
568,neuroscience,"Leibniz thought experiment of perception, sensing, and thinking is
reconsidered. We try to understand Leibniz picture in view of our knowledge of
basic neuroscience. In particular we can see how the emergence of consciousness
could in principle be understood.",39,4,259,49.82
569,neuroscience,"Human learning is a complex phenomenon that requires adaptive processes
across a range of temporal and spacial scales. While our understanding of those
processes at single scales has increased exponentially over the last few years,
a mechanistic understanding of the entire phenomenon has remained elusive. We
propose that progress has been stymied by the lack of a quantitative framework
that can account for the full range of neurophysiological and behavioral
dynamics both across scales in the systems and also across different types of
learning. We posit that network neuroscience offers promise in meeting this
challenge. Built on the mathematical fields of complex systems science and
graph theory, network neuroscience embraces the interconnected and hierarchical
nature of human learning, offering insights into the emergent properties of
adaptability. In this review, we discuss the utility of network neuroscience as
a tool to build a quantitative framework in which to study human learning,
which seeks to explain the full chain of events in the brain from sensory input
to motor output, being both biologically plausible and able to make predictions
about how an intervention at a single level of the chain may cause alterations
in another level of the chain. We close by laying out important remaining
challenges in network neuroscience in explicitly bridging spatial scales at
which neurophysiological processes occur, and underscore the utility of such a
quantitative framework for education and therapy.",231,8,1519,21.06
570,neuroscience,"Network neuroscience is the emerging discipline concerned with investigating
the complex patterns of interconnections found in neural systems, and to
identify principles with which to understand them. Within this discipline, one
particularly powerful approach is network generative modeling, in which wiring
rules are algorithmically implemented to produce synthetic network
architectures with the same properties as observed in empirical network data.
Successful models can highlight the principles by which a network is organized
and potentially uncover the mechanisms by which it grows and develops. Here we
review the prospects and promise of generative models for network neuroscience.
We begin with a primer on network generative models, with a discussion of
compressibility and predictability, utility in intuiting mechanisms, and a
short history on their use in network science broadly. We then discuss
generative models in practice and application, paying particular attention to
the critical need for cross-validation. Next, we review generative models of
biological neural networks, both at the cellular and large-scale level, and
across a variety of species including \emph{C. elegans}, \emph{Drosophila},
mouse, rat, cat, macaque, and human. We offer a careful treatment of a few
relevant distinctions, including differences between generative models and null
models, sufficiency and redundancy, inferring and claiming mechanism, and
functional and structural connectivity. We close with a discussion of future
directions, outlining exciting frontiers both in empirical data collection
efforts as well as in method and theory development that, together, further the
utility of the generative network modeling approach for network neuroscience.",246,11,1756,12.67
571,neuroscience,"Granger-Geweke causality (GGC) is a powerful and popular method for
identifying directed functional (`causal') connectivity in neuroscience. In a
recent paper, Stokes and Purdon [1] raise several concerns about its use. They
make two primary claims: (1) that GGC estimates may be severely biased or of
high variance, and (2) that GGC fails to reveal the full structural/causal
mechanisms of a system. However, these claims rest, respectively, on an
incomplete evaluation of the literature, and a misconception about what GGC can
be said to measure. Here we explain how existing approaches (as implemented,
for example, in our popular MVGC software [2,3]) resolve the first issue, and
discuss the frequently-misunderstood distinction between functional and
effective neural connectivity which underlies Stokes and Purdon's second claim.
  [1] Patrick A. Stokes and Patrick. L. Purdon (2017), A study of problems
encountered in Granger causality analysis from a neuroscience perspective,
Proc. Natl. Acad. Sci. USA 114(34):7063-7072.
  [2] Lionel Barnett and Anil K. Seth (2012), The MVGC Multivariate Granger
Causality Matlab toolbox, http://users.sussex.ac.uk/~lionelb/MVGC/
  [3] Lionel Barnett and Anil K. Seth (2014), The MVGC multivariate Granger
causality toolbox: A new approach to Granger-causal inference, J. Neurosci.
Methods 223:50-68",191,21,1344,46.88
572,neuroscience,"Neuroscience education can be promoted by the availability of low cost and
engaging teaching materials. To address this issue, we developed an open-source
lipid bilayer amplifier, the OpenPicoAmp, which is appropriate for use in
introductory courses in biophysics or neurosciences dealing with the electrical
properties of the cell membrane. The amplifier is designed using the common
lithographic printed circuit board fabrication process and off-the-shelf
electronic components. In addition, we propose a specific design for
experimental chambers allowing the insertion of a commercially available
polytetrafluoroethylene film. This experimental setup can be used in simple
experiments in which students monitor the bilayer formation by capacitance
measurement and record unitary currents produced by ionic channels like
gramicidin A. Used in combination with a low-cost data acquisition board this
system provides a complete solution for hands-on lessons, therefore improving
the effectiveness in teaching basic neurosciences or biophysics.",143,7,1043,13.48
573,neuroscience,"At many scales in neuroscience, appropriate mathematical models take the form
of complex dynamical systems. Parametrising such models to conform to the
multitude of available experimental constraints is a global nonlinear
optimisation problem with a complex fitness landscape, requiring numerical
techniques to find suitable approximate solutions. Stochastic optimisation
approaches, such as evolutionary algorithms, have been shown to be effective,
but often the setting up of such optimisations and the choice of a specific
search algorithm and its parameters is non-trivial, requiring domain-specific
expertise. Here we describe BluePyOpt, a Python package targeted at the broad
neuroscience community to simplify this task. BluePyOpt is an extensible
framework for data-driven model parameter optimisation that wraps and
standardises several existing open-source tools. It simplifies the task of
creating and sharing these optimisations, and the associated techniques and
knowledge. This is achieved by abstracting the optimisation and evaluation
tasks into various reusable and flexible discrete elements according to
established best-practices. Further, BluePyOpt provides methods for setting up
both small- and large-scale optimisations on a variety of platforms, ranging
from laptops to Linux clusters and cloud-based compute infrastructures. The
versatility of the BluePyOpt framework is demonstrated by working through three
representative neuroscience specific use cases.",199,10,1482,15.2
574,neuroscience,"From interacting cellular components to networks of neurons and neural
systems, interconnected units comprise a fundamental organizing principle of
the nervous system. Understanding how their patterns of connections and
interactions give rise to the many functions of the nervous system is a primary
goal of neuroscience. Recently, this pursuit has begun to benefit from the
development of new mathematical tools that can relate a system's architecture
to its dynamics and function. These tools, which are known collectively as
network science, have been used with increasing success to build models of
neural systems across spatial scales and species. Here we discuss the nature of
network models in neuroscience. We begin with a review of model theory from a
philosophical perspective to inform our view of networks as models of complex
systems in general, and of the brain in particular. We then summarize the types
of models that are frequently studied in network neuroscience along three
primary dimensions: from data representations to first-principles theory, from
biophysical realism to functional phenomenology, and from elementary
descriptions to coarse-grained approximations. We then consider ways to
validate these models, focusing on approaches that perturb a system to probe
its function. We close with a description of important frontiers in the
construction of network models and their relevance for understanding
increasingly complex functions of neural systems.",219,10,1480,29.89
575,neuroscience,"As a neuroscientist and a theoretical physicist, both working on time, we
have decided to open a direct dialogue to examine if the apparent discrepancies
regarding the nature of time can be composed.",33,2,199,21.06
576,neuroscience,"Like many scientific disciplines, neuroscience has increasingly attempted to
confront pervasive gender imbalances within the field. While much of the
conversation has centered around publishing and conference participation,
recent research in other fields has called attention to the prevalence of
gender bias in citation practices. Because of the downstream effects that
citations can have on visibility and career advancement, understanding and
eliminating gender bias in citation practices is vital for addressing inequity
in a scientific community. In this study, we sought to determine whether there
is evidence of gender bias in the citation practices of neuroscientists. Using
data from five top neuroscience journals, we find that reference lists tend to
include more papers with men as first and last author than would be expected if
gender were not a factor in referencing. Importantly, we show that this
overcitation of men and undercitation of women is driven largely by the
citation practices of men, and is increasing over time as the field becomes
more diverse. We develop a co-authorship network to assess homophily in
researchers' social networks, and we find that men tend to overcite men even
when their social networks are representative. We discuss possible mechanisms
and consider how individual researchers might address these findings in their
own practices.",209,9,1382,36.52
577,neuroscience,"Artificial intelligence (AI) and neuroscience share a rich history, with
advancements in neuroscience shaping the development of AI systems capable of
human-like knowledge retention. Leveraging insights from neuroscience and
existing research in adversarial and continual learning, we introduce a novel
framework comprising two core concepts: feature distillation and
re-consolidation. Our framework, named Robust Rehearsal, addresses the
challenge of catastrophic forgetting inherent in continual learning (CL)
systems by distilling and rehearsing robust features. Inspired by the mammalian
brain's memory consolidation process, Robust Rehearsal aims to emulate the
rehearsal of distilled experiences during learning tasks. Additionally, it
mimics memory re-consolidation, where new experiences influence the integration
of past experiences to mitigate forgetting. Extensive experiments conducted on
CIFAR10, CIFAR100, and real-world helicopter attitude datasets showcase the
superior performance of CL models trained with Robust Rehearsal compared to
baseline methods. Furthermore, examining different optimization training
objectives-joint, continual, and adversarial learning-we highlight the crucial
role of feature learning in model performance. This underscores the
significance of rehearsing CL-robust samples in mitigating catastrophic
forgetting. In conclusion, aligning CL approaches with neuroscience insights
offers promising solutions to the challenge of catastrophic forgetting, paving
the way for more robust and human-like AI systems.",195,10,1551,7.15
578,neuroscience,"This report enlists 13 functional conditions cashed out in computational
terms that have been argued to be constituent of conscious valenced experience.
These are extracted from existing empirical and theoretical literature on,
among others, animal sentience, medical disorders, anaesthetics, philosophy,
evolution, neuroscience, and artificial intelligence.",45,3,358,-2.13
579,neuroscience,"Computational neuroscience is being revolutionized with the advent of
multi-electrode arrays that provide real-time, dynamic, perspectives into brain
function. Mining event streams from these chips is critical to understanding
the firing patterns of neurons and to gaining insight into the underlying
cellular activity. We present a GPGPU solution to mining spike trains. We focus
on mining frequent episodes which captures coordinated events across time even
in the presence of intervening background/""junk"" events. Our algorithmic
contributions are two-fold: MapConcatenate, a new computation-to-core mapping
scheme, and a two-pass elimination approach to quickly find supported episodes
from a large number of candidates. Together, they help realize a real-time
""chip-on-chip"" solution to neuroscience data mining, where one chip (the
multi-electrode array) supplies the spike train data and another (the GPGPU)
mines it at a scale unachievable previously. Evaluation on both synthetic and
real datasets demonstrate the potential of our approach.",146,8,1049,33.34
580,neuroscience,"Recent developments in data management and imaging technologies have
significantly affected diagnostic and extrapolative research in the
understanding of neurodegenerative diseases. However, the impact of these new
technologies is largely dependent on the speed and reliability with which the
medical data can be visualised, analysed and interpreted. The EUs neuGRID for
Users (N4U) is a follow-on project to neuGRID, which aims to provide an
integrated environment to carry out computational neuroscience experiments.
This paper reports on the design and development of the N4U Analysis Base and
related Information Services, which addresses existing research and practical
challenges by offering an integrated medical data analysis environment with the
necessary building blocks for neuroscientists to optimally exploit neuroscience
workflows, large image datasets and algorithms in order to conduct analyses.
The N4U Analysis Base enables such analyses by indexing and interlinking the
neuroimaging and clinical study datasets stored on the N4U Grid infrastructure,
algorithms and scientific workflow definitions along with their associated
provenance information.",160,6,1167,5.16
581,neuroscience,"Information theory is a practical and theoretical framework developed for the
study of communication over noisy channels. Its probabilistic basis and
capacity to relate statistical structure to function make it ideally suited for
studying information flow in the nervous system. It has a number of useful
properties: it is a general measure sensitive to any relationship, not only
linear effects; it has meaningful units which in many cases allow direct
comparison between different experiments; and it can be used to study how much
information can be gained by observing neural responses in single trials,
rather than in averages over multiple trials. A variety of information
theoretic quantities are commonly used in neuroscience - (see entry
""Definitions of Information-Theoretic Quantities""). In this entry we review
some applications of information theory in neuroscience to study encoding of
information in both single neurons and neuronal populations.",143,6,959,8.81
582,neuroscience,"The tools of weakly coupled phase oscillator theory have had a profound
impact on the neuroscience community, providing insight into a variety of
network behaviours ranging from central pattern generation to synchronisation,
as well as predicting novel network states such as chimeras. However, there are
many instances when this theory is expected to break down, say in the presence
of strong coupling, or must be carefully interpreted, as in the presence of
stochastic forcing. There are also surprises in the dynamical complexity of the
attractors that can robustly appear - for example, heteroclinic network
attractors. In this review we present a set of mathematical tools that are
suitable for addressing the dynamics of oscillatory neural networks, broadening
from a standard phase oscillator perspective to provide a practical framework
for further successful applications of mathematics to understanding network
dynamics in neuroscience.",140,5,946,10.77
583,neuroscience,"Neuroscience has focused on the detailed implementation of computation,
studying neural codes, dynamics and circuits. In machine learning, however,
artificial neural networks tend to eschew precisely designed codes, dynamics or
circuits in favor of brute force optimization of a cost function, often using
simple and relatively uniform initial architectures. Two recent developments
have emerged within machine learning that create an opportunity to connect
these seemingly divergent perspectives. First, structured architectures are
used, including dedicated systems for attention, recursion and various forms of
short- and long-term memory storage. Second, cost functions and training
procedures have become more complex and are varied across layers and over time.
Here we think about the brain in terms of these ideas. We hypothesize that (1)
the brain optimizes cost functions, (2) these cost functions are diverse and
differ across brain locations and over development, and (3) optimization
operates within a pre-structured architecture matched to the computational
problems posed by behavior. Such a heterogeneously optimized system, enabled by
a series of interacting cost functions, serves to make learning data-efficient
and precisely targeted to the needs of the organism. We suggest directions by
which neuroscience could seek to refine and test these hypotheses.",196,10,1374,32.43
584,neuroscience,"This paper discusses the risks and potential impacts of spreadsheet errors in
scientific research data in a Neuroscience research centre in the UK.
  Spreadsheets usage in neuroscience, or indeed any medical discipline, is a
largely unreported area of spreadsheet research. This paper presents a case
study exploring the possible risks and impacts of spreadsheet errors in the
neuroscience research centre at the University of Newcastle. Data was collected
using an online questionnaire with 17 participants and two detailed
semi-structured interviews.
  The analysis highlights that errors in research data may lead to severe
impacts such as misleading science and damaged personal and organisational
reputations. In addition, many risks factors arise from using spreadsheets such
as inadequate design and a lack of training.
  Spreadsheets are used widely in business and the impacts and risks in these
fields have been studied and highlighted in detail. However, scientific
research and spreadsheets have also a significant relationship that has not
been clarified. The paper also draws out the similarities in spreadsheet
practice between the scientific and business communities.",173,10,1183,35.07
585,neuroscience,"This is a comment to the paper 'A study of problems encountered in Granger
causality analysis from a neuroscience perspective'. We agree that
interpretation issues of Granger Causality in Neuroscience exist (partially due
to the historical unfortunate use of the name 'causality', as nicely described
in previous literature). On the other hand we think that the paper uses a
formulation of Granger causality which is outdated (albeit still used), and in
doing so it dismisses the measure based on a suboptimal use of it. Furthermore,
since data from simulated systems are used, the pitfalls that are found with
the used formulation are intended to be general, and not limited to
neuroscience. It would be a pity if this paper, even written in good faith,
became a wildcard against all possible applications of Granger Causality,
regardless of the hard work of colleagues aiming to seriously address the
methodological and interpretation pitfalls. In order to provide a balanced
view, we replicated their simulations used the updated State Space
implementation, proposed already some years ago, in which the pitfalls are
mitigated or directly solved.",181,7,1149,32.36
586,neuroscience,"The impact of built environment on the human restorativeness has long been
argued; however, the interrelations between neuroscience and the built
environment, and the degree to which the built environment contributes to
increased human restorativeness has not been completely understood yet.
Understanding the interrelations between neuroscience and the built environment
is critical as 90% of time in a typical day is spent indoors and architectural
features impact the productivity, health and comfort of occupants. The goal of
this study is to bring a structured understanding of architecture and
neuroscience interactions in designed facilities and quantification of the
impact of design on human experience. The authors first built two virtual
environments (i.e., restorative and non-restorative) using the architectural
designs features related to human restorativeness identified by previous
research efforts. Next, user experiments were conducted in the two built
virtual environments including 22 people. The subjects were asked to conduct
navigational tasks while their bodily responses recorded by body area sensors
(e.g., EEG, GSR, and Eye-tracking). The result showed that human responses in
restorative and non-restorative environment had statistically significant
difference. This study serves as the first step of understanding human
responses in the virtual environment, and designing spaces that maximize human
experience.",201,13,1440,25.69
587,neuroscience,"This article proposes a systematic methodological review and objective
criticism of existing methods enabling the derivation of time-varying
Granger-causality statistics in neuroscience. The increasing interest and the
huge number of publications related to this topic calls for this systematic
review which describes the very complex methodological aspects. The capacity to
describe the causal links between signals recorded at different brain locations
during a neuroscience experiment is of primary interest for neuroscientists,
who often have very precise prior hypotheses about the relationships between
recorded brain signals that arise at a specific time and in a specific
frequency band. The ability to compute a time-varying frequency-specific
causality statistic is therefore essential. Two steps are necessary to achieve
this: the first consists of finding a statistic that can be interpreted and
that directly answers the question of interest. The second concerns the model
that underlies the causality statistic and that has this time-frequency
specific causality interpretation. In this article, we will review
Granger-causality statistics with their spectral and time-varying extensions.",167,8,1202,21.84
588,neuroscience,"Human-machine interactions are being increasingly explored to create
alternative ways of communication and to improve our daily life. Based on a
classification of the user's intention from the user's underlying neural
activity, brain-computer interfaces (BCIs) allow direct interactions with the
external environment while bypassing the traditional effector of the
musculoskeletal system. Despite the enormous potential of BCIs, there are still
a number of challenges that limit their societal impact, ranging from the
correct decoding of a human's thoughts, to the application of effective
learning strategies. Despite several important engineering advances, the basic
neuroscience behind these challenges remains poorly explored. Indeed, BCIs
involve complex dynamic changes related to neural plasticity at a diverse range
of spatiotemporal scales. One promising antidote to this complexity lies in
network science, which provides a natural language in which to model the
organizational principles of brain architecture and function as manifest in its
interconnectivity. Here, we briefly review the main limitations currently
affecting BCIs, and we offer our perspective on how they can be addressed by
means of network theoretic approaches. We posit that the emerging field of
network neuroscience will prove to be an effective tool to unlock human-machine
interactions.",195,9,1373,21.33
589,neuroscience,"To learn how cognition is implemented in the brain, we must build
computational models that can perform cognitive tasks, and test such models
with brain and behavioral experiments. Cognitive science has developed
computational models of human cognition, decomposing task performance into
computational components. However, its algorithms still fall short of human
intelligence and are not grounded in neurobiology. Computational neuroscience
has investigated how interacting neurons can implement component functions of
brain computation. However, it has yet to explain how those components interact
to explain human cognition and behavior. Modern technologies enable us to
measure and manipulate brain activity in unprecedentedly rich ways in animals
and humans. However, experiments will yield theoretical insight only when
employed to test brain-computational models. It is time to assemble the pieces
of the puzzle of brain computation. Here we review recent work in the
intersection of cognitive science, computational neuroscience, and artificial
intelligence. Computational models that mimic brain information processing
during perceptual, cognitive, and control tasks are beginning to be developed
and tested with brain and behavioral data.",173,11,1248,20.08
590,neuroscience,"Neural network models can now recognise images, understand text, translate
languages, and play many human games at human or superhuman levels. These
systems are highly abstracted, but are inspired by biological brains and use
only biologically plausible computations. In the coming years, neural networks
are likely to become less reliant on learning from massive labelled datasets,
and more robust and generalisable in their task performance. From their
successes and failures, we can learn about the computational requirements of
the different tasks at which brains excel. Deep learning also provides the
tools for testing cognitive theories. In order to test a theory, we need to
realise the proposed information-processing system at scale, so as to be able
to assess its feasibility and emergent behaviours. Deep learning allows us to
scale up from principles and circuit models to end-to-end trainable models
capable of performing complex tasks. There are many levels at which cognitive
neuroscientists can use deep learning in their work, from inspiring theories to
serving as full computational models. Ongoing advances in deep learning bring
us closer to understanding how cognition and perception may be implemented in
the brain -- the grand challenge at the core of cognitive neuroscience.",198,10,1299,40.79
591,neuroscience,"At present, artificial intelligence in the form of machine learning is making
impressive progress, especially the field of deep learning (DL) [1]. Deep
learning algorithms have been inspired from the beginning by nature,
specifically by the human brain, in spite of our incomplete knowledge about its
brain function. Learning from nature is a two-way process as discussed in
[2][3][4], computing is learning from neuroscience, while neuroscience is
quickly adopting information processing models. The question is, what can the
inspiration from computational nature at this stage of the development
contribute to deep learning and how much models and experiments in machine
learning can motivate, justify and lead research in neuroscience and cognitive
science and to practical applications of artificial intelligence.",119,5,817,24.31
592,neuroscience,"Neuroscience research is undergoing a minor revolution. Recent advances in
machine learning and artificial intelligence (AI) research have opened up new
ways of thinking about neural computation. Many researchers are excited by the
possibility that deep neural networks may offer theories of perception,
cognition and action for biological brains. This perspective has the potential
to radically reshape our approach to understanding neural systems, because the
computations performed by deep networks are learned from experience, not
endowed by the researcher. If so, how can neuroscientists use deep networks to
model and understand biological brains? What is the outlook for neuroscientists
who seek to characterise computations or neural codes, or who wish to
understand perception, attention, memory, and executive functions? In this
Perspective, our goal is to offer a roadmap for systems neuroscience research
in the age of deep learning. We discuss the conceptual and methodological
challenges of comparing behaviour, learning dynamics, and neural representation
in artificial and biological systems. We highlight new research questions that
have emerged for neuroscience as a direct consequence of recent advances in
machine learning.",178,8,1243,26.0
593,neuroscience,"The Thermodynamic Formalism provides a rigorous mathematical framework to
study quantitative and qualitative aspects of dynamical systems. At its core
there is a variational principle corresponding, in its simplest form, to the
Maximum Entropy principle. It is used as a statistical inference procedure to
represent, by specific probability measures (Gibbs measures), the collective
behaviour of complex systems. This framework has found applications in
different domains of science. In particular, it has been fruitful and
influential in neurosciences. In this article, we review how the Thermodynamic
Formalism can be exploited in the field of theoretical neuroscience, as a
conceptual and operational tool, to link the dynamics of interacting neurons
and the statistics of action potentials from either experimental data or
mathematical models. We comment on perspectives and open problems in
theoretical neuroscience that could be addressed within this formalism.",138,8,967,17.64
594,neuroscience,"Attention is a complex and broad concept, studied across multiple disciplines
spanning artificial intelligence, cognitive science, psychology, neuroscience,
and related fields. Although many of the ideas regarding attention do not
significantly overlap among these fields, there is a common theme of adaptive
control of limited resources. In this work, we review the concept and variants
of attention in artificial neural networks (ANNs). We also discuss the origin
of attention from the neuroscience point of view parallel to that of ANNs.
Instead of having seemingly disconnected dialogues between varied disciplines,
we suggest grounding the ideas on common conceptual frameworks for a systematic
analysis of attention and towards possible unification of ideas in AI and
Neuroscience.",114,6,787,31.41
595,neuroscience,"In recent years, deep neural networks (DNNs) achieved state-of-the-art
performance on several computer vision tasks. However, the one typical drawback
of these DNNs is the requirement of massive labeled data. Even though few-shot
learning methods address this problem, they often use techniques such as
meta-learning and metric-learning on top of the existing methods. In this work,
we address this problem from a neuroscience perspective by proposing a
hypothesis named Ikshana, which is supported by several findings in
neuroscience. Our hypothesis approximates the refining process of conceptual
gist in the human brain while understanding a natural scene/image. While our
hypothesis holds no particular novelty in neuroscience, it provides a novel
perspective for designing DNNs for vision tasks. By following the Ikshana
hypothesis, we design a novel neural-inspired CNN architecture named
IkshanaNet. The empirical results demonstrate the effectiveness of our method
by outperforming several baselines on the entire and subsets of the Cityscapes
and the CamVid semantic segmentation benchmarks.",157,9,1100,34.66
596,neuroscience,"Neuroscience is undergoing faster changes than ever before. Over 100 years
our field qualitatively described and invasively manipulated single or few
organisms to gain anatomical, physiological, and pharmacological insights. In
the last 10 years neuroscience spawned quantitative big-sample datasets on
microanatomy, synaptic connections, optogenetic brain-behavior assays, and
high-level cognition. While growing data availability and information
granularity have been amply discussed, we direct attention to a routinely
neglected question: How will the unprecedented data richness shape data
analysis practices? Statistical reasoning is becoming more central to distill
neurobiological knowledge from healthy and pathological brain recordings. We
believe that large-scale data analysis will use more models that are
non-parametric, generative, mixing frequentist and Bayesian aspects, and
grounded in different statistical inferences.",119,6,936,9.08
597,neuroscience,"We developed a prediction model based on the evolutionary causal matrices
(ECM) and the Markov Chain to predict long-term influences of educational
interventions on adolescents development. Particularly, we created a
computational model predicting longitudinal influences of different types of
stories of moral exemplars on adolescents voluntary service participation. We
tested whether the developed prediction model can properly predict a long-term
longitudinal trend of change in voluntary service participation rate by
comparing prediction results and surveyed data. Furthermore, we examined which
type of intervention would most effectively promote service engagement and what
is the minimum required frequency of intervention to produce a large effect. We
discussed the implications of the developed prediction model in educational
interventions based on educational neuroscience.",119,6,886,5.02
598,neuroscience,"This paper is the final part of the scientific discussion organised by the
Journal ""Physics of Life Rviews"" about the simplicity revolution in
neuroscience and AI. This discussion was initiated by the review paper ""The
unreasonable effectiveness of small neural ensembles in high-dimensional
brain"". Phys Life Rev 2019, doi 10.1016/j.plrev.2018.09.005, arXiv:1809.07656.
The topics of the discussion varied from the necessity to take into account the
difference between the theoretical random distributions and ""extremely
non-random"" real distributions and revise the common machine learning theory,
to different forms of the curse of dimensionality and high-dimensional pitfalls
in neuroscience. V. K{\r{u}}rkov{\'a}, A. Tozzi and J.F. Peters, R. Quian
Quiroga, P. Varona, R. Barrio, G. Kreiman, L. Fortuna, C. van Leeuwen, R. Quian
Quiroga, and V. Kreinovich, A.N. Gorban, V.A. Makarov, and I.Y. Tyukin
participated in the discussion. In this paper we analyse the symphony of
opinions and the possible outcomes of the simplicity revolution for machine
learning and neuroscience.",156,31,1080,40.14
599,neuroscience,"Although a number of studies have explored deep learning in neuroscience, the
application of these algorithms to neural systems on a microscopic scale, i.e.
parameters relevant to lower scales of organization, remains relatively novel.
Motivated by advances in whole-brain imaging, we examined the performance of
deep learning models on microscopic neural dynamics and resulting emergent
behaviors using calcium imaging data from the nematode C. elegans. We show that
neural networks perform remarkably well on both neuron-level dynamics
prediction, and behavioral state classification. In addition, we compared the
performance of structure agnostic neural networks and graph neural networks to
investigate if graph structure can be exploited as a favorable inductive bias.
To perform this experiment, we designed a graph neural network which explicitly
infers relations between neurons from neural activity and leverages the
inferred graph structure during computations. In our experiments, we found that
graph neural networks generally outperformed structure agnostic models and
excel in generalization on unseen organisms, implying a potential path to
generalizable machine learning in neuroscience.",168,10,1202,13.28
600,neuroscience,"A major shift is happening within neurophysiology: a population doctrine is
drawing level with the single-neuron doctrine that has long dominated the
field. Population-level ideas have so far had their greatest impact in motor
neuroscience, but they hold great promise for resolving open questions in
cognition as well. Here, we codify the population doctrine and survey recent
work that leverages this view to specifically probe cognition. Our discussion
is organized around five core concepts that provide a foundation for
population-level thinking: (1) state spaces, (2) manifolds, (3) coding
dimensions, (4) subspaces, and (5) dynamics. The work we review illustrates the
progress and promise that population neurophysiology holds for cognitive
neuroscience$-$for delivering new insight into attention, working memory,
decision-making, executive function, learning, and reward processing.",124,6,892,20.92
601,neuroscience,"Computational modeling plays an increasingly important role in neuroscience,
highlighting the philosophical question of how computational models explain. In
the context of neural network models for neuroscience, concerns have been
raised about model intelligibility, and how they relate (if at all) to what is
found in the brain. We claim that what makes a system intelligible is an
understanding of the dependencies between its behavior and the factors that are
causally responsible for that behavior. In biological systems, many of these
dependencies are naturally ""top-down"": ethological imperatives interact with
evolutionary and developmental constraints under natural selection. We describe
how the optimization techniques used to construct NN models capture some key
aspects of these dependencies, and thus help explain why brain systems are as
they are -- because when a challenging ecologically-relevant goal is shared by
a NN and the brain, it places tight constraints on the possible mechanisms
exhibited in both kinds of systems. By combining two familiar modes of
explanation -- one based on bottom-up mechanism (whose relation to neural
network models we address in a companion paper) and the other on top-down
constraints, these models illuminate brain function.",190,7,1277,22.79
602,neuroscience,"The Computational Metaphor, comparing the brain to the computer and vice
versa, is the most prominent metaphor in neuroscience and artificial
intelligence (AI). Its appropriateness is highly debated in both fields,
particularly with regards to whether it is useful for the advancement of
science and technology. Considerably less attention, however, has been devoted
to how the Computational Metaphor is used outside of the lab, and particularly
how it may shape society's interactions with AI. As such, recently publicized
concerns over AI's role in perpetuating racism, genderism, and ableism suggest
that the term ""artificial intelligence"" is misplaced, and that a new lexicon is
needed to describe these computational systems. Thus, there is an essential
question about the Computational Metaphor that is rarely asked by
neuroscientists: whom does it help and whom does it harm? This essay invites
the neuroscience community to consider the social implications of the field's
most controversial metaphor.",150,6,1008,29.18
603,neuroscience,"Many deep neural network architectures loosely based on brain networks have
recently been shown to replicate neural firing patterns observed in the brain.
One of the most exciting and promising novel architectures, the Transformer
neural network, was developed without the brain in mind. In this work, we show
that transformers, when equipped with recurrent position encodings, replicate
the precisely tuned spatial representations of the hippocampal formation; most
notably place and grid cells. Furthermore, we show that this result is no
surprise since it is closely related to current hippocampal models from
neuroscience. We additionally show the transformer version offers dramatic
performance gains over the neuroscience version. This work continues to bind
computations of artificial and brain networks, offers a novel understanding of
the hippocampal-cortical interaction, and suggests how wider cortical areas may
perform complex tasks beyond current neuroscience models such as language
comprehension.",143,7,1012,30.4
604,neuroscience,"Neuroscience models commonly have a high number of degrees of freedom and
only specific regions within the parameter space are able to produce dynamics
of interest. This makes the development of tools and strategies to efficiently
find these regions of high importance to advance brain research. Exploring the
high dimensional parameter space using numerical simulations has been a
frequently used technique in the last years in many areas of computational
neuroscience. High performance computing (HPC) can provide today a powerful
infrastructure to speed up explorations and increase our general understanding
of the model's behavior in reasonable times.",97,5,656,29.89
605,neuroscience,"In human neuroscience, machine learning can help reveal lower-dimensional
neural representations relevant to subjects' behavior. However,
state-of-the-art models typically require large datasets to train, so are prone
to overfitting on human neuroimaging data that often possess few samples but
many input dimensions. Here, we capitalized on the fact that the features we
seek in human neuroscience are precisely those relevant to subjects' behavior.
We thus developed a Task-Relevant Autoencoder via Classifier Enhancement
(TRACE), and tested its ability to extract behaviorally-relevant, separable
representations compared to a standard autoencoder, a variational autoencoder,
and principal component analysis for two severely truncated machine learning
datasets. We then evaluated all models on fMRI data from 59 subjects who
observed animals and objects. TRACE outperformed all models nearly
unilaterally, showing up to 12% increased classification accuracy and up to 56%
improvement in discovering ""cleaner"", task-relevant representations. These
results showcase TRACE's potential for a wide variety of data related to human
behavior.",155,8,1139,15.2
606,neuroscience,"Despite evidence for the existence of engrams as memory support structures in
our brains, there is no consensus framework in neuroscience as to what their
physical implementation might be. Here we propose how we might design a
computer system to implement engrams using neural networks, with the main aim
of exploring new ideas using machine learning techniques, guided by challenges
in neuroscience. Building on autoencoders, we propose latent neural spaces as
indexes for storing and retrieving information in a compressed format. We
consider this technique as a first step towards predictive learning:
autoencoders are designed to compare reconstructed information with the
original information received, providing a kind of predictive ability, which is
an attractive evolutionary argument. We then consider how different states in
latent neural spaces corresponding to different types of sensory input could be
linked by synchronous activation, providing the basis for a sparse
implementation of memory using concept neurons. Finally, we list some of the
challenges and questions that link neuroscience and data science and that could
have implications for both fields, and conclude that a more interdisciplinary
approach is needed, as many scientists have already suggested.",189,7,1279,22.58
607,neuroscience,"In many neuromorphic workflows, simulators play a vital role for important
tasks such as training spiking neural networks (SNNs), running neuroscience
simulations, and designing, implementing and testing neuromorphic algorithms.
Currently available simulators are catered to either neuroscience workflows
(such as NEST and Brian2) or deep learning workflows (such as BindsNET). While
the neuroscience-based simulators are slow and not very scalable, the deep
learning-based simulators do not support certain functionalities such as
synaptic delay that are typical of neuromorphic workloads. In this paper, we
address this gap in the literature and present SuperNeuro, which is a fast and
scalable simulator for neuromorphic computing, capable of both homogeneous and
heterogeneous simulations as well as GPU acceleration. We also present
preliminary results comparing SuperNeuro to widely used neuromorphic simulators
such as NEST, Brian2 and BindsNET in terms of computation times. We demonstrate
that SuperNeuro can be approximately 10--300 times faster than some of the
other simulators for small sparse networks. On large sparse and large dense
networks, SuperNeuro can be approximately 2.2 and 3.4 times faster than the
other simulators respectively.",178,10,1255,34.46
608,neuroscience,"In this paper we consider Bayesian parameter inference associated to a class
of partially observed stochastic differential equations (SDE) driven by jump
processes. Such type of models can be routinely found in applications, of which
we focus upon the case of neuroscience. The data are assumed to be observed
regularly in time and driven by the SDE model with unknown parameters. In
practice the SDE may not have an analytically tractable solution and this leads
naturally to a time-discretization. We adapt the multilevel Markov chain Monte
Carlo method of [11], which works with a hierarchy of time discretizations and
show empirically and theoretically that this is preferable to using one single
time discretization. The improvement is in terms of the computational cost
needed to obtain a pre-specified numerical error. Our approach is illustrated
on models that are found in neuroscience.",140,8,895,42.72
609,neuroscience,"In neuroscience, researchers have developed informal notions of what it means
to reverse engineer a system, e.g., being able to model or simulate a system in
some sense. A recent influential paper of Jonas and Kording, that examines a
microprocessor using techniques from neuroscience, suggests that common
techniques to understand neural systems are inadequate. Part of the difficulty,
as a previous work of Lazebnik noted, lies in lack of formal language. We
provide a theoretical framework for defining reverse engineering of
computational systems, motivated by the neuroscience context. Of specific
interest are recent works where, increasingly, interventions are being made to
alter the function of the neural circuitry to both understand the system and
treat disorders. Starting from Lazebnik's viewpoint that understanding a system
means you can ``fix it'', and motivated by use-cases in neuroscience, we
propose the following requirement on reverse engineering: once an agent claims
to have reverse-engineered a neural circuit, they subsequently need to be able
to: (a) provide a minimal set of interventions to change the input/output (I/O)
behavior of the circuit to a desired behavior; (b) arrive at this minimal set
of interventions while operating under bounded rationality constraints (e.g.,
limited memory) to rule out brute-force approaches. Under certain assumptions,
we show that this reverse engineering goal falls within the class of
undecidable problems. Next, we examine some canonical computational systems and
reverse engineering goals (as specified by desired I/O behaviors) where reverse
engineering can indeed be performed. Finally, using an exemplar network, the
``reward network'' in the brain, we summarize the state of current
neuroscientific understanding, and discuss how computer-science and
information-theoretic concepts can inform goals of future neuroscience studies.",276,14,1905,20.62
610,neuroscience,"How does the brain represent different modes of information? Can we design a
system that automatically understands what the user is thinking? Such questions
can be answered by studying brain recordings like functional magnetic resonance
imaging (fMRI). As a first step, the neuroscience community has contributed
several large cognitive neuroscience datasets related to passive
reading/listening/viewing of concept words, narratives, pictures and movies.
Encoding and decoding models using these datasets have also been proposed in
the past two decades. These models serve as additional tools for basic research
in cognitive science and neuroscience. Encoding models aim at generating fMRI
brain representations given a stimulus automatically. They have several
practical applications in evaluating and diagnosing neurological conditions and
thus also help design therapies for brain damage. Decoding models solve the
inverse problem of reconstructing the stimuli given the fMRI. They are useful
for designing brain-machine or brain-computer interfaces. Inspired by the
effectiveness of deep learning models for natural language processing, computer
vision, and speech, recently several neural encoding and decoding models have
been proposed. In this survey, we will first discuss popular representations of
language, vision and speech stimuli, and present a summary of neuroscience
datasets. Further, we will review popular deep learning based encoding and
decoding architectures and note their benefits and limitations. Finally, we
will conclude with a brief summary and discussion about future trends. Given
the large amount of recently published work in the `computational cognitive
neuroscience' community, we believe that this survey nicely organizes the
plethora of work and presents it as a coherent story.",257,14,1814,28.74
611,neuroscience,"Neuromatch Academy designed and ran a fully online 3-week Computational
Neuroscience summer school for 1757 students with 191 teaching assistants
working in virtual inverted (or flipped) classrooms and on small group
projects. Fourteen languages, active community management, and low cost allowed
for an unprecedented level of inclusivity and universal accessibility.",50,3,367,12.26
612,neuroscience,"Understanding the function of complex cortical circuits requires the
simultaneous recording of action potentials from many neurons in awake and
behaving animals. Practically, this can be achieved by extracellularly
recording from multiple brain sites using single wire electrodes. However, in
densely packed neural structures such as the human hippocampus, a single
electrode can record the activity of multiple neurons. Thus, analytic
techniques that differentiate action potentials of different neurons are
required. Offline spike sorting approaches are currently used to detect and
sort action potentials after finishing the experiment. Because the
opportunities to record from the human brain are relatively rare, it is
desirable to analyze large numbers of simultaneous recordings quickly using
online sorting and detection algorithms. In this way, the experiment can be
optimized for the particular response properties of the recorded neurons. Here
we present and evaluate a method that is capable of detecting and sorting
extracellular single-wire recordings in realtime. We demonstrate the utility of
the method by applying it to an extensive data set we acquired from
chronically-implanted depth electrodes in the hippocampus of human epilepsy
patients. This dataset is particularly challenging because it was recorded in a
noisy clinical environment. This method will allow the development of
closed-loop experiments, which immediately adapt the experimental stimuli
and/or tasks to the neural response observed.",217,12,1522,26.1
613,neuroscience,"Almost all research work in computational neuroscience involves software. As
researchers try to understand ever more complex systems, there is a continual
need for software with new capabilities. Because of the wide range of questions
being investigated, new software is often developed rapidly by individuals or
small groups. In these cases, it can be hard to demonstrate that the software
gives the right results. Software developers are often open about the code they
produce and willing to share it, but there is little appreciation among
potential users of the great diversity of software development practices and
end results, and how this affects the suitability of software tools for use in
research projects. To help clarify these issues, we have reviewed a range of
software tools and asked how the culture and practice of software development
affects their validity and trustworthiness. We identified four key questions
that can be used to categorize software projects and correlate them with the
type of product that results. The first question addresses what is being
produced. The other three concern why, how, and by whom the work is done. The
answers to these questions show strong correlations with the nature of the
software being produced, and its suitability for particular purposes. Based on
our findings, we suggest ways in which current software development practice in
computational neuroscience can be improved and propose checklists to help
developers, reviewers and scientists to assess the quality whether particular
pieces of software are ready for use in research.",249,12,1594,48.54
614,neuroscience,"Given the constant rise in quantity and quality of data obtained from neural
systems on many scales ranging from molecular to systems',
information-theoretic analyses became increasingly necessary during the past
few decades in the neurosciences. Such analyses can provide deep insights into
the functionality of such systems, as well as a rigid mathematical theory and
quantitative measures of information processing in both healthy and diseased
states of neural systems. This chapter will present a short introduction to the
fundamentals of information theory, especially suited for people having a less
firm background in mathematics and probability theory. To begin, the
fundamentals of probability theory such as the notion of probability,
probability distributions, and random variables will be reviewed. Then, the
concepts of information and entropy (in the sense of Shannon), mutual
information, and transfer entropy (sometimes also referred to as conditional
mutual information) will be outlined. As these quantities cannot be computed
exactly from measured data in practice, estimation techniques for
information-theoretic quantities will be presented. The chapter will conclude
with the applications of information theory in the field of neuroscience,
including questions of possible medical applications and a short review of
software packages that can be used for information-theoretic analyses of neural
data.",203,8,1423,8.2
615,neuroscience,"We extend the theory of neural fields which has been developed in a
deterministic framework by considering the influence spatio-temporal noise. The
outstanding problem that we here address is the development of a theory that
gives rigorous meaning to stochastic neural field equations, and conditions
ensuring that they are well-posed. Previous investigations in the field of
computational and mathematical neuroscience have been numerical for the most
part. Such questions have been considered for a long time in the theory of
stochastic partial differential equations, where at least two different
approaches have been developed, each having its advantages and disadvantages.
It turns out that both approaches have also been used in computational and
mathematical neuroscience, but with much less emphasis on the underlying
theory. We present a review of two existing theories and show how they can be
used to put the theory of stochastic neural fields on a rigorous footing. We
also provide general conditions on the parameters of the stochastic neural
field equations under which we guarantee that these equations are well-posed.
In so doing we relate each approach to previous work in computational and
mathematical neuroscience. We hope this will provide a reference that will pave
the way for future studies (both theoretical and applied) of these equations,
where basic questions of existence and uniqueness will no longer be a cause for
concern.",225,10,1454,37.64
616,neuroscience,"Motivated by recent experiments in neuroscience which indicate that neuronal
avalanches exhibit scale invariant behavior similar to self-organized critical
systems, we study the role of noisy (non-conservative) local dynamics on the
critical behavior of a sandpile model which can be taken to mimic the dynamics
of neuronal avalanches. We find that despite the fact that noise breaks the
strict local conservation required to attain criticality, our system exhibit
true criticality for a wide range of noise in various dimensions, given that
conservation is respected \textit{on the average}. Although the system remains
critical, exhibiting finite-size scaling, the value of critical exponents
change depending on the intensity of local noise. Interestingly, for
sufficiently strong noise level, the critical exponents approach and saturate
at their mean-field values, consistent with empirical measurements of neuronal
avalanches. This is confirmed for both two and three dimensional models.
However, addition of noise does not affect the exponents at the upper critical
dimension ($D=4$). In addition to extensive finite-size scaling analysis of our
systems, we also employ a useful time-series analysis method in order to
establish true criticality of noisy systems. Finally, we discuss the
implications of our work in neuroscience as well as some implications for
general phenomena of criticality in non-equilibrium systems.",206,9,1429,19.91
617,neuroscience,"Dedicated systems are fundamental for neuroscience experimental protocols
that require timing determinism and synchronous stimuli generation. We
developed a data acquisition and stimuli generator system for neuroscience
research, optimized for recording timestamps from up to 6 spiking neurons and
entirely specified in a high-level Hardware Description Language (HDL). Despite
the logic complexity penalty of synthesizing from such a language, it was
possible to implement our design in a low-cost small reconfigurable device.
Under a modular framework, we explored two different memory arbitration schemes
for our system, evaluating both their logic element usage and resilience to
input activity bursts. One of them was designed with a decoupled and latency
insensitive approach, allowing for easier code reuse, while the other adopted a
centralized scheme, constructed specifically for our application. The usage of
a high-level HDL allowed straightforward and stepwise code modifications to
transform one architecture into the other. The achieved modularity is very
useful for rapidly prototyping novel electronic instrumentation systems
tailored to scientific research.",163,8,1175,13.99
618,neuroscience,"Repetitive spatio-temporal propagation patterns are encountered in fields as
wide-ranging as climatology, social communication and network science. In
neuroscience, perfectly consistent repetitions of the same global propagation
pattern are called a synfire pattern. For any recording of sequences of
discrete events (in neuroscience terminology: sets of spike trains) the
questions arise how closely it resembles such a synfire pattern and which are
the spike trains that lead/follow. Here we address these questions and
introduce an algorithm built on two new indicators, termed SPIKE-Order and
Spike Train Order, that define the Synfire Indicator value, which allows to
sort multiple spike trains from leader to follower and to quantify the
consistency of the temporal leader-follower relationships for both the original
and the optimized sorting. We demonstrate our new approach using artificially
generated datasets before we apply it to analyze the consistency of propagation
patterns in two real datasets from neuroscience (Giant Depolarized Potentials
in mice slices) and climatology (El Ni~no sea surface temperature recordings).
The new algorithm is distinguished by conceptual and practical simplicity, low
computational cost, as well as flexibility and universality.",181,7,1278,15.44
619,neuroscience,"Motivated by neuroscience applications, we introduce the concept of
qualitative detection, that is, the problem of determining on-line the current
qualitative dynamical behavior (e.g., resting, oscillating, bursting, spiking
etc.) of a nonlinear system. The approach is thought for systems characterized
by i) large parameter variability and redundancy, ii) a small number of
possible robust, qualitatively different dynamical behaviors and, iii) the
presence of sharply different characteristic timescales. These properties are
omnipresent in neurosciences and hamper quantitative modeling and fitting of
experimental data. As a result, novel control theoretical strategies are needed
to face neuroscience challenges like on-line epileptic seizure detection. The
proposed approach aims at detecting the current dynamical behavior of the
system and whether a qualitative change is likely to occur without
quantitatively fitting any model nor asymptotically estimating any parameter.
We talk of qualitative detection. We rely on the qualitative properties of the
system dynamics, extracted via singularity and singular perturbation theories,
to design low dimensional qualitative detectors. We introduce this concept on a
general class of singularly perturbed systems and then solve the problem for an
analytically tractable class of two-dimensional systems with a single unknown
sigmoidal nonlinearity and two sharply separated timescales. Numerical results
are provided to show the performance of the designed qualitative detector.",209,13,1532,9.89
620,neuroscience,"This reply is in response to commentaries by Barnett, Barrett, and Seth
(arXiv:1708.08001) and Faes, Stramaglia, and Marinazzo (arXiv:1708.06990) on
our paper entitled ""A study of problems encountered in Granger causality
analysis from a neuroscience perspective."" (PNAS 114(34):7063-7072. 2017). In
our paper, we analyzed several properties of Granger-Geweke causality (GGC) and
discussed potential problems in neuroscience applications. We demonstrated: (i)
that GGC, estimated using separate model fits, is either severely biased,
particularly when the true model is known, or a high variance is introduced to
overcome the bias; and (ii) that GGC does not reflect some component dynamics
of the system. The commentaries by both Faes et al. and Barnett et al. point
out that the computational problems of (i) are resolved by using recent
computational methods. We acknowledge that these problems are indeed resolved
by these methods. However, the traditional computation using separate model
fits continues to be presented and applied. More fundamentally, the
interpretational problems stemming from (ii) are not in anyway addressed by the
improved methods because they are inherent to the definition of GGC. These
properties are indeed acknowledged by both commentaries. We have no
misconception of the GGC measure and do not claim that these properties are
facially wrong. But we do discuss at length how these properties make it
inappropriate and misleading for common types of scientific questions, how
presentation of GGC results without model estimates are not decipherable, and
how the absence of clear statements of questions of interest present further
opportunities for misinterpretation.",251,17,1700,44.85
621,neuroscience,"Time series, as frequently the case in neuroscience, are rarely stationary,
but often exhibit abrupt changes due to attractor transitions or bifurcations
in the dynamical systems producing them. A plethora of methods for detecting
such change points in time series statistics have been developed over the
years, in addition to test criteria to evaluate their significance. Issues to
consider when developing change point analysis methods include computational
demands, difficulties arising from either limited amount of data or a large
number of covariates, and arriving at statistical tests with sufficient power
to detect as many changes as contained in potentially high-dimensional time
series. Here, a general method called Paired Adaptive Regressors for Cumulative
Sum is developed for detecting multiple change points in the mean of
multivariate time series. The method's advantages over alternative approaches
are demonstrated through a series of simulation experiments. This is followed
by a real data application to neural recordings from rat medial prefrontal
cortex during learning. Finally, the method's flexibility to incorporate useful
features from state-of-the-art change point detection techniques is discussed,
along with potential drawbacks and suggestions to remedy them.",184,8,1291,19.4
622,neuroscience,"Continuous control and planning remains a major challenge in robotics and
machine learning. Neuroscience offers the possibility of learning from animal
brains that implement highly successful controllers, but it is unclear how to
relate an animal's behavior to control principles. Animals may not always act
optimally from the perspective of an external observer, but may still act
rationally: we hypothesize that animals choose actions with highest expected
future subjective value according to their own internal model of the world.
Their actions thus result from solving a different optimal control problem from
those on which they are evaluated in neuroscience experiments. With this
assumption, we propose a novel framework of model-based inverse rational
control that learns the agent's internal model that best explains their actions
in a task described as a partially observable Markov decision process (POMDP).
In this approach we first learn optimal policies generalized over the entire
model space of dynamics and subjective rewards, using an extended Kalman filter
to represent the belief space, a neural network in the actor-critic framework
to optimize the policy, and a simplified basis for the parameter space. We then
compute the model that maximizes the likelihood of the experimentally
observable data comprising the agent's sensory observations and chosen actions.
Our proposed method is able to recover the true model of simulated agents
within theoretical error bounds given by limited data. We illustrate this
method by applying it to a complex naturalistic task currently used in
neuroscience experiments. This approach provides a foundation for interpreting
the behavioral and neural dynamics of highly adapted controllers in animal
brains.",263,11,1765,27.86
623,neuroscience,"Prediction in language has traditionally been studied using simple designs in
which neural responses to expected and unexpected words are compared in a
categorical fashion. However, these designs have been contested as being
`prediction encouraging', potentially exaggerating the importance of prediction
in language understanding. A few recent studies have begun to address these
worries by using model-based approaches to probe the effects of linguistic
predictability in naturalistic stimuli (e.g. continuous narrative). However,
these studies so far only looked at very local forms of prediction, using
models that take no more than the prior two words into account when computing a
word's predictability. Here, we extend this approach using a state-of-the-art
neural language model that can take roughly 500 times longer linguistic
contexts into account. Predictability estimates from the neural network offer a
much better fit to EEG data from subjects listening to naturalistic narrative
than simpler models, and reveal strong surprise responses akin to the P200 and
N400. These results show that predictability effects in language are not a
side-effect of simple designs, and demonstrate the practical use of recent
advances in AI for the cognitive neuroscience of language.",189,10,1282,27.15
624,neuroscience,"Recent work in cognitive neuroscience has focused on analyzing the brain as a
network, rather than as a collection of independent regions. Prior studies
taking this approach have found that individual differences in the degree of
modularity of the brain network relate to performance on cognitive tasks.
However, inconsistent results concerning the direction of this relationship
have been obtained, with some tasks showing better performance as modularity
increases and other tasks showing worse performance. A recent theoretical model
(Chen & Deem, 2015) suggests that these inconsistencies may be explained on the
grounds that high-modularity networks favor performance on simple tasks whereas
low-modularity networks favor performance on more complex tasks. The current
study tests these predictions by relating modularity from resting-state fMRI to
performance on a set of simple and complex behavioral tasks. Complex and simple
tasks were defined on the basis of whether they did or did not draw on
executive attention. Consistent with predictions, we found a negative
correlation between individuals' modularity and their performance on a
composite measure combining scores from the complex tasks but a positive
correlation with performance on a composite measure combining scores from the
simple tasks. These results and theory presented here provide a framework for
linking measures of whole brain organization from network neuroscience to
cognitive processing.",214,9,1470,19.1
625,neuroscience,"Synchronized brain rhythms, associated with diverse cognitive functions, have
been observed in electrical recordings of brain activity. Neural
synchronization may be well described by using the population-averaged global
potential $V_G$ in computational neuroscience. The time-averaged fluctuation of
$V_G$ plays the role of a ""thermodynamic"" order parameter $\cal {O}$ used for
describing the synchrony-asynchrony transition in neural systems. Population
spike synchronization may be well visualized in the raster plot of neural
spikes. The degree of neural synchronization seen in the raster plot is well
measured in terms of a ""statistical-mechanical"" spike-based measure $M_s$
introduced by considering the occupation and the pacing patterns of spikes. The
global potential $V_G$ is also used to give a reference global cycle for the
calculation of $M_s$. Hence, $V_G$ becomes an important collective quantity
because it is associated with calculation of both $\cal {O}$ and $M_s$.
However, it is practically difficult to directly get $V_G$ in real experiments.
To overcome this difficulty, instead of $V_G$, we employ the instantaneous
population spike rate (IPSR) which can be obtained in experiments, and develop
realistic thermodynamic and statistical-mechanical measures, based on IPSR, to
make practical characterization of the neural synchronization in both
computational and experimental neuroscience. Particularly, more accurate
characterization of weak sparse spike synchronization can be achieved in terms
of realistic statistical-mechanical IPSR-based measure, in comparison with the
conventional measure based on $V_G$.",225,11,1636,14.8
626,neuroscience,"The functional network approach, where fMRI BOLD time series are mapped to
networks depicting functional relationships between brain areas, has opened new
insights into the function of the human brain. In this approach, the choice of
network nodes is of crucial importance. One option is to consider fMRI voxels
as nodes. This results in a large number of nodes, making network analysis and
interpretation of results challenging. A common alternative is to use
pre-defined clusters of anatomically close voxels, Regions of Interest (ROIs).
This approach assumes that voxels within ROIs are functionally similar. Because
these two approaches result in different network structures, it is crucial to
understand what happens to network connectivity when moving from the voxel
level to the ROI level. We show that the consistency of ROIs, defined as the
mean Pearson correlation coefficient between the time series of their voxels,
varies widely in resting-state experimental data. Therefore the assumption of
similar voxel dynamics within each ROI does not generally hold. Further, the
time series of low-consistency ROIs may be highly correlated, resulting in
spurious links in ROI-level networks. Based on these results, we recommend that
averaging BOLD signals over anatomically defined ROIs should be carefully
considered.",199,12,1323,36.18
627,neuroscience,"The properties of functional brain networks strongly depend on how their
nodes are chosen. Commonly, nodes are defined by Regions of Interest (ROIs),
pre-determined groupings of fMRI measurement voxels. Earlier, we have
demonstrated that the functional homogeneity of ROIs, captured by their spatial
consistency, varies widely across ROIs in commonly-used brain atlases. Here, we
ask how ROIs behave as nodes of dynamic brain networks. To this end, we use two
measures: spatiotemporal consistency measures changes in spatial consistency
across time and network turnover quantifies the changes in the local network
structure around a ROI. We find that spatial consistency varies non-uniformly
in space and time, which is reflected in the variation of spatiotemporal
consistency across ROIs. Further, we see time-dependent changes in the network
neighborhoods of the ROIs, reflected in high network turnover. Network turnover
is nonuniformly distributed across ROIs: ROIs with high spatiotemporal
consistency have low network turnover. Finally, we reveal that there is rich
voxel-level correlation structure inside ROIs. Because the internal structure
and the connectivity of ROIs vary in time, the common approach of using static
node definitions may be surprisingly inaccurate. Therefore, network
neuroscience would greatly benefit from node definition strategies tailored for
dynamical networks.",199,12,1396,44.64
628,neuroscience,"Much of neuroscience aims at reverse engineering the brain, but we only
record a small number of neurons at a time. We do not currently know if reverse
engineering the brain requires us to simultaneously record most neurons or if
multiple recordings from smaller subsets suffice. This is made even more
important by the development of novel techniques that allow recording from
selected subsets of neurons, e.g. using optical techniques. To get at this
question, we analyze a neural network, trained on the MNIST dataset, using only
partial recordings and characterize the dependency of the quality of our
reverse engineering on the number of simultaneously recorded ""neurons"". We find
that reverse engineering of the nonlinear neural network is meaningfully
possible if a sufficiently large number of neurons is simultaneously recorded
but that this number can be considerably smaller than the number of neurons.
Moreover, recording many times from small random subsets of neurons yields
surprisingly good performance. Application in neuroscience suggests to
approximate the I/O function of an actual neural system, we need to record from
a much larger number of neurons. The kind of scaling analysis we perform here
can, and arguably should be used to calibrate approaches that can dramatically
scale up the size of recorded data sets in neuroscience.",212,11,1353,39.06
629,neuroscience,"In recent years, the field of neuroscience has gone through rapid
experimental advances and a significant increase in the use of quantitative and
computational methods. This growth has created a need for clearer analyses of
the theory and modeling approaches used in the field. This issue is
particularly complex in neuroscience because the field studies phenomena across
a wide range of scales and often requires consideration of these phenomena at
varying degrees of abstraction, from precise biophysical interactions to the
computations they implement. We argue that a pragmatic perspective of science,
in which descriptive, mechanistic, and normative approaches each play a
distinct role in defining and bridging levels of abstraction will facilitate
neuroscientific practice. This analysis leads to methodological suggestions,
including selecting a level of abstraction that is appropriate for a given
problem, identifying transfer functions to connect models and data, and the use
of models themselves as a form of experiment.",152,6,1032,15.24
630,neuroscience,"Recently, deep feedforward neural networks have achieved considerable success
in modeling biological sensory processing, in terms of reproducing the
input-output map of sensory neurons. However, such models raise profound
questions about the very nature of explanation in neuroscience. Are we simply
replacing one complex system (a biological circuit) with another (a deep
network), without understanding either? Moreover, beyond neural
representations, are the deep network's computational mechanisms for generating
neural responses the same as those in the brain? Without a systematic approach
to extracting and understanding computational mechanisms from deep neural
network models, it can be difficult both to assess the degree of utility of
deep learning approaches in neuroscience, and to extract experimentally
testable hypotheses from deep networks. We develop such a systematic approach
by combining dimensionality reduction and modern attribution methods for
determining the relative importance of interneurons for specific visual
computations. We apply this approach to deep network models of the retina,
revealing a conceptual understanding of how the retina acts as a predictive
feature extractor that signals deviations from expectations for diverse
spatiotemporal stimuli. For each stimulus, our extracted computational
mechanisms are consistent with prior scientific literature, and in one case
yields a new mechanistic hypothesis. Thus overall, this work not only yields
insights into the computational mechanisms underlying the striking predictive
capabilities of the retina, but also places the framework of deep networks as
neuroscientific models on firmer theoretical foundations, by providing a new
roadmap to go beyond comparing neural representations to extracting and
understand computational mechanisms.",251,8,1829,9.32
631,neuroscience,"With the wide adoption of functional magnetic resonance imaging (fMRI) by
cognitive neuroscience researchers, large volumes of brain imaging data have
been accumulated in recent years. Aggregating these data to derive scientific
insights often faces the challenge that fMRI data are high-dimensional,
heterogeneous across people, and noisy. These challenges demand the development
of computational tools that are tailored both for the neuroscience questions
and for the properties of the data. We review a few recently developed
algorithms in various domains of fMRI research: fMRI in naturalistic tasks,
analyzing full-brain functional connectivity, pattern classification, inferring
representational similarity and modeling structured residuals. These algorithms
all tackle the challenges in fMRI similarly: they start by making clear
statements of assumptions about neural data and existing domain knowledge,
incorporating those assumptions and domain knowledge into probabilistic
graphical models, and using those models to estimate properties of interest or
latent structures in the data. Such approaches can avoid erroneous findings,
reduce the impact of noise, better utilize known properties of the data, and
better aggregate data across groups of subjects. With these successful cases,
we advocate wider adoption of explicit model construction in cognitive
neuroscience. Although we focus on fMRI, the principle illustrated here is
generally applicable to brain data of other modalities.",208,9,1496,11.25
632,neuroscience,"A common feature in many neuroscience datasets is the presence of
hierarchical data structures, most commonly recording the activity of multiple
neurons in multiple animals across multiple trials. Accordingly, the
measurements constituting the dataset are not independent, even though the
traditional statistical analyses often applied in such cases (e.g., Students
t-test) treat them as such. The hierarchical bootstrap has been shown to be an
effective tool to accurately analyze such data and while it has been used
extensively in the statistical literature, its use is not widespread in
neuroscience - despite the ubiquity of hierarchical datasets. In this paper, we
illustrate the intuitiveness and utility of this approach to analyze
hierarchically nested datasets. We use simulated neural data to show that
traditional statistical tests can result in a false positive rate of over 45%,
even if the Type-I error rate is set at 5%. While summarizing data across
non-independent points (or lower levels) can potentially fix this problem, this
approach greatly reduces the statistical power of the analysis. The
hierarchical bootstrap, when applied sequentially over the levels of the
hierarchical structure, keeps the Type-I error rate within the intended bound
and retains more statistical power than summarizing methods. We conclude by
demonstrating the effectiveness of the method in two real-world examples, first
analyzing singing data in male Bengalese finches (Lonchura striata var.
domestica) and second quantifying changes in behavior under optogenetic control
in flies (Drosophila melanogaster).",236,12,1609,30.7
633,neuroscience,"Sensory and emotional experiences such as pain and empathy are essential for
mental and physical health. Cognitive neuroscience has been working on
revealing mechanisms underlying pain and empathy. Furthermore, as trending
research areas, computational pain recognition and empathic artificial
intelligence (AI) show progress and promise for healthcare or human-computer
interaction. Although AI research has recently made it increasingly possible to
create artificial systems with affective processing, most cognitive
neuroscience and AI research do not jointly address the issues of empathy in AI
and cognitive neuroscience. The main aim of this paper is to introduce key
advances, cognitive challenges and technical barriers in computational pain
recognition and the implementation of artificial empathy. Our discussion covers
the following topics: How can AI recognize pain from unimodal and multimodal
information? Is it crucial for AI to be empathic? What are the benefits and
challenges of empathic AI? Despite some consensus on the importance of AI,
including empathic recognition and responses, we also highlight future
challenges for artificial empathy and possible paths from interdisciplinary
perspectives. Furthermore, we discuss challenges for responsible evaluation of
cognitive methods and computational techniques and show approaches to future
work to contribute to affective assistants capable of empathy.",198,8,1423,17.54
634,neuroscience,"In neuroscience, learning and memory are usually associated to long-term
changes of neuronal connectivity. In this context, synaptic plasticity refers
to the set of mechanisms driving the dynamics of neuronal connections, called
{\em synapses} and represented by a scalar value, the synaptic weight.
Spike-Timing Dependent Plasticity (STDP) is a biologically-based model
representing the time evolution of the synaptic weight as a functional of the
past spiking activity of adjacent neurons.
  If numerous models of neuronal cells have been proposed in the mathematical
literature, few of them include a variable for the time-varying strength of the
connection. A new, general, mathematical framework is introduced to study
synaptic plasticity associated to different STDP rules. The system composed of
two neurons connected by a single synapse is investigated and a stochastic
process describing its dynamical behavior is presented and analyzed. The notion
of plasticity kernel is introduced as a key component of plastic neural
networks models, generalizing a notion used for pair-based models. We show that
a large number of STDP rules from neuroscience and physics can be represented
by this formalism. Several aspects of these models are discussed and compared
to canonical models of computational neuroscience. An important sub-class of
plasticity kernels with a Markovian formulation is also defined and
investigated. In these models, the time evolution of cellular processes such as
the neuronal membrane potential and the concentrations of chemical components
created/suppressed by spiking activity has the Markov property.",238,12,1632,24.17
635,neuroscience,"Functional MRI (fMRI) is a powerful technique that has allowed us to
characterize visual cortex responses to stimuli, yet such experiments are by
nature constructed based on a priori hypotheses, limited to the set of images
presented to the individual while they are in the scanner, are subject to noise
in the observed brain responses, and may vary widely across individuals. In
this work, we propose a novel computational strategy, which we call NeuroGen,
to overcome these limitations and develop a powerful tool for human vision
neuroscience discovery. NeuroGen combines an fMRI-trained neural encoding model
of human vision with a deep generative network to synthesize images predicted
to achieve a target pattern of macro-scale brain activation. We demonstrate
that the reduction of noise that the encoding model provides, coupled with the
generative network's ability to produce images of high fidelity, results in a
robust discovery architecture for visual neuroscience. By using only a small
number of synthetic images created by NeuroGen, we demonstrate that we can
detect and amplify differences in regional and individual human brain response
patterns to visual stimuli. We then verify that these discoveries are reflected
in the several thousand observed image responses measured with fMRI. We further
demonstrate that NeuroGen can create synthetic images predicted to achieve
regional response patterns not achievable by the best-matching natural images.
The NeuroGen framework extends the utility of brain encoding models and opens
up a new avenue for exploring, and possibly precisely controlling, the human
visual system.",247,9,1638,23.19
636,neuroscience,"The deep neural nets of modern artificial intelligence (AI) have not achieved
defining features of biological intelligence, including abstraction, causal
learning, and energy-efficiency. While scaling to larger models has delivered
performance improvements for current applications, more brain-like capacities
may demand new theories, models, and methods for designing artificial learning
systems. Here, we argue that this opportunity to reassess insights from the
brain should stimulate cooperation between AI research and theory-driven
computational neuroscience (CN). To motivate a brain basis of neural
computation, we present a dynamical view of intelligence from which we
elaborate concepts of sparsity in network structure, temporal dynamics, and
interactive learning. In particular, we suggest that temporal dynamics, as
expressed through neural synchrony, nested oscillations, and flexible
sequences, provide a rich computational layer for reading and updating
hierarchical models distributed in long-term memory networks. Moreover,
embracing agent-centered paradigms in AI and CN will accelerate our
understanding of the complex dynamics and behaviors that build useful world
models. A convergence of AI/CN theories and objectives will reveal dynamical
principles of intelligence for brains and engineered learning systems. This
article was inspired by our symposium on dynamical neuroscience and machine
learning at the 6th Annual US/NIH BRAIN Initiative Investigators Meeting.",200,9,1488,12.26
637,neuroscience,"Clinical tools involving immersive virtual reality (VR) may bring several
advantages to cognitive neuroscience and neuropsychology. However, there are
some technical and methodological pitfalls. The American Academy of Clinical
Neuropsychology (AACN) and the National Academy of Neuropsychology (NAN) raised
8 key issues pertaining to Computerized Neuropsychological Assessment Devices.
These issues pertain to: (1) the safety and effectivity; (2) the identity of
the end-user; (3) the technical hardware and software features; (4) privacy and
data security; (5) the psychometric properties; (6) examinee issues; (7) the
use of reporting services; and (8) the reliability of the responses and
results. The VR Everyday Assessment Lab (VR-EAL) is the first immersive VR
neuropsychological battery with enhanced ecological validity for the assessment
of everyday cognitive functions by offering a pleasant testing experience
without inducing cybersickness. The VR-EAL meets the criteria of the NAN and
AACN, addresses the methodological pitfalls, and brings advantages for
neuropsychological testing. However, there are still shortcomings of the
VR-EAL, which should be addressed. Future iterations should strive to improve
the embodiment illusion in VR-EAL and the creation of an open access VR
software library should be attempted. The discussed studies demonstrate the
utility of VR methods in cognitive neuroscience and neuropsychology.",200,10,1437,15.1
638,neuroscience,"Object-based attention is a key component of the visual system, relevant for
perception, learning, and memory. Neurons tuned to features of attended objects
tend to be more active than those associated with non-attended objects. There
is a rich set of models of this phenomenon in computational neuroscience.
However, there is currently a divide between models that successfully match
physiological data but can only deal with extremely simple problems and models
of attention used in computer vision. For example, attention in the brain is
known to depend on top-down processing, whereas self-attention in deep learning
does not. Here, we propose an artificial neural network model of object-based
attention that captures the way in which attention is both top-down and
recurrent. Our attention model works well both on simple test stimuli, such as
those using images of handwritten digits, and on more complex stimuli, such as
natural images drawn from the COCO dataset. We find that our model replicates a
range of findings from neuroscience, including attention-invariant tuning,
inhibition of return, and attention-mediated scaling of activity. Understanding
object based attention is both computationally interesting and a key problem
for computational neuroscience.",189,10,1272,33.24
639,neuroscience,"Our daily human life is filled with a myriad of joint action moments, be it
children playing, adults working together (i.e., team sports), or strangers
navigating through a crowd. Joint action brings individuals (and embodiment of
their emotions) together, in space and in time. Yet little is known about how
individual emotions propagate through embodied presence in a group, and how
joint action changes individual emotion. In fact, the multi-agent component is
largely missing from neuroscience-based approaches to emotion, and reversely
joint action research has not found a way yet to include emotion as one of the
key parameters to model socio-motor interaction. In this review, we first
identify the gap and then stockpile evidence showing strong entanglement
between emotion and acting together from various branches of sciences. We
propose an integrative approach to bridge the gap, highlight five research
avenues to do so in behavioral neuroscience and digital sciences, and address
some of the key challenges in the area faced by modern societies.",164,9,1059,39.26
640,neuroscience,"A fundamental goal in neuroscience is to understand the relationship between
neural activity and behavior. For example, the ability to extract behavioral
intentions from neural data, or neural decoding, is critical for developing
effective brain machine interfaces. Although simple linear models have been
applied to this challenge, they cannot identify important non-linear
relationships. Thus, a self-supervised means of identifying non-linear
relationships between neural dynamics and behavior, in order to compute neural
representations, remains an important open problem. To address this challenge,
we generated a new multimodal dataset consisting of the spontaneous behaviors
generated by fruit flies, Drosophila melanogaster -- a popular model organism
in neuroscience research. The dataset includes 3D markerless motion capture
data from six camera views of the animal generating spontaneous actions, as
well as synchronously acquired two-photon microscope images capturing the
activity of descending neuron populations that are thought to drive actions.
Standard contrastive learning and unsupervised domain adaptation techniques
struggle to learn neural action representations (embeddings computed from the
neural data describing action labels) due to large inter-animal differences in
both neural and behavioral modalities. To overcome this deficiency, we
developed simple yet effective augmentations that close the inter-animal domain
gap, allowing us to extract behaviorally relevant, yet domain agnostic,
information from neural data. This multimodal dataset and our new set of
augmentations promise to accelerate the application of self-supervised learning
methods in neuroscience.",228,10,1696,12.06
641,neuroscience,"Interpreting computations in the visual cortex as learning and inference in a
generative model of the environment has received wide support both in
neuroscience and cognitive science. However, hierarchical computations, a
hallmark of visual cortical processing, has remained impervious for generative
models because of a lack of adequate tools to address it. Here we capitalize on
advances in Variational Autoencoders (VAEs) to investigate the early visual
cortex with sparse coding hierarchical VAEs trained on natural images. We
design alternative architectures that vary both in terms of the generative and
the recognition components of the two latent-layer VAE. We show that
representations similar to the one found in the primary and secondary visual
cortices naturally emerge under mild inductive biases. Importantly, a nonlinear
representation for texture-like patterns is a stable property of the high-level
latent space resistant to the specific architecture of the VAE, reminiscent of
the secondary visual cortex. We show that a neuroscience-inspired choice of the
recognition model, which features a top-down processing component is critical
for two signatures of computations with generative models: learning higher
order moments of the posterior beyond the mean and image inpainting. Patterns
in higher order response statistics provide inspirations for neuroscience to
interpret response correlations and for machine learning to evaluate the
learned representations through more detailed characterization of the
posterior.",218,9,1536,9.93
642,neuroscience,"How neural networks in the human brain represent commonsense knowledge, and
complete related reasoning tasks is an important research topic in
neuroscience, cognitive science, psychology, and artificial intelligence.
Although the traditional artificial neural network using fixed-length vectors
to represent symbols has gained good performance in some specific tasks, it is
still a black box that lacks interpretability, far from how humans perceive the
world. Inspired by the grandmother-cell hypothesis in neuroscience, this work
investigates how population encoding and spiking timing-dependent plasticity
(STDP) mechanisms can be integrated into the learning of spiking neural
networks, and how a population of neurons can represent a symbol via guiding
the completion of sequential firing between different neuron populations. The
neuron populations of different communities together constitute the entire
commonsense knowledge graph, forming a giant graph spiking neural network.
Moreover, we introduced the Reward-modulated spiking timing-dependent
plasticity (R-STDP) mechanism to simulate the biological reinforcement learning
process and completed the related reasoning tasks accordingly, achieving
comparable accuracy and faster convergence speed than the graph convolutional
artificial neural networks. For the fields of neuroscience and cognitive
science, the work in this paper provided the foundation of computational
modeling for further exploration of the way the human brain represents
commonsense knowledge. For the field of artificial intelligence, this paper
indicated the exploration direction for realizing a more robust and
interpretable neural network by constructing a commonsense knowledge
representation and reasoning spiking neural networks with solid biological
plausibility.",239,8,1805,-5.45
643,neuroscience,"Neuromorphic computing is an emerging research field that aims to develop new
intelligent systems by integrating theories and technologies from
multi-disciplines such as neuroscience and deep learning. Currently, there have
been various software frameworks developed for the related fields, but there is
a lack of an efficient framework dedicated for spike-based computing models and
algorithms. In this work, we present a Python based spiking neural network
(SNN) simulation and training framework, aka SPAIC that aims to support
brain-inspired model and algorithm researches integrated with features from
both deep learning and neuroscience. To integrate different methodologies from
the two overwhelming disciplines, and balance between flexibility and
efficiency, SPAIC is designed with neuroscience-style frontend and deep
learning backend structure. We provide a wide range of examples including
neural circuits Simulation, deep SNN learning and neuromorphic applications,
demonstrating the concise coding style and wide usability of our framework. The
SPAIC is a dedicated spike-based artificial intelligence computing platform,
which will significantly facilitate the design, prototype and validation of new
models, theories and applications. Being user-friendly, flexible and
high-performance, it will help accelerate the rapid growth and wide
applicability of neuromorphic computing research.",189,8,1402,10.23
644,neuroscience,"Artificial intelligence (AI) is a fast-growing field focused on modeling and
machine implementation of various cognitive functions with an increasing number
of applications in computer vision, text processing, robotics, neurotechnology,
bio-inspired computing and others. In this chapter, we describe how AI methods
can be applied in the context of intracranial electroencephalography (iEEG)
research. IEEG data is unique as it provides extremely high-quality signals
recorded directly from brain tissue. Applying advanced AI models to these data
carries the potential to further our understanding of many fundamental
questions in neuroscience. At the same time, as an invasive technique, iEEG
lends itself well to long-term, mobile brain-computer interface applications,
particularly for communication in severely paralyzed individuals. We provide a
detailed overview of these two research directions in the application of AI
techniques to iEEG. That is, (1) the development of computational models that
target fundamental questions about the neurobiological nature of cognition
(AI-iEEG for neuroscience) and (2) applied research on monitoring and
identification of event-driven brain states for the development of clinical
brain-computer interface systems (AI-iEEG for neurotechnology). We explain key
machine learning concepts, specifics of processing and modeling iEEG data and
details of state-of-the-art iEEG-based neurotechnology and brain-computer
interfaces.",197,9,1468,12.67
645,neuroscience,"A pervasive research protocol of cognitive neuroscience is to train subjects
to perform deliberately designed experiments and record brain activity
simultaneously, aiming to understand the brain mechanism underlying cognition.
However, how the results of this protocol can be applied in technology is
seldom discussed. Here, I review the studies on time processing of the brain as
examples of this protocol, as well as two main application areas of
neuroscience (neuroengineering and brain-inspired artificial intelligence).
Time processing is an indispensable dimension of cognition; time is also an
indispensable dimension of any real-world signal to be processed in technology.
So one may expect that the studies of time processing in cognition profoundly
influence brain-related technology. Surprisingly, I found that the results from
cognitive studies on timing processing are hardly helpful in solving practical
problems. This awkward situation may be due to the lack of generalizability of
the results of cognitive studies, which are under well-controlled laboratory
conditions, to real-life situations. This lack of generalizability may be
rooted in the fundamental unknowability of the world (including cognition).
Overall, this paper questions and criticizes the usefulness and prospect of the
above-mentioned research protocol of cognitive neuroscience. I then give three
suggestions for future research. First, to improve the generalizability of
research, it is better to study brain activity under real-life conditions
instead of in well-controlled laboratory experiments. Second, to overcome the
unknowability of the world, we can engineer an easily accessible surrogate of
the object under investigation, so that we can predict the behavior of the
object by experimenting on the surrogate. Third, I call for technology-oriented
research, with the aim of technology creation instead of knowledge discovery.",274,14,1920,16.22
646,neuroscience,"The brain can learn to execute a wide variety of tasks quickly and
efficiently. Nevertheless, most of the mechanisms that enable us to learn are
unclear or incredibly complicated. Recently, considerable efforts have been
made in neuroscience and artificial intelligence to understand and model the
structure and mechanisms behind the amazing learning capability of the brain.
However, in the current understanding of cognitive neuroscience, it is widely
accepted that synaptic plasticity plays an essential role in our amazing
learning capability. This mechanism is also known as the Credit Assignment
Problem (CAP) and is a fundamental challenge in neuroscience and Artificial
Intelligence (AI). The observations of neuroscientists clearly confirm the role
of two important mechanisms including the error feedback system and
unsupervised learning in synaptic plasticity. With this inspiration, a new
learning rule is proposed via the fusion of reinforcement learning (RL) and
unsupervised learning (UL). In the proposed computational model, the nonlinear
optimal control theory is used to resemble the error feedback loop systems and
project the output error to neurons membrane potential (neurons state), and an
unsupervised learning rule based on neurons membrane potential or neurons
activity are utilized to simulate synaptic plasticity dynamics to ensure that
the output error is minimized.",203,9,1396,20.31
647,neuroscience,"The brain is a complex system comprising a myriad of interacting elements,
posing significant challenges in understanding its structure, function, and
dynamics. Network science has emerged as a powerful tool for studying such
intricate systems, offering a framework for integrating multiscale data and
complexity. Here, we discuss the application of network science in the study of
the brain, addressing topics such as network models and metrics, the
connectome, and the role of dynamics in neural networks. We explore the
challenges and opportunities in integrating multiple data streams for
understanding the neural transitions from development to healthy function to
disease, and discuss the potential for collaboration between network science
and neuroscience communities. We underscore the importance of fostering
interdisciplinary opportunities through funding initiatives, workshops, and
conferences, as well as supporting students and postdoctoral fellows with
interests in both disciplines. By uniting the network science and neuroscience
communities, we can develop novel network-based methods tailored to neural
circuits, paving the way towards a deeper understanding of the brain and its
functions.",169,7,1210,17.47
648,neuroscience,"Convolutional neural networks (CNNs) have recently emerged as promising
models of the ventral visual stream, despite their lack of biological
specificity. While current state-of-the-art models of the primary visual cortex
(V1) have surfaced from training with adversarial examples and extensively
augmented data, these models are still unable to explain key neural properties
observed in V1 that arise from biological circuitry. To address this gap, we
systematically incorporated neuroscience-derived architectural components into
CNNs to identify a set of mechanisms and architectures that comprehensively
explain neural activity in V1. We show drastic improvements in model-V1
alignment driven by the integration of architectural components that simulate
center-surround antagonism, local receptive fields, tuned normalization, and
cortical magnification. Upon enhancing task-driven CNNs with a collection of
these specialized components, we uncover models with latent representations
that yield state-of-the-art explanation of V1 neural activity and tuning
properties. Our results highlight an important advancement in the field of
NeuroAI, as we systematically establish a set of architectural components that
contribute to unprecedented explanation of V1. The neuroscience insights that
could be gleaned from increasingly accurate in-silico models of the brain have
the potential to greatly advance the fields of both neuroscience and artificial
intelligence.",197,8,1465,9.11
649,neuroscience,"Criticality is hypothesized as a physical mechanism underlying efficient
transitions between cortical states and remarkable information processing
capacities in the brain. While considerable evidence generally supports this
hypothesis, non-negligible controversies persist regarding the ubiquity of
criticality in neural dynamics and its role in information processing. Validity
issues frequently arise during identifying potential brain criticality from
empirical data. Moreover, the functional benefits implied by brain criticality
are frequently misconceived or unduly generalized. These problems stem from the
non-triviality and immaturity of the physical theories that analytically derive
brain criticality and the statistic techniques that estimate brain criticality
from empirical data. To help solve these problems, we present a systematic
review and reformulate the foundations of studying brain criticality, i.e.,
ordinary criticality (OC), quasi-criticality (qC), self-organized criticality
(SOC), and self-organized quasi-criticality (SOqC), using the terminology of
neuroscience. We offer accessible explanations of the physical theories and
statistic techniques of brain criticality, providing step-by-step derivations
to characterize neural dynamics as a physical system with avalanches. We
summarize error-prone details and existing limitations in brain criticality
analysis and suggest possible solutions. Moreover, we present a forward-looking
perspective on how optimizing the foundations of studying brain criticality can
deepen our understanding of various neuroscience questions.",200,12,1601,-16.51
650,neuroscience,"Humans and animals exhibit a range of interesting behaviors in dynamic
environments, and it is unclear how our brains actively reformat this dense
sensory information to enable these behaviors. Experimental neuroscience is
undergoing a revolution in its ability to record and manipulate hundreds to
thousands of neurons while an animal is performing a complex behavior. As these
paradigms enable unprecedented access to the brain, a natural question that
arises is how to distill these data into interpretable insights about how
neural circuits give rise to intelligent behaviors. The classical approach in
systems neuroscience has been to ascribe well-defined operations to individual
neurons and provide a description of how these operations combine to produce a
circuit-level theory of neural computations. While this approach has had some
success for small-scale recordings with simple stimuli, designed to probe a
particular circuit computation, often times these ultimately lead to disparate
descriptions of the same system across stimuli. Perhaps more strikingly, many
response profiles of neurons are difficult to succinctly describe in words,
suggesting that new approaches are needed in light of these experimental
observations. In this thesis, we offer a different definition of
interpretability that we show has promise in yielding unified structural and
functional models of neural circuits, and describes the evolutionary
constraints that give rise to the response properties of the neural population,
including those that have previously been difficult to describe individually.
We demonstrate the utility of this framework across multiple brain areas and
species to study the roles of recurrent processing in the primate ventral
visual pathway; mouse visual processing; heterogeneity in rodent medial
entorhinal cortex; and facilitating biological learning.",270,9,1873,11.79
651,neuroscience,"Similarity analyses between multiple correlation or covariance tables
constitute the cornerstone of network neuroscience. Here, we introduce
covSTATIS, a versatile, linear, unsupervised multi-table method designed to
identify structured patterns in multi-table data, and allow for the
simultaneous extraction and interpretation of both individual and group-level
features. With covSTATIS, multiple similarity tables can now be easily
integrated, without requiring a priori data simplification, complex black-box
implementations, user-dependent specifications, or supervised frameworks.
Applications of covSTATIS, a tutorial with Open Data and source code are
provided. CovSTATIS offers a promising avenue for advancing the theoretical and
analytic landscape of network neuroscience.",98,6,782,-7.65
652,neuroscience,"Most scientists need software to perform their research (Barker et al., 2020;
Carver et al., 2022; Hettrick, 2014; Hettrick et al., 2014; Switters and Osimo,
2019), and neuroscientists are no exception. Whether we work with reaction
times, electrophysiological signals, or magnetic resonance imaging data, we
rely on software to acquire, analyze, and statistically evaluate the raw data
we obtain - or to generate such data if we work with simulations. In recent
years there has been a shift toward relying on free, open-source scientific
software (FOSSS) for neuroscience data analysis (Poldrack et al., 2019), in
line with the broader open science movement in academia (McKiernan et al.,
2016) and wider industry trends (Eghbal, 2016). Importantly, FOSSS is typically
developed by working scientists (not professional software developers) which
sets up a precarious situation given the nature of the typical academic
workplace (wherein academics, especially in their early careers, are on short
and fixed term contracts). In this paper, we will argue that the existing
ecosystem of neuroscientific open source software is brittle, and discuss why
and how the neuroscience community needs to come together to ensure a healthy
growth of our software landscape to the benefit of all.",197,11,1282,43.12
653,neuroscience,"Artificial neural networks (ANNs) have evolved from the 1940s primitive
models of brain function to become tools for artificial intelligence. They
comprise many units, artificial neurons, interlinked through weighted
connections. ANNs are trained to perform tasks through learning rules that
modify the connection weights. With these rules being in the focus of research,
ANNs have become a branch of machine learning developing independently from
neuroscience. Although likely required for the development of truly intelligent
machines, the integration of neuroscience into ANNs has remained a neglected
proposition.
  Here, we demonstrate that designing an ANN along biological principles
results in drastically improved task performance. As a challenging real-world
problem, we choose real-time ocean-wave prediction which is essential for
various maritime operations. Motivated by the similarity of ocean waves
measured at a single location to sound waves arriving at the eardrum, we
redesign an echo state network to resemble the brain's auditory system. This
yields a powerful predictive tool which is computationally lean, robust with
respect to network parameters, and works efficiently across a wide range of sea
states. Our results demonstrate the advantages of integrating neuroscience with
machine learning and offer a tool for use in the production of green energy
from ocean waves.",202,11,1395,34.05
654,neuroscience,"New to neuroscience with implications for AI, the exclusive OR, or any other
Boolean gate may be biologically accomplished within a single region where
active dendrites merge. This is demonstrated below using dynamic circuit
analysis. Medical knowledge aside, this observation points to the possibility
of specially coated conductors to accomplish artificial dendrites.",52,4,369,20.08
655,neuroscience,"This paper is concerned with a class of nonlinear reaction-hyperbolic systems
as models for axonal transport in neuroscience. We show the global existence of
entropy-satisfying BV-solutions to the initial-value problems by using
hyperbolic-type methods. Moreover, we rigorously justify the limit as the
biochemical processes are much faster than the transport ones.",51,4,365,20.38
656,neuroscience,"In the principal cells of the insect mushroom body, the Kenyon cells (KC),
olfactory information is represented by a spatially and temporally sparse code.
Each odor stimulus will activate only a small portion of neurons and each
stimulus leads to only a short phasic response following stimulus onset
irrespective of the actual duration of a constant stimulus. The mechanisms
responsible for the sparse code in the KCs are yet unresolved.
  Here, we explore the role of the neuron-intrinsic mechanism of
spike-frequency adaptation (SFA) in producing temporally sparse responses to
sensory stimulation in higher processing stages. Our single neuron model is
defined through a conductance-based integrate-and-fire neuron with
spike-frequency adaptation [1]. We study a fully connected feed-forward network
architecture in coarse analogy to the insect olfactory pathway. A first layer
of ten neurons represents the projection neurons (PNs) of the antenna lobe. All
PNs receive a step-like input from the olfactory receptor neurons, which was
realized by independent Poisson processes. The second layer represents 100 KCs
which converge onto ten neurons in the output layer which represents the
population of mushroom body extrinsic neurons (ENs).
  Our simulation result matches with the experimental observations. In
particular, intracellular recordings of PNs show a clear phasic-tonic response
that outlasts the stimulus [2] while extracellular recordings from KCs in the
locust express sharp transient responses [3]. We conclude that the
neuron-intrinsic mechanism is can explain a progressive temporal response
sparsening in the insect olfactory system. Further experimental work is needed
to test this hypothesis empirically.
  [1] Muller et. al., Neural Comput, 19(11):2958-3010, 2007. [2] Assisi et.
al., Nat Neurosci, 10(9):1176-1184, 2007. [3] Krofczik et. al. Front. Comput.
Neurosci., 2(9), 2009.",275,26,1905,39.03
657,neuroscience,"A complete data acquisition and signal output control system for synchronous
stimuli generation, geared towards in vivo neuroscience experiments, was
developed using the Terasic DE2i-150 board. All emotions and thoughts are an
emergent property of the chemical and electrical activity of neurons. Most of
these cells are regarded as excitable cells (spiking neurons), which produce
temporally localized electric patterns (spikes). Researchers usually consider
that only the instant of occurrence (timestamp) of these spikes encodes
information. Registering neural activity evoked by stimuli demands timing
determinism and data storage capabilities that cannot be met without dedicated
hardware and a hard real-time operational system (RTOS). Indeed, research in
neuroscience usually requires dedicated electronic instrumentation for studies
in neural coding, brain machine interfaces and closed loop in vivo or in vitro
experiments. We developed a complete embedded system solution consisting of a
hardware/software co-design with the Intel Atom processor running a free RTOS
and a FPGA communicating via a PCIe-to-Avalon bridge. Our system is capable of
registering input event timestamps with 1{\mu}s precision and digitally
generating stimuli output in hard real-time. The whole system is controlled by
a Linux-based Graphical User Interface (GUI). Collected results are
simultaneously saved in a local file and broadcasted wirelessly to mobile
device web-browsers in an user-friendly graphic format, enhanced by HTML5
technology. The developed system is low-cost and highly configurable, enabling
various neuroscience experimental setups, while the commercial off-the-shelf
systems have low availability and are less flexible to adapt to specific
experimental configurations.",245,12,1779,15.0
658,neuroscience,"Definition. The phase-of-firing code is a neural coding scheme whereby
neurons encode information using the time at which they fire spikes within a
cycle of the ongoing oscillatory pattern of network activity. This coding
scheme may allow neurons to use their temporal pattern of spikes to encode
information that is not encoded in their firing rate.",56,4,350,34.6
659,neuroscience,"This article presents an Anthropocene citizen-cantered framework by
incorporating the neuroscience of sustainability related stressors, the biology
of collaboration in multi-agent ecosystems such as urban systems, and by
emphasising on the importance of harnessing the collective intelligence of the
crowd in addressing wicked challenges of sustainable development. The
Anthropocene citizenship framework aims to transcend the cognitive model of
global citizenship and sustainability to a dynamic, resilient and thriving
mental model of collective cooperation.",73,3,560,-16.34
660,neuroscience,"Research at the interface between cognitive psychology, neuroscience, and the
science of complex, dynamical systems, is piecing together an understanding of
the creative process, including how it works, how it can be fostered, and the
developmental antecedents and personality traits of particularly creative
people. This chapter examines the workings of creative minds, those with the
potential to significantly impact the evolution of human culture.",64,3,451,13.62
661,neuroscience,"To provide adequate multivariate measures of information flow between neural
structures, modified expressions of Partial Directed Coherence (PDC) and
Directed Transfer Function (DTF), two popular multivariate connectivity
measures employed in neuroscience, are introduced and their formal relationship
to mutual information rates are proved.",43,2,341,-22.94
662,neuroscience,"We discuss estimation problems where a polynomial is observed under Ornstein
Uhlenbeck noise over a long time interval. We prove local asymptotic normality
(LAN) and specify asymptotically efficient estimators. We apply this to the
following problem: feeding noise into the classical (deterministic) Hodgkin
Huxley model of neuroscience, we are interested in asymptotically efficient
estimation of the parameters of the noise process.",61,4,434,17.03
663,neuroscience,"Determining and measuring cause-effect relationships is fundamental to most
scientific studies of natural phenomena. The notion of causation is distinctly
different from correlation which only looks at association of trends or
patterns in measurements. In this article, we review different notions of
causality and focus especially on measuring causality from time series data.
Causality testing finds numerous applications in diverse disciplines such as
neuroscience, econometrics, climatology, physics and artificial intelligence.",70,5,532,2.95
664,neuroscience,"We present a procedure to approximate a plane contour by piecewise polynomial
functions, depending on various parameters, such as degree, number of local
patches, selection of knots. This procedure aims to be adopted to study how
information about shape is represented.",41,3,269,33.75
665,neuroscience,"The present document is devoted to structural properties of neural population
dynamics and especially their differential flatness. Several applications of
differential flatness in the present context can be envisioned, among which:
trajectory tracking, feedforward to feedback switching, cyclic character,
positivity and boundedness.",42,3,333,7.86
666,neuroscience,"A machine thinking model is proposed in this report based on recent advances
of computer vision and the recent results of neuroscience devoted to brain
understanding. We deliver the result of machine thinking in the form of
sentences of natural-language or drawn sketches either informative or
decisional. This result is obtained from a reasoning performed on new acquired
data and memorized data.",62,4,397,33.54
667,neuroscience,"In this paper presented hardware and software for shield PiEEG for reading
signals through the families of single-board computers - RaspberryPi, OrangePi,
BananaPi, etc. For the most part, the paper provides technical information on
how to implement this device. This device is designed to be familiar with
neuroscience and is one of the easiest ways to get started with EEG
measurements.",61,4,388,51.18
668,neuroscience,"Inspired by empirical work in neuroscience for Bayesian approaches to brain
function, we give a unified probabilistic account of various types of symbolic
reasoning from data. We characterise them in terms of formal logic using the
classical consequence relation, an empirical consequence relation, maximal
consistent sets, maximal possible sets and maximum likelihood estimation. The
theory gives new insights into reasoning towards human-like machine
intelligence.",64,4,466,16.02
669,neuroscience,"Scientific discoveries often hinge on synthesizing decades of research, a
task that potentially outstrips human information processing capacities. Large
language models (LLMs) offer a solution. LLMs trained on the vast scientific
literature could potentially integrate noisy yet interrelated findings to
forecast novel results better than human experts. To evaluate this possibility,
we created BrainBench, a forward-looking benchmark for predicting neuroscience
results. We find that LLMs surpass experts in predicting experimental outcomes.
BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet.
Like human experts, when LLMs were confident in their predictions, they were
more likely to be correct, which presages a future where humans and LLMs team
together to make discoveries. Our approach is not neuroscience-specific and is
transferable to other knowledge-intensive endeavors.",125,9,909,30.26
670,neuroscience,"This chapter illustrates how tools from univariate and multivariate
statistics of extremes can complement classical methods used to study brain
signals and enhance the understanding of brain activity and connectivity during
specific cognitive tasks or abnormal episodes, such as an epileptic seizure.",42,2,300,3.47
671,neuroscience,"Jackendoff (2002) posed four challenges that linguistic combinatoriality and
rules of language present to theories of brain function. The essence of these
problems is the question of how to neurally instantiate the rapid construction
and transformation of the compositional structures that are typically taken to
be the domain of symbolic processing. He contended that typical connectionist
approaches fail to meet these challenges and that the dialogue between
linguistic theory and cognitive neuroscience will be relatively unproductive
until the importance of these problems is widely recognised and the challenges
answered by some technical innovation in connectionist modelling. This paper
claims that a little-known family of connectionist models (Vector Symbolic
Architectures) are able to meet Jackendoff's challenges.",115,5,826,16.86
672,neuroscience,"Estimating the degree of synchrony or reliability between two or more spike
trains is a frequent task in both experimental and computational neuroscience.
In recent years, many different methods have been proposed that typically
compare the timing of spikes on a certain time scale to be fixed beforehand.
Here, we propose the ISI-distance, a simple complementary approach that
extracts information from the interspike intervals by evaluating the ratio of
the instantaneous frequencies. The method is parameter free, time scale
independent and easy to visualize as illustrated by an application to real
neuronal spike trains obtained in vitro from rat slices. In a comparison with
existing approaches on spike trains extracted from a simulated Hindemarsh-Rose
network, the ISI-distance performs as well as the best time-scale-optimized
measure based on spike timing.",129,6,866,28.37
673,neuroscience,"Statistical properties of environments experienced by biological signaling
systems in the real world change, which necessitate adaptive responses to
achieve high fidelity information transmission. One form of such adaptive
response is gain control. Here we argue that a certain simple mechanism of gain
control, understood well in the context of systems neuroscience, also works for
molecular signaling. The mechanism allows to transmit more than one bit (on or
off) of information about the signal independently of the signal variance. It
does not require additional molecular circuitry beyond that already present in
many molecular systems, and, in particular, it does not depend on existence of
feedback loops. The mechanism provides a potential explanation for abundance of
ultrasensitive response curves in biological regulatory networks.",122,7,843,25.49
674,neuroscience,"We study a Fokker-Planck equation modelling the firing rates of two
interacting populations of neurons. This model arises in computational
neuroscience when considering, for example, bistable visual perception problems
and is based on a stochastic Wilson-Cowan system of differential equations. In
a previous work, the slow-fast behavior of the solution of the Fokker-Planck
equation has been highlighted. Our aim is to demonstrate that the complexity of
the model can be drastically reduced using this slow-fast structure. In fact,
we can derive a one-dimensional Fokker-Planck equation that describes the
evolution of the solution along the so-called slow manifold. This permits to
have a direct efficient determination of the equilibrium state and its
effective potential, and thus to investigate its dependencies with respect to
various parameters of the model. It also allows to obtain information about the
time escaping behavior. The results obtained for the reduced 1D equation are
validated with those of the original 2D equation both for equilibrium and
transient behavior.",161,9,1083,34.15
675,neuroscience,"Many systems are modulated by unknown slow processes. This hinders analysis
in highly non-linear systems, such as excitable systems. We show that for such
systems, if the input matches the sparse `spiky' nature of the output, the
spiking input-output relation can be derived. We use this relation to reproduce
and interpret the irregular and complex 1/f response observed in isolated
neurons stimulated over days. We decompose the neuronal response into
contributions from its long history of internal noise and its short (few
minutes) history of inputs, quantifying memory, noise and stability.",91,6,595,36.08
676,neuroscience,"This review gives a short historical account of the excitable maps approach
for modeling neurons and neuronal networks. Some early models, due to Pasemann
(1993), Chialvo (1995) and Kinouchi and Tragtenberg (1996), are compared with
more recent proposals by Rulkov (2002) and Izhikevich (2003). We also review
map-based schemes for electrical and chemical synapses and some recent findings
as critical avalanches in map-based neural networks. We conclude with
suggestions for further work in this area like more efficient maps,
compartmental modeling and close dynamical comparison with conductance-based
models.",88,5,612,40.69
677,neuroscience,"Current psychiatric research is in crisis. In this review I will describe the
causes of this crisis and highlight recent efforts to overcome current
challenges. One particularly promising approach is the emerging field of
computational psychiatry. By using methods and insights from computational
cognitive neuroscience, computational psychiatry might enable us to move from a
symptom-based description of mental illness to descriptors based on objective
computational multidimensional functional variables. To exemplify this I will
survey recent efforts towards this goal. I will then describe a set of methods
that together form a toolbox of cognitive models to aid this research program.
At the core of this toolbox are sequential sampling models which have been used
to explain diverse cognitive neuroscience phenomena but have so far seen little
adoption in psychiatric research. I will then describe how these models can be
fitted to subject data and highlight how hierarchical Bayesian estimation
provides a rich framework with many desirable properties and benefits compared
to traditional optimization-based approaches. Finally, non-parametric Bayesian
methods provide general solutions to the problem of classifying mental illness
within this framework.",181,10,1263,25.69
678,neuroscience,"In cognitive neuroscience the sense of agency is defined as the as the
experience of controlling ones own actions and, through this control, affecting
the external world. At CHI 2012 I presented a paper entitled I did that!
Measuring Users Experience of Agency in their own Actions [1]. This extended
abstract draws heavily on that paper, which described an implicit measure
called intentional binding. This measure, developed by researchers in cognitive
neuroscience, has been shown to provide a robust implicit measure for the sense
of agency. My interest in intentional binding stemmed from prior HCI
literature, (e.g. the work of Shneiderman) which emphasises the importance of
the sense of control in human-computer interactions. The key question behind
the CHI 2012 paper was: can we apply intention binding to provide an implicit
measure for the experience of control in human-computer interactions? In
investigating this question, replication was a key element of the experimental
process.",153,9,997,37.3
679,neuroscience,"Two major initiatives to accelerate research in the brain sciences have
focused attention on developing a new generation of scientific instruments for
neuroscience. These instruments will be used to record static (structural) and
dynamic (behavioral) information at unprecedented spatial and temporal
resolution and report out that information in a form suitable for computational
analysis. We distinguish between recording - taking measurements of individual
cells and the extracellular matrix - and reporting - transcoding, packaging and
transmitting the resulting information for subsequent analysis - as these
represent very different challenges as we scale the relevant technologies to
support simultaneously tracking the many neurons that comprise neural circuits
of interest. We investigate a diverse set of technologies with the purpose of
anticipating their development over the span of the next 10 years and
categorizing their impact in terms of short-term [1-2 years], medium-term [2-5
years] and longer-term [5-10 years] deliverables.",148,5,1046,9.56
680,neuroscience,"The objective of this chapter is to provide a guide to using functional
magnetic resonance imaging (fMRI) to inform cognitive theory. This is, of
course, a daunting task, as the premise itself - that fMRI data can inform
cognitive theory - is still actively debated. Below, we touch on this debate as
a means of framing our guide. In particular, we argue that cognitive theories
can be constrained by neuroscientific data, including that offered by fMRI, but
to do so requires embellishing the cognitive theory so that it can make
predictions for neuroscience; much the same as how testing a cognitive theory
using behavior requires embellishing that theory to make experimentally
realizable behavioral predictions (i.e., the process of generating operational
definitions). Moreover, recent years have seen the development of several new
approaches that allow fMRI to better test neurally-embellished models. Along
with a review of several ways of testing neurally-embellished cognitive theory
using fMRI, we also consider the inferential challenges that can accompany
these approaches. Readers of this chapter should gain an understanding of both
of the potential power and the challenges associated with fMRI as a cognitive
neuroscience methodology.",190,10,1251,22.24
681,neuroscience,"The brain can be regarded as a network: a connected system where nodes, or
units, represent different specialized regions and links, or connections,
represent communication pathways. From a functional perspective communication
is coded by temporal dependence between the activities of different brain
areas. In the last decade, the abstract representation of the brain as a graph
has allowed to visualize functional brain networks and describe their
non-trivial topological properties in a compact and objective way. Nowadays,
the use of graph analysis in translational neuroscience has become essential to
quantify brain dysfunctions in terms of aberrant reconfiguration of functional
brain networks. Despite its evident impact, graph analysis of functional brain
networks is not a simple toolbox that can be blindly applied to brain signals.
On the one hand, it requires a know-how of all the methodological steps of the
processing pipeline that manipulates the input brain signals and extract the
functional network properties. On the other hand, a knowledge of the neural
phenomenon under study is required to perform physiological-relevant analysis.
The aim of this review is to provide practical indications to make sense of
brain network analysis and contrast counterproductive attitudes.",191,9,1295,30.3
682,neuroscience,"The means by which cortical neural networks are able to efficiently solve
inference problems remains an open question in computational neuroscience.
Recently, abstract models of Bayesian computation in neural circuits have been
proposed, but they lack a mechanistic interpretation at the single-cell level.
In this article, we describe a complete theoretical framework for building
networks of leaky integrate-and-fire neurons that can sample from arbitrary
probability distributions over binary random variables. We test our framework
for a model inference task based on a psychophysical phenomenon (the
Knill-Kersten optical illusion) and further assess its performance when applied
to randomly generated distributions. As the local computations performed by the
network strongly depend on the interaction between neurons, we compare several
types of couplings mediated by either single synapses or interneuron chains.
Due to its robustness to substrate imperfections such as parameter noise and
background noise correlations, our model is particularly interesting for
implementation on novel, neuro-inspired computing architectures, which can
thereby serve as a fast, low-power substrate for solving real-world inference
problems.",169,7,1233,9.01
683,neuroscience,"Multivariate processes with long-range dependent properties are found in a
large number of applications including finance, geophysics and neuroscience.
For real data applications, the correlation between time series is crucial.
Usual estimations of correlation can be highly biased due to phase-shifts
caused by the differences in the properties of autocorrelation in the
processes. To address this issue, we introduce a semiparametric estimation of
multivariate long-range dependent processes. The parameters of interest in the
model are the vector of the long-range dependence parameters and the long-run
covariance matrix, also called functional connectivity in neuroscience. This
matrix characterizes coupling between time series. The proposed multivariate
wavelet-based Whittle estimation is shown to be consistent for the estimation
of both the long-range dependence and the covariance matrix and to encompass
both stationary and nonstationary processes. A simulation study and a real data
example are presented to illustrate the finite sample behaviour.",147,9,1060,18.96
684,neuroscience,"Information theory is a practical and theoretical framework developed for the
study of communication over noisy channels. Its probabilistic basis and
capacity to relate statistical structure to function make it ideally suited for
studying information flow in the nervous system. It has a number of useful
properties: it is a general measure sensitive to any relationship, not only
linear effects; it has meaningful units which in many cases allow direct
comparison between different experiments; and it can be used to study how much
information can be gained by observing neural responses in single trials,
rather than in averages over multiple trials. A variety of information
theoretic quantities are in common use in neuroscience - (see entry ""Summary of
Information-Theoretic Quantities""). Estimating these quantities in an accurate
and unbiased way from real neurophysiological data frequently presents
challenges, which are explained in this entry.",142,6,954,17.47
685,neuroscience,"Research on the so-called ""free-energy principle'' (FEP) in cognitive
neuroscience is becoming increasingly high-profile. To date, introductions to
this theory have proved difficult for many readers to follow, but it depends
mainly upon two relatively simple ideas: firstly that normative or teleological
values can be expressed as probability distributions (active inference), and
secondly that approximate Bayesian reasoning can be effectively performed by
gradient descent on model parameters (the free-energy principle). The notion of
active inference is of great interest for a number of disciplines including
cognitive science and artificial intelligence, as well as cognitive
neuroscience, and deserves to be more widely known.
  This paper attempts to provide an accessible introduction to active inference
and informational free-energy, for readers from a range of scientific
backgrounds. In this work introduce an agent-based model with an agent trying
to make predictions about its position in a one-dimensional discretized world
using methods from the FEP.",151,6,1068,15.44
686,neuroscience,"Analyzing point patterns with linear structures has recently been of interest
in e.g. neuroscience and geography. To detect anisotropy in such cases, we
introduce a functional summary statistic, called the cylindrical $K$-function,
since it is a directional $K$-function whose structuring element is a cylinder.
Further we introduce a class of anisotropic Cox point processes, called Poisson
line cluster point processes. The points of such a process are random
displacements of Poisson point processes defined on the lines of a Poisson line
process. Parameter estimation based on moment methods or Bayesian inference for
this model is discussed when the underlying Poisson line process and the
cluster memberships are treated as hidden processes. To illustrate the
methodologies, we analyze a two and a three-dimensional point pattern data set.
The 3D data set is of particular interest as it relates to the minicolumn
hypothesis in neuroscience, claiming that pyramidal and other brain cells have
a columnar arrangement perpendicular to the pial surface of the brain.",162,10,1069,42.41
687,neuroscience,"Technological advances have dramatically expanded our ability to probe
multi-neuronal dynamics and connectivity in the brain. However, our ability to
extract a simple conceptual understanding from complex data is increasingly
hampered by the lack of theoretically principled data analytic procedures, as
well as theoretical frameworks for how circuit connectivity and dynamics can
conspire to generate emergent behavioral and cognitive functions. We review and
outline potential avenues for progress, including new theories of high
dimensional data analysis, the need to analyze complex artificial networks, and
methods for analyzing entire spaces of circuit models, rather than one model at
a time. Such interplay between experiments, data analysis and theory will be
indispensable in catalyzing conceptual advances in the age of large-scale
neuroscience.",120,5,856,-1.28
688,neuroscience,"Here we introduce a new model of natural textures based on the feature spaces
of convolutional neural networks optimised for object recognition. Samples from
the model are of high perceptual quality demonstrating the generative power of
neural networks trained in a purely discriminative fashion. Within the model,
textures are represented by the correlations between feature maps in several
layers of the network. We show that across layers the texture representations
increasingly capture the statistical properties of natural images while making
object information more and more explicit. The model provides a new tool to
generate stimuli for neuroscience and might offer insights into the deep
representations learned by convolutional neural networks.",110,6,755,23.77
689,neuroscience,"Here we provide a thorough discussion of a rebuttal by D'Ambrosio et al to a
study conducted by Rodgers et al. (Rodgers KM, Dudek FE, Barth DS (2015)
Progressive, Seizure-Like, Spike- Wave Discharges Are Common in Both Injured
and Uninjured Sprague-Dawley Rats: Implications for the Fluid Percussion Injury
Model of Post-Traumatic Epilepsy. J Neurosci. 35(24):9194-204. doi:
10.1523/JNEUROSCI.0919-15.2015.) to investigate focal seizures and acquired
epileptogenesis induced by head injury in the rat. This manuscript serves as
supplementary document for our letter to the Editor to appear in the Journal of
Neuroscience. We find the rebuttal is flawed on all points, particularly
concerning use of proper controls, experimental methods, analytical methods,
and epilepsy diagnostic criteria, leading to mistaking absence seizures for
post-traumatic epilepsy.",121,12,858,29.99
690,neuroscience,"Task based neuroimaging tools for the study of cognitive neuroscience provide
insight into understanding how the brain responds to increasing cognitive
demand. Theoretical models of neural-cognitive relationships have been
developed based on observations of linear and non-linear increases in brain
activity. Neural efficiency and capacity are two parameters of current
theoretical models. These two theoretical parameters describe the rate of
increase of brain activity and the upper limits of the increases, respectively.
The current work demonstrates that a quadratic model of increasing brain
activity in response to the n-back task is a solution to a differential
equation model. This reinterpretation of a standard approach to analyzing a
common cognitive task provides a wealth of new insight. The results include
brain wide measures of neural efficiency and capacity. The quantification of
neural-cognitive relationships provides evidence to support current cognitive
neuroscience theories. In addition, the methods provide a framework for
understanding the neural mechanisms of working memory. This allows estimation
of the effects of experimental manipulations within a conceptual research
framework. The proposed methods were applied to twenty-one healthy young adults
while engaging in four levels of the n-back task. All methods are easily
applicable using standard current software packages for neuroimaging.",200,13,1422,20.68
691,neuroscience,"It was previously reported, that temperature may significantly influence
neural dynamics on different levels of brain modelling. Due to this fact, while
creating the model in computational neuroscience we would like to make it
scalable for wide-range of various brain temperatures. However currently,
because of a lack of experimental data and an absence of analytical model
describing temperature influence on synapses, it is not possible to include
temperature effects on multi-neuron modelling level. In this paper, we propose
first step to deal with this problem: new analytical model of AMPA-type
synaptic conductance, which is able to include temperature effects in
low-frequency stimulations. It was constructed on basis of Markov model
description of AMPA receptor kinetics and few simplifications motivated both
experimentally and from Monte Carlo simulation of synaptic transmission. The
model may be used for efficient and accurate implementation of temperature
effects on AMPA receptor conductance in large scale neural network simulations.
This in fact, opens wide-range of new possibilities for researching an
influence of temperature on brain functioning.",169,8,1170,13.17
692,neuroscience,"The human brain is a complex network that supports mental function. The
nascent field of network neuroscience applies tools from mathematics to
neuroimaging data in the hopes of shedding light on cognitive function. A
critical question arising from these empirical studies is how to modulate a
human brain network to treat cognitive deficits or enhance mental abilities.
While historically a number of tools have been employed to modulate mental
states (such as cognitive behavioral therapy and brain stimulation),
theoretical frameworks to guide these interventions - and to optimize them for
clinical use - are fundamentally lacking. One promising and as-yet
underexplored approach lies in a sub-discipline of engineering known as network
control theory. Here, we posit that network control fundamentally relates to
mind control, and that this relationship highlights important areas for future
empirical research and opportunities to translate knowledge in practical
domains. We clarify the conceptual intersection between neuroanatomy,
cognition, and control engineering in the context of network neuroscience.
Finally, we discuss the challenges, ethics, and promises of mind control.",171,9,1188,24.68
693,neuroscience,"Computational neuroscience models have been used for understanding neural
dynamics in the brain and how they may be altered when physiological or other
conditions change. We review and develop a data-driven approach to neuroimaging
data called the energy landscape analysis. The methods are rooted in
statistical physics theory, in particular the Ising model, also known as the
(pairwise) maximum entropy model and Boltzmann machine. The methods have been
applied to fitting electrophysiological data in neuroscience for a decade, but
their use in neuroimaging data is still in its infancy. We first review the
methods and discuss some algorithms and technical aspects. Then, we apply the
methods to functional magnetic resonance imaging data recorded from healthy
individuals to inspect the relationship between the accuracy of fitting, the
size of the brain system to be analyzed, and the data length.",138,7,903,31.21
694,neuroscience,"Studying the neurological, genetic and evolutionary basis of human vocal
communication mechanisms using animal vocalization models is an important field
of neuroscience. The data sets typically comprise structured sequences of
syllables or `songs' produced by animals from different genotypes under
different social contexts. We develop a novel Bayesian semiparametric framework
for inference in such data sets. Our approach is built on a novel class of
mixed effects Markov transition models for the songs that accommodates
exogenous influences of genotype and context as well as animal-specific
heterogeneity. We design efficient Markov chain Monte Carlo algorithms for
posterior computation. Crucial advantages of the proposed approach include its
ability to provide insights into key scientific queries related to global and
local influences of the exogenous predictors on the transition dynamics via
automated tests of hypotheses. The methodology is illustrated using simulation
experiments and the aforementioned motivating application in neuroscience.",146,8,1058,16.42
695,neuroscience,"We establish center manifold theorems that allow one to study the bifurcation
of small solutions from a trivial state in systems of functional equations
posed on the real line. The class of equations includes most importantly
nonlinear equations with nonlocal coupling through convolution operators as
they arise in the description of spatially extended dynamics in neuroscience.
These systems possess a natural spatial translation symmetry but local
existence or uniqueness theorems for a spatial evolution associated with this
spatial shift or even a well motivated choice of phase space for the induced
dynamics do not seem to be available, due to the infinite range forward- and
backward-coupling through nonlocal convolution operators. We perform a
reduction relying entirely on functional analytic methods. Despite the nonlocal
nature of the problem, we do recover a local differential equation describing
the dynamics on the set of small bounded solutions, exploiting that the
translation invariance of the original problem induces a flow action on the
center manifold. We apply our reduction procedure to problems in mathematical
neuroscience, illustrating in particular the new type of algebra necessary for
the computation of Taylor jets of reduced vector fields.",190,7,1273,13.92
696,neuroscience,"One of the most important challenges in mathematical neuroscience is to
properly illustrate the stochastic nature of neurons. Among different
approaches, the noisy leaky integrate-and-fire and the escape rate models are
probably the most popular. These two models are usually chosen to express
different noise action over the neural cell. In this paper we investigate the
link between the two formalisms in the case of a neuron subject to a time
dependent input. To this aim, we introduce a new general stochastic framework.
As we shall prove, our general framework entails the two already existing ones.
Our result has theoretical implications since it offers a general view upon the
two stochastic processes mostly used in neuroscience, upon the way they can be
linked, and explain their observed statistical similarity.",129,8,822,44.34
697,neuroscience,"A major open challenge in neuroscience is the ability to measure and perturb
neural activity in vivo from well-defined neural sub-populations at cellular
resolution anywhere in the brain. However, limitations posed by scattering and
absorption prohibit non-invasive (surface) multiphoton approaches for deep
(>2mm) structures, while Gradient Refreactive Index (GRIN) endoscopes are thick
and cause significant damage upon insertion. Here, we demonstrate a novel
microendoscope to image neural activity at arbitrary depths via an ultrathin
multimode optical fiber (MMF) probe that is 5-10X thinner than commercially
available microendoscopes. We demonstrate micron-scale resolution,
multispectral and volumetric imaging. In contrast to previous approaches, we
show that this method has an improved acquisition speed that is sufficient to
capture rapid neuronal dynamics in-vivo in rodents expressing a genetically
encoded calcium indicator. Our results emphasize the potential of this
technology in neuroscience applications and open up possibilities for cellular
resolution imaging in previously unreachable brain regions.",151,7,1122,3.6
698,neuroscience,"Computational models in fields such as computational neuroscience are often
evaluated via stochastic simulation or numerical approximation. Fitting these
models implies a difficult optimization problem over complex, possibly noisy
parameter landscapes. Bayesian optimization (BO) has been successfully applied
to solving expensive black-box problems in engineering and machine learning.
Here we explore whether BO can be applied as a general tool for model fitting.
First, we present a novel hybrid BO algorithm, Bayesian adaptive direct search
(BADS), that achieves competitive performance with an affordable computational
overhead for the running time of typical models. We then perform an extensive
benchmark of BADS vs. many common and state-of-the-art nonconvex,
derivative-free optimizers, on a set of model-fitting problems with real data
and models from six studies in behavioral, cognitive, and computational
neuroscience. With default settings, BADS consistently finds comparable or
better solutions than other methods, including `vanilla' BO, showing great
promise for advanced BO techniques, and BADS in particular, as a general
model-fitting tool.",160,9,1160,25.8
699,neuroscience,"Animals (especially humans) have an amazing ability to learn new tasks
quickly, and switch between them flexibly. How brains support this ability is
largely unknown, both neuroscientifically and algorithmically. One reasonable
supposition is that modules drawing on an underlying general-purpose sensory
representation are dynamically allocated on a per-task basis. Recent results
from neuroscience and artificial intelligence suggest the role of the general
purpose visual representation may be played by a deep convolutional neural
network, and give some clues how task modules based on such a representation
might be discovered and constructed. In this work, we investigate module
architectures in an embodied two-dimensional touchscreen environment, in which
an agent's learning must occur via interactions with an environment that emits
images and rewards, and accepts touches as input. This environment is designed
to capture the physical structure of the task environments that are commonly
deployed in visual neuroscience and psychophysics. We show that in this
context, very simple changes in the nonlinear activations used by such a module
can significantly influence how fast it is at learning visual tasks and how
suitable it is for switching to new tasks.",187,8,1268,27.45
700,neuroscience,"In this paper we consider the modern theory of the Bayesian brain from
cognitive neurosciences in the light of recommender systems and expose
potentials for our community. In particular, we elaborate on noisy user
feedback and the thus resulting multicomponent user models, which have indeed a
biological origin. In real user experiments we observe the impact of both
factors directly in a repeated rating task along with recommendation. As a
consequence, this contribution supports the plausibility of contemporary
theories of mind in the context of recommender systems and can be understood as
a solicitation to integrate ideas of cognitive neurosciences into our systems
in order to further improve the prediction of human behaviour.",113,5,736,17.37
701,neuroscience,"The ""neural code"" is the way the brain characterizes, stores, and processes
information. Unraveling the neural code is a key goal of mathematical
neuroscience. Topology, coding theory, and, recently, commutative algebra are
some the mathematical areas that are involved in analyzing these codes. Neural
rings and ideals are algebraic objects that create a bridge between
mathematical neuroscience and commutative algebra. A neural ideal is an ideal
in a polynomial ring that encodes the combinatorial firing data of a neural
code. Using some algebraic techniques one hopes to understand more about the
structure of a neural code via neural rings and ideals. In this paper, we
introduce an operation, called ""polarization,"" that allows us to relate neural
ideals with squarefree monomial ideals, which are very well studied and known
for their nice behavior in commutative algebra.",135,8,880,34.97
702,neuroscience,"Since the enormous breakthroughs in machine learning over the last decade,
functional neural network models are of growing interest for many researchers
in the field of computational neuroscience. One major branch of research is
concerned with biologically plausible implementations of reinforcement
learning, with a variety of different models developed over the recent years.
However, most studies in this area are conducted with custom simulation scripts
and manually implemented tasks. This makes it hard for other researchers to
reproduce and build upon previous work and nearly impossible to compare the
performance of different learning architectures. In this work, we present a
novel approach to solve this problem, connecting benchmark tools from the field
of machine learning and state-of-the-art neural network simulators from
computational neuroscience. This toolchain enables researchers in both fields
to make use of well-tested high-performance simulation software supporting
biologically plausible neuron, synapse and network models and allows them to
evaluate and compare their approach on the basis of standardized environments
of varying complexity. We demonstrate the functionality of the toolchain by
implementing a neuronal actor-critic architecture for reinforcement learning in
the NEST simulator and successfully training it on two different environments
from the OpenAI Gym.",196,8,1400,17.68
703,neuroscience,"The mammalian brain is a densely interconnected network that consists of
millions to billions of neurons. Decoding how information is represented and
processed by this neural circuitry requires the ability to capture and
manipulate the dynamics of large populations at high speed and resolution over
a large area of the brain. While there has been a rapid increase in use of
optical approaches in the neuroscience community over the last two decades,
most microscopy approaches lack the ability to record the activity of all
neurons comprising a functional network across the mammalian brain at relevant
temporal and spatial resolution. In this review, we survey the recent
development in the optical calcium imaging technologies in this regard and
provide an overview of the strengths and limitations of each modality and their
potential for scalability. We provide a guidance from a biological user
perspective that is driven by the typical biological applications and sample
conditions. We also discuss the potential for future advances and synergies
that could be obtained through hybrid approaches or other modalities.",173,7,1123,25.32
704,neuroscience,"Random noise plays a beneficial role in cognitive processing and produces
measurable improvement in simulations and biological agents' task performance.
Stochastic facilitation, the phenomenon of additive noise improving signal
transmission in complex systems, has been shown to occur in a variety of neural
contexts. However, neuroscience analyses to date have not fully explored the
colours that neural noise could be. The literature shows a 1/f pink noise power
spectrum distribution at many levels, but many less rigourous studies assume
white noise, with little justification of why that assumption is made. In this
work, we briefly review the colours of noise and their useful applications in
other fields. If we consider that noise is not so black and white, we could
more colourfully regularize artificial neural networks and re-investigate some
surprising results about how the brain benefits from noise.",138,7,913,39.67
705,neuroscience,"Neuroscience has been carried into the domain of big data and high
performance computing (HPC) on the backs of initiatives in data collection and
an increasingly compute-intensive tools. While managing HPC experiments
requires considerable technical acumen, platforms and standards have been
developed to ease this burden on scientists. While web-portals make resources
widely accessible, data organizations such as the Brain Imaging Data Structure
and tool description languages such as Boutiques provide researchers with a
foothold to tackle these problems using their own datasets, pipelines, and
environments. While these standards lower the barrier to adoption of HPC and
cloud systems for neuroscience applications, they still require the
consolidation of disparate domain-specific knowledge. We present Clowdr, a
lightweight tool to launch experiments on HPC systems and clouds, record rich
execution records, and enable the accessible sharing of experimental summaries
and results. Clowdr uniquely sits between web platforms and bare-metal
applications for experiment management by preserving the flexibility of
do-it-yourself solutions while providing a low barrier for developing,
deploying and disseminating neuroscientific analysis.",170,7,1244,17.37
706,neuroscience,"The main goal of group testing with inhibitors (GTI) is to efficiently
identify a small number of defective items and inhibitor items in a large set
of items. A test on a subset of items is positive if the subset satisfies some
specific properties. Inhibitor items cancel the effects of defective items,
which often make the outcome of a test containing defective items negative.
Different GTI models can be formulated by considering how specific properties
have different cancellation effects. This work introduces generalized GTI
(GGTI) in which a new type of items is added, i.e., hybrid items. A hybrid item
plays the roles of both defectives items and inhibitor items. Since the number
of instances of GGTI is large (more than 7 million), we introduce a framework
for classifying all types of items non-adaptively, i.e., all tests are designed
in advance. We then explain how GGTI can be used to classify neurons in
neuroscience. Finally, we show how to realize our proposed scheme in practice.",165,14,999,63.19
707,neuroscience,"Deep neural networks (DNNs) transform stimuli across multiple processing
stages to produce representations that can be used to solve complex tasks, such
as object recognition in images. However, a full understanding of how they
achieve this remains elusive. The complexity of biological neural networks
substantially exceeds the complexity of DNNs, making it even more challenging
to understand the representations that they learn. Thus, both machine learning
and computational neuroscience are faced with a shared challenge: how can we
analyze their representations in order to understand how they solve complex
tasks?
  We review how data-analysis concepts and techniques developed by
computational neuroscientists can be useful for analyzing representations in
DNNs, and in turn, how recently developed techniques for analysis of DNNs can
be useful for understanding representations in biological neural networks. We
explore opportunities for synergy between the two fields, such as the use of
DNNs as in-silico model systems for neuroscience, and how this synergy can lead
to new hypotheses about the operating principles of biological neural networks.",168,6,1156,17.68
708,neuroscience,"In good old-fashioned artificial intelligence (GOFAI), humans specified
systems that solved problems. Much of the recent progress in AI has come from
replacing human insights by learning. However, learning itself is still usually
built by humans -- specifically the choice that parameter updates should follow
the gradient of a cost function. Yet, in analogy with GOFAI, there is no reason
to believe that humans are particularly good at defining such learning systems:
we may expect learning itself to be better if we learn it. Recent research in
machine learning has started to realize the benefits of that strategy. We
should thus expect this to be relevant for neuroscience: how could the correct
learning rules be acquired? Indeed, cognitive science has long shown that
humans learn-to-learn, which is potentially responsible for their impressive
learning abilities. Here we discuss ideas across machine learning,
neuroscience, and cognitive science that matter for the principle of
learning-to-learn.",152,8,1006,43.83
709,neuroscience,"This paper introduces a framework of gesture recognition operating on the
output of an event based camera using the computational resources of a mobile
phone. We will introduce a new development around the concept of time-surfaces
modified and adapted to run on the limited computational resources of a mobile
platform. We also introduce a new method to remove dynamically backgrounds that
makes full use of the high temporal resolution of event-based cameras. We
assess the performances of the framework by operating on several dynamic
scenarios in uncontrolled lighting conditions indoors and outdoors. We also
introduce a new publicly available event-based dataset for gesture recognition
selected through a clinical process to allow human-machine interactions for the
visually-impaired and the elderly. We finally report comparisons with prior
works that tackled event-based gesture recognition reporting comparable if not
superior results if taking into account the limited computational and memory
constraints of the used hardware.",151,7,1037,20.52
710,neuroscience,"Recent successes in deep learning have started to impact neuroscience. Of
particular significance are claims that current segmentation algorithms achieve
""super-human"" accuracy in an area known as connectomics. However, as we will
show, these algorithms do not effectively generalize beyond the particular
source and brain tissues used for training -- severely limiting their usability
by the broader neuroscience community. To fill this gap, we describe a novel
connectomics challenge for source- and tissue-agnostic reconstruction of
neurons (STAR), which favors broad generalization over fitting specific
datasets. We first demonstrate that current state-of-the-art approaches to
neuron segmentation perform poorly on the challenge. We further describe a
novel convolutional recurrent neural network module that combines short-range
horizontal connections within a processing stage and long-range top-down
connections between stages. The resulting architecture establishes the state of
the art on the STAR challenge and represents a significant step towards widely
usable and fully-automated connectomics analysis.",150,8,1117,16.02
711,neuroscience,"The reciprocal impact of applied neuroscience and cognitive studies on
humanities has been extensive and growing over the past 30 years of research.
Studies on neuroaesthetics have provided novel insights in visual arts, music
as well as abstract and dramatic art. Neuro-Art is an experimental concept in
applied neuroscience where scientists can study the mechanistic pathways
involved for instance in visual art through which creativity and artistic
capacity might receive further empowerment. Based on the existing evidence, at
least 3 large-scale brain networks are involved simultaneously when one is
submitted to a creativity-related task. The question whether the key brain
regions involved in visual art creativity can be identified and receive
neuromodulation to get empowered prompted us to perform the present case
investigation. Virtual reality and functional quantitative
electroencephalography upon 2- vs 3-dimentional painting were employed to study
cortical neurodynamics in a professional painting artist.",145,7,1022,21.53
712,neuroscience,"Deep learning has sparked a network of mutual interactions between different
disciplines and AI. Naturally, each discipline focuses and interprets the
workings of deep learning in different ways. This diversity of perspectives on
deep learning, from neuroscience to statistical physics, is a rich source of
inspiration that fuels novel developments in the theory and applications of
machine learning. In this perspective, we collect and synthesize different
intuitions scattered across several communities as for how deep learning works.
In particular, we will briefly discuss the different perspectives that
disciplines across mathematics, physics, computation, and neuroscience take on
how deep learning does its tricks. Our discussion on each perspective is
necessarily shallow due to the multiple views that had to be covered. The
deepness in this case should come from putting all these faces of deep learning
together in the reader's mind, so that one can look at the same problem from
different angles.",152,8,1009,40.99
713,neuroscience,"Although social neuroscience is concerned with understanding how the brain
interacts with its social environment, prevailing research in the field has
primarily considered the human brain in isolation, deprived of its rich social
context. Emerging work in social neuroscience that leverages tools from network
analysis has begun to pursue this issue, advancing knowledge of how the human
brain influences and is influenced by the structures of its social environment.
In this paper, we provide an overview of key theory and methods in network
analysis (especially for social systems) as an introduction for social
neuroscientists who are interested in relating individual cognition to the
structures of an individual's social environments. We also highlight some
exciting new work as examples of how to productively use these tools to
investigate questions of relevance to social neuroscientists. We include
tutorials to help with practical implementation of the concepts that we
discuss. We conclude by highlighting a broad range of exciting research
opportunities for social neuroscientists who are interested in using network
analysis to study social systems.",172,7,1162,16.96
714,neuroscience,"Parallel developments in neuroscience and deep learning have led to mutually
productive exchanges, pushing our understanding of real and artificial neural
networks in sensory and cognitive systems. However, this interaction between
fields is less developed in the study of motor control. In this work, we
develop a virtual rodent as a platform for the grounded study of motor activity
in artificial models of embodied control. We then use this platform to study
motor activity across contexts by training a model to solve four complex tasks.
Using methods familiar to neuroscientists, we describe the behavioral
representations and algorithms employed by different layers of the network
using a neuroethological approach to characterize motor activity relative to
the rodent's behavior and goals. We find that the model uses two classes of
representations which respectively encode the task-specific behavioral
strategies and task-invariant behavioral kinematics. These representations are
reflected in the sequential activity and population dynamics of neural
subpopulations. Overall, the virtual rodent facilitates grounded collaborations
between deep reinforcement learning and motor neuroscience.",168,9,1200,16.32
715,neuroscience,"Examining locomotion has improved our basic understanding of motor control
and aided in treating motor impairment. Mice and rats are premier models of
human disease and increasingly the model systems of choice for basic
neuroscience. High frame rates (250 Hz) are needed to quantify the kinematics
of these running rodents. Manual tracking, especially for multiple markers,
becomes time-consuming and impossible for large sample sizes. Therefore, the
need for automatic segmentation of these markers has grown in recent years.
Here, we address this need by presenting a method to segment the markers using
the SLIC superpixel method. The 2D coordinates on the image plane are projected
to a 3D domain using direct linear transform (DLT) and a 3D Kalman filter has
been used to predict the position of markers based on the speed and position of
markers from the previous frames. Finally, a probabilistic function is used to
find the best match among superpixels. The method is evaluated for different
difficulties for tracking of the markers and it achieves 95% correct labeling
of markers.",173,10,1089,43.53
716,neuroscience,"In cognitive network neuroscience, the connectivity and community structure
of the brain network is related to cognition. Much of this research has focused
on two measures of connectivity - modularity and flexibility - which frequently
have been examined in isolation. By using resting state fMRI data from 52 young
adults, we investigate the relationship between modularity, flexibility and
performance on cognitive tasks. We show that flexibility and modularity are
highly negatively correlated. However, we also demonstrate that flexibility and
modularity make unique contributions to explain task performance, with
modularity predicting performance for simple tasks and flexibility predicting
performance on complex tasks that require cognitive control and executive
functioning. The theory and results presented here allow for stronger links
between measures of brain network connectivity and cognitive processes.",127,7,918,8.06
717,neuroscience,"This paper formulates a generalized classification algorithm with an
application to classifying (or `decoding') neural activity in the brain.
Medical doctors and researchers have long been interested in how brain activity
correlates to body movement. Experiments have been conducted on patients whom
are unable to move, in order to gain insight as to how thinking about movements
might generate discernable neural activity. Researchers are tasked with
determining which neurons are responsible for different imagined movements and
how the firing behavior changes, given neural firing data. For instance,
imagined movements may include wrist flexion, elbow extension, or closing the
hand. This is just one of many applications to data classification. Though this
article deals with an application in neuroscience, the generalized algorithm
proposed in this article has applications in scientific areas ranging from
neuroscience to acoustic and medical imaging.",138,8,959,26.1
718,neuroscience,"Recently, we put forwarded a redox molecular hypothesis involving the natural
biophysical substrate of visual perception and imagery. Here, we explicitly
propose that the feedback and feedforward iterative operation processes can be
interpreted in terms of a homunculus looking at the biophysical picture in our
brain during visual imagery. We further propose that the brain can use both
picture-like and language-like representation processes. In our interpretation,
visualization (imagery) is a special kind of representation i.e., visual
imagery requires a peculiar inherent biophysical (picture-like) mechanism. We
also conjecture that the evolution of higher levels of complexity made the
biophysical picture representation of the external visual world possible by
controlled redox and bioluminescent nonlinear (iterative) biochemical reactions
in the V1 and V2 areas during visual imagery. Our proposal deals only with the
primary level of visual representation (i.e. perceived ""scene"").",138,11,993,9.18
719,neuroscience,"Models of simple excitable dynamics on graphs are an efficient framework for
studying the interplay between network topology and dynamics. This subject is a
topic of practical relevance to diverse fields, ranging from neuroscience to
engineering. Here we analyze how a single excitation propagates through a
random network as a function of the excitation threshold, that is, the relative
amount of activity in the neighborhood required for an excitation of a node.
Using numerical simulations and analytical considerations, we can understand
the onset of sustained activity as an interplay between topological cycle
statistics and path statistics. Our findings are interpreted in the context of
the theory of network reverberations in neural systems, which is a question of
long-standing interest in computational neuroscience.",122,6,827,21.33
720,neuroscience,"Neuroscience research has produced many theories and computational neural
models of sensory nervous systems. Notwithstanding many different perspectives
towards developing intelligent machines, artificial intelligence has ultimately
been influenced by neuroscience. Therefore, this paper provides an introduction
to biologically inspired machine intelligence by exploring the basic principles
of sensation and perception as well as the structure and behavior of biological
sensory nervous systems like the neocortex. Concepts like spike timing,
synaptic plasticity, inhibition, neural structure, and neural behavior are
applied to a new model, Simple Cortex (SC). A software implementation of SC has
been built and demonstrates fast observation, learning, and prediction of
spatio-temporal sensory-motor patterns and sequences. Finally, this paper
suggests future areas of improvement and growth for Simple Cortex and other
related machine intelligence models.",126,7,960,7.86
721,neuroscience,"The last decades saw dramatic progress in brain research. These advances were
often buttressed by probing single variables to make circumscribed discoveries,
typically through null hypothesis significance testing. New ways for generating
massive data fueled tension between the traditional methodology, used to infer
statistically relevant effects in carefully-chosen variables, and
pattern-learning algorithms, used to identify predictive signatures by
searching through abundant information. In this article, we detail the
antagonistic philosophies behind two quantitative approaches: certifying robust
effects in understandable variables, and evaluating how accurately a built
model can forecast future outcomes. We discourage choosing analysis tools via
categories like 'statistics' or 'machine learning'. Rather, to establish
reproducible knowledge about the brain, we advocate prioritizing tools in view
of the core motivation of each quantitative analysis: aiming towards
mechanistic insight, or optimizing predictive accuracy.",133,7,1034,6.64
722,neuroscience,"Neuroscience has traditionally relied on manually observing lab animals in
controlled environments. Researchers usually record animals behaving in free or
restrained manner and then annotate the data manually. The manual annotation is
not desirable for three reasons; one, it is time consuming, two, it is prone to
human errors and three, no two human annotators will 100\% agree on annotation,
so it is not reproducible. Consequently, automated annotation of such data has
gained traction because it is efficient and replicable. Usually, the automatic
annotation of neuroscience data relies on computer vision and machine leaning
techniques. In this article, we have covered most of the approaches taken by
researchers for locomotion and gesture tracking of lab animals. We have divided
these papers in categories based upon the hardware they use and the software
approach they take. We also have summarized their strengths and weaknesses.",143,9,940,36.39
723,neuroscience,"Identifying the physiological processes underlying the emergence and
maintenance of consciousness is one of the most fundamental problems of
neuroscience, with implications ranging from fundamental neuroscience to the
treatment of patients with disorders of consciousness (DOC). One major
challenge is to understand how cortical circuits at drastically different
spatial scales, from local networks to brain-scale networks, operate in concert
to enable consciousness, and how those processes are impaired in DOC patients.
In this review, we attempt to relate available neurophysiological and clinical
data with existing theoretical models of consciousness, while linking the
micro- and macro-circuit levels. First, we address the relationships between
awareness and wakefulness on the one hand, and cortico-cortical, and
thalamo-cortical connectivity on the other hand. Second, we discuss the role of
three main types of GABAergic interneurons in specific circuits responsible for
the dynamical re-organization of functional networks. Third, we explore
advances in the functional role of nested oscillations for neural
synchronization and communication, emphasizing the importance of the balance
between local (high-frequency) and distant (low-frequency) activity for
efficient information processing. The clinical implications of these
theoretical considerations are presented. We propose that such cellular-scale
mechanisms could extend current theories of consciousness.",195,9,1473,4.41
724,neuroscience,"While deep neural networks have surpassed human performance in multiple
situations, they are prone to catastrophic forgetting: upon training a new
task, they rapidly forget previously learned ones. Neuroscience studies, based
on idealized tasks, suggest that in the brain, synapses overcome this issue by
adjusting their plasticity depending on their past history. However, such
""metaplastic"" behaviours do not transfer directly to mitigate catastrophic
forgetting in deep neural networks. In this work, we interpret the hidden
weights used by binarized neural networks, a low-precision version of deep
neural networks, as metaplastic variables, and modify their training technique
to alleviate forgetting. Building on this idea, we propose and demonstrate
experimentally, in situations of multitask and stream learning, a training
technique that reduces catastrophic forgetting without needing previously
presented data, nor formal boundaries between datasets and with performance
approaching more mainstream techniques with task boundaries. We support our
approach with a theoretical analysis on a tractable task. This work bridges
computational neuroscience and deep learning, and presents significant assets
for future embedded and neuromorphic systems, especially when using novel
nanodevices featuring physics analogous to metaplasticity.",182,8,1344,19.71
725,neuroscience,"This study extends the mathematical model of emotion dimensions that we
previously proposed (Yanagisawa, et al. 2019, Front Comput Neurosci) to
consider perceived complexity as well as novelty, as a source of arousal
potential. Berlyne's hedonic function of arousal potential (or the inverse
U-shaped curve, the so-called Wundt curve) is assumed. We modeled the arousal
potential as information contents to be processed in the brain after sensory
stimuli are perceived (or recognized), which we termed sensory surprisal. We
mathematically demonstrated that sensory surprisal represents free energy, and
it is equivalent to a summation of information gain (or information from
novelty) and perceived complexity (or information from complexity), which are
the collative variables forming the arousal potential. We demonstrated
empirical evidence with visual stimuli (profile shapes of butterfly) supporting
the hypothesis that the summation of perceived novelty and complexity shapes
the inverse U-shaped beauty function. We discussed the potential of free energy
as a mathematical principle explaining emotion initiators.",158,8,1120,23.16
726,neuroscience,"We define a notion of complexity, which quantifies the nonlinearity of the
computation of a neural network, as well as a complementary measure of the
effective dimension of feature representations. We investigate these
observables both for trained networks for various datasets as well as explore
their dynamics during training, uncovering in particular power law scaling.
These observables can be understood in a dual way as uncovering hidden internal
structure of the datasets themselves as a function of scale or depth. The
entropic character of the proposed notion of complexity should allow to
transfer modes of analysis from neuroscience and statistical physics to the
domain of artificial neural networks. The introduced observables can be applied
without any change to the analysis of biological neuronal systems.",124,6,821,29.38
727,neuroscience,"Mining human-brain networks to discover patterns that can be used to
discriminate between healthy individuals and patients affected by some
neurological disorder, is a fundamental task in neuroscience. Learning simple
and interpretable models is as important as mere classification accuracy. In
this paper we introduce a novel approach for classifying brain networks based
on extracting contrast subgraphs, i.e., a set of vertices whose induced
subgraphs are dense in one class of graphs and sparse in the other. We formally
define the problem and present an algorithmic solution for extracting contrast
subgraphs. We then apply our method to a brain-network dataset consisting of
children affected by Autism Spectrum Disorder and children Typically Developed.
Our analysis confirms the interestingness of the discovered patterns, which
match background knowledge in the neuroscience literature. Further analysis on
other classification tasks confirm the simplicity, soundness, and high
explainability of our proposal, which also exhibits superior classification
accuracy, to more complex state-of-the-art methods.",156,10,1114,26.3
728,neuroscience,"The famous claim that we only use about 10% of the brain capacity has
recently been challenged. Researchers argue that we are likely to use the whole
brain, against the 10% claim. Some evidence and results from relevant studies
and experiments related to memory in the field of neuroscience leads to the
conclusion that if the rest 90% of the brain is not used, then many neural
pathways would degenerate. What is memory? How does the brain function? What
would be the limit of memory capacity? This article provides a model
established upon the physiological and neurological characteristics of the
human brain, which could give some theoretical support and scientific
explanation to explain some phenomena. It may not only have theoretically
significance in neuroscience, but could also be practically useful to fill in
the gap between the natural and machine intelligence.",141,6,875,45.15
729,neuroscience,"We investigate time-dependent data analysis from the perspective of recurrent
kernel machines, from which models with hidden units and gated memory cells
arise naturally. By considering dynamic gating of the memory cell, a model
closely related to the long short-term memory (LSTM) recurrent neural network
is derived. Extending this setup to $n$-gram filters, the convolutional neural
network (CNN), Gated CNN, and recurrent additive network (RAN) are also
recovered as special cases. Our analysis provides a new perspective on the
LSTM, while also extending it to $n$-gram convolutional filters. Experiments
are performed on natural language processing tasks and on analysis of local
field potentials (neuroscience). We demonstrate that the variants we derive
from kernels perform on par or even better than traditional neural methods. For
the neuroscience application, the new models demonstrate significant
improvements relative to the prior state of the art.",141,8,963,34.15
730,neuroscience,"Although Deep Neural Networks have seen great success in recent years through
various changes in overall architectures and optimization strategies, their
fundamental underlying design remains largely unchanged. Computational
neuroscience on the other hand provides more biologically realistic models of
neural processing mechanisms, but they are still high level abstractions of the
actual experimentally observed behaviour. Here a model is proposed that bridges
Neuroscience, Machine Learning and Evolutionary Algorithms to evolve individual
soma and synaptic compartment models of neurons in a scalable manner. Instead
of attempting to manually derive models for all the observed complexity and
diversity in neural processing, we propose an Evolvable Neural Unit (ENU) that
can approximate the function of each individual neuron and synapse. We
demonstrate that this type of unit can be evolved to mimic Integrate-And-Fire
neurons and synaptic Spike-Timing-Dependent Plasticity. Additionally, by
constructing a new type of neural network where each synapse and neuron is such
an evolvable neural unit, we show it is possible to evolve an agent capable of
learning to solve a T-maze environment task. This network independently
discovers spiking dynamics and reinforcement type learning rules, opening up a
new path towards biologically inspired artificial intelligence.",194,8,1371,17.98
731,neuroscience,"The need for more transparency of the decision-making processes in artificial
neural networks steadily increases driven by their applications in safety
critical and ethically challenging domains such as autonomous driving or
medical diagnostics. We address today's lack of transparency of neural networks
and shed light on the roles of single neurons and groups of neurons within the
network fulfilling a learned task. Inspired by research in the field of
neuroscience, we characterize the learned representations by activation
patterns and network ablations, revealing functional neuron populations that a)
act jointly in response to specific stimuli or b) have similar impact on the
network's performance after being ablated. We find that neither a neuron's
magnitude or selectivity of activation, nor its impact on network performance
are sufficient stand-alone indicators for its importance for the overall task.
We argue that such indicators are essential for future advances in transfer
learning and modern neuroscience.",150,6,1026,15.65
732,neuroscience,"Predictive coding, currently a highly influential theory in neuroscience, has
not been widely adopted in machine learning yet. In this work, we transform the
seminal model of Rao and Ballard (1999) into a modern deep learning framework
while remaining maximally faithful to the original schema. The resulting
network we propose (PreCNet) is tested on a widely used next frame video
prediction benchmark, which consists of images from an urban environment
recorded from a car-mounted camera, and achieves state-of-the-art performance.
Performance on all measures (MSE, PSNR, SSIM) was further improved when a
larger training set (2M images from BDD100k), pointing to the limitations of
the KITTI training set. This work demonstrates that an architecture carefully
based in a neuroscience model, without being explicitly tailored to the task at
hand, can exhibit exceptional performance.",132,6,885,36.22
733,neuroscience,"Attempting to imitate the brain functionalities, researchers have bridged
between neuroscience and artificial intelligence for decades; however,
experimental neuroscience has not directly advanced the field of machine
learning. Here, using neuronal cultures, we demonstrate that increased training
frequency accelerates the neuronal adaptation processes. This mechanism was
implemented on artificial neural networks, where a local learning step-size
increases for coherent consecutive learning steps and tested on a simple
dataset of handwritten digits, MNIST. Based on our online learning results with
a few handwriting examples, success rates for brain-inspired algorithms
substantially outperform the commonly used machine learning algorithms. We
speculate this emerging bridge from slow brain function to machine learning
will promote ultrafast decision making under limited examples, which is the
reality in many aspects of human activity, robotic control, and network
optimization.",131,6,987,11.04
734,neuroscience,"Decoding behavior, perception, or cognitive state directly from neural
signals has applications in brain-computer interface research as well as
implications for systems neuroscience. In the last decade, deep learning has
become the state-of-the-art method in many machine learning tasks ranging from
speech recognition to image segmentation. The success of deep networks in other
domains has led to a new wave of applications in neuroscience. In this article,
we review deep learning approaches to neural decoding. We describe the
architectures used for extracting useful features from neural recording
modalities ranging from spikes to EEG. Furthermore, we explore how deep
learning has been leveraged to predict common outputs including movement,
speech, and vision, with a focus on how pretrained deep networks can be
incorporated as priors for complex decoding targets like acoustic speech or
images. Deep learning has been shown to be a useful tool for improving the
accuracy and flexibility of neural decoding across a wide range of tasks, and
we point out areas for future scientific development.",167,8,1103,38.76
735,neuroscience,"The emergence of powerful artificial intelligence is defining new research
directions in neuroscience. To date, this research has focused largely on deep
neural networks trained using supervised learning, in tasks such as image
classification. However, there is another area of recent AI work which has so
far received less attention from neuroscientists, but which may have profound
neuroscientific implications: deep reinforcement learning. Deep RL offers a
comprehensive framework for studying the interplay among learning,
representation and decision-making, offering to the brain sciences a new set of
research tools and a wide range of novel hypotheses. In the present review, we
provide a high-level introduction to deep RL, discuss some of its initial
applications to neuroscience, and survey its wider implications for research on
brain and behavior, concluding with a list of opportunities for next-stage
research.",135,6,924,27.15
736,neuroscience,"In neuroscience, attention has been shown to bidirectionally interact with
reinforcement learning (RL) processes. This interaction is thought to support
dimensionality reduction of task representations, restricting computations to
relevant features. However, it remains unclear whether these properties can
translate into real algorithmic advantages for artificial agents, especially in
dynamic environments. We design a model incorporating a self-attention
mechanism that implements task-state representations in semantic feature-space,
and test it on a battery of Atari games. To evaluate the agent's selective
properties, we add a large volume of task-irrelevant features to observations.
In line with neuroscience predictions, self-attention leads to increased
robustness to noise compared to benchmark models. Strikingly, this
self-attention mechanism is general enough, such that it can be naturally
extended to implement a transient working-memory, able to solve a partially
observable maze task. Lastly, we highlight the predictive quality of attended
stimuli. Because we use semantic observations, we can uncover not only which
features the agent elects to base decisions on, but also how it chooses to
compile more complex, relational features from simpler ones. These results
formally illustrate the benefits of attention in deep RL and provide evidence
for the interpretability of self-attention mechanisms.",195,11,1419,17.84
737,neuroscience,"In previous studies, decoding electroencephalography (EEG) signals has not
considered the topological relationship of EEG electrodes. However, the latest
neuroscience has suggested brain network connectivity. Thus, the exhibited
interaction between EEG channels might not be appropriately measured via
Euclidean distance. To fill the gap, an attention-based graph residual network,
a novel structure of Graph Convolutional Neural Network (GCN), was presented to
detect human motor intents from raw EEG signals, where the topological
structure of EEG electrodes was built as a graph. Meanwhile, deep residual
learning with a full-attention architecture was introduced to address the
degradation problem concerning deeper networks in raw EEG motor imagery (MI)
data. Individual variability, the critical and longstanding challenge
underlying EEG signals, has been successfully handled with the state-of-the-art
performance, 98.08% accuracy at the subject level, 94.28% for 20 subjects.
Numerical results were promising that the implementation of the
graph-structured topology was superior to decode raw EEG data. The innovative
deep learning approach was expected to entail a universal method towards both
neuroscience research and real-world EEG-based practical applications, e.g.,
seizure prediction.",176,13,1300,19.77
738,neuroscience,"The paper re-analyzes a version of the celebrated Johnson-Lindenstrauss
Lemma, in which matrices are subjected to constraints that naturally emerge
from neuroscience applications: a) sparsity and b) sign-consistency. This
particular variant was studied first by Allen-Zhu, Gelashvili, Micali, Shavit
and more recently by Jagadeesan (RANDOM'19).
  The contribution of this work is a novel proof, which in contrast to previous
works a) uses the modern probability toolkit, particularly basics of
sub-gaussian and sub-gamma estimates b) is self-contained, with no dependencies
on subtle third-party results c) offers explicit constants.
  At the heart of our proof is a novel variant of Hanson-Wright Lemma (on
concentration of quadratic forms). Of independent interest are also auxiliary
facts on sub-gaussian random variables.",116,6,825,22.55
739,neuroscience,"A fundamental problem in statistical neuroscience is to model how neurons
encode information by analyzing electrophysiological recordings. A popular and
widely-used approach is to fit the spike trains with an autoregressive point
process model. These models are characterized by a set of convolutional
temporal filters, whose subsequent analysis can help reveal how neurons encode
stimuli, interact with each other, and process information. In practice a
sufficiently rich but small ensemble of temporal basis functions needs to be
chosen to parameterize the filters. However, obtaining a satisfactory fit often
requires burdensome model selection and fine tuning the form of the basis
functions and their temporal span. In this paper we propose a nonparametric
approach for jointly inferring the filters and hyperparameters using the
Gaussian process framework. Our method is computationally efficient taking
advantage of the sparse variational approximation while being flexible and rich
enough to characterize arbitrary filters in continuous time lag. Moreover, our
method automatically learns the temporal span of the filter. For the particular
application in neuroscience, we designed priors for stimulus and history
filters useful for the spike trains. We compare and validate our method on
simulated and real neural spike train data.",195,11,1340,26.3
740,neuroscience,"Computational models lie at the intersection of basic neuroscience and
healthcare applications because they allow researchers to test hypotheses
\textit{in silico} and predict the outcome of experiments and interactions that
are very hard to test in reality. Yet, what is meant by ""computational model""
is understood in many different ways by researchers in different fields of
neuroscience and psychology, hindering communication and collaboration. In this
review, we point out the state of the art of computational modeling in
Electroencephalography (EEG) and outline how these models can be used to
integrate findings from electrophysiology, network-level models, and behavior.
On the one hand, computational models serve to investigate the mechanisms that
generate brain activity, for example measured with EEG, such as the transient
emergence of oscillations at different frequency bands and/or with different
spatial topographies. On the other hand, computational models serve to design
experiments and test hypotheses \emph{in silico}. The final purpose of
computational models of EEG is to obtain a comprehensive understanding of the
mechanisms that underlie the EEG signal. This is crucial for an accurate
interpretation of EEG measurements that may ultimately serve in the development
of novel clinical applications.",191,8,1326,18.39
741,neuroscience,"The application of graph theory to model the complex structure and function
of the brain has shed new light on its organization and function, prompting the
emergence of network neuroscience. Despite the tremendous progress that has
been achieved in this field, still relatively few methods exploit the topology
of brain networks to analyze brain activity. Recent attempts in this direction
have leveraged on graph spectral analysis and graph signal processing to
decompose brain activity in connectivity eigenmodes or gradients. If results
are promising in terms of interpretability and functional relevance,
methodologies and terminology are sometimes confusing. The goals of this paper
are twofold. First, we summarize recent contributions related to connectivity
gradients and graph signal processing, and attempt a clarification of the
terminology and methods used in the field, while pointing out current
methodological limitations. Second, we discuss the perspective that the
functional relevance of connectivity gradients could be fruitfully exploited by
considering them as graph Fourier bases of brain activity.",161,8,1120,22.75
742,neuroscience,"Over the past decades, research in cognitive and affective neuroscience has
emphasized that emotion is crucial for human intelligence and in fact
inseparable from cognition. Concurrently, there has been growing interest in
simulating and modeling emotion-related processes in robots and artificial
agents. In this opinion paper, our goal is to provide a snapshot of the present
landscape in emotion modeling and to show how neuroscience can help advance the
current state of the art. We start with an overview of the existing literature
on emotion modeling in three areas of research: affective computing, social
robotics, and neurorobotics. Briefly summarizing the current state of knowledge
on natural emotion, we then highlight how existing proposals in artificial
emotion do not make sufficient contact with neuroscientific evidence. We
conclude by providing a set of principles to help guide future research in
artificial emotion and intelligent machines more generally. Overall, we argue
that a stronger integration of emotion-related processes in robot models is
critical for the design of human-like behavior in future intelligent machines.
Such integration not only will contribute to the development of autonomous
social machines capable of tackling real-world problems but would contribute to
advancing understanding of human emotion.",197,9,1345,21.13
743,neuroscience,"The perceptual experience of architecture is enacted by the sensory and motor
system. When we act, we change the perceived environment according to a set of
expectations that depend on our body and the built environment. The continuous
process of collecting sensory information is thus based on bodily affordances.
Affordances characterize the fit between the physical structure of the body and
capacities for movement in the built environment. Since little has been done
regarding the role of architectural design in the emergence of perceptual
experience on a neuronal level, this paper offers a first step towards the role
of architectural design in perceptual experience. An approach to synthesize
concepts from computational neuroscience with architectural phenomenology into
a computational neurophenomenology is considered. The outcome is a framework
under which studies of architecture and cognitive neuroscience can be cast.",137,8,933,26.2
744,neuroscience,"The principle of self-organization has acquired a fundamental significance in
the newly emerging field of computational philosophy. Self-organizing systems
have been described in various domains in science and philosophy including
physics, neuroscience, biology and medicine, ecology, and sociology. While
system architecture and their general purpose may depend on domain specific
concepts and definitions, there are at least seven key properties of
self-organization clearly identified in brain systems: modular connectivity,
unsupervised learning, adaptive ability, functional resiliency, functional
plasticity, from-local-to-global functional organization and dynamic system
growth. These are defined here in the light of insight from neurobiology,
cognitive neuroscience and Adaptive Resonance Theory (ART), and physics to show
that self-organization achieves stability and functional plasticity while
minimizing structural system complexity. A specific example informed by
empirical research is discussed to illustrate how modularity, adaptive
learning, and dynamic network growth enable stable yet plastic somatosensory
representation for human grip force control. Implications for the design of
strong artificial intelligence in robotics are brought forward.",161,7,1266,-6.5
745,neuroscience,"We are entering an age of `big' computational neuroscience, in which neural
network models are increasing in size and in numbers of underlying data sets.
Consolidating the zoo of models into large-scale models simultaneously
consistent with a wide range of data is only possible through the effort of
large teams, which can be spread across multiple research institutions. To
ensure that computational neuroscientists can build on each other's work, it is
important to make models publicly available as well-documented code. This
chapter describes such an open-source model, which relates the connectivity
structure of all vision-related cortical areas of the macaque monkey with their
resting-state dynamics. We give a brief overview of how to use the executable
model specification, which employs NEST as simulation engine, and show its
runtime scaling. The solutions found serve as an example for organizing the
workflow of future models from the raw experimental data to the visualization
of the results, expose the challenges, and give guidance for the construction
of ICT infrastructure for neuroscience.",168,7,1110,26.14
746,neuroscience,"Our ability to generalize beyond training data to novel, out-of-distribution,
image degradations is a hallmark of primate vision. The predictive brain,
exemplified by predictive coding networks (PCNs), has become a prominent
neuroscience theory of neural computation. Motivated by the recent successes of
variational autoencoders (VAEs) in machine learning, we rigorously derive a
correspondence between PCNs and VAEs. This motivates us to consider iterative
extensions of VAEs (iVAEs) as plausible variational extensions of the PCNs. We
further demonstrate that iVAEs generalize to distributional shifts
significantly better than both PCNs and VAEs. In addition, we propose a novel
measure of recognizability for individual samples which can be tested against
human psychophysical data. Overall, we hope this work will spur interest in
iVAEs as a promising new direction for modeling in neuroscience.",129,8,901,18.96
747,neuroscience,"Interdisciplinary research among engineering, computer science, and
neuroscience to understand and utilize the human brain signals resulted in
advances and widespread applicability of wearable neurotechnology in adaptive
human-in-the-loop smart systems. Considering these advances, we envision that
future education will exploit the advances in wearable neurotechnology and move
toward more personalized smart classrooms where instructions and interactions
are tailored towards. students' individual strengths and needs. In this paper,
we discuss the future of smart classrooms and how advances in neuroscience,
machine learning, and embedded systems as key enablers will provide the
infrastructure for envisioned smart classrooms and personalized education along
with open challenges that are required to be addressed.",108,5,819,18.69
748,neuroscience,"To characterize a physical system to behave as desired, either its underlying
governing rules must be known a priori or the system itself be accurately
measured. The complexity of full measurements of the system scales with its
size. When exposed to real-world conditions, such as perturbations or
time-varying settings, the system calibrated for a fixed working condition
might require non-trivial re-calibration, a process that could be prohibitively
expensive, inefficient and impractical for real-world use cases. In this work,
we propose a learning procedure to obtain a desired target output from a
physical system. We use Variational Auto-Encoders (VAE) to provide a generative
model of the system function and use this model to obtain the required input of
the system that produces the target output. We showcase the applicability of
our method for two datasets in optical physics and neuroscience.",139,7,906,31.01
749,neuroscience,"Optimal control of bilinear systems has been a well-studied subject in the
areas of mathematical and computational optimal control. However, effective
methods for solving emerging optimal control problems involving an ensemble of
deterministic or stochastic bilinear systems are underdeveloped. These
burgeoning problems arise in diverse applications from quantum control and
molecular imaging to neuroscience. In this work, we develop an iterative method
to find optimal controls for an inhomogeneous bilinear ensemble system with
free-endpoint conditions. The central idea is to represent the bilinear
ensemble system at each iteration as a time-varying linear ensemble system, and
then solve it in an iterative manner. We analyze convergence of the iterative
procedure and discuss optimality of the convergent solutions. The method is
directly applicable to solve the same class of optimal control problems
involving a stochastic bilinear ensemble system driven by independent additive
noise processes. We demonstrate the robustness and applicability of the
developed iterative method through practical control designs in neuroscience
and quantum control.",162,9,1158,17.03
750,neuroscience,"Modelling non-homogeneous and multi-component data is a problem that
challenges scientific researchers in several fields. In general, it is not
possible to find a simple and closed form probabilistic model to describe such
data. That is why one often resorts to non-parametric approaches. However, when
the multiple components are separable, parametric modelling becomes again
tractable. In this study, we propose a self-calibrating method to model
multi-component data that exhibit heavy tails. We introduce a three-component
hybrid distribution: a Gaussian distribution is linked to a Generalized Pareto
one via an exponential distribution that bridges the gap between mean and tail
behaviors. An unsupervised algorithm is then developed for estimating the
parameters of this model. We study analytically and numerically its
convergence. The effectiveness of the self-calibrating method is tested on
simulated data, before applying it to real data from neuroscience and finance,
respectively. A comparison with other standard Extreme Value Theory approaches
confirms the relevance and the practical advantage of this new method.",162,11,1130,21.19
751,neuroscience,"Neuroengineering is faced with unique challenges in repairing or replacing
complex neural systems that are composed of many interacting parts. These
interactions form intricate patterns over large spatiotemporal scales, and
produce emergent behaviors that are difficult to predict from individual
elements. Network science provides a particularly appropriate framework in
which to study and intervene in such systems, by treating neural elements
(cells, volumes) as nodes in a graph and neural interactions (synapses, white
matter tracts) as edges in that graph. Here, we review the emerging discipline
of network neuroscience, which uses and develops tools from graph theory to
better understand and manipulate neural systems, from micro- to macroscales. We
present examples of how human brain imaging data is being modeled with network
analysis and underscore potential pitfalls. We then highlight current
computational and theoretical frontiers, and emphasize their utility in
informing diagnosis and monitoring, brain-machine interfaces, and brain
stimulation. A flexible and rapidly evolving enterprise, network neuroscience
provides a set of powerful approaches and fundamental insights critical to the
neuroengineer's toolkit.",171,8,1233,21.33
752,neuroscience,"Developing whole-brain emulation (WBE) technology would provide immense
benefits across neuroscience, biomedicine, artificial intelligence, and
robotics. At this time, constructing a simulated human brain lacks feasibility
due to limited experimental data and limited computational resources. However,
I suggest that progress towards this goal might be accelerated by working
towards an intermediate objective, namely insect brain emulation (IBE). More
specifically, this would entail creating biologically realistic simulations of
entire insect nervous systems along with more approximate simulations of
non-neuronal insect physiology to make ""virtual insects."" I argue that this
could be realistically achievable within the next 20 years. I propose that
developing emulations of insect brains will galvanize the global community of
scientists, businesspeople, and policymakers towards pursuing the loftier goal
of emulating the human brain. By demonstrating that WBE is possible via IBE,
simulating mammalian brains and eventually the human brain may no longer be
viewed as too radically ambitious to deserve substantial funding and resources.
Furthermore, IBE will facilitate dramatic advances in cognitive neuroscience,
artificial intelligence, and robotics through studies performed using virtual
insects.",175,9,1310,6.95
753,neuroscience,"Although lagging behind classical computational neuroscience, theoretical and
computational approaches are beginning to emerge to characterize different
aspects of neuron-glial interactions. This chapter aims to provide essential
knowledge on neuron-glial interactions in the mammalian brain, leveraging on
computational studies that focus on structure (anatomy) and function
(physiology) of such interactions in the healthy brain. Although our
understanding of the need of neuron-glial interactions in the brain is still at
its infancy, being mostly based on predictions that await for experimental
validation, simple general modeling arguments borrowed from control theory are
introduced to support the importance of including such interactions in
traditional neuron-based modeling paradigms.",104,4,794,-6.06
754,neuroscience,"Convolutional neural networks (CNNs) were inspired by early findings in the
study of biological vision. They have since become successful tools in computer
vision and state-of-the-art models of both neural activity and behavior on
visual tasks. This review highlights what, in the context of CNNs, it means to
be a good model in computational neuroscience and the various ways models can
provide insight. Specifically, it covers the origins of CNNs and the methods by
which we validate them as models of biological vision. It then goes on to
elaborate on what we can learn about biological vision by understanding and
experimenting on CNNs and discusses emerging opportunities for the use of CNNS
in vision research beyond basic object recognition.",119,6,748,38.86
755,neuroscience,"Within computational neuroscience, informal interactions with modelers often
reveal wildly divergent goals. In this opinion piece, we explicitly address the
diversity of goals that motivate and ultimately influence modeling efforts. We
argue that a wide range of goals can be meaningfully taken to be of highest
importance. A simple informal survey conducted on the Internet confirmed the
diversity of goals in the community. However, different priorities or
preferences of individual researchers can lead to divergent model evaluation
criteria. We propose that many disagreements in evaluating the merit of
computational research stem from differences in goals and not from the
mechanics of constructing, describing, and validating models. We suggest that
authors state explicitly their goals when proposing models so that others can
judge the quality of the research with respect to its stated goals.",133,8,902,26.81
756,neuroscience,"Reaching a global view of brain organization requires assembling evidence on
widely different mental processes and mechanisms. The variety of human
neuroscience concepts and terminology poses a fundamental challenge to relating
brain imaging results across the scientific literature. Existing meta-analysis
methods perform statistical tests on sets of publications associated with a
particular concept. Thus, large-scale meta-analyses only tackle single terms
that occur frequently. We propose a new paradigm, focusing on prediction rather
than inference. Our multivariate model predicts the spatial distribution of
neurological observations, given text describing an experiment, cognitive
process, or disease. This approach handles text of arbitrary length and terms
that are too rare for standard meta-analysis. We capture the relationships and
neural correlates of 7 547 neuroscience terms across 13 459 neuroimaging
publications. The resulting meta-analytic tool, neuroquery.org, can ground
hypothesis generation and data-analysis priors on a comprehensive view of
published findings on the brain.",148,11,1101,22.61
757,neuroscience,"The principle of stationary action is a cornerstone of modern physics,
providing a powerful framework for investigating dynamical systems found in
classical mechanics through to quantum field theory. However, computational
neuroscience, despite its heavy reliance on concepts in physics, is anomalous
in this regard as its main equations of motion are not compatible with a
Lagrangian formulation and hence with the principle of stationary action.
Taking the Dynamic Causal Modelling neuronal state equation, Hodgkin-Huxley
model, and the Leaky Integrate-and-Fire model as examples, we show that it is
possible to write complex oscillatory forms of these equations in terms of a
single Lagrangian. We therefore bring mathematical descriptions in
computational neuroscience under the remit of the principle of stationary
action and use this reformulation to express symmetries and associated
conservation laws arising in neural systems.",134,5,935,12.09
758,neuroscience,"Software containers greatly facilitate the deployment and reproducibility of
scientific data analyses in various platforms. However, container images often
contain outdated or unnecessary software packages, which increases the number
of security vulnerabilities in the images, widens the attack surface in the
container host, and creates substantial security risks for computing
infrastructures at large. This paper presents a vulnerability analysis of
container images for scientific data analysis. We compare results obtained with
four vulnerability scanners, focusing on the use case of neuroscience data
analysis, and quantifying the effect of image update and minification on the
number of vulnerabilities. We find that container images used for neuroscience
data analysis contain hundreds of vulnerabilities, that software updates remove
about two thirds of these vulnerabilities, and that removing unused packages is
also effective. We conclude with recommendations on how to build container
images with a reduced amount of vulnerabilities.",145,7,1047,4.61
759,neuroscience,"This article is a public deliverable of the EU project ""Memory technologies
with multi-scale time constants for neuromorphic architectures"" (MeMScales,
https://memscales.eu, Call ICT-06-2019 Unconventional Nanoelectronics, project
number 871371). This arXiv version is a verbatim copy of the deliverable
report, with administrative information stripped. It collects a wide and varied
assortment of phenomena, models, research themes and algorithmic techniques
that are connected with timescale phenomena in the fields of computational
neuroscience, mathematics, machine learning and computer science, with a bias
toward aspects that are relevant for neuromorphic engineering. It turns out
that this theme is very rich indeed and spreads out in many directions which
defy a unified treatment. We collected several dozens of sub-themes, each of
which has been investigated in specialized settings (in the neurosciences,
mathematics, computer science and machine learning) and has been documented in
its own body of literature. The more we dived into this diversity, the more it
became clear that our first effort to compose a survey must remain sketchy and
partial. We conclude with a list of insights distilled from this survey which
give general guidelines for the design of future neuromorphic systems.",189,9,1303,30.6
760,neuroscience,"In recent years, trends towards studying simulated games have gained momentum
in the fields of artificial intelligence, cognitive science, psychology, and
neuroscience. The intersections of these fields have also grown recently, as
researchers increasing study such games using both artificial agents and human
or animal subjects. However, implementing games can be a time-consuming
endeavor and may require a researcher to grapple with complex codebases that
are not easily customized. Furthermore, interdisciplinary researchers studying
some combination of artificial intelligence, human psychology, and animal
neurophysiology face additional challenges, because existing platforms are
designed for only one of these domains. Here we introduce Modular
Object-Oriented Games, a Python task framework that is lightweight, flexible,
customizable, and designed for use by machine learning, psychology, and
neurophysiology researchers.",123,6,932,4.21
761,neuroscience,"In neuroscience, researchers seek to uncover the connectivity of neurons from
large-scale neural recordings or imaging; often people employ graphical model
selection and estimation techniques for this purpose. But, existing
technologies can only record from a small subset of neurons leading to a
challenging problem of graph selection in the presence of extensive latent
variables. Chandrasekaran et al. (2012) proposed a convex program to address
this problem that poses challenges from both a computational and statistical
perspective. To solve this problem, we propose an incredibly simple solution:
apply a hard thresholding operator to existing graph selection methods.
Conceptually simple and computationally attractive, we demonstrate that
thresholding the graphical Lasso, neighborhood selection, or CLIME estimators
have superior theoretical properties in terms of graph selection consistency as
well as stronger empirical results than existing approaches for the latent
variable graphical model problem. We also demonstrate the applicability of our
approach through a neuroscience case study on calcium-imaging data to estimate
functional neural connections.",161,8,1169,14.29
762,neuroscience,"Active inference is a state-of-the-art framework in neuroscience that offers
a unified theory of brain function. It is also proposed as a framework for
planning in AI. Unfortunately, the complex mathematics required to create new
models -- can impede application of active inference in neuroscience and AI
research. This paper addresses this problem by providing a complete
mathematical treatment of the active inference framework -- in discrete time
and state spaces -- and the derivation of the update equations for any new
model. We leverage the theoretical connection between active inference and
variational message passing as describe by John Winn and Christopher M. Bishop
in 2005. Since, variational message passing is a well-defined methodology for
deriving Bayesian belief update equations, this paper opens the door to
advanced generative models for active inference. We show that using a fully
factorized variational distribution simplifies the expected free energy -- that
furnishes priors over policies -- so that agents seek unambiguous states.
Finally, we consider future extensions that support deep tree searches for
sequential policy optimisation -- based upon structure learning and belief
propagation.",181,10,1222,26.4
763,neuroscience,"Unlike robots, humans learn, adapt and perceive their bodies by interacting
with the world. Discovering how the brain represents the body and generates
actions is of major importance for robotics and artificial intelligence. Here
we discuss how neuroscience findings open up opportunities to improve current
estimation and control algorithms in robotics. In particular, how active
inference, a mathematical formulation of how the brain resists a natural
tendency to disorder, provides a unified recipe to potentially solve some of
the major challenges in robotics, such as adaptation, robustness, flexibility,
generalization and safe interaction. This paper summarizes some experiments and
lessons learned from developing such a computational model on real embodied
platforms, i.e., humanoid and industrial robots. Finally, we showcase the
limitations and challenges that we are still facing to give robots human-like
perception",132,8,928,26.91
764,neuroscience,"We study the problem of sparse nonlinear model recovery of high dimensional
compositional functions. Our study is motivated by emerging opportunities in
neuroscience to recover fine-grained models of biological neural circuits using
collected measurement data. Guided by available domain knowledge in
neuroscience, we explore conditions under which one can recover the underlying
biological circuit that generated the training data. Our results suggest
insights of both theoretical and practical interests. Most notably, we find
that a sign constraint on the weights is a necessary condition for system
recovery, which we establish both theoretically with an identifiability
guarantee and empirically on simulated biological circuits. We conclude with a
case study on retinal ganglion cell circuits using data collected from mouse
retina, showcasing the practical potential of this approach.",126,7,891,16.32
765,neuroscience,"Recurrent neural networks (RNNs) are widely used throughout neuroscience as
models of local neural activity. Many properties of single RNNs are well
characterized theoretically, but experimental neuroscience has moved in the
direction of studying multiple interacting areas, and RNN theory needs to be
likewise extended. We take a constructive approach towards this problem,
leveraging tools from nonlinear control theory and machine learning to
characterize when combinations of stable RNNs will themselves be stable.
Importantly, we derive conditions which allow for massive feedback connections
between interacting RNNs. We parameterize these conditions for easy
optimization using gradient-based techniques, and show that
stability-constrained ""networks of networks"" can perform well on challenging
sequential-processing benchmark tasks. Altogether, our results provide a
principled approach towards understanding distributed, modular function in the
brain.",126,7,961,16.32
766,neuroscience,"Fitting network models to neural activity is an important tool in
neuroscience. A popular approach is to model a brain area with a probabilistic
recurrent spiking network whose parameters maximize the likelihood of the
recorded activity. Although this is widely used, we show that the resulting
model does not produce realistic neural activity. To correct for this, we
suggest to augment the log-likelihood with terms that measure the dissimilarity
between simulated and recorded activity. This dissimilarity is defined via
summary statistics commonly used in neuroscience and the optimization is
efficient because it relies on back-propagation through the stochastically
simulated spike trains. We analyze this method theoretically and show
empirically that it generates more realistic activity statistics. We find that
it improves upon other fitting algorithms for spiking network models like GLMs
(Generalized Linear Models) which do not usually rely on back-propagation. This
new fitting algorithm also enables the consideration of hidden neurons which is
otherwise notoriously hard, and we show that it can be crucial when trying to
infer the network connectivity from spike recordings.",175,9,1191,23.87
767,neuroscience,"Computational Medical Extended Reality (CMXR), brings together life sciences
and neuroscience with mathematics, engineering and computer science. It unifies
computational science (scientific computing) with intelligent extended reality
and spatial computing for the medical field. It significantly differs from
previous ""Clinical XR"" or ""Medical XR"" terms, as it is focusing on how to
integrate computational methods from neural simulation to computational
geometry, computational vision and computer graphics with deep learning models
to solve specific hard problems in medicine and neuroscience: from
low/no-code/genAI authoring platforms to deep learning XR systems for training,
planning, operative navigation, therapy and rehabilitation.",96,4,742,-11.77
768,neuroscience,"Scientific datasets and analysis pipelines are increasingly being shared
publicly in the interest of open science. However, mechanisms are lacking to
reliably identify which pipelines and datasets can appropriately be used
together. Given the increasing number of high-quality public datasets and
pipelines, this lack of clear compatibility threatens the findability and
reusability of these resources. We investigate the feasibility of a
collaborative filtering system to recommend pipelines and datasets based on
provenance records from previous executions. We evaluate our system using
datasets and pipelines extracted from the Canadian Open Neuroscience Platform,
a national initiative for open neuroscience. The recommendations provided by
our system (AUC$=0.83$) are significantly better than chance and outperform
recommendations made by domain experts using their previous knowledge as well
as pipeline and dataset descriptions (AUC$=0.63$). In particular, domain
experts often neglect low-level technical aspects of a pipeline-dataset
interaction, such as the level of pre-processing, which are captured by a
provenance-based system. We conclude that provenance-based pipeline and dataset
recommenders are feasible and beneficial to the sharing and usage of
open-science resources. Future work will focus on the collection of more
comprehensive provenance traces, and on deploying the system in production.",193,12,1415,26.51
769,neuroscience,"When making decisions under risk, people often exhibit behaviors that
classical economic theories cannot explain. Newer models that attempt to
account for these irrational behaviors often lack neuroscience bases and
require the introduction of subjective and problem-specific constructs. Here,
we present a decision-making model inspired by the prediction error signals and
introspective neuronal replay reported in the brain. In the model, decisions
are chosen based on anticipated surprise, defined by a nonlinear average of the
differences between individual outcomes and a reference point. The reference
point is determined by the expected value of the possible outcomes, which can
dynamically change during the mental simulation of decision-making problems
involving sequential stages. Our model elucidates the contribution of each
stage to the appeal of available options in a decision-making problem. This
allows us to explain several economic paradoxes and gambling behaviors. Our
work could help bridge the gap between decision-making theories in economics
and neurosciences.",153,9,1084,26.71
770,neuroscience,"Learning to act in an environment to maximise rewards is among the brain's
key functions. This process has often been conceptualised within the framework
of reinforcement learning, which has also gained prominence in machine learning
and artificial intelligence (AI) as a way to optimise decision-making. A common
aspect of both biological and machine reinforcement learning is the
reactivation of previously experienced episodes, referred to as replay. Replay
is important for memory consolidation in biological neural networks, and is key
to stabilising learning in deep neural networks. Here, we review recent
developments concerning the functional roles of replay in the fields of
neuroscience and AI. Complementary progress suggests how replay might support
learning processes, including generalisation and continual learning, affording
opportunities to transfer knowledge across the two fields to advance the
understanding of biological and artificial learning and memory.",138,7,978,22.75
771,neuroscience,"Most neuroimaging experiments are under-powered, limited by the number of
subjects and cognitive processes that an individual study can investigate.
Nonetheless, over decades of research, neuroscience has accumulated an
extensive wealth of results. It remains a challenge to digest this growing
knowledge base and obtain new insights since existing meta-analytic tools are
limited to keyword queries. In this work, we propose Text2Brain, a neural
network approach for coordinate-based meta-analysis of neuroimaging studies to
synthesize brain activation maps from open-ended text queries. Combining a
transformer-based text encoder and a 3D image generator, Text2Brain was trained
on variable-length text snippets and their corresponding activation maps
sampled from 13,000 published neuroimaging studies. We demonstrate that
Text2Brain can synthesize anatomically-plausible neural activation patterns
from free-form textual descriptions of cognitive concepts. Text2Brain is
available at https://braininterpreter.com as a web-based tool for retrieving
established priors and generating new hypotheses for neuroscience research.",146,9,1127,19.06
772,neuroscience,"If we are ever to move beyond the study of isolated special cases in
theoretical neuroscience, we need to develop more general theories of neural
circuits over a given neural model. The present paper considers this challenge
in the context of continuous-time recurrent neural networks (CTRNNs), a simple
but dynamically-universal model that has been widely utilized in both
computational neuroscience and neural networks. Here we extend previous work on
the parameter space structure of codimension-1 local bifurcations in CTRNNs to
include codimension-2 local bifurcation manifolds. Specifically, we derive the
necessary conditions for all generic local codimension-2 bifurcations for
general CTRNNs, specialize these conditions to circuits containing from one to
four neurons, illustrate in full detail the application of these conditions to
example circuits, derive closed-form expressions for these bifurcation
manifolds where possible, and demonstrate how this analysis allows us to find
and trace several global codimension-1 bifurcation manifolds that originate
from the codimension-2 bifurcations.",154,5,1105,7.02
773,neuroscience,"Attention is a state of arousal capable of dealing with limited processing
bottlenecks in human beings by focusing selectively on one piece of information
while ignoring other perceptible information. For decades, concepts and
functions of attention have been studied in philosophy, psychology,
neuroscience, and computing. Currently, this property has been widely explored
in deep neural networks. Many different neural attention models are now
available and have been a very active research area over the past six years.
From the theoretical standpoint of attention, this survey provides a critical
analysis of major neural attention models. Here we propose a taxonomy that
corroborates with theoretical aspects that predate Deep Learning. Our taxonomy
provides an organizational structure that asks new questions and structures the
understanding of existing attentional mechanisms. In particular, 17 criteria
derived from psychology and neuroscience classic studies are formulated for
qualitative comparison and critical analysis on the 51 main models found on a
set of more than 650 papers analyzed. Also, we highlight several theoretical
issues that have not yet been explored, including discussions about biological
plausibility, highlight current research trends, and provide insights for the
future.",187,10,1307,24.98
774,neuroscience,"Neuromorphic computing is poised to further the success of software-based
neural networks by utilizing improved customized hardware. However, the
translation of neuromorphic algorithms to hardware specifications is a problem
that has been seldom explored. Building superconducting neuromorphic systems
requires extensive expertise in both superconducting physics and theoretical
neuroscience. In this work, we aim to bridge this gap by presenting a tool and
methodology to translate algorithmic parameters into circuit specifications. We
first show the correspondence between theoretical neuroscience models and the
dynamics of our circuit topologies. We then apply this tool to solve linear
systems by implementing a spiking neural network with our superconducting
nanowire-based hardware.",106,7,790,19.67
775,neuroscience,"The principled design and discovery of biologically- and physically-informed
models of neuronal dynamics has been advancing since the mid-twentieth century.
Recent developments in artificial intelligence (AI) have accelerated this
progress. This review article gives a high-level overview of the approaches
across different scales of organization and levels of abstraction. The studies
covered in this paper include fundamental models in computational neuroscience,
nonlinear dynamics, data-driven methods, as well as emergent practices. While
not all of these models span the intersection of neuroscience, AI, and system
dynamics, all of them do or can work in tandem as generative models, which, as
we argue, provide superior properties for the analysis of neuroscientific data.
We discuss the limitations and unique dynamical traits of brain data and the
complementary need for hypothesis- and data-driven modeling. By way of
conclusion, we present several hybrid generative models from recent literature
in scientific machine learning, which can be efficiently deployed to yield
interpretable models of neural dynamics.",159,8,1123,14.59
776,neuroscience,"Neural mechanisms of touch are typically studied in laboratory settings using
robotic or other types of well-controlled devices. Such stimuli are very
different from highly complex naturalistic human-to-human touch interactions.
The lack of scientifically useful naturalistic stimuli hampers progress,
particularly in social touch research. Vision science, on the other hand, has
benefitted from inventions such as virtual reality systems that have provided
researchers with precision control of naturalistic stimuli. In the field of
touch research, producing and manipulating stimuli is particularly challenging
due to the complexity of skin mechanics. Here we review the history of touch
neuroscience focusing on the contrast between strictly controlled and
naturalistic stimuli and compare with vision science. We discuss new methods
that may overcome the obstacles with precision-controlled tactile stimuli, and
recent successes in naturalistic texture production. In social touch research,
precise tracking and measurement of naturalistic human-to-human touch
interactions offers exciting new possibilities.",149,9,1112,10.3
777,neuroscience,"The study of the brain's representations of uncertainty is a central topic in
neuroscience. Unlike most quantities of which the neural representation is
studied, uncertainty is a property of an observer's beliefs about the world,
which poses specific methodological challenges. We analyze how the literature
on the neural representations of uncertainty addresses those challenges and
distinguish between ""code-driven"" and ""correlational"" approaches. Code-driven
approaches make assumptions about the neural code for representing world states
and the associated uncertainty. By contrast, correlational approaches search
for relationships between uncertainty and neural activity without constraints
on the neural representation of the world state that this uncertainty
accompanies. To compare these two approaches, we apply several criteria for
neural representations: sensitivity, specificity, invariance, functionality.
Our analysis reveals that the two approaches lead to different, but
complementary findings, shaping new research questions and guiding future
experiments.",140,8,1074,8.88
778,neuroscience,"Unsupervised learning plays an important role in many fields, such as
artificial intelligence, machine learning, and neuroscience. Compared to static
data, methods for extracting low-dimensional structure for dynamic data are
lagging. We developed a novel information-theoretic framework, Compressed
Predictive Information Coding (CPIC), to extract useful representations from
dynamic data. CPIC selectively projects the past (input) into a linear subspace
that is predictive about the compressed data projected from the future
(output). The key insight of our framework is to learn representations by
minimizing the compression complexity and maximizing the predictive information
in latent space. We derive variational bounds of the CPIC loss which induces
the latent space to capture information that is maximally predictive. Our
variational bounds are tractable by leveraging bounds of mutual information. We
find that introducing stochasticity in the encoder robustly contributes to
better representation. Furthermore, variational approaches perform better in
mutual information estimation compared with estimates under a Gaussian
assumption. We demonstrate that CPIC is able to recover the latent space of
noisy dynamical systems with low signal-to-noise ratios, and extracts features
predictive of exogenous variables in neuroscience data.",183,11,1346,19.06
779,neuroscience,"To take advantage of recent and ongoing advances in large-scale computational
methods, and to preserve the scientific data created by publicly funded
research projects, data archives must be created as well as standards for
specifying, identifying, and annotating deposited data. The OpenNeuro.org
archive, begun as a repository for magnetic resonance imaging (MRI) data, is
such an archive. We present a gateway to OpenNeuro for human electrophysiology
data (BIDS-formatted EEG and MEG, as well as intracranial data). The NEMAR
gateway allows users to visualize electrophysiological data, including
time-domain and frequency-domain dynamics time locked to sets of experimental
events recorded using BIDS- and HED-formatted data annotation. In addition,
NEMAR allows users to process archived EEG data on the XSEDE high-performance
resources at SDSC in conjunction with the Neuroscience Gateway (nsgportal.org),
a freely available and easy to use portal to leverage high-performance
computing resources for neuroscience research.",144,8,1029,21.74
780,neuroscience,"Representation is a key notion in neuroscience and artificial intelligence
(AI). However, a longstanding philosophical debate highlights that specifying
what counts as representation is trickier than it seems. With this brief
opinion paper we would like to bring the philosophical problem of
representation into attention and provide an implementable solution. We note
that causal and teleological approaches often assumed by neuroscientists and
engineers fail to provide a satisfactory account of representation. We sketch
an alternative according to which representations correspond to inferred latent
structures in the world, identified on the basis of conditional patterns of
activation. These structures are assumed to have certain properties
objectively, which allows for planning, prediction, and detection of unexpected
events. We illustrate our proposal with the simulation of a simple neural
network model. We believe this stronger notion of representation could inform
future research in neuroscience and AI.",143,9,1019,19.47
781,neuroscience,"Neural codes appear efficient. Naturally, neuroscientists contend that an
efficient process is responsible for generating efficient codes. They argue
that natural selection is the efficient process that generates those codes.
Although natural selection is an adaptive process, evolution itself, is not.
Evolution consists of not only natural selection, but also neutral stochastic
forces that can generate biological inefficiencies. The explanatory power of
natural selection cannot be appealed to, without regards for the remaining
evolutionary forces. In this paper, we aim to reformulate the explanatory role
of evolutionary forces on neural coding, with special attention to neutral
forces. We propose a framework that argues for differing contributions of
adaptive and stochastic evolutionary forces, for different phenotypic `levels',
including those of neural codes. We assert that this framework is of special
interest to neuroscience, because the field has derived much progress from an
efficiency-based worldview. We advocate for a pluralistic neuroscience capable
of appealing to both adaptive and non-adaptive explanations.",158,11,1135,30.06
782,neuroscience,"Machine Learning with Deep Neural Networks (DNNs) has become a successful
tool in solving tasks across various fields of application. However, the
complexity of DNNs makes it difficult to understand how they solve their
learned task. To improve the explainability of DNNs, we adapt methods from
neuroscience that analyze complex and opaque systems. Here, we draw inspiration
from how neuroscience uses topographic maps to visualize brain activity. To
also visualize activations of neurons in DNNs as topographic maps, we research
techniques to layout the neurons in a two-dimensional space such that neurons
of similar activity are in the vicinity of each other. In this work, we
introduce and compare methods to obtain a topographic layout of neurons in a
DNN layer. Moreover, we demonstrate how to use topographic activation maps to
identify errors or encoded biases and to visualize training processes. Our
novel visualization technique improves the transparency of DNN-based
decision-making systems and is interpretable without expert knowledge in
Machine Learning.",161,9,1069,34.15
783,neuroscience,"Neuronal network computation and computation by avalanche supporting networks
are of interest to the fields of physics, computer science (computation theory
as well as statistical or machine learning) and neuroscience. Here we show that
computation of complex Boolean functions arises spontaneously in threshold
networks as a function of connectivity and antagonism (inhibition), computed by
logic automata (motifs) in the form of computational cascades. We explain the
emergent inverse relationship between the computational complexity of the
motifs and their rank-ordering by function probabilities due to motifs, and its
relationship to symmetry in function space. We also show that the optimal
fraction of inhibition observed here supports results in computational
neuroscience, relating to optimal information processing.",114,5,826,8.71
784,neuroscience,"Neuronal networks in dissociated culture combined with cell engineering
technology offer a pivotal platform to constructively explore the relationship
between structure and function in living neuronal networks. Here, we fabricated
defined neuronal networks possessing a modular architecture on high-density
microelectrode arrays (HD-MEAs), a state-of-the-art electrophysiological tool
for recording neural activity with high spatial and temporal resolutions. We
first established a surface coating protocol using a cell-permissive hydrogel
to stably attach polydimethylsiloxane microfluidic film on the HD-MEA. We then
recorded the spontaneous neural activity of the engineered neuronal network,
which revealed an important portrait of the engineered neuronal
network--modular architecture enhances functional complexity by reducing the
excessive neural correlation between spatially segregated modules. The results
of this study highlight the impact of HD-MEA recordings combined with cell
engineering technologies as a novel tool in neuroscience to constructively
assess the structure-function relationships in neuronal networks.",143,6,1131,0.15
785,neuroscience,"Many questions in neuroscience involve understanding of the responses of
large populations of neurons. However, when dealing with large-scale neural
activity, interpretation becomes difficult, and comparisons between two
animals, or across different time points becomes challenging. One major
challenge that we face in modern neuroscience is that of correspondence, e.g.
we do not record the exact same neurons at the exact same times. Without some
way to link two or more datasets, comparing different collections of neural
activity patterns becomes impossible. Here, we describe approaches for
leveraging shared latent structure across neural recordings to tackle this
correspondence challenge. We review algorithms that map two datasets into a
shared space where they can be directly compared, and argue that alignment is
key for comparing high-dimensional neural activities across times, subsets of
neurons, and individuals.",133,9,928,35.27
786,neuroscience,"In this paper, we present an efficient deep learning based approach to
extract technology-related topics and keywords within scientific literature,
and identify corresponding technologies within patent applications.
Specifically, we utilize transformer based language models, tailored for use
with scientific text, to detect coherent topics over time and describe these by
relevant keywords that are automatically extracted from a large text corpus. We
identify these keywords using Named Entity Recognition, distinguishing between
those describing methods, applications and other scientific terminology. We
create a large amount of search queries based on combinations of method- and
application-keywords, which we use to conduct semantic search and identify
related patents. By doing so, we aim at contributing to the growing body of
research on text-based technology mapping and forecasting that leverages latest
advances in natural language processing and deep learning. We are able to map
technologies identified in scientific literature to patent applications,
thereby providing an empirical foundation for the study of science-technology
linkages. We illustrate the workflow as well as results obtained by mapping
publications within the field of neuroscience to related patent applications.",180,8,1298,20.01
787,neuroscience,"Bayesian hierarchical models are well-suited to analyzing the often noisy
data from electroencephalography experiments in cognitive neuroscience: these
models provide an intuitive framework to account for structures and
correlations in the data, and they allow a straightforward handling of
uncertainty. In a typical neurolinguistic experiment, event-related potentials
show only very small effect sizes and frequentist approaches to data analysis
fail to establish the significance of some of these effects. Here, we present a
Bayesian approach to analyzing event-related potentials using as an example
data from an experiment which relates word surprisal and neural response. Our
model is able to estimate the effect of word surprisal on most components of
the event-related potential and provides a richer description of the data. The
Bayesian framework also allows easier comparison between estimates based on
surprisal values calculated using different language models.",138,6,974,18.08
788,neuroscience,"Two-sample network hypothesis testing is an important inference task with
applications across diverse fields such as medicine, neuroscience, and
sociology. Many of these testing methodologies operate under the implicit
assumption that the vertex correspondence across networks is a priori known.
This assumption is often untrue, and the power of the subsequent test can
degrade when there are misaligned/label-shuffled vertices across networks. This
power loss due to shuffling is theoretically explored in the context of random
dot product and stochastic block model networks for a pair of hypothesis tests
based on Frobenius norm differences between estimated edge probability matrices
or between adjacency matrices. The loss in testing power is further reinforced
by numerous simulations and experiments, both in the stochastic block model and
in the random dot product graph model, where the power loss across multiple
recently proposed tests in the literature is considered. Lastly, the impact
that shuffling can have in real-data testing is demonstrated in a pair of
examples from neuroscience and from social network analysis.",167,7,1133,26.34
789,neuroscience,"In this paper, we investigate the Gaussian graphical model inference problem
in a novel setting that we call erose measurements, referring to irregularly
measured or observed data. For graphs, this results in different node pairs
having vastly different sample sizes which frequently arises in data
integration, genomics, neuroscience, and sensor networks. Existing works
characterize the graph selection performance using the minimum pairwise sample
size, which provides little insights for erosely measured data, and no existing
inference method is applicable. We aim to fill in this gap by proposing the
first inference method that characterizes the different uncertainty levels over
the graph caused by the erose measurements, named GI-JOE (Graph Inference when
Joint Observations are Erose). Specifically, we develop an edge-wise inference
method and an affiliated FDR control procedure, where the variance of each edge
depends on the sample sizes associated with corresponding neighbors. We prove
statistical validity under erose measurements, thanks to careful localized
edge-wise analysis and disentangling the dependencies across the graph.
Finally, through simulation studies and a real neuroscience data example, we
demonstrate the advantages of our inference methods for graph selection from
erosely measured data.",188,8,1326,18.79
790,neuroscience,"A large amount of recent research has the far-reaching goal of finding
training methods for deep neural networks that can serve as alternatives to
backpropagation (BP). A prominent example is predictive coding (PC), which is a
neuroscience-inspired method that performs inference on hierarchical Gaussian
generative models. These methods, however, fail to keep up with modern neural
networks, as they are unable to replicate the dynamics of complex layers and
activation functions. In this work, we solve this problem by generalizing PC to
arbitrary probability distributions, enabling the training of architectures,
such as transformers, that are hard to approximate with only Gaussian
assumptions. We perform three experimental analyses. First, we study the gap
between our method and the standard formulation of PC on multiple toy examples.
Second, we test the reconstruction quality on variational autoencoders, where
our method reaches the same reconstruction quality as BP. Third, we show that
our method allows us to train transformer networks and achieve a performance
comparable with BP on conditional language models. More broadly, this method
allows neuroscience-inspired learning to be applied to multiple domains, since
the internal distributions can be flexibly adapted to the data, tasks, and
architectures used.",195,10,1327,32.53
791,neuroscience,"Predictive coding networks are neuroscience-inspired models with roots in
both Bayesian statistics and neuroscience. Training such models, however, is
quite inefficient and unstable. In this work, we show how by simply changing
the temporal scheduling of the update rule for the synaptic weights leads to an
algorithm that is much more efficient and stable than the original one, and has
theoretical guarantees in terms of convergence. The proposed algorithm, that we
call incremental predictive coding (iPC) is also more biologically plausible
than the original one, as it it fully automatic. In an extensive set of
experiments, we show that iPC constantly performs better than the original
formulation on a large number of benchmarks for image classification, as well
as for the training of both conditional and masked language models, in terms of
test accuracy, efficiency, and convergence with respect to a large set of
hyperparameters.",145,6,940,25.12
792,neuroscience,"The brain is a nonlinear and highly Recurrent Neural Network (RNN). This RNN
is surprisingly plastic and supports our astonishing ability to learn and
execute complex tasks. However, learning is incredibly complicated due to the
brain's nonlinear nature and the obscurity of mechanisms for determining the
contribution of each synapse to the output error. This issue is known as the
Credit Assignment Problem (CAP) and is a fundamental challenge in neuroscience
and Artificial Intelligence (AI). Nevertheless, in the current understanding of
cognitive neuroscience, it is widely accepted that a feedback loop systems play
an essential role in synaptic plasticity. With this as inspiration, we propose
a computational model by combining Neural Networks (NN) and nonlinear optimal
control theory. The proposed framework involves a new NN-based actor-critic
method which is used to simulate the error feedback loop systems and
projections on the NN's synaptic plasticity so as to ensure that the output
error is minimized.",154,8,1019,32.22
793,neuroscience,"Attention mechanisms are a central property of cognitive systems allowing
them to selectively deploy cognitive resources in a flexible manner. Attention
has been long studied in the neurosciences and there are numerous
phenomenological models that try to capture its core properties. Recently
attentional mechanisms have become a dominating architectural choice of machine
learning and are the central innovation of Transformers. The dominant intuition
and formalism underlying their development has drawn on ideas of keys and
queries in database management systems. In this work, we propose an alternative
Bayesian foundation for attentional mechanisms and show how this unifies
different attentional architectures in machine learning. This formulation
allows to to identify commonality across different attention ML architectures
as well as suggest a bridge to those developed in neuroscience. We hope this
work will guide more sophisticated intuitions into the key properties of
attention architectures and suggest new ones.",146,8,1027,24.88
794,neuroscience,"Most models in cognitive and computational neuroscience trained on one
subject do not generalize to other subjects due to individual differences. An
ideal individual-to-individual neural converter is expected to generate real
neural signals of one subject from those of another one, which can overcome the
problem of individual differences for cognitive and computational models. In
this study, we propose a novel individual-to-individual EEG converter, called
EEG2EEG, inspired by generative models in computer vision. We applied THINGS
EEG2 dataset to train and test 72 independent EEG2EEG models corresponding to
72 pairs across 9 subjects. Our results demonstrate that EEG2EEG is able to
effectively learn the mapping of neural representations in EEG signals from one
subject to another and achieve high conversion performance. Additionally, the
generated EEG signals contain clearer representations of visual information
than that can be obtained from real data. This method establishes a novel and
state-of-the-art framework for neural conversion of EEG signals, which can
realize a flexible and high-performance mapping from individual to individual
and provide insight for both neural engineering and cognitive neuroscience.",176,8,1232,20.62
795,neuroscience,"Autoregressive models are ubiquitous tools for the analysis of time series in
many domains such as computational neuroscience and biomedical engineering. In
these domains, data is, for example, collected from measurements of brain
activity. Crucially, this data is subject to measurement errors as well as
uncertainties in the underlying system model. As a result, standard signal
processing using autoregressive model estimators may be biased. We present a
framework for autoregressive modelling that incorporates these uncertainties
explicitly via an overparameterised loss function. To optimise this loss, we
derive an algorithm that alternates between state and parameter estimation. Our
work shows that the procedure is able to successfully denoise time series and
successfully reconstruct system parameters. This new paradigm can be used in a
multitude of applications in neuroscience such as brain-computer interface data
analysis and better understanding of brain dynamics in diseases such as
epilepsy.",144,9,1010,19.37
796,neuroscience,"Metastability, characterized by a variability of regimes in time, is a
ubiquitous type of neural dynamics. It has been formulated in many different
ways in the neuroscience literature, however, which may cause some confusion.
In this Perspective, we discuss metastability from the point of view of
dynamical systems theory. We extract from the literature a very simple but
general definition through the concept of metastable regimes as long-lived but
transient epochs of activity with unique dynamical properties. This definition
serves as an umbrella term that encompasses formulations from other works, and
readily connects to concepts from dynamical systems theory. This allows us to
examine general dynamical properties of metastable regimes, propose in a
didactic manner several dynamics-based mechanisms that generate them, and
discuss a theoretical tool to characterize them quantitatively. This
perspective leads to insights that help to address issues debated in the
literature and also suggest pathways for future research.",151,8,1034,24.17
797,neuroscience,"In motor neuroscience, artificial recurrent neural networks models often
complement animal studies. However, most modeling efforts are limited to
data-fitting, and the few that examine virtual embodied agents in a
reinforcement learning context, do not draw direct comparisons to their
biological counterparts. Our study addressing this gap, by uncovering
structured neural activity of a virtual robot performing legged locomotion that
directly support experimental findings of primate walking and cycling. We find
that embodied agents trained to walk exhibit smooth dynamics that avoid
tangling -- or opposing neural trajectories in neighboring neural space -- a
core principle in computational neuroscience. Specifically, across a wide suite
of gaits, the agent displays neural trajectories in the recurrent layers are
less tangled than those in the input-driven actuation layers. To better
interpret the neural separation of these elliptical-shaped trajectories, we
identify speed axes that maximizes variance of mean activity across different
forward, lateral, and rotational speed conditions.",153,7,1097,12.06
798,neuroscience,"Forming accurate memory of sequential stimuli is a fundamental function of
biological agents. However, the computational mechanism underlying sequential
memory in the brain remains unclear. Inspired by neuroscience theories and
recent successes in applying predictive coding (PC) to \emph{static} memory
tasks, in this work we propose a novel PC-based model for \emph{sequential}
memory, called \emph{temporal predictive coding} (tPC). We show that our tPC
models can memorize and retrieve sequential inputs accurately with a
biologically plausible neural implementation. Importantly, our analytical study
reveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN)
with an implicit statistical whitening process, which leads to more stable
performance in sequential memory tasks of structured inputs. Moreover, we find
that tPC exhibits properties consistent with behavioral observations and
theories in neuroscience, thereby strengthening its biological relevance. Our
work establishes a possible computational mechanism underlying sequential
memory in the brain that can also be theoretically interpreted using existing
memory model frameworks.",157,8,1167,6.44
799,neuroscience,"Interactions with large language models have led to the suggestion that these
models may soon be conscious. From the perspective of neuroscience, this
position is difficult to defend. For one, the inputs to large language models
lack the embodied, embedded information content characteristic of our sensory
contact with the world around us. Secondly, the architecture of large language
models is missing key features of the thalamocortical system that have been
linked to conscious awareness in mammals. Finally, the evolutionary and
developmental trajectories that led to the emergence of living conscious
organisms arguably have no parallels in artificial systems as envisioned today.
The existence of living organisms depends on their actions, and their survival
is intricately linked to multi-level cellular, inter-cellular, and organismal
processes culminating in agency and consciousness.",128,7,894,24.48
800,neuroscience,"As our understanding of the mechanisms of brain function is enhanced, the
value of insights gained from neuroscience to the development of AI algorithms
deserves further consideration. Here, we draw parallels with an existing
tree-based ANN architecture and a recent neuroscience study[27] arguing that
the error-based organization of neurons in the cerebellum that share a
preference for a personalized view of the entire error space, may account for
several desirable features of behavior and learning. We then analyze the
learning behavior and characteristics of the model under varying scenarios to
gauge the potential benefits of a similar mechanism in ANN. Our empirical
results suggest that having separate populations of neurons with personalized
error views can enable efficient learning under class imbalance and limited
data, and reduce the susceptibility to unintended shortcut strategies, leading
to improved generalization. This work highlights the potential of translating
the learning machinery of the brain into the design of a new generation of ANNs
and provides further credence to the argument that biologically inspired AI may
hold the key to overcoming the shortcomings of ANNs.",179,6,1200,9.76
801,neuroscience,"We present a software tool -- extended Dynamic Causal Modelling for Phase
Coupling (eDCM PC) -- that is able to estimate effective connectivity between
any kind of oscillating systems, e.g. distant brain regions, using the phase
information obtained from experimental signals. With the help of a
transformation function eDCM PC can measure observable independent coupling
functions within and between different frequency bands. eDCM PC is written in
the numerical computing language MATLAB as an extension to Dynamic Causal
Modelling (DCM) for phase coupling (Penny et al. 2009). eDCM PC is available on
GitLab under the GNU General Public License (Version 3 or later).",103,8,669,34.05
802,neuroscience,"Advances in neuroscience have enabled researchers to measure the activities
of large numbers of neurons simultaneously in behaving animals. We have access
to the fluorescence of each of the neurons which provides a first-order
approximation of the neural activity over time. Determining the exact spike of
a neuron from this fluorescence trace constitutes an active area of research
within the field of computational neuroscience. We propose a novel Bayesian
approach based on a mixture of half-non-local prior densities and point masses
for this task. Instead of a computationally expensive MCMC algorithm, we adopt
a stochastic search-based approach that is capable of taking advantage of
modern computing environments often equipped with multiple processors, to
explore all possible arrangements of spikes and lack thereof in an observed
spike train. It then reports the highest posterior probability arrangement of
spikes and posterior probability for a spike at each location of the spike
train. Our proposals lead to substantial improvements over existing proposals
based on L1 regularization, and enjoy comparable estimation accuracy to the
state-of-the-art L0 proposal, in simulations, and on recent calcium imaging
data sets. Notably, contrary to optimization-based frequentist approaches, our
methodology yields automatic uncertainty quantification associated with the
spike-train inference.",199,9,1401,20.82
803,neuroscience,"Large language models (LLMs) exhibit remarkable performance improvement
through in-context learning (ICL) by leveraging task-specific examples in the
input. However, the mechanisms behind this improvement remain elusive. In this
work, we investigate how LLM embeddings and attention representations change
following in-context-learning, and how these changes mediate improvement in
behavior. We employ neuroscience-inspired techniques such as representational
similarity analysis (RSA) and propose novel methods for parameterized probing
and measuring ratio of attention to relevant vs. irrelevant information in
Llama-2 70B and Vicuna 13B. We designed two tasks with a priori relationships
among their conditions: linear regression and reading comprehension. We formed
hypotheses about expected similarities in task representations and measured
hypothesis alignment of LLM representations before and after ICL as well as
changes in attention. Our analyses revealed a meaningful correlation between
improvements in behavior after ICL and changes in both embeddings and attention
weights across LLM layers. This empirical framework empowers a nuanced
understanding of how latent representations shape LLM behavior, offering
valuable tools and insights for future research and practical applications.",172,10,1298,18.25
804,neuroscience,"Present day artificial neural architecture search (NAS) strategies are
essentially prediction-error-optimized. That holds true for AI functions in
general. From the developmental neuroscience perspective, I present evidence
for the central role of metabolically, rather than prediction-error-optimized
neural architecture search (NAS). Supporting evidence is drawn from the latest
insights into the glial-neural organization of the human brain and the dynamic
coordination theory which provides a mathematical foundation for the functional
expression of this optimization strategy. This is relevant to devising novel
NAS strategies in AI, especially in AGI. Additional implications arise for
causal reasoning from deep neural nets. Together, the insights from
developmental neuroscience offer a new perspective on NAS and the foundational
assumptions in AI modeling.",116,8,866,20.79
805,neuroscience,"While advances in artificial intelligence and neuroscience have enabled the
emergence of neural networks capable of learning a wide variety of tasks, our
understanding of the temporal dynamics of these networks remains limited. Here,
we study the temporal dynamics during learning of Hebbian Feedforward (HebbFF)
neural networks in tasks of continual familiarity detection. Drawing
inspiration from the field of network neuroscience, we examine the network's
dynamic reconfiguration, focusing on how network modules evolve throughout
learning. Through a comprehensive assessment involving metrics like network
accuracy, modular flexibility, and distribution entropy across diverse learning
modes, our approach reveals various previously unknown patterns of network
reconfiguration. In particular, we find that the emergence of network
modularity is a salient predictor of performance, and that modularization
strengthens with increasing flexibility throughout learning. These insights not
only elucidate the nuanced interplay of network modularity, accuracy, and
learning dynamics but also bridge our understanding of learning in artificial
and biological realms.",155,7,1163,2.99
806,neuroscience,"Connecting neural activity to function is a common aim in neuroscience. How
to define and conceptualize function, however, can vary. Here I focus on
grounding this goal in the specific question of how a given change in behavior
is produced by a change in neural circuits or activity. Artificial neural
network models offer a particularly fruitful format for tackling such questions
because they use neural mechanisms to perform complex transformations and
produce appropriate behavior. Therefore, they can be a means of causally
testing the extent to which a neural change can be responsible for an
experimentally observed behavioral change. Furthermore, because the field of
interpretability in artificial intelligence has similar aims, neuroscientists
can look to interpretability methods for new ways of identifying neural
features that drive performance and behaviors.",129,7,872,24.27
807,neuroscience,"To mitigate dictionary attacks or similar undesirable automated attacks to
information systems, developers mostly prefer using CAPTCHA challenges as Human
Interactive Proofs (HIPs) to distinguish between human users and scripts.
Appropriate use of CAPTCHA requires a setup that balances between robustness
and usability during the design of a challenge. The previous research reveals
that most usability studies have used accuracy and response time as measurement
criteria for quantitative analysis. The present study aims at applying optical
neuroimaging techniques for the analysis of CAPTCHA design. The functional
Near-Infrared Spectroscopy technique was used to explore the hemodynamic
responses in the prefrontal cortex elicited by CAPTCHA stimulus of varying
types. )e findings suggest that regions in the left and right dorsolateral and
right dorsomedial prefrontal cortex respond to the degrees of line occlusion,
rotation, and wave distortions present in a CAPTCHA. The systematic addition of
the visual effects introduced nonlinear effects on the behavioral and
prefrontal oxygenation measures, indicative of the emergence of Gestalt effects
that might have influenced the perception of the overall CAPTCHA figure.",173,8,1225,29.48
808,neuroscience,"We explore a few common models on how correlations affect information. The
main model considered is the Shannon mutual information $I(S:R_1,\cdots, R_i)$
over distributions with marginals $P_{S,R_i}$ fixed for each $i$, with the
analogy in which $S$ is the stimulus and $R_i$'s are neurons. We work out basic
models in details, using algebro-geometric tools to write down discriminants
that separate distributions with distinct qualitative behaviours in the
probability simplex into toric chambers and evaluate the volumes of them
algebraically. As a byproduct, we provide direct translation between a
decomposition of mutual information inspired by a series expansion and one from
partial information decomposition (PID) problems, characterising the
synergistic terms of the former. We hope this paper serves for communication
between communities especially mathematics and theoretical neuroscience on the
topic.
  KEYWORDS: information theory, algebraic statistics, mathematical
neuroscience, partial information decomposition",139,6,1028,5.63
809,neuroscience,"Understanding object recognition patterns in mice is crucial for advancing
behavioral neuroscience and has significant implications for human health,
particularly in the realm of Alzheimer's research. This study is centered on
the development, application, and evaluation of a state-of-the-art
computational pipeline designed to analyze such behaviors, specifically
focusing on Novel Object Recognition (NOR) and Spontaneous Location Recognition
(SLR) tasks. The pipeline integrates three advanced computational models:
Any-Maze for initial data collection, DeepLabCut for detailed pose estimation,
and Convolutional Neural Networks (CNNs) for nuanced behavioral classification.
Employed across four distinct mouse groups, this pipeline demonstrated high
levels of accuracy and robustness. Despite certain challenges like video
quality limitations and the need for manual calculations, the results affirm
the pipeline's efficacy and potential for scalability. The study serves as a
proof of concept for a multidimensional computational approach to behavioral
neuroscience, emphasizing the pipeline's versatility and readiness for future,
more complex analyses.",150,7,1160,3.8
810,neuroscience,"The statistical analysis of group studies in neuroscience is particularly
challenging due to the complex spatio-temporal nature of the data, its multiple
levels and the inter-individual variability in brain responses. In this
respect, traditional ANOVA-based studies and linear mixed effects models
typically provide only limited exploration of the dynamic of the group brain
activity and variability of the individual responses potentially leading to
overly simplistic conclusions and/or missing more intricate patterns. In this
study we propose a novel method based on functional Principal Components
Analysis and Bayesian model-based clustering to simultaneously assess group
effects and individual deviations over the most important temporal features in
the data. This method provides a thorough exploration of group differences and
individual deviations in neuroscientific group studies without compromising on
the spatio-temporal nature of the data. By means of a simulation study we
demonstrate that the proposed model returns correct classification in different
clustering scenarios under low and high of noise levels in the data. Finally we
consider a case study using Electroencephalogram data recorded during an object
recognition task where our approach provides new insights into the underlying
brain mechanisms generating the data and their variability.",192,7,1367,5.16
811,neuroscience,"In recent years, neuroscience has made significant progress in building
large-scale artificial neural network (ANN) models of brain activity and
behavior. However, there is no consensus on the most efficient ways to collect
data and design experiments to develop the next generation of models. This
article explores the controversial opinions that have emerged on this topic in
the domain of vision and language. Specifically, we address two critical
points. First, we weigh the pros and cons of using qualitative insights from
empirical results versus raw experimental data to train models. Second, we
consider model-free (intuition-based) versus model-based approaches for data
collection, specifically experimental design and stimulus selection, for
optimal model development. Finally, we consider the challenges of developing a
synergistic approach to experimental design and model building, including
encouraging data and model sharing and the implications of iterative additions
to existing models. The goal of the paper is to discuss decision points and
propose directions for both experimenters and model developers in the quest to
understand the brain.",168,9,1161,24.78
812,neuroscience,"This review aims to contribute to the quest for artificial general
intelligence by examining neuroscience and cognitive psychology methods for
potential inspiration. Despite the impressive advancements achieved by deep
learning models in various domains, they still have shortcomings in abstract
reasoning and causal understanding. Such capabilities should be ultimately
integrated into artificial intelligence systems in order to surpass data-driven
limitations and support decision making in a way more similar to human
intelligence. This work is a vertical review that attempts a wide-ranging
exploration of brain function, spanning from lower-level biological neurons,
spiking neural networks, and neuronal ensembles to higher-level concepts such
as brain anatomy, vector symbolic architectures, cognitive and categorization
models, and cognitive architectures. The hope is that these concepts may offer
insights for solutions in artificial general intelligence.",129,6,966,2.99
813,neuroscience,"Electroencephalography (EEG) and Magnetoencephalography (MEG) are pivotal in
understanding brain activity but are limited by their poor spatial resolution.
EEG/MEG source imaging (ESI) infers the high-resolution electric field
distribution in the brain based on the low-resolution scalp EEG/MEG
observations. However, the ESI problem is ill-posed, and how to bring
neuroscience priors into ESI method is the key. Here, we present a novel method
which utilizes the Brain Geometric-informed Basis Functions (GBFs) as priors to
enhance EEG/MEG source imaging. Through comprehensive experiments on both
synthetic data and real task EEG data, we demonstrate the superiority of GBFs
over traditional spatial basis functions (e.g., Harmonic and MSP), as well as
existing ESI methods (e.g., dSPM, MNE, sLORETA, eLORETA). GBFs provide robust
ESI results under different noise levels, and result in biologically
interpretable EEG sources. We believe the high-resolution EEG source imaging
from GBFs will greatly advance neuroscience research.",146,12,1032,38.11
814,neuroscience,"Covariance matrix estimation is an important task in the analysis of
multivariate data in disparate scientific fields, including neuroscience,
genomics, and astronomy. However, modern scientific data are often incomplete
due to factors beyond the control of researchers, and data missingness may
prohibit the use of traditional covariance estimation methods. Some existing
methods address this problem by completing the data matrix, or by filling the
missing entries of an incomplete sample covariance matrix by assuming a
low-rank structure. We propose a novel approach that exploits auxiliary
variables to complete covariance matrix estimates. An example of auxiliary
variable is the distance between neurons, which is usually inversely related to
the strength of neuronal correlation. Our method extracts auxiliary information
via regression, and involves a single tuning parameter that can be selected
empirically. We compare our method with other matrix completion approaches via
simulations, and apply it to the analysis of large-scale neuroscience data.",151,8,1060,24.17
815,neuroscience,"In this paper we introduce SynaptoGen, a novel framework that aims to bridge
the gap between genetic manipulations and neuronal network behavior by
simulating synaptogenesis and guiding the development of neuronal networks
capable of solving predetermined computational tasks. Drawing inspiration from
recent advancements in the field, we propose SynaptoGen as a bio-plausible
approach to modeling synaptogenesis through differentiable functions. To
validate SynaptoGen, we conduct a preliminary experiment using reinforcement
learning as a benchmark learning framework, demonstrating its effectiveness in
generating neuronal networks capable of solving the OpenAI Gym's Cart Pole
task, compared to carefully designed baselines. The results highlight the
potential of SynaptoGen to inspire further advancements in neuroscience and
computational modeling, while also acknowledging the need for incorporating
more realistic genetic rules and synaptic conductances in future research.
Overall, SynaptoGen represents a promising avenue for exploring the
intersection of genetics, neuroscience, and artificial intelligence.",145,6,1118,-0.27
816,neuroscience,"A major goal in neuroscience is to discover neural data representations that
generalize. This goal is challenged by variability along recording sessions
(e.g. environment), subjects (e.g. varying neural structures), and sensors
(e.g. sensor noise), among others. Recent work has begun to address
generalization across sessions and subjects, but few study robustness to sensor
failure which is highly prevalent in neuroscience experiments. In order to
address these generalizability dimensions we first collect our own
electroencephalography dataset with numerous sessions, subjects, and sensors,
then study two time series models: EEGNet (Lawhern et al., 2018) and TOTEM
(Talukder et al., 2024). EEGNet is a widely used convolutional neural network,
while TOTEM is a discrete time series tokenizer and transformer model. We find
that TOTEM outperforms or matches EEGNet across all generalizability cases.
Finally through analysis of TOTEM's latent codebook we observe that
tokenization enables generalization.",142,16,1009,41.46
817,neuroscience,"One major criticism of deep learning centers around the biological
implausibility of the credit assignment schema used for learning --
backpropagation of errors. This implausibility translates into practical
limitations, spanning scientific fields, including incompatibility with
hardware and non-differentiable implementations, thus leading to expensive
energy requirements. In contrast, biologically plausible credit assignment is
compatible with practically any learning condition and is energy-efficient. As
a result, it accommodates hardware and scientific modeling, e.g. learning with
physical systems and non-differentiable behavior. Furthermore, it can lead to
the development of real-time, adaptive neuromorphic processing systems. In
addressing this problem, an interdisciplinary branch of artificial intelligence
research that lies at the intersection of neuroscience, cognitive science, and
machine learning has emerged. In this paper, we survey several vital algorithms
that model bio-plausible rules of credit assignment in artificial neural
networks, discussing the solutions they provide for different scientific fields
as well as their advantages on CPUs, GPUs, and novel implementations of
neuromorphic hardware. We conclude by discussing the future challenges that
will need to be addressed in order to make such algorithms more useful in
practical applications.",182,11,1381,8.77
818,neuroscience,"The FitzHugh-Nagumo equation, originally conceived in neuroscience during the
1960s, became a key model providing a simplified view of excitable neuron cell
behavior. Its applicability, however, extends beyond neuroscience into fields
like cardiac physiology, cell division, population dynamics, electronics, and
other natural phenomena. In this review spanning six decades of research, we
discuss the diverse spatio-temporal dynamical behaviors described by the
FitzHugh-Nagumo equation. These include dynamics like bistability,
oscillations, and excitability, but it also addresses more complex phenomena
such as traveling waves and extended patterns in coupled systems. The review
serves as a guide for modelers aiming to utilize the strengths of the
FitzHugh-Nagumo model to capture generic dynamical behavior. It not only
catalogs known dynamical states and bifurcations, but also extends previous
studies by providing stability and bifurcation analyses for coupled spatial
systems.",134,7,987,15.0
819,neuroscience,"Deep learning methods are increasingly becoming instrumental as modeling
tools in computational neuroscience, employing optimality principles to build
bridges between neural responses and perception or behavior. Developing models
that adequately represent uncertainty is however challenging for deep learning
methods, which often suffer from calibration problems. This constitutes a
difficulty in particular when modeling cortical circuits in terms of Bayesian
inference, beyond single point estimates such as the posterior mean or the
maximum a posteriori. In this work we systematically studied uncertainty
representations in latent representations of variational auto-encoders (VAEs),
both in a perceptual task from natural images and in two other canonical tasks
of computer vision, finding a poor alignment between uncertainty and
informativeness or ambiguities in the images. We next showed how a novel
approach which we call explaining-away variational auto-encoders (EA-VAEs),
fixes these issues, producing meaningful reports of uncertainty in a variety of
scenarios, including interpolation, image corruption, and even
out-of-distribution detection. We show EA-VAEs may prove useful both as models
of perception in computational neuroscience and as inference tools in computer
vision.",175,7,1293,-0.47
820,neuroscience,"With an increasing presence of science throughout all parts of society, there
is a rising expectation for researchers to effectively communicate their work
and, equally, for teachers to discuss contemporary findings in their
classrooms. While the community can resort to an established set of teaching
aids for the fundamental concepts of most natural sciences, there is a need for
similarly illustrative experiments and demonstrators in neuroscience. We
therefore introduce Lu.i: a parametrizable electronic implementation of the
leaky-integrate-and-fire neuron model in an engaging form factor. These
palm-sized neurons can be used to visualize and experience the dynamics of
individual cells and small spiking neural networks. When stimulated with real
or simulated sensory input, Lu.i demonstrates brain-inspired information
processing in the hands of a student. As such, it is actively used at
workshops, in classrooms, and for science communication. As a versatile tool
for teaching and outreach, Lu.i nurtures the comprehension of neuroscience
research and neuromorphic engineering among future generations of scientists
and in the general public.",165,11,1154,29.35
821,neuroscience,"Non-parametric models, such as Gaussian Processes (GP), show promising
results in the analysis of complex data. Their applications in neuroscience
data have recently gained traction. In this research, we introduce a novel
neural decoder model built upon GP models. The core idea is that two GPs
generate neural data and their associated labels using a set of low-dimensional
latent variables. Under this modeling assumption, the latent variables
represent the underlying manifold or essential features present in the neural
data. When GPs are trained, the latent variable can be inferred from neural
data to decode the labels with a high accuracy. We demonstrate an application
of this decoder model in a verbal memory experiment dataset and show that the
decoder accuracy in predicting stimulus significantly surpasses the
state-of-the-art decoder models. The preceding performance of this model
highlights the importance of utilizing non-parametric models in the analysis of
neuroscience data.",148,9,995,35.78
822,neuroscience,"Modern neuroscience has evolved into a frontier field that draws on numerous
disciplines, resulting in the flourishing of novel conceptual frames primarily
inspired by physics and complex systems science. Contributing in this
direction, we recently introduced a mathematical framework to describe the
spatiotemporal interactions of systems of neurons using lattice field theory,
the reference paradigm for theoretical particle physics. In this note, we
provide a concise summary of the basics of the theory, aiming to be intuitive
to the interdisciplinary neuroscience community. We contextualize our methods,
illustrating how to readily connect the parameters of our formulation to
experimental variables using well-known renormalization procedures. This
synopsis yields the key concepts needed to describe neural networks using
lattice physics. Such classes of methods are attention-worthy in an era of
blistering improvements in numerical computations, as they can facilitate
relating the observation of neural activity to generative models underpinned by
physical principles.",149,7,1079,12.46
823,neuroscience,"The human brain is a highly efficient processing unit, and understanding how
it works can inspire new algorithms and architectures in machine learning. In
this work, we introduce a novel framework named Brain Activation Network
(BRACTIVE), a transformer-based approach to studying the human visual brain.
The main objective of BRACTIVE is to align the visual features of subjects with
corresponding brain representations via fMRI signals. It allows us to identify
the brain's Regions of Interest (ROI) of the subjects. Unlike previous brain
research methods, which can only identify ROIs for one subject at a time and
are limited by the number of subjects, BRACTIVE automatically extends this
identification to multiple subjects and ROIs. Our experiments demonstrate that
BRACTIVE effectively identifies person-specific regions of interest, such as
face and body-selective areas, aligning with neuroscience findings and
indicating potential applicability to various object categories. More
importantly, we found that leveraging human visual brain activity to guide deep
neural networks enhances performance across various benchmarks. It encourages
the potential of BRACTIVE in both neuroscience and machine intelligence
studies.",175,9,1228,23.87
824,neuroscience,"Inner Interpretability is a promising emerging field tasked with uncovering
the inner mechanisms of AI systems, though how to develop these mechanistic
theories is still much debated. Moreover, recent critiques raise issues that
question its usefulness to advance the broader goals of AI. However, it has
been overlooked that these issues resemble those that have been grappled with
in another field: Cognitive Neuroscience. Here we draw the relevant connections
and highlight lessons that can be transferred productively between fields.
Based on these, we propose a general conceptual framework and give concrete
methodological strategies for building mechanistic explanations in AI inner
interpretability research. With this conceptual framework, Inner
Interpretability can fend off critiques and position itself on a productive
path to explain AI systems.",123,7,858,33.75
825,neuroscience,"We present a self-supervised framework that learns population-level codes for
intracranial neural recordings at scale, unlocking the benefits of
representation learning for a key neuroscience recording modality. The
Population Transformer (PopT) lowers the amount of data required for decoding
experiments, while increasing accuracy, even on never-before-seen subjects and
tasks. We address two key challenges in developing PopT: sparse electrode
distribution and varying electrode location across patients. PopT stacks on top
of pretrained representations and enhances downstream tasks by enabling learned
aggregation of multiple spatially-sparse data channels. Beyond decoding, we
interpret the pretrained PopT and fine-tuned models to show how it can be used
to provide neuroscience insights learned from massive amounts of data. We
release a pretrained PopT to enable off-the-shelf improvements in multi-channel
intracranial data decoding and interpretability, and code is available at
https://github.com/czlwang/PopulationTransformer.",135,8,1039,23.26
826,neuroscience,"Neuroscience research has expanded dramatically over the past 30 years by
advancing standardization and tool development to support rigor and
transparency. Consequently, the complexity of the data pipeline has also
increased, hindering access to FAIR (Findable, Accessible, Interoperabile, and
Reusable) data analysis to portions of the worldwide research community.
brainlife.io was developed to reduce these burdens and democratize modern
neuroscience research across institutions and career levels. Using community
software and hardware infrastructure, the platform provides open-source data
standardization, management, visualization, and processing and simplifies the
data pipeline. brainlife.io automatically tracks the provenance history of
thousands of data objects, supporting simplicity, efficiency, and transparency
in neuroscience research. Here brainlife.io's technology and data services are
described and evaluated for validity, reliability, reproducibility,
replicability, and scientific utility. Using data from 4 modalities and 3,200
participants, we demonstrate that brainlife.io's services produce outputs that
adhere to best practices in modern neuroscience research.",148,12,1188,1.94
827,neuroscience,"Growing neuropsychological and neurophysiological evidence suggests that the
visual cortex uses parts-based representations to encode, store and retrieve
relevant objects. In such a scheme, objects are represented as a set of
spatially distributed local features, or parts, arranged in stereotypical
fashion. To encode the local appearance and to represent the relations between
the constituent parts, there has to be an appropriate memory structure formed
by previous experience with visual objects. Here, we propose a model how a
hierarchical memory structure supporting efficient storage and rapid recall of
parts-based representations can be established by an experience-driven process
of self-organization. The process is based on the collaboration of slow
bidirectional synaptic plasticity and homeostatic unit activity regulation,
both running at the top of fast activity dynamics with winner-take-all
character modulated by an oscillatory rhythm. These neural mechanisms lay down
the basis for cooperation and competition between the distributed units and
their synaptic connections. Choosing human face recognition as a test task, we
show that, under the condition of open-ended, unsupervised incremental
learning, the system is able to form memory traces for individual faces in a
parts-based fashion. On a lower memory layer the synaptic structure is
developed to represent local facial features and their interrelations, while
the identities of different persons are captured explicitly on a higher layer.
An additional property of the resulting representations is the sparseness of
both the activity during the recall and the synaptic patterns comprising the
memory traces.",241,10,1686,18.89
828,neuroscience,"We begin this chapter with the bold claim that it provides a neuroscientific
explanation of the magic of creativity. Creativity presents a formidable
challenge for neuroscience. Neuroscience generally involves studying what
happens in the brain when someone engages in a task that involves responding to
a stimulus, or retrieving information from memory and using it the right way,
or at the right time. If the relevant information is not already encoded in
memory, the task generally requires that the individual make systematic use of
information that is encoded in memory. But creativity is different. It
paradoxically involves studying how someone pulls out of their brain something
that was never put into it! Moreover, it must be something both new and useful,
or appropriate to the task at hand. The ability to pull out of memory something
new and appropriate that was never stored there in the first place is what we
refer to as the magic of creativity. Even if we are so fortunate as to
determine which areas of the brain are active and how these areas interact
during creative thought, we will not have an answer to the question of how the
brain comes up with solutions and artworks that are new and appropriate. On the
other hand, since the representational capacity of neurons emerges at a level
that is higher than that of the individual neurons themselves, the inner
workings of neurons is too low a level to explain the magic of creativity. Thus
we look to a level that is midway between gross brain regions and neurons.
Since creativity generally involves combining concepts from different domains,
or seeing old ideas from new perspectives, we focus our efforts on the neural
mechanisms underlying the representation of concepts and ideas. Thus we ask
questions about the brain at the level that accounts for its representational
capacity, i.e. at the level of distributed aggregates of neurons.",317,15,1912,40.08
829,neuroscience,"Information theory allows us to investigate information processing in neural
systems in terms of information transfer, storage and modification. Especially
the measure of information transfer, transfer entropy, has seen a dramatic
surge of interest in neuroscience. Estimating transfer entropy from two
processes requires the observation of multiple realizations of these processes
to estimate associated probability density functions. To obtain these
observations, available estimators assume stationarity of processes to allow
pooling of observations over time. This assumption however, is a major obstacle
to the application of these estimators in neuroscience as observed processes
are often non-stationary. As a solution, Gomez-Herrero and colleagues
theoretically showed that the stationarity assumption may be avoided by
estimating transfer entropy from an ensemble of realizations. Such an ensemble
is often readily available in neuroscience experiments in the form of
experimental trials. Thus, in this work we combine the ensemble method with a
recently proposed transfer entropy estimator to make transfer entropy
estimation applicable to non-stationary time series. We present an efficient
implementation of the approach that deals with the increased computational
demand of the ensemble method's practical application. In particular, we use a
massively parallel implementation for a graphics processing unit to handle the
computationally most heavy aspects of the ensemble method. We test the
performance and robustness of our implementation on data from simulated
stochastic processes and demonstrate the method's applicability to
magnetoencephalographic data. While we mainly evaluate the proposed method for
neuroscientific data, we expect it to be applicable in a variety of fields that
are concerned with the analysis of information transfer in complex biological,
social, and artificial systems.",266,13,1914,6.64
830,neuroscience,"Background: Current neuronal monitoring techniques, such as calcium imaging
and multi-electrode arrays, enable recordings of spiking activity from hundreds
of neurons simultaneously. Of primary importance in systems neuroscience is the
identification of cell assemblies: groups of neurons that cooperate in some
form within the recorded population.
  New Method: We introduce a simple, integrated framework for the detection of
cell-assemblies from spiking data without a priori assumptions about the size
or number of groups present. We define a biophysically-inspired measure to
extract a directed functional connectivity matrix between both excitatory and
inhibitory neurons based on their spiking history. The resulting network
representation is analyzed using the Markov Stability framework, a graph
theoretical method for community detection across scales, to reveal groups of
neurons that are significantly related in the recorded time-series at different
levels of granularity.
  Results and comparison with existing methods: Using synthetic spike-trains,
including simulated data from leaky-integrate-and-fire networks, our method is
able to identify important patterns in the data such as hierarchical structure
that are missed by other standard methods. We further apply the method to
experimental data from retinal ganglion cells of mouse and salamander, in which
we identify cell-groups that correspond to known functional types, and to
hippocampal recordings from rats exploring a linear track, where we detect
place cells with high fidelity.
  Conclusions: We present a versatile method to detect neural assemblies in
spiking data applicable across a spectrum of relevant scales that contributes
to understanding spatio-temporal information gathered from systems neuroscience
experiments.",248,9,1803,14.63
831,neuroscience,"The scientific community has witnessed an exponential increase in the
applications of graphene and graphene-based materials in a wide range of
fields. For what concerns neuroscience, the interest raised by these materials
is two-fold. On one side, nanosheets made of graphene or graphene derivatives
(graphene oxide, or its reduced form) can be used as carriers for drug
delivery. Here, an important aspect is to evaluate their toxicity, which
strongly depends on flake composition, chemical functionalization and
dimensions. On the other side, graphene can be exploited as a substrate for
tissue engineering. In this case, conductivity is probably the most relevant
amongst the various properties of the different graphene materials, as it may
allow to instruct and interrogate neural networks, as well as to drive neural
growth and differentiation. In this review, we try to give a comprehensive view
of the accomplishments and new challenges of the field, as well as which in our
view are the most exciting directions to take in the immediate future. These
include the need to engineer multifunctional nanoparticles able to cross the
blood-brain-barrier to reach neural cells, and to achieve on-demand delivery of
specific drugs. We describe the state-of-the-art in the use of graphene
materials to engineer three-dimensional scaffolds to drive neuronal growth and
regeneration in vivo, and the possibility of using graphene as a component of
hybrid composites/multi-layer organic electronics devices. Last but not least,
we address the need of an accurate theoretical modeling of the interface
between graphene and biological material, by modeling the interaction of
graphene with proteins and cell membranes at the nanoscale, and describing the
physical mechanism(s) of charge transfer by which the various graphene
materials can influence the excitability and physiology of neural cells.",285,11,1893,25.63
832,neuroscience,"Whale Optimization Algorithm (WOA) is a nature-inspired meta-heuristic
optimization algorithm, which was proposed by Mirjalili and Lewis in 2016. This
algorithm has shown its ability to solve many problems. Comprehensive surveys
have been conducted about some other nature-inspired algorithms, such as ABC,
PSO, etc.Nonetheless, no survey search work has been conducted on WOA.
Therefore, in this paper, a systematic and meta analysis survey of WOA is
conducted to help researchers to use it in different areas or hybridize it with
other common algorithms. Thus, WOA is presented in depth in terms of
algorithmic backgrounds, its characteristics, limitations, modifications,
hybridizations, and applications. Next, WOA performances are presented to solve
different problems. Then, the statistical results of WOA modifications and
hybridizations are established and compared with the most common optimization
algorithms and WOA. The survey's results indicate that WOA performs better than
other common algorithms in terms of convergence speed and balancing between
exploration and exploitation. WOA modifications and hybridizations also perform
well compared to WOA. In addition, our investigation paves a way to present a
new technique by hybridizing both WOA and BAT algorithms. The BAT algorithm is
used for the exploration phase, whereas the WOA algorithm is used for the
exploitation phase. Finally, statistical results obtained from WOA-BAT are very
competitive and better than WOA in 16 benchmarks functions. WOA-BAT also
outperforms well in 13 functions from CEC2005 and 7 functions from CEC2019.",233,15,1603,46.17
833,neuroscience,"Spiking Neural Networks (SNN) are mathematical models in neuroscience to
describe the dynamics among a set of neurons that interact with each other by
firing instantaneous signals, a.k.a., spikes. Interestingly, a recent advance
in neuroscience [Barrett-Den\`eve-Machens, NIPS 2013] showed that the neurons'
firing rate, i.e., the average number of spikes fired per unit of time, can be
characterized by the optimal solution of a quadratic program defined by the
parameters of the dynamics. This indicated that SNN potentially has the
computational power to solve non-trivial quadratic programs. However, the
results were justified empirically without rigorous analysis.
  We put this into the context of natural algorithms and aim to investigate the
algorithmic power of SNN. Especially, we emphasize on giving rigorous
asymptotic analysis on the performance of SNN in solving optimization problems.
To enforce a theoretical study, we first identify a simplified SNN model that
is tractable for analysis. Next, we confirm the empirical observation in the
work of Barrett et al. by giving an upper bound on the convergence rate of SNN
in solving the quadratic program. Further, we observe that in the case where
there are infinitely many optimal solutions, SNN tends to converge to the one
with smaller l1 norm. We give an affirmative answer to our finding by showing
that SNN can solve the l1 minimization problem under some regular conditions.
  Our main technical insight is a dual view of the SNN dynamics, under which
SNN can be viewed as a new natural primal-dual algorithm for the l1
minimization problem. We believe that the dual view is of independent interest
and may potentially find interesting interpretation in neuroscience.",271,19,1738,34.86
834,neuroscience,"Research suggests that the duration of a VR session modulates the presence
and intensity of VRISE, but there are no suggestions regarding the appropriate
maximum duration of VR sessions. The implementation of high-end VR HMDs in
conjunction with ergonomic VR software seems to mitigate the presence of VRISE
substantially. However, a brief tool does not currently exist to appraise and
report both the quality of software features and VRISE intensity
quantitatively. The VRNQ was developed to assess the quality of VR software in
terms of user experience, game mechanics, in-game assistance, and VRISE. Forty
participants aged between 28 and 43 years were recruited (18 gamers and 22
non-gamers) for the study. They participated in 3 different VR sessions until
they felt weary or discomfort and subsequently filled in the VRNQ. Our results
demonstrated that VRNQ is a valid tool for assessing VR software as it has good
convergent, discriminant, and construct validity. The maximum duration of VR
sessions should be between 55-70 minutes when the VR software meets or exceeds
the parsimonious cut-offs of the VRNQ and the users are familiarized with the
VR system. Also. the gaming experience does not seem to affect how long VR
sessions should last. Also, while the quality of VR software substantially
modulates the maximum duration of VR sessions, age and education do not.
Finally, deeper immersion, better quality of graphics and sound, and more
helpful in-game instructions and prompts were found to reduce VRISE intensity.
The VRNQ facilitates the brief assessment and reporting of the quality of VR
software features and/or the intensity of VRISE, while its minimum and
parsimonious cut-offs may appraise the suitability of VR software. The findings
of this study contribute to the establishment of rigorous VR methods that are
crucial for the viability of immersive VR as a research and clinical tool.",303,15,1911,39.37
835,neuroscience,"Virtual reality (VR) head-mounted displays (HMD) appear to be effective
research tools, which may address the problem of ecological validity in
neuropsychological testing. However, their widespread implementation is
hindered by VR induced symptoms and effects (VRISE) and the lack of skills in
VR software development. This study offers guidelines for the development of VR
software in cognitive neuroscience and neuropsychology, by describing and
discussing the stages of the development of Virtual Reality Everyday Assessment
Lab (VR-EAL), the first neuropsychological battery in immersive VR. Techniques
for evaluating cognitive functions within a realistic storyline are discussed.
The utility of various assets in Unity, software development kits, and other
software are described so that cognitive scientists can overcome challenges
pertinent to VRISE and the quality of the VR software. In addition, this pilot
study attempts to evaluate VR-EAL in accordance with the necessary criteria for
VR software for research purposes. The VR neuroscience questionnaire (VRNQ;
Kourtesis et al., 2019b) was implemented to appraise the quality of the three
versions of VR-EAL in terms of user experience, game mechanics, in-game
assistance, and VRISE. Twenty-five participants aged between 20 and 45 years
with 12-16 years of full-time education evaluated various versions of VR-EAL.
The final version of VR-EAL achieved high scores in every sub-score of the VRNQ
and exceeded its parsimonious cut-offs. It also appeared to have better in-game
assistance and game mechanics, while its improved graphics substantially
increased the quality of the user experience and almost eradicated VRISE. The
results substantially support the feasibility of the development of effective
VR research and clinical software without the presence of VRISE during a
60-minute VR session.",270,13,1862,31.72
836,neuroscience,"Our sensory systems transform external signals into neural activity, thereby
producing percepts. We are endowed with an intuitive notion of similarity
between percepts, that need not reflect the proximity of the physical
properties of the corresponding external stimuli. The quantitative
characterization of the geometry of percepts is therefore an endeavour that
must be accomplished behaviorally. Here we characterized the geometry of color
space using discrimination and matching experiments. We proposed an
individually tailored metric defined in terms of the minimal chromatic
difference required for each observer to differentiate a stimulus from its
surround. Next, we showed that this perceptual metric was particularly adequate
to describe two additional experiments, since it revealed the natural symmetry
of perceptual computations. In one of the experiments, observers were required
to discriminate two stimuli surrounded by a chromaticity that differed from
that of the tested stimuli. In the perceptual coordinates, the change in
discrimination thresholds induced by the surround followed a simple law that
only depended on the perceptual distance between the surround and each of the
two compared stimuli. In the other experiment, subjects were asked to match the
color of two stimuli surrounded by two different chromaticities. Again, in the
perceptual coordinates the induction effect produced by surrounds followed a
simple, symmetric law. We conclude that the individually-tailored notion of
perceptual distance reveals the symmetry of the laws governing perceptual
computations.",228,12,1598,16.62
837,neuroscience,"The thesis explores the role machine learning methods play in creating
intuitive computational models of neural processing. Combined with
interpretability techniques, machine learning could replace human modeler and
shift the focus of human effort to extracting the knowledge from the ready-made
models and articulating that knowledge into intuitive descroptions of reality.
This perspective makes the case in favor of the larger role that exploratory
and data-driven approach to computational neuroscience could play while
coexisting alongside the traditional hypothesis-driven approach.
  We exemplify the proposed approach in the context of the knowledge
representation taxonomy with three research projects that employ
interpretability techniques on top of machine learning methods at three
different levels of neural organization. The first study (Chapter 3) explores
feature importance analysis of a random forest decoder trained on intracerebral
recordings from 100 human subjects to identify spectrotemporal signatures that
characterize local neural activity during the task of visual categorization.
The second study (Chapter 4) employs representation similarity analysis to
compare the neural responses of the areas along the ventral stream with the
activations of the layers of a deep convolutional neural network. The third
study (Chapter 5) proposes a method that allows test subjects to visually
explore the state representation of their neural signal in real time. This is
achieved by using a topology-preserving dimensionality reduction technique that
allows to transform the neural data from the multidimensional representation
used by the computer into a two-dimensional representation a human can grasp.
  The approach, the taxonomy, and the examples, present a strong case for the
applicability of machine learning methods to automatic knowledge discovery in
neuroscience.",265,10,1892,16.25
838,neuroscience,"Despite the recent success of neural network models in mimicking animal
performance on visual perceptual tasks, critics worry that these models fail to
illuminate brain function. We take it that a central approach to explanation in
systems neuroscience is that of mechanistic modeling, where understanding the
system is taken to require fleshing out the parts, organization, and activities
of a system, and how those give rise to behaviors of interest. However, it
remains somewhat controversial what it means for a model to describe a
mechanism, and whether neural network models qualify as explanatory.
  We argue that certain kinds of neural network models are actually good
examples of mechanistic models, when the right notion of mechanistic mapping is
deployed. Building on existing work on model-to-mechanism mapping (3M), we
describe criteria delineating such a notion, which we call 3M++. These criteria
require us, first, to identify a level of description that is both abstract but
detailed enough to be ""runnable"", and then, to construct model-to-brain
mappings using the same principles as those employed for brain-to-brain mapping
across individuals. Perhaps surprisingly, the abstractions required are those
already in use in experimental neuroscience, and are of the kind deployed in
the construction of more familiar computational models, just as the principles
of inter-brain mappings are very much in the spirit of those already employed
in the collection and analysis of data across animals.
  In a companion paper, we address the relationship between optimization and
intelligibility, in the context of functional evolutionary explanations. Taken
together, mechanistic interpretations of computational models and the
dependencies between form and function illuminated by optimization processes
can help us to understand why brain systems are built they way they are.",280,10,1887,22.99
839,neuroscience,"We present Clinica (www.clinica.run), an open-source software platform
designed to make clinical neuroscience studies easier and more reproducible.
Clinica aims for researchers to i) spend less time on data management and
processing, ii) perform reproducible evaluations of their methods, and iii)
easily share data and results within their institution and with external
collaborators. The core of Clinica is a set of automatic pipelines for
processing and analysis of multimodal neuroimaging data (currently, T1-weighted
MRI, diffusion MRI and PET data), as well as tools for statistics, machine
learning and deep learning. It relies on the brain imaging data structure
(BIDS) for the organization of raw neuroimaging datasets and on established
tools written by the community to build its pipelines. It also provides
converters of public neuroimaging datasets to BIDS (currently ADNI, AIBL, OASIS
and NIFD). Processed data include image-valued scalar fields (e.g. tissue
probability maps), meshes, surface-based scalar fields (e.g. cortical thickness
maps) or scalar outputs (e.g. regional averages). These data follow the ClinicA
Processed Structure (CAPS) format which shares the same philosophy as BIDS.
Consistent organization of raw and processed neuroimaging files facilitates the
execution of single pipelines and of sequences of pipelines, as well as the
integration of processed data into statistics or machine learning frameworks.
The target audience of Clinica is neuroscientists or clinicians conducting
clinical neuroscience studies involving multimodal imaging, and researchers
developing advanced machine learning algorithms applied to neuroimaging data.",234,18,1671,34.76
840,neuroscience,"Biological neural networks define the brain function and intelligence of
humans and other mammals, and form ultra-large, spatial, structured graphs.
Their neuronal organization is closely interconnected with the spatial
organization of the brain's microvasculature, which supplies oxygen to the
neurons and builds a complementary spatial graph. This vasculature (or the
vessel structure) plays an important role in neuroscience; for example, the
organization of (and changes to) vessel structure can represent early signs of
various pathologies, e.g. Alzheimer's disease or stroke. Recently, advances in
tissue clearing have enabled whole brain imaging and segmentation of the
entirety of the mouse brain's vasculature. Building on these advances in
imaging, we are presenting an extendable dataset of whole-brain vessel graphs
based on specific imaging protocols. Specifically, we extract vascular graphs
using a refined graph extraction scheme leveraging the volume rendering engine
Voreen and provide them in an accessible and adaptable form through the OGB and
PyTorch Geometric dataloaders. Moreover, we benchmark numerous state-of-the-art
graph learning algorithms on the biologically relevant tasks of vessel
prediction and vessel classification using the introduced vessel graph dataset.
Our work paves a path towards advancing graph learning research into the field
of neuroscience. Complementarily, the presented dataset raises challenging
graph learning research questions for the machine learning community, in terms
of incorporating biological priors into learning algorithms, or in scaling
these algorithms to handle sparse,spatial graphs with millions of nodes and
edges. All datasets and code are available for download at
https://github.com/jocpae/VesselGraph .",244,14,1778,32.12
841,neuroscience,"Recurrent Neural Networks (RNNs) were recently successfully used to model the
way neural activity drives task-related behavior in animals, operating under
the implicit assumption that the obtained solutions are universal. Observations
in both neuroscience and machine learning challenge this assumption. Animals
can approach a given task with a variety of strategies, and training machine
learning algorithms introduces the phenomenon of underspecification. These
observations imply that every task is associated with a space of solutions. To
date, the structure of this space is not understood, limiting the approach of
comparing RNNs with neural data. Here, we characterize the space of solutions
associated with various tasks. We first study a simple two-neuron network on a
task that leads to multiple solutions. We trace the nature of the final
solution back to the network's initial connectivity and identify discrete
dynamical regimes that underlie this diversity. We then examine three
neuroscience-inspired tasks: Delayed and interval discrimination, and Time
reproduction. For each task, we find a rich set of solutions. Variability can
be found directly in the neural activity of the networks, and additionally by
testing the trained networks' ability to extrapolate, as a perturbation to a
system often reveals hidden structure. Furthermore, we relate extrapolation
patterns to specific dynamical objects and effective algorithms found by the
networks. We introduce a tool to derive the reduced dynamics of networks by
generating a compact directed graph describing the essence of the dynamics with
regards to behavioral inputs and outputs. Using this representation, we can
partition the solutions to each task into a handful of types and partially
predict them from neural features. Our results shed light on the concept of the
space of solutions and its uses in Machine learning and in Neuroscience.",287,16,1914,35.17
842,neuroscience,"The quest for human imitative AI has been an enduring topic in AI research
since its inception. The technical evolution and emerging capabilities of the
latest cohort of large language models (LLMs) have reinvigorated the subject
beyond academia to the cultural zeitgeist. While recent NLP evaluation
benchmark tasks test some aspects of human-imitative behaviour (e.g.,
BIG-bench's 'human-like behavior' tasks), few, if not none, examine creative
problem solving abilities. Creative problem solving in humans is a well-studied
topic in cognitive neuroscience with standardized tests that predominantly use
the ability to associate (heterogeneous) connections among clue words as a
metric for creativity. Exposure to misleading stimuli - distractors dubbed red
herrings - impede human performance in such tasks via the fixation effect and
Einstellung paradigm. In cognitive neuroscience studies, such fixations are
experimentally induced by pre-exposing participants to orthographically similar
incorrect words to subsequent word-fragments or clues. The popular British quiz
show Only Connect's Connecting Wall segment essentially mimics Mednick's Remote
Associates Test (RAT) formulation with built-in, deliberate red herrings, which
makes it an ideal proxy dataset to explore and study fixation effect and
Einstellung paradigm from cognitive neuroscience in LLMs. In this paper we
present the novel Only Connect Wall (OCW) dataset and report results from our
evaluation of selected pre-trained language models and LLMs on creative problem
solving tasks like grouping clue words by heterogeneous connections, and
identifying correct open knowledge domain connections in respective groups. We
synthetically generate two additional datasets: OCW-Randomized, OCW-WordNet to
further analyze our red-herrings hypothesis in language models. The code and
link to the dataset are available at https://github.com/TaatiTeam/OCW.",264,14,1919,21.94
843,neuroscience,"In neuroscience, optics and condensed matter there is ample physical evidence
for multistable dynamical systems, that is, systems with a large number of
attractors. The known mathematical mechanisms that lead to multiple attractors
are homoclinic tangencies and stabilization, by small perturbations or by
coupling, of systems possessing a large number of unstable invariant sets. A
short review of the existent results is presented, as well as two new results
concerning the existence of a large number of stable periodic orbits in a
perturbed marginally stable dissipative map and an infinite number of such
orbits in two coupled quadratic maps working on the Feigenbaum accumulation
point.",105,4,692,19.03
844,neuroscience,"Networks of coupled neural systems represent an important class of models in
computational neuroscience. In some applications it is required that
equilibrium points in these networks remain stable under parameter variations.
Here we present a general methodology to yield explicit constraints on the
coupling strengths to ensure the stability of the equilibrium point. Two models
of coupled excitatory-inhibitory oscillators are used to illustrate the
approach.",65,5,461,21.09
845,neuroscience,"Based on the invariance principle of differential equations a simple,
systematic, and rigorous feedback scheme with the variable feedback strength is
proposed to stabilize nonlinearly any chaotic systems without any prior
analytical knowledge of the systems. Especially the method may be used to
control near-nonhyperbolic chaotic systems, which although arising naturally
from models in astrophysics to those for neurobiology, all OGY-type methods
will fail to stabilize. The technique is successfully used to the famous
Hindmarsh-Rose model neuron and the R$\ddot{\textrm{o}}$ssler hyperchaos
system.",82,4,602,18.39
846,neuroscience,"The paradigm of stochastic resonance (SR)---the idea that signal detection
and transmission may benefit from noise---has met with great interest in both
physics and the neurosciences. We investigate here the consequences of reducing
the dynamics of a periodically driven neuron to a renewal process (stimulation
with reset or endogenous stimulation). This greatly simplifies the mathematical
analysis, but we show that stochastic resonance as reported earlier occurs in
this model only as a consequence of the reduced dynamics.",77,4,527,20.01
847,neuroscience,"We compare two different definitions for the wavelet entropy associated to
stochastic processes. The first one, the Normalized Total Wavelet Entropy
(NTWS) family [Phys. Rev. E 57 (1998) 932; J. Neuroscience Method 105 (2001)
65; Physica A (2005) in press] and a second introduced by Tavares and Lucena
[Physica A 357 (2005)~71]. In order to understand their advantages and
disadvantages, exact results obtained for fractional Gaussian noise (-1<alpha<
1) and the fractional Brownian motion (1 < alpha < 3) are assessed. We find out
that NTWS family performs better as a characterization method for these
stochastic processes.",97,8,626,46.98
848,neuroscience,"A formula for an average connectivity between cortical areas in mammals is
derived. Based on comparative neuroanatomical data, it is found, surprisingly,
that this connectivity is either only weakly dependent or independent of brain
size. It is discussed how this formula can be used to estimate the average
length of axons in white matter. Other allometric relations, such as cortical
patches and area sizes vs. brain size, are also provided. Finally, some
functional implications, with an emphasis on efficient cortical computation,
are discussed as well.",85,7,557,31.68
849,neuroscience,"We adapt an information theory analysis of interacting cognitive biological
and social modules to the problem of the global neuronal workspace, the current
standard neuroscience picture of consciousness. Tunable punctuation emerges in
a natural manner, suggesting the possibility of fitting appropriate phase
transition power law, and, away from transition, generalized Onsager relation
expressions, to observational data on conscious reaction. The development can
be extended in a straightforward way to include the role of psychosocial
stress, culture, or other embedding structured contexts in individual
consciousness, producing a 'biopsychosocial' model that closely retains the
flavor of the standard treatment, but better meets philosophical and other
objections to brain-only descriptions.",107,4,797,1.4
850,neuroscience,"One of the key points addressed by Per Bak in his models of brain function
was that biological neural systems must be able not just to learn, but also to
adapt--to quickly change their behaviour in response to a changing environment.
I discuss this in the context of various simple learning rules and adaptive
problems, centred around the Chialvo-Bak `minibrain' model [Neurosci. 90 (1999)
1137--1148].",65,4,402,57.91
851,neuroscience,"We propose a model for description of activity-dependent evolution and
self-wiring between binary neurons. Specifically, this model can be used for
investigation of growth of neuronal connectivity in the developing neocortex.
By using computational simulations with appropriate training pattern sequences,
we show that long-term memory can be encoded in neuronal connectivity and that
the external stimulations form part of the functioning neocortical circuit. It
is proposed that such binary neuron representations of point-like cortical
neurons fail to reproduce cytoarchitectural differences of the neocortical
organization, which has implications for inadequacies of compartmental models.",92,5,692,-2.64
852,neuroscience,"Intensity-tuned auditory cortex neurons may be formed by intensity-tuned
synaptic excitation. Synaptic inhibition has also been shown to enhance, and
possibly even create intensity-tuned neurons. Here we show, using in vivo whole
cell recordings in pentobarbital-anesthetized rats, that some intensity-tuned
neurons are indeed created solely through disproportionally large inhibition at
high intensities, without any intensity-tuned excitation. Since inhibition is
essentially cortical in origin, these neurons provide examples of auditory
feature-selectivity arising de novo at the cortex.",76,5,591,1.43
853,neuroscience,"I discuss several aspects of information theory and its relationship to
physics and neuroscience. The unifying thread of this somewhat chaotic essay is
the concept of Kolmogorov or algorithmic complexity (Kolmogorov Complexity, for
short). I argue that it is natural to interpret cognition as the art of finding
algorithms that apprach the Solomonoff-Kolmogorov-Chaitin (algorithmic)
Complexity limit with appropriate tradeoffs. In addition, I claim that what we
call the universe is an interpreted abstraction--a mental construct--based on
the observed coherence between multiple sensory input streams and our own
interactions. Hence, the notion of Universe is itself a model.",97,6,677,34.86
854,neuroscience,"We discuss the task of reconstructing the topological map of an environment
based on the sequences of locations visited by a mobile agent -- this occurs in
systems neuroscience, where one runs into the task of reconstructing the global
topological map of the environment based on activation patterns of the place
coding cells in hippocampus area of the brain. A similar task appears in the
context of establishing wifi connectivity maps.",71,3,437,27.49
855,neuroscience,"In the study of one dimensional dynamical systems one often assumes that the
functions involved have a negative Schwarzian derivative. In this paper we
consider a generalization of this condition. Specifically, we consider the
interval functions of a real variable having some iterate with a negative
Schwarzian derivative and show that many known results generalize to this
larger class of functions. The introduction of this class was motivated by some
maps arising in neuroscience.",74,5,484,35.78
856,neuroscience,"Popular computational models of visual attention tend to neglect the
influence of saccadic eye movements whereas it has been shown that the primates
perform on average three of them per seconds and that the neural substrate for
the deployment of attention and the execution of an eye movement might
considerably overlap. Here we propose a computational model in which the
deployment of attention with or without a subsequent eye movement emerges from
local, distributed and numerical computations.",77,3,497,15.48
857,neuroscience,"The problem of the transformation of microscopic information to the
macroscopic level is an intriguing challenge in computational neuroscience, but
also of general mathematical importance. Here, a phenomenological mathematical
model is introduced that simulates the internal information processing of brain
compartments. Synaptic potentials are integrated over small number of
realistically coupled neurons to obtain macroscopic quantities. The striatal
complex, an important part of the basal ganglia circuit in the brain for
regulating motor activity, has been investigated as an example for the
validation of the model.",86,5,622,7.35
858,neuroscience,"Here we investigate specifically the transient of a synchronizing system,
considering synchronization as a relaxation phenomenon. The stepwise
establishment of synchronization is studied in the system of dynamically
coupled maps introduced by Ito & Kaneko (Phys. Rev. Lett., 88, 028701, 2001 &
Phys. Rev. E, 67, 046226, 2003), where the plasticity of dynamical couplings
might be relevant in the context of neuroscience. We show the occurrence of
logarithmically slow dynamics in the transient of a fully deterministic
dynamical system.",79,9,536,30.46
859,neuroscience,"Recently Osorio et al (Eur. J. Neurosci., 30 (2009) 1554) reported that
probability distribution of intervals between successive epileptic seizures
follows a power law with exponent 1.5. We theoretically explain this finding by
modeling epileptic activity as a branching process, which we in turn
approximate by a random walk. We confirm the theoretical conclusion by
numerical simulation.",57,8,389,23.12
860,neuroscience,"A tutorial is presented which demonstrates the theory and usage of the
Parker-Sochacki method of numerically solving systems of differential
equations. Solutions are demonstrated for the case of projectile motion in air,
and for the classical Newtonian N-body problem with mutual gravitational
attraction.",43,3,305,15.81
861,neuroscience,"Students entering engineering in universities of applied sciences were tested
to see whether they understood easy Science problems within the first week of
the first semester. The test comprised of mathematics and physics questions in
both linear and diagrammatic form. Science misconceptions are investigated here
by comparison to a model of misconception based on the findings of other
investigators. The misconceptions demonstrated by the answers confirm this
model of misconception. The results are discussed with traditional theories
about education as well as with recent psychological research and with
neuroscience insights. These comparisons enable further investigation of
misconceptions.",97,7,698,29.65
862,neuroscience,"A large repertoire of spatiotemporal activity patterns in the brain is the
basis for adaptive behaviour. Understanding the mechanism by which the brain's
hundred billion neurons and hundred trillion synapses manage to produce such a
range of cortical configurations in a flexible manner remains a fundamental
problem in neuroscience. One plausible solution is the involvement of universal
mechanisms of emergent complex phenomena evident in dynamical systems poised
near a critical point of a second-order phase transition. We review recent
theoretical and empirical results supporting the notion that the brain is
naturally poised near criticality, as well as its implications for better
understanding of the brain.",105,5,716,19.4
863,neuroscience,"In this Chapter, we ask questions (1) What is the right way to measure the
quality of information processing in a biological system? and (2) What can
real-life organisms do in order to improve their performance in
information-processing tasks? We then review the body of work that investigates
these questions experimentally, computationally, and theoretically in
biological domains as diverse as cell biology, population biology, and
computational neuroscience",67,1,461,15.0
864,neuroscience,"We show that trial-to-trial variability in sensory detection of a weak visual
stimulus is dramatically diminished when rather than presenting a fixed
stimulus contrast, fluctuations in a subject's judgment are matched by
fluctuations in stimulus contrast. This attenuation of fluctuations does not
involve a change in the subject's psychometric function. The result is
consistent with the interpretation of trial-to-trial variability in this
sensory detection task being a high-level meta-cognitive control process that
explores for something that our brains are so used to: subject-object
relational dynamics.",85,4,610,8.91
865,neuroscience,"We consider a conductance based neural network inspired by the generalized
Integrate and Fire model introduced by Rudolph and Destexhe. We show the
existence and uniqueness of a unique Gibbs distribution characterizing spike
train statistics. The corresponding Gibbs potential is explicitly computed.
These results hold in presence of a time-dependent stimulus and apply therefore
to non-stationary dynamics.",57,5,408,31.58
866,neuroscience,"We consider recent reports on small-world topologies of interaction networks
derived from the dynamics of spatially extended systems that are investigated
in diverse scientific fields such as neurosciences, geophysics, or meteorology.
With numerical simulations that mimic typical experimental situations we have
identified an important constraint when characterizing such networks:
indications of a small-world topology can be expected solely due to the spatial
sampling of the system along with commonly used time series analysis based
approaches to network characterization.",78,3,577,-10.42
867,neuroscience,"Intertemporal choice has drawn attention in behavioral economics,
econophysics, and neuroeconomics. Recent studies in mainstream economics have
mainly focused on inconsistency in intertemporal choice (dynamic
inconsistency); while impulsivity/impatience in intertemporal choice has been
extensively studied in behavioral economics of addiction. However, recent
advances in neuroeconomic and econophysical studies on intertemporal choice
have made it possible to study both impulsivity and inconsistency in
intertemporal choice within a unified framework. In this paper I propose the
new frameworks for investigations into neuroeconomics of intertemporal choice.
The importance of studying neurochemical and neuroendocrinological modulations
of intertemporal choice and time-perception (e.g. serotonin, dopamine,
cortisol, testosterone, and epinephrine) is emphasized.",105,8,867,2.95
868,neuroscience,"We analytically investigate the stability of {\it splay states} in networks
of $N$ pulse-coupled phase-like models of neurons. By developing a perturbative
technique, we find that, in the limit of large $N$, the Floquet spectrum scales
as $1/N^2$ for generic discontinuous velocity fields. Moreover, the stability
of the so-called short-wavelength component is determined by the sign of the
jump at the discontinuity. Altogether, the form of the spectrum depends on the
pulse shape but is independent of the velocity field.",80,5,523,34.26
869,neuroscience,"Hawkes process is a self-exciting point process with clustering effect whose
intensity depends on its entire past history. It has wide applications in
neuroscience, finance and many other fields. In this paper, we obtain a
functional central limit theorem for nonlinear Hawkes process. Under the same
assumptions, we also obtain a Strassen's invariance principle, i.e. a
functional law of the iterated logarithm.",62,7,412,50.43
870,neuroscience,"I discuss an experiment demonstrating nonlocality and conservation of energy
under the assumption that the decision of the outcome happens at detection. The
experiment does not require Bell's inequalities and is loophole-free. I further
argue that the local hidden variables assumed in Bell's theorem involve de
Broglie's ""empty waves"", and therefore ""many worlds"" achieves to reconcile
locality with the violation of Bell's inequalities. Accordingly, the discussed
experiment may be the first loophole-free demonstration of nonlocality.",75,5,537,27.01
871,neuroscience,"Decision under ambiguity (uncertainty with unknown probabilities) has been
attracting attention in behavioral and neuroeconomics. However, recent
neuroimaging studies have mainly focused on gain domains while little attention
has been paid to the magnitudes of outcomes. In this study, we examined the
effects of the sign (i.e. gain and loss) and magnitude of outcomes on ambiguity
aversion and the additivity of subjective probabilities in Ellsberg's urn
problem. We observed that (i) ambiguity aversion was observed in both signs,
and (ii) subadditivity of subjective probability was not observed in negative
outcomes.",90,7,620,27.83
872,neuroscience,"A comment on `Population rate dynamics and multineuron firing patterns in
sensory cortex' by Okun et al. Journal of Neuroscience 32(48):17108-17119, 2012
and our response to the corresponding reply by Okun et al's (arXiv, 2013).",35,3,228,53.71
873,neuroscience,"Neuronal dynamics is intrinsically unstable, producing activity fluctuations
that are essentially scale-free. Here we show that while these scale-free
fluctuations are independent of temporal input statistics, they can be
entrained by input variation. Joint input output statistics and spike train
reproducibility in synaptically isolated cortical neurons were measured in
response to various input regimes over extended time scales (many minutes).
Response entrainment was found to be maximal when the input itself possesses
natural-like, scale-free statistics. We conclude that preference for natural
stimuli, often observed at the system level, exists already at the elementary,
single neuron level.",96,6,702,18.15
874,neuroscience,"A single axon can generate branches connecting with plenty synaptic targets.
Process of branching is very important for making connections in central
nervous system. The interstitial branching along primary axon shaft occurs
during nervous system development. Growing axon makes pause in its movement and
leaves active points behind its terminal. The new branches appear from these
points. We suggest mathematical model to describe and investigate neural
network branching process. The model under consideration describes neural
network growth in which the concentration of axon guidance molecules manages
axon's growth. We model the interstitial branching from axon shaft. Numerical
simulations show that in the model framework axonal networks are similar to
neural network.",111,10,775,42.07
875,neuroscience,"Physical symbol systems are needed for open-ended cognition. A good way to
understand physical symbol systems is by comparison of thought to chemistry.
Both have systematicity, productivity and compositionality. The state of the
art in cognitive architectures for open-ended cognition is critically assessed.
I conclude that a cognitive architecture that evolves symbol structures in the
brain is a promising candidate to explain open-ended cognition. Part 2 of the
paper presents such a cognitive architecture.",74,7,511,33.61
876,neuroscience,"In this paper, I examine what I refer to as the spike doctrine, which is the
generally held belief in neuroscience that information in the brain is encoded
by sequences of neural action potentials. I present the argument that specific
neurochemicals, and not spikes, are the elementary units of information in the
brain. I outline several predictions that arise from this interpretation,
relate them to results in the current research literature, and show how they
address some open questions.",79,4,493,36.32
877,neuroscience,"In the present work we derive a Central Limit Theorem for sequences of
Hilbert-valued Piecewise Deterministic Markov process models and their global
fluctuations around their deterministic limit identified by the Law of Large
Numbers. We provide a version of the limiting fluctuations processes in the
form of a distribution valued stochastic partial differential equation which
can be the starting point for further theoretical and numerical analysis. We
also present applications of our results to two examples of hybrid models of
spatially extended excitable membranes: compartmental-type neuron models and
neural fields models. These models are fundamental in neuroscience modelling
both for theory and numerics.",103,5,716,19.91
878,neuroscience,"We explore both analytically and numerically an ensemble of coupled
phase-oscillators governed by a Kuramoto-type system of differential equations.
However, we have included the effects of time-delay (due to finite
signal-propagation speeds) and network plasticity (via dynamic coupling
constants) inspired by the Hebbian learning rule in neuroscience. When
time-delay and learning effects combine, novel synchronization phenomena are
observed. We investigate the formation of spatio-temporal patterns in both one-
and two-dimensional oscillator lattices with periodic boundary conditions and
comment on the role of dimensionality.",83,5,631,8.06
879,neuroscience,"To further advance our understanding of the brain, new concepts and theories
are needed. In particular, the ability of the brain to create information flows
must be reconciled with its propensity for synchronization and mass action. The
framework of Coordination Dynamics and the theory of metastability are
presented as a starting point to study the interplay of integrative and
segregative tendencies that are expressed in space and time during the normal
course of brain function. Some recent shifts in perspective are emphasized,
that may ultimately lead to a better understanding of brain complexity.",93,5,605,39.37
880,neuroscience,"A fundamental goal of systems neuroscience is to probe the dynamics of neural
activity that drive behavior. Here we present an instrument to simultaneously
manipulate neural activity via Channelrhodopsin, monitor neural response via
GCaMP3, and observe behavior in freely moving C. elegans. We use the instrument
to directly observe the relation between sensory stimuli, interneuron activity
and locomotion in the mechanosensory circuit.",62,5,437,16.62
881,neuroscience,"Experimental neuroscience increasingly requires tractable models for
analyzing and predicting the behavior of neurons and networks. The generalized
linear model (GLM) is an increasingly popular statistical framework for
analyzing neural data that is flexible, exhibits rich dynamic behavior and is
computationally tractable (Paninski, 2004; Pillow et al., 2008; Truccolo et
al., 2005). What follows is a brief summary of the primary equations governing
the application of GLM's to spike trains with a few sentences linking this work
to the larger statistical literature. Latter sections include extensions of a
basic GLM to model spatio-temporal receptive fields as well as network activity
in an arbitrary numbers of neurons.",106,7,726,24.58
882,neuroscience,"Kernel density estimation is a technique for approximating probability
distributions. Here, it is applied to the calculation of mutual information on
a metric space. This is motivated by the problem in neuroscience of calculating
the mutual information between stimuli and spiking responses; the space of
these responses is a metric space. It is shown that kernel density estimation
on a metric space resembles the k-nearest-neighbor approach. This approach is
applied to a toy dataset designed to mimic electrophysiological data.",79,6,530,21.6
883,neuroscience,"To truly eliminate Cartesian ghosts from the science of consciousness, we
must describe consciousness as an aspect of the physical. Integrated
Information Theory states that consciousness arises from intrinsic information
generated by dynamical systems; however existing formulations of this theory
are not applicable to standard models of fundamental physical entities. Modern
physics has shown that fields are fundamental entities, and in particular that
the electromagnetic field is fundamental. Here I hypothesize that consciousness
arises from information intrinsic to fundamental fields. This hypothesis unites
fundamental physics with what we know empirically about the neuroscience
underlying consciousness, and it bypasses the need to consider quantum effects.",104,6,769,8.06
884,neuroscience,"Google's PageRank method was developed to evaluate the importance of
web-pages via their link structure. The mathematics of PageRank, however, are
entirely general and apply to any graph or network in any domain. Thus,
PageRank is now regularly used in bibliometrics, social and information network
analysis, and for link prediction and recommendation. It's even used for
systems analysis of road networks, as well as biology, chemistry, neuroscience,
and physics. We'll see the mathematics and ideas that unite these diverse
applications.",80,6,539,46.78
885,neuroscience,"In this paper, we propose first to start by presenting a state of the art of
existing approaches about scientific workflows (including neuroscience
workflows) in order to highlight business users' needs in terms of Web Services
combination. Then we discuss about intentional process modeling for scientific
workflows especially to search for Web Services. Next we present our approach
SATIS to provide reasoning and traceability capabilities on Web Services
business combination know-how, in order to bridge the gap between workflows
providers and users.",82,4,554,35.31
886,neuroscience,"Spike Timing Dependent Plasticity (STDP) is a Hebbian like synaptic learning
rule. The basis of STDP has strong experimental evidences and it depends on
precise input and output spike timings. In this paper we show that under
biologically plausible spiking regime, slight variability in the spike timing
leads to drastically different evolution of synaptic weights when its dynamics
are governed by the additive STDP rule.",65,4,422,40.99
887,neuroscience,"In this paper we obtain uniform propagation estimates for systems of
interacting diffusions. We adopt a general model, satisfying various conditions
which ensure that the decay resulting from the internal dynamics term dominates
the interaction and noise terms. The result should have diverse applications,
particularly in neuroscience, and allows for models more elaborate than that of
Wilson and Cowan, not requiring the internal dynamics to be of linear decay.",69,4,463,22.75
888,neuroscience,"In this paper, we present our approach, called SATIS (Semantically AnnotaTed
Intentions for Services), relying on intentional process modeling and semantic
web technologies and models, to assist collaboration among the members of a
neurosciences community. The main expected result of this work is to derive and
share semantic web service specifications from a neuro-scientists point of view
in order to operationalise image analysis pipelines with web services.",67,3,462,12.09
889,neuroscience,"In the decade since Jeff Hawkins proposed Hierarchical Temporal Memory (HTM)
as a model of neocortical computation, the theory and the algorithms have
evolved dramatically. This paper presents a detailed description of HTM's
Cortical Learning Algorithm (CLA), including for the first time a rigorous
mathematical formulation of all aspects of the computations. Prediction
Assisted CLA (paCLA), a refinement of the CLA is presented, which is both
closer to the neuroscience and adds significantly to the computational power.
Finally, we summarise the key functions of neocortex which are expressed in
paCLA implementations.",91,5,622,22.95
890,neuroscience,"This chapter reviews recent computational models of visual attention. We
begin with models for the bottom-up or stimulus-driven guidance of attention to
salient visual items, which we examine in seven different broad categories. We
then examine more complex models which address the top-down or goal-oriented
guidance of attention towards items that are more relevant to the task at hand.",59,4,388,43.02
891,neuroscience,"We build information geometry for a partially ordered set of variables and
define the orthogonal decomposition of information theoretic quantities. The
natural connection between information geometry and order theory leads to
efficient decomposition algorithms. This generalization of Amari's seminal work
on hierarchical decomposition of probability distributions on event
combinations enables us to analyze high-order statistical interactions arising
in neuroscience, biology, and machine learning.",63,4,500,-17.53
892,neuroscience,"The growing availability of three-dimensional point process data asks for a
development of suitable analysis techniques. In this paper, we focus on two
recently developed summary statistics, the conical and the cylindrical
$K$-function, which may be used to detect anisotropies in 3D point patterns. We
give some recommendations on choosing their arguments and investigate their
ability to detect two special types of anisotropy. Finally, both functions are
compared on some real data sets from neuroscience and glaciology.",77,5,523,34.97
893,neuroscience,"Principal Component Analysis (PCA) is a highly useful topic within an
introductory Linear Algebra course, especially since it can be used to
incorporate a number of applied projects. This method represents an essential
application and extension of the Spectral Theorem and is commonly used within a
variety of fields, including statistics, neuroscience, and image compression.
We present a synopsis of PCA and include a number of examples that can be used
within upper-level mathematics courses to engage undergraduate students while
introducing them to one of the most widely-used applications of linear algebra.",92,4,613,14.93
894,neuroscience,"Information theory provides powerful tools for understanding communication
systems. This analysis can be applied to intercellular signal transduction,
which is a means of chemical communication among cells and microbes. We discuss
how to apply information-theoretic analysis to ligand-receptor systems, which
form the signal carrier and receiver in intercellular signal transduction
channels. We also discuss the applications of these results to neuroscience.",61,5,459,13.65
895,neuroscience,"Directed graphs are widely used in modelling of nonsymmetric relations in
various sciences and engineering disciplines. We discuss invariants of strongly
connected directed graphs - minimal number of vertices or edges necessary to
remove to make remaining graphs not strongly connected. By analogy with
undirected graphs these invariants are called strong vertex/edge
connectivities. We review some properties of these invariants. Computational
results for some publicly available connectome graphs used in neuroscience are
described.",73,6,534,31.48
896,neuroscience,"The objective of this dissertation is to shed light on some fundamental
impediments in learning control laws in continuous state spaces. In particular,
if one wants to build artificial devices capable to learn motor tasks the same
way they learn to classify signals and images, one needs to establish control
rules that do not necessitate comparisons between quantities of the surrounding
space. We propose, in that context, to take inspiration from the ""end effector
control"" principle, as suggested by neuroscience studies, as opposed to the
""displacement control"" principle used in the classical control theory.",94,4,614,31.25
897,neuroscience,"Data analysed here derive from experiments conducted to study neurons'
activity in the visual cortex of behaving monkeys. We consider a
spatio-temporal adaptive penalized spline (P-spline) approach for modelling the
firing rate of visual neurons. To the best of our knowledge, this is the first
attempt in the statistical literature for locally adaptive smoothing in three
dimensions. Estimation is based on the Separation of Overlapping Penalties
(SOP) algorithm, which provides the stability and speed we look for.",77,5,516,34.97
898,neuroscience,"The ""fire together, wire together"" Hebbian model is a central principle for
learning in neuroscience, but surprisingly, it has found limited applicability
in modern machine learning. In this paper, we take a first step towards
bridging this gap, by developing flavors of competitive Hebbian learning which
produce sparse, distributed neural codes using online adaptation with minimal
tuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning
(AHL). We illustrate the distributed nature of the learned representations via
output entropy computations for synthetic data, and demonstrate superior
performance, compared to standard alternatives such as autoencoders, in
training a deep convolutional net on standard image datasets.",104,5,748,19.71
899,neuroscience,"The elegant Stalnaker/Lewis semantics for counterfactual conditonals works
with distances between models. But human beings certainly have no tables of
models and distances in their head. We begin here an investigation using a more
realistic picture, based on findings in neuroscience. We call it a
pre-semantics, as its meaning is not a description of the world, but of the
brain, whose structure is (partly) determined by the world it reasons about. In
the final section, we reconsider the components, and postulate that there are
no atomic pictures, we can always look inside.",92,6,578,44.34
900,neuroscience,"When making choices in software projects, engineers and other stakeholders
engage in decision making that involves uncertain future outcomes. Research in
psychology, behavioral economics and neuroscience has questioned many of the
classical assumptions of how such decisions are made. This literature review
aims to characterize the assumptions that underpin the study of these decisions
in Software Engineering. We identify empirical research on this subject and
analyze how the role of time has been characterized in the study of decision
making in SE. The literature review aims to support the development of
descriptive frameworks for empirical studies of intertemporal decision making
in practice.",102,6,702,25.39
901,neuroscience,"Hawkes process is a class of simple point processes with self-exciting and
clustering properties. Hawkes process has been widely applied in finance,
neuroscience, social networks, criminology, seismology, and many other fields.
In this paper, we study precise deviations for Hawkes processes for large time
asymptotics, that strictly extends and improves the existing results in the
literature. Numerical illustrations will also be provided.",62,5,441,38.82
902,neuroscience,"In the present work we analyzed the pupil size behavior of forty subjects
while they read well defined sentences with different contextual predictability
(i.e., regular sentences and proverbs). In general, pupil size increased when
reading regular sentences, but when readers realized that they were reading
proverbs their pupils strongly increase until finishing proverbs' reading. Our
results suggest that an increased pupil size is not limited to cognitive load
(i.e., relative difficulty in processing) because when participants accurately
recognized words during reading proverbs, theirs pupil size increased too. Our
results show that pupil size dynamics may be a reliable measure to investigate
the cognitive processes involved in sentence processing and memory functioning.",111,9,781,44.24
903,neuroscience,"Hawkes process is a class of simple point processes with self-exciting and
clustering properties. Hawkes process has been widely applied in finance,
neuroscience, social networks, criminology, seismology, and many other fields.
In this paper, we study fluctuations, large deviations and moderate deviations
nonlinear Hawkes processes in a new asymptotic regime, the large intensity
function and the small exciting function regime. It corresponds to the large
baseline intensity asymptotics for the linear case, and can also be interpreted
as the asymptotics for the mean process of Hawkes processes on a large network.",91,5,618,39.87
904,neuroscience,"For simulating large networks of neurons Hines proposed a method which uses
extensively the structure of the arising systems of ordinary differential
equations in order to obtain an efficient implementation. The original method
requires constant step sizes and produces the solution on a staggered grid. In
the present paper a one-step modification of this method is introduced and
analyzed with respect to their stability properties. The new method allows for
step size control. Local error estimators are constructed. The method has been
implemented in matlab and tested using simple Hodgkin-Huxley type models.
Comparisons with standard state-of-the-art solvers are provided.",99,8,678,40.24
905,neuroscience,"We propose a novel continuous testing framework to test the intensities of
Poisson Processes. This framework allows a rigorous definition of the complete
testing procedure, from an infinite number of hypothesis to joint error rates.
Our work extends traditional procedures based on scanning windows, by
controlling the family-wise error rate and the false discovery rate in a
non-asymptotic manner and in a continuous way. The decision rule is based on a
\pvalue process that can be estimated by a Monte-Carlo procedure. We also
propose new test statistics based on kernels. Our method is applied in
Neurosciences and Genomics through the standard test of homogeneity, and the
two-sample test.",108,7,693,44.75
906,neuroscience,"Correctly identifying neuronal subsets is critical to multiple downstream
methods in several areas of neuroscience research. The hippocampal interneuron
characterization technology has achieved rapid development in recent years.
However, capturing true neuronal features for accurate interneuron
characterization and segmentation has remained elusive. In the current study, a
novel global preserving estimate algorithm is used to capture the non-linearity
in the features of hippocampal interneurons after factor Algorithm. Our results
provide evidence for the effective integration of the original linear and
nonlinear neuronal features and achieves better characterization performance on
multiple hippocampal interneuron databases through array matching.",96,6,756,1.23
907,neuroscience,"Neuro-inspired recurrent neural network algorithms, such as echo state
networks, are computationally lightweight and thereby map well onto untethered
devices. The baseline echo state network algorithms are shown to be efficient
in solving small-scale spatio-temporal problems. However, they underperform for
complex tasks that are characterized by multi-scale structures. In this
research, an intrinsic plasticity-infused modular deep echo state network
architecture is proposed to solve complex and multiple timescale temporal
tasks. It outperforms state-of-the-art for time series prediction tasks.",78,6,600,30.26
908,neuroscience,"Maximum entropy principle (MEP) analysis with few non-zero effective
interactions successfully characterizes the distribution of dynamical states of
pulse-coupled networks in many experiments, e.g., in neuroscience. To better
understand the underlying mechanism, we found a relation between the dynamical
structure, i.e., effective interactions in MEP analysis, and the coupling
structure of pulse-coupled network to understand how a sparse coupling
structure could lead to a sparse coding by effective interactions. This
relation quantitatively displays how the dynamical structure is closely related
to the coupling structure.",84,8,628,16.32
909,neuroscience,"In recent years, the rapid development of neuroimaging technology has been
providing many powerful tools for cognitive neuroscience research. Among them,
the functional magnetic resonance imaging (fMRI), which has high spatial
resolution, acceptable temporal resolution, simple calibration, and short
preparation time, has been widely used in brain research. Compared with the
electroencephalogram (EEG), real-time fMRI-based brain computer interface
(rtfMRI-BCI) not only can perform decoding analysis across the whole brain to
control external devices, but also allows a subject to voluntarily
self-regulate specific brain regions. This paper reviews the basic architecture
of rtfMRI-BCI, the emerging machine learning based data analysis approaches
(also known as multi-voxel pattern analysis), and the applications and recent
advances of rtfMRI-BCI.",114,5,853,8.71
910,neuroscience,"The comparison of observed brain activity with the statistics generated by
artificial intelligence systems is useful to probe brain functional
organization under ecological conditions. Here we study fMRI activity in ten
subjects watching color natural movies and compute deep representations of
these movies with an architecture that relies on optical flow and image
content. The association of activity in visual areas with the different layers
of the deep architecture displays complexity-related contrasts across visual
areas and reveals a striking foveal/peripheral dichotomy.",81,4,580,10.23
911,neuroscience,"Continuous attractors have been used to understand recent neuroscience
experiments where persistent activity patterns encode internal representations
of external attributes like head direction or spatial location. However, the
conditions under which the emergent bump of neural activity in such networks
can be manipulated by space and time-dependent external sensory or motor
signals are not understood. Here, we find fundamental limits on how rapidly
internal representations encoded along continuous attractors can be updated by
an external signal. We apply these results to place cell networks to derive a
velocity-dependent non-equilibrium memory capacity in neural networks.",94,5,680,5.32
912,neuroscience,"In this review, we examine the recent progress in saliency prediction and
proposed several avenues for future research. In spite of tremendous efforts
and huge progress, there is still room for improvement in terms finer-grained
analysis of deep saliency models, evaluation measures, datasets, annotation
methods, cognitive studies, and new applications. This chapter will appear in
Encyclopedia of Computational Neuroscience.",59,4,426,34.56
913,neuroscience,"We propose that the Continual Learning desiderata can be achieved through a
neuro-inspired architecture, grounded on Mountcastle's cortical column
hypothesis. The proposed architecture involves a single module, called
Self-Taught Associative Memory (STAM), which models the function of a cortical
column. STAMs are repeated in multi-level hierarchies involving feedforward,
lateral and feedback connections. STAM networks learn in an unsupervised
manner, based on a combination of online clustering and hierarchical predictive
coding. This short paper only presents the architecture and its connections
with neuroscience. A mathematical formulation and experimental results will be
presented in an extended version of this paper.",98,7,729,21.09
914,neuroscience,"Multivariate time series with long-dependence are observed in many
applications such as finance , geophysics or neuroscience. Many packages
provide estimation tools for univariate settings but few are addressing the
problem of long-dependence estimation for multivariate settings. The package
multiwave is providing efficient estimation procedures for multivariate time
series. Two semi-parametric estimation methods of the long-memory exponents and
long-run covariance matrix of time series are implemented. The first one is the
Fourier-based estimation proposed by [18] and the second one is a wavelet-based
estimation described in [4]. The objective of this paper is to provide an
overview of the R package multiwave with its practical application
perspectives.",107,7,764,28.13
915,neuroscience,"A neuroscience method to understanding the brain is to find and study the
preferred stimuli that highly activate an individual cell or groups of cells.
Recent advances in machine learning enable a family of methods to synthesize
preferred stimuli that cause a neuron in an artificial or biological brain to
fire strongly. Those methods are known as Activation Maximization (AM) or
Feature Visualization via Optimization. In this chapter, we (1) review existing
AM techniques in the literature; (2) discuss a probabilistic interpretation for
AM; and (3) review the applications of AM in debugging and explaining networks.",96,5,620,30.2
916,neuroscience,"Henry Stapp has for 60 years been a leader, perhaps the leader, in exploring
the role of mind (psyche, consciousness, experience) in the ontology of quantum
mechanics. Henry's contention is that the very structure of quantum mechanics
implies a central and irreducible role for mind: an experiential aspect of
nature distinct from that of the physical matter and energy described by the
dynamical equations of physics. The task then becomes generating interest
across disciplines in the exploration of this thesis, and in particular to seek
connections with neuroscience and with empirical psychology.",92,4,601,23.39
917,neuroscience,"The problem of monotone smoothing splines with bounds is formulated as a
constrained minimization problem of the calculus of variations. Existence and
uniqueness of solutions of this problem is proved, as well as the equivalence
of it to a finite dimensional but nonlinear optimization problem. A new
algorithm for computing the solution which is a spline curve, using a branch
and bound technique, is presented. The method is applied to examples in
neuroscience and for fitting cumulative distribution functions from data.",81,5,523,42.41
918,neuroscience,"Deep convolutional neural networks are biologically driven models that
resemble the hierarchical structure of primate visual cortex and are the
current best predictors of the neural responses measured along the ventral
stream. However, the networks lack topographic properties that are present in
the visual cortex, such as orientation maps in primary visual cortex and
category-selective maps in inferior temporal (IT) cortex. In this work, the
minimum wiring cost constraint was approximated as an additional learning rule
in order to generate topographic maps of the networks. We found that our
topographic deep artificial neural networks (ANNs) can reproduce the category
selectivity maps of the primate IT cortex.",106,5,718,19.2
919,neuroscience,"Despite ample evidence that our concepts, our cognitive architecture, and
mathematics itself are all deeply compositional, few models take advantage of
this structure. We therefore propose a radically compositional approach to
computational neuroscience, drawing on the methods of applied category theory.
We describe how these tools grant us a means to overcome complexity and improve
interpretability, and supply a rigorous common language for scientific
modelling, analogous to the type theories of computer science. As a case study,
we sketch how to translate from compositional narrative concepts to neural
circuits and back again.",92,5,636,22.75
920,neuroscience,"Learning representations of data is an important problem in statistics and
machine learning. While the origin of learning representations can be traced
back to factor analysis and multidimensional scaling in statistics, it has
become a central theme in deep learning with important applications in computer
vision and computational neuroscience. In this article, we review recent
advances in learning representations from a statistical perspective. In
particular, we review the following two themes: (a) unsupervised learning of
vector representations and (b) learning of both vector and matrix
representations.",86,5,611,15.81
921,neuroscience,"Analysis on the unit sphere $\mathbb{S}^{2}$ found many applications in
seismology, weather prediction, astrophysics, signal analysis, crystallography,
computer vision, computerized tomography, neuroscience, and statistics.
  In the last two decades, the importance of these and other applications
triggered the development of various tools such as splines and wavelet bases
suitable for the unit spheres $\mathbb{S}^{2}$, $\>\>\mathbb{S}^{3}$ and the
rotation group $SO(3)$. Present paper is a summary of some of results of the
author and his collaborators on generalized (average) variational splines and
localized frames (wavelets) on compact Riemannian manifolds. The results are
illustrated by applications to Radon-type transforms on $\mathbb{S}^{d}$ and
$SO(3)$.",101,5,769,20.42
922,neuroscience,"This paper describes a new model for an artificial neural network processing
unit or neuron. It is slightly different to a traditional feedforward network
by the fact that it favours a mechanism of trying to match the wave-like
'shape' of the input with the shape of the output against specific value error
corrections. The expectation is then that a best fit shape can be transposed
into the desired output values more easily. This allows for notions of
reinforcement through resonance and also the construction of synapses.",86,5,525,49.65
923,neuroscience,"The idea of a moving present or `now' seems to form part of our most basic
beliefs about reality. Such a present, however, is not reflected in any of our
theories of the physical world. I show in this article that presentism, the
doctrine that only what is present exists, is in conflict with modern
relativistic cosmology and recent advances in neurosciences. I argue for a
tenseless view of time, where what we call `the present' is just an emergent
secondary quality arising from the interaction of perceiving self-conscious
individuals with their environment. I maintain that there is no flow of time,
but just an ordered system of events.",109,6,643,57.81
924,neuroscience,"This paper presents the use of the CRISTAL software in the N4U project.
CRISTAL was used to create a set of provenance aware analysis tools for the
Neuroscience domain. This paper advocates that the approach taken in N4U to
build the analysis suite is sufficiently generic to be able to be applied to
the HEP domain. A mapping to the PROV model for provenance interoperability is
also presented and how this can be applied to the HEP domain for the
interoperability of HEP analyses.",84,5,482,58.62
925,neuroscience,"Understanding how the brain functions is one of the biggest challenges of our
time. The analysis of experimentally recorded neural firing patterns (spike
trains) plays a crucial role in addressing this problem. Here, the PySpike
library is introduced, a Python package for spike train analysis providing
parameter-free and time-scale independent measures of spike train synchrony. It
allows to compute similarity and dissimilarity profiles, averaged values and
distance matrices. Although mainly focusing on neuroscience, PySpike can also
be applied in other contexts like climate research or social sciences. The
package is available as Open Source on Github and PyPI.",98,7,669,46.47
926,neuroscience,"This paper concerns the proof of the exponential rate of convergence of the
solution of a Fokker-Planck equation, with a drift term not being the gradient
of a potential function and endowed by Robin type boundary conditions. This
kind of problem arises, for example, in the study of interacting neurons
populations. Previous studies have numerically shown that, after a small period
of time, the solution of the evolution problem exponentially converges to the
stable state of the equation.",78,4,491,36.63
927,neuroscience,"This paper introduce a software system including widely-used Swarm
Intelligence algorithms or approaches to be used for the related scientific
research studies associated with the subject area. The programmatic
infrastructure of the system allows working on a fast, easy-to-use, interactive
platform to perform Swarm Intelligence based studies in a more effective,
efficient and accurate way. In this sense, the system employs all of the
necessary controls for the algorithms and it ensures an interactive platform on
which computer users can perform studies on a wide spectrum of solution
approaches associated with simple and also more advanced problems.",97,4,656,21.77
928,neuroscience,"We introduce the TUH EEG Seizure Corpus (TUSZ), which is the largest open
source corpus of its type, and represents an accurate characterization of
clinical conditions. In this paper, we describe the techniques used to develop
TUSZ, evaluate their effectiveness, and present some descriptive statistics on
the resulting corpus.",49,3,327,38.15
929,neuroscience,"For many years, researchers in psychology, education, statistics, and machine
learning have been developing practical methods to improve learning speed,
retention, and generalizability, and this work has been successful. Many of
these methods are rooted in common underlying principles that seem to drive
learning and overlearning in both humans and machines. I present a review of a
small part of this work to point to potentially novel applications in both
machine and human learning that may be worth exploring.",79,4,514,36.32
930,neuroscience,"We review evidence supporting the role of early life programming in the
susceptibility for adult neurodegenerative diseases while highlighting
questions and proposing avenues for future research to advance our
understanding of this fundamental process. The key elements of this phenomenon
are chronic stress, neuroinflammation triggering microglial polarization,
microglial memory and their connection to neurodegeneration. We review the
mediating mechanisms which may function as early biomarkers of increased
susceptibility for neurodegeneration. Can we devise novel early life-modifying
interventions to steer developmental trajectories to their optimum?",84,4,657,-0.61
931,neuroscience,"The Inverse First Passage time problem seeks to determine the boundary
corresponding to a given stochastic process and a fixed first passage time
distribution. Here, we determine the numerical solution of this problem in the
case of a two dimensional Gauss-Markov diffusion process. We investigate the
boundary shape corresponding to Inverse Gaussian or Gamma first passage time
distributions for different choices of the parameters, including heavy and
light tails instances. Applications in neuroscience framework are illustrated.",76,5,532,35.27
932,neuroscience,"Twenty-five years ago, Dunkelmann and Radons (1994) proposed that neural
networks should self-organize to a critical state. In models, criticality
offers a number of computational advantages. Thus this hypothesis, and in
particular the experimental work by Beggs and Plenz (2003), has triggered an
avalanche of research, with thousands of studies referring to it. Nonetheless,
experimental results are still contradictory. How is it possible, that a
hypothesis has attracted active research for decades, but nonetheless remains
controversial? We discuss the experimental and conceptual controversy, and then
present a parsimonious solution that (i) unifies the contradictory experimental
results, (ii) avoids disadvantages of a critical state, and (iii) enables
rapid, adaptive tuning of network properties to task requirements.",115,6,828,26.61
933,neuroscience,"This article aims to provide insights into the qualitative analysis of some
nonlinear Reaction-Diffusion (RD) systems arising in Neuroscience. We first
introduce a non-homogeneous FitzHugh-Nagumo (nhFHN) featuring excitability and
oscillatory properties. Then, we discuss the qualitative analysis of a toy
model related to nhFHN. In particular, we focus on the convergence of solutions
of the toy model toward different solutions (fixed point, periodic) and show
the existence of a cascade of Hopf bifurcations. Finally, we connect this
analysis to the nhFHN system.",82,6,566,20.99
934,neuroscience,"We can define a neural network that can learn to recognize objects in less
than 100 lines of code. However, after training, it is characterized by
millions of weights that contain the knowledge about many object types across
visual scenes. Such networks are thus dramatically easier to understand in
terms of the code that makes them than the resulting properties, such as tuning
or connections. In analogy, we conjecture that rules for development and
learning in brains may be far easier to understand than their resulting
properties. The analogy suggests that neuroscience would benefit from a focus
on learning and development.",101,6,631,50.97
935,neuroscience,"We consider the additive superimposition of an extensive number of
independent Euclidean Random Matrices in the high-density regime. The resolvent
is computed with techniques from free probability theory, as well as with the
replica method of statistical physics of disordered systems. Results for the
spectrum and eigenmodes are shown for a few applications relevant to
computational neuroscience, and are corroborated by numerical simulations.",63,4,445,16.32
936,neuroscience,"BrainScaleS-2 is a mixed-signal accelerated neuromorphic system targeted for
research in the fields of computational neuroscience and beyond-von-Neumann
computing. To augment its flexibility, the analog neural network core is
accompanied by an embedded SIMD microprocessor. The BrainScaleS Operating
System (BrainScaleS OS) is a software stack designed for the user-friendly
operation of the BrainScaleS architectures. We present and walk through the
software-architectural enhancements that were introduced for the BrainScaleS-2
architecture. Finally, using a second-version BrainScaleS-2 prototype we
demonstrate its application in an example experiment based on spike-based
expectation maximization.",88,6,702,11.31
937,neuroscience,"Random projection is often used to project higher-dimensional vectors onto a
lower-dimensional space, while approximately preserving their pairwise
distances. It has emerged as a powerful tool in various data processing tasks
and has attracted considerable research interest. Partly motivated by the
recent discoveries in neuroscience, in this paper we study the problem of
random projection using binary matrices with controllable sparsity patterns.
Specifically, we proposed two sparse binary projection models that work on
general data vectors. Compared with the conventional random projection models
with dense projection matrices, our proposed models enjoy significant
computational advantages due to their sparsity structure, as well as improved
accuracies in empirical evaluations.",107,6,788,15.91
938,neuroscience,"Correlation matrices are used in many domains of neurosciences such as fMRI,
EEG, MEG. However, statistical analyses often rely on embeddings into a
Euclidean space or into Symmetric Positive Definite matrices which do not
provide intrinsic tools. The quotient-affine metric was recently introduced as
the quotient of the affine-invariant metric on SPD matrices by the action of
diagonal matrices. In this work, we provide most of the fundamental Riemannian
operations of the quotient-affine metric: the expression of the metric itself,
the geodesics with initial tangent vector, the Levi-Civita connection and the
curvature.",92,5,625,31.21
939,neuroscience,"A novel representationalist theory of consciousness is presented that is
grounded in neuroscience and provides a path to artificially conscious
computing. Central to the theory are representational affordances of the
conscious experience based on the generation of qualia, the fundamental unit of
the conscious representation. The current approach is focused on understanding
the balance of simulation, situatedness, and structural coherence of artificial
conscious representations through converging evidence from neuroscientific and
modeling experiments. Representations instantiating a suitable balance of
situated and structurally coherent simulation-based qualia are hypothesized to
afford the agent the flexibilities required to succeed in rapidly changing
environments.",99,5,776,-12.93
940,neuroscience,"Hawkes process is a simple point process that is self-exciting and has
clustering effect. The intensity of this point process depends on its entire
past history. It has wide applications in finance, neuroscience, social
networks, criminology, seismology, and many other fields. In this paper, we
study the linear Hawkes process with an exponential exciting function in the
asymptotic regime where the initial intensity of the Hawkes process is large.
We derive limit theorems under this asymptotic regime as well as the regime
when both the initial intensity and the time are large.",92,6,582,52.8
941,neuroscience,"The Takacs--Fiksel method is a general approach to estimate the parameters of
a spatial Gibbs point process. This method embraces standard procedures such as
the pseudolikelihood and is defined via weight functions. In this paper we
propose a general procedure to find weight functions which reduce the Godambe
information and thus outperform pseudolikelihood in certain situations. The new
procedure is applied to a standard dataset and to a recent neuroscience
replicated point pattern dataset. Finally, the performance of the new procedure
is investigated in a simulation study.",87,6,581,36.89
942,neuroscience,"Since it was first used in 1926, EEG has been one of the most useful
instruments of neuroscience. In order to start using EEG data we need not only
EEG apparatus, but also some analytical tools and skills to understand what our
data mean. This article describes several classical analytical tools and also
new one which appeared only several years ago. We hope it will be useful for
those researchers who have only started working in the field of cognitive EEG.",81,5,461,59.33
943,neuroscience,"Attention endows animals an ability to concentrate on the most relevant
information among a deluge of distractors at any given time, either through
volitionally 'top-down' biasing, or driven by automatically 'bottom-up'
saliency of stimuli, in favour of advantageous competition in neural
modulations for information processing. Nevertheless, instead of being limited
to perceive simple features, human and other advanced animals adaptively learn
the world into categories and abstract concepts from experiences, imparting the
world meanings. This thesis suggests that the high-level cognitive ability of
human is more likely driven by attention basing on abstract perceptions, which
is defined as concept based attention (CbA).",102,4,728,3.13
944,neuroscience,"A wide range of signs are acquired from the human body called Biomedical
signs or biosignals, they can be at the cell level, organ level, or sub-atomic
level. Electroencephalogramis the electrical activity from the cerebrum, the
electrocardiogram is the electrical activity from the heart, electrical action
from the muscle sound signals referred to as electromyogram, the
electroretinogram from the eye, and so on. Studying these signals can be so
helpful for doctors, it can help them examine and predict and cure many
diseases.",83,4,530,43.36
945,neuroscience,"Phase response curves are important for analysis and modeling of oscillatory
dynamics in various applications, particularly in neuroscience. Standard
experimental technique for determining them requires isolation of the system
and application of a specifically designed input. However, isolation is not
always feasible and we are compelled to observe the system in its natural
environment under free-running conditions. To that end we propose an approach
relying only on passive observations of the system and its input. We illustrate
it with simulation results of an oscillator driven by a stochastic force.",89,6,608,19.57
946,neuroscience,"This work is aimed at the derivation of reliable and efficient a posteriori
error estimates for convection-dominated diffusion problems motivated by a
linear Fokker-Planck problem appearing in computational neuroscience. We obtain
computable error bounds of the functional type for the static and
time-dependent case and for different boundary conditions (mixed and pure
Neumann boundary conditions). Finally, we present a set of various numerical
examples including discussions on mesh adaptivity and space-time
discretisation. The numerical results confirm the reliability and efficiency of
the error estimates derived.",85,5,621,16.02
947,neuroscience,"{\it Caenorhabditis elegans} nematode worms are the only animals with the
known detailed neural connectivity diagram, well characterized genomics, and
relatively simple quantifiable behavioral output. With this in mind, many
researchers view this animal as the best candidate for a systems biology
approach, where one can integrate molecular and cellular knowledge to gain
global understanding of worm's behavior. This work reviews some research in
this direction, emphasizing computational perspective, and points out some
successes and challenges to meet this lofty goal.",81,4,573,18.69
948,neuroscience,"To handle the ubiquitous problem of ""dependence learning,"" copulas are
quickly becoming a pervasive tool across a wide range of data-driven
disciplines encompassing neuroscience, finance, econometrics, genomics, social
science, machine learning, healthcare and many more. Copula (or connection)
functions were invented in 1959 by Abe Sklar in response to a query of Maurice
Frechet. After 60 years, where do we stand now? This article provides a history
of the key developments and offers a unified perspective.",76,4,511,43.73
949,neuroscience,"The evolution of biological brains has always been contingent on their
embodiment within their respective environments, in which survival required
appropriate navigation and manipulation skills. Studying such interactions thus
represents an important aspect of computational neuroscience and, by extension,
a topic of interest for neuromorphic engineering. Here, we present three
examples of embodiment on the BrainScaleS-2 architecture, in which dynamical
timescales of both agents and environment are accelerated by several orders of
magnitude with respect to their biological archetypes.",79,4,590,2.48
950,neuroscience,"In this essay, we explore a point of intersection between deep learning and
neuroscience, through the lens of large language models, transfer learning and
network compression. Just like perceptual and cognitive neurophysiology has
inspired effective deep neural network architectures which in turn make a
useful model for understanding the brain, here we explore how biological neural
development might inspire efficient and robust optimization procedures which in
turn serve as a useful model for the maturation and aging of the brain.",80,3,536,13.96
951,neuroscience,"Audio-visual speaker recognition is one of the tasks in the recent 2019 NIST
speaker recognition evaluation (SRE). Studies in neuroscience and computer
science all point to the fact that vision and auditory neural signals interact
in the cognitive process. This motivated us to study a cross-modal network,
namely voice-face discriminative network (VFNet) that establishes the general
relation between human voice and face. Experiments show that VFNet provides
additional speaker discriminative information. With VFNet, we achieve 16.54%
equal error rate relative reduction over the score level fusion audio-visual
baseline on evaluation set of 2019 NIST SRE.",95,7,659,30.06
952,neuroscience,"Oyster fungi \emph{Pleurotus djamor} generate actin potential like spikes of
electrical potential. The trains of spikes might manifest propagation of
growing mycelium in a substrate, transportation of nutrients and metabolites
and communication processes in the mycelium network. The spiking activity of
the mycelium networks is highly variable compared to neural activity and
therefore can not be analysed by standard tools from neuroscience. We propose
original techniques for detecting and classifying the spiking activity of
fungi. Using these techniques, we analyse the information-theoretic complexity
of the fungal electrical activity. The results can pave ways for future
research on sensorial fusion and decision making of fungi.",104,7,738,20.08
953,neuroscience,"The framework for Simulation of Human and Artificial Emotion (SHArE)
describes the architecture of emotion in terms of parameters transferable
between psychology, neuroscience, and artificial intelligence. These parameters
can be defined as abstract concepts or granularized down to the voltage levels
of individual neurons. This model enables emotional trajectory design for
humans which may lead to novel therapeutic solutions for various mental health
concerns. For artificial intelligence, this work provides a compact notation
which can be applied to neural networks as a means to observe the emotions and
motivations of machines.",91,5,635,22.95
954,neuroscience,"Many real-world networks, including nervous systems, exhibit meso-scale
structure. This means that their elements can be grouped into meaningful
sub-networks. In general, these sub-networks are unknown ahead of time and must
be ""discovered"" algorithmically using community detection methods. In this
article, we review evidence that nervous systems exhibit meso-scale structure
in the form of communities, clusters, and modules. We also provide a set of
guidelines to assist users in applying community detection methods to their own
network data. These guidelines focus on the method of modularity maximization
but, in many cases, are general and applicable to other techniques.",98,7,679,38.01
955,neuroscience,"Over the past few decades, neuroscience experiments have become increasingly
complex and naturalistic. Experimental design has in turn become more
challenging, as experiments must conform to an ever-increasing diversity of
design constraints. In this article we demonstrate how this design process can
be greatly assisted using an optimization tool known as Mixed Integer Linear
Programming (MILP). MILP provides a rich framework for incorporating many types
of real-world design constraints into a neuroimaging experiment. We introduce
the mathematical foundations of MILP, compare MILP to other experimental design
techniques, and provide four case studies of how MILP can be used to solve
complex experimental design challenges.",104,6,731,24.98
956,neuroscience,"With the overwhelming advances in Artificial Intelligence (AI), brain science
and neuroscience, robots are developing towards a direction of much more
human-like and human-friendly. We can't help but wonder whether robots could be
regarded as humans in future? In this article, we propose a novel perspective
to analyze the essential difference between humans and robots, that is based on
their respective living spaces, particularly the independent and intrinsic
thinking space. We finally come to the conclusion that, only when robots own
the independent and intrinsic thinking space as humans, could they have the
prerequisites to be regarded as humans.",99,4,656,29.38
957,neuroscience,"We define a categorical notion of cybernetic system as a dynamical
realisation of a generalized open game, along with a coherence condition. We
show that this notion captures a wide class of cybernetic systems in
computational neuroscience and statistical machine learning, exposes their
compositional structure, and gives an abstract justification for the
bidirectional structure empirically observed in cortical circuits. Our
construction is built on the observation that Bayesian updates compose
optically, a fact which we prove along the way, via a fibred category of
state-dependent stochastic channels.",87,4,608,8.2
958,neuroscience,"We propose the Fourier-domain transfer entropy spectrum, a novel
generalization of transfer entropy, as a model-free metric of causality. For
arbitrary systems, this approach systematically quantifies the causality among
their different system components rather than merely analyze systems as
entireties. The generated spectrum offers a rich-information representation of
time-varying latent causal relations, efficiently dealing with non-stationary
processes and high-dimensional conditions. We demonstrate its validity in the
aspects of parameter dependence, statistic significance test, and sensibility.
An open-source multi-platform implementation of this metric is developed and
computationally applied on neuroscience data sets and diffusively coupled
logistic oscillators.",96,6,779,-7.24
959,neuroscience,"We present a design framework to induce stable oscillations through mixed
feedback control. We provide conditions on the feedback gain and on the balance
between positive and negative feedback contributions to guarantee robust
oscillations. Using linear matrix inequalities, we later derive a systematic
design for robustness to bounded dynamic uncertainties and for passive
interconnections. The results of the paper provide a system-theoretic
justification to several observations from system biology and neuroscience
pointing at the mixed feedback as a fundamental enabler for robust
oscillations. Our results are illustrated through a distributed electrical
circuit mimicking (simplified) neural dynamics.",96,6,709,9.69
960,neuroscience,"Potts models, which can be used to analyze dependent observations on a
lattice, have seen widespread application in a variety of areas, including
statistical mechanics, neuroscience, and quantum computing. To address the
intractability of Potts likelihoods for large spatial fields, we propose fast
ordered conditional approximations that enable rapid inference for observed and
hidden Potts models. Our methods can be used to directly obtain samples from
the approximate joint distribution of an entire Potts field. The computational
complexity of our approximation methods is linear in the number of spatial
locations; in addition, some of the necessary computations are naturally
parallel. We illustrate the advantages of our approach using simulated data and
a satellite image.",114,6,781,22.95
961,neuroscience,"Metaphors of Computation and Information tended to detract attention from the
intrinsic modes of neural system functions, uncontaminated by the observer's
role for collection and interpretation of experimental data. Recognizing the
self-referential mode of function, and the propensity for self-organization to
critical states requires a fundamental re-orientation with emphasis on the
conceptual approaches of Complex System Dynamics. Accordingly, local
cooperative processes, intrinsic to neural structures and of fractal nature,
call for applying Fractional Calculus and models of Random Walks in Theoretical
Neuroscience studies.",83,4,633,-7.41
962,neuroscience,"This document contains the documentation of TOBI (Tools for BCI) Interface D
(TiD). TiD tries to establish a standardized interface for event transmission
in neuroscience experiments. It is designed in a client-server architecture.
Clients are connecting to a single server and events are delivered in a
""bus-like"" manner. TiD events are based on XML messages. So TiD messages can
also get custom extended. A cross platform C++ library is available and
provides all TiD functionality. To avoid jitter effect, hampering event
processing, TiD was optimized towards performance. The documentation provides
further performance tweaks to decrease TiD message processing latency and also
decrease event timing jitter.",105,10,711,42.68
963,neuroscience,"It is still not fully understood exactly how neural networks are able to
solve the complex tasks that have recently pushed AI research forward. We
present a novel method for determining how information is structured inside a
neural network. Using ablation (a neuroscience technique for cutting away parts
of a brain to determine their function), we approach several neural network
architectures from a biological perspective. Through an analysis of this
method's results, we examine important similarities between biological and
artificial neural networks to search for the implicit knowledge locked away in
the network's weights.",94,5,630,30.7
964,neuroscience,"C. elegans is commonly used in neuroscience for behaviour analysis because of
it's compact nervous system with well-described connectivity. Localizing the
animal and distinguishing between its head and tail are important tasks to
track the worm during behavioural assays and to perform quantitative analyses.
We demonstrate a neural network based approach to localize both the head and
the tail of the worm in an image. To make empirical results in the paper
reproducible and promote open source machine learning based solutions for C.
elegans behavioural analysis, we also make our code publicly available.",93,7,607,44.14
965,neuroscience,"In the recent publication (arxiv:2007.08063v2 [cs.LG]) a fast prediction
algorithm for a single recurrent network (RN) was suggested. In this manuscript
we generalize this approach to a chain of RNs and show that it can be
implemented in natural neural systems. When the network is used recursively to
predict sequence of values the proposed algorithm does not require to store the
original input sequence. It increases robustness of the new approach compared
to the standard moving/expanding window predictive procedure. We consider
requirements on trained networks that allow to implement the proposed algorithm
and discuss them in the neuroscience context.",99,8,659,46.27
966,neuroscience,"We present a differential equations model in which contagious disease
transmission is affected by contagious fear of the disease and contagious fear
of the control, in this case vaccine. The three contagions are coupled. The two
fears evolve and interact in ways that shape distancing behavior, vaccine
uptake, and their relaxation. These behavioral dynamics in turn can amplify or
suppress disease transmission, which feeds back to affect behavior. The model
reveals several coupled contagion mechanisms for multiple epidemic waves.
Methodologically, the paper advances infectious disease modeling by including
human behavioral adaptation, drawing on the neuroscience of fear learning,
extinction, and transmission.",101,7,716,37.5
967,neuroscience,"Over the last ten years, developments in whole-brain microscopy now allow for
high-resolution imaging of intact brains of small rodents such as mice. These
complex images contain a wealth of information, but many neuroscience
laboratories do not have all of the computational knowledge and tools needed to
process these data. We review recent open source tools for registration of
images to atlases, and the segmentation, visualisation and analysis of brain
regions and labelled structures such as neurons. Since the field lacks fully
integrated analysis pipelines for all types of whole-brain microscopy analysis,
we propose a pathway for tool developers to work together to meet this
challenge.",106,5,696,36.12
968,neuroscience,"Nonlocal cross-diffusion systems on the torus, arising in population dynamics
and neuroscience, are analyzed. The global existence of weak solutions, the
weak-strong uniqueness, and the localization limit are proved. The kernels are
assumed to be positive definite and in detailed balance. The proofs are based
on entropy estimates coming from Shannon-type and Rao-type entropies, while the
weak-strong uniqueness result follows from the relative entropy method. The
existence and uniqueness theorems hold for nondifferentiable kernels. The
associated local cross-diffusion system, derived in the localization limit, is
also discussed.",87,7,635,31.38
969,neuroscience,"In 2006, during a meeting of a working group of scientists in La Jolla,
California at The Neurosciences Institute (NSI), Gerald Edelman described a
roadmap towards the creation of a Conscious Artifact. As far as I know, this
roadmap was not published. However, it did shape my thinking and that of many
others in the years since that meeting. This short paper, which is based on my
notes taken during the meeting, describes the key steps in this roadmap. I
believe it is as groundbreaking today as it was more than 15 years ago.",94,6,528,69.31
970,neuroscience,"Recent studies in neuroscience show great potential of functional brain
networks constructed from fMRI data for popularity modeling and clinical
predictions. However, existing functional brain networks are noisy and unaware
of downstream prediction tasks, while also incompatible with recent powerful
machine learning models of GNNs. In this work, we develop an end-to-end
trainable pipeline to extract prominent fMRI features, generate brain networks,
and make predictions with GNNs, all under the guidance of downstream prediction
tasks. Preliminary experiments on the PNC fMRI data show the superior
effectiveness and unique interpretability of our framework.",92,5,662,22.75
971,neuroscience,"Multi-electrode arrays serve to record electrical signals of many neurons in
the brain simultaneously. For most of the past century, electrodes that
penetrate brain tissue have had exactly one shape: a straight needle. Certainly
this was a good starting choice at the time, but there is no reason to think
that a straight line would be the optimal shape in all Neuroscience
applications. Here I argue that, in fact, a wide variety of curved shapes is
equally practical: all possible helices. I discuss the manufacture and
manipulation of such devices, and illustrate a few use cases where they will
likely outperform conventional needles. With some collective action from the
research community, curved arrays could be manufactured and distributed at low
cost.",121,7,760,50.97
972,neuroscience,"Poisson shot noise processes are natural generalizations of compound Poisson
processes that have been widely applied in insurance, neuroscience, seismology,
computer science and epidemiology. In this paper we study sharp deviations,
fluctuations and the stable probability approximation of Poisson shot noise
processes. Our achievements extend, improve and complement existing results in
the literature. We apply the theoretical results to Poisson cluster point
processes, including generalized linear Hawkes processes, and risk processes
with delayed claims. Many examples are discussed in detail.",80,6,598,12.94
973,neuroscience,"Since Claude Shannon founded Information Theory, information theory has
widely fostered other scientific fields, such as statistics, artificial
intelligence, biology, behavioral science, neuroscience, economics, and
finance. Unfortunately, actuarial science has hardly benefited from information
theory. So far, only one actuarial paper on information theory can be searched
by academic search engines. Undoubtedly, information and risk, both as
Uncertainty, are constrained by entropy law. Today's insurance big data era
means more data and more information. It is unacceptable for risk management
and actuarial science to ignore information theory. Therefore, this paper aims
to exploit information theory to discover the performance limits of insurance
big data systems and seek guidance for risk modeling and the development of
actuarial pricing systems.",118,8,858,12.02
974,neuroscience,"The Ising model is an equilibrium stochastic process used as a model in
several branches of science including magnetic materials, geophysics,
neuroscience, sociology and finance. Real systems of interest have finite size
and a fixed coupling matrix exhibiting quenched disorder. Exact methods for the
Ising model, however, employ infinite size limits, translational symmetries of
lattices and the Cayley tree, or annealed structures as ensembles of networks.
Here we show how the Ising partition function can be evaluated exactly by
exploiting small tree-width. This structural property is exhibited by a large
set of networks, both empirical and model generated.",98,6,663,34.66
975,neuroscience,"Subgraph centrality, introduced by Estrada and Rodr\'iguez-Vel\'azquez in
[12], has become a widely used centrality measure in the analysis of networks,
with applications in biology, neuroscience, economics and many other fields. It
is also worthy of study from a strictly mathematical point of view, in view of
its connections to topics in spectral graph theory, number theory, analytic
matrix functions, and combinatorics. In this paper we present some new results
and a list of open questions about subgraph centrality and other node
centrality measures based on graph walks.",88,4,578,33.28
976,neuroscience,"A new generation of molecular tools for analyzing neural activity has been
contributing to elucidate classical open questions in neuroscience. With
enhanced GEVIs and advanced optical imaging techniques, voltage-imaging
technologies have been increasingly used to observe the dynamics of large
circuits. In this chapter, we describe how to combine cortical wide-field
voltage imaging with hippocampal electrophysiology in awake behaving mice.
Furthermore, we highlight how this method can be useful for different possible
investigations.",73,5,537,27.52
977,neuroscience,"Regularized optimal mass transport (rOMT) problem adds a diffusion term to
the continuity equation in the original dynamic formulation of the optimal mass
transport (OMT) problem proposed by Benamou and Brenier. We show that the rOMT
model serves as a powerful tool in computational fluid dynamics (CFD) for
visualizing fluid flows in the glymphatic system. In the present work, we
describe how to modify the previous numerical method for efficient
implementation, resulting in a significant reduction in computational runtime.
Numerical results applied to synthetic and real-data are provided.",88,5,594,15.31
978,neuroscience,"Consciousness will be introduced axiomatically, inspired by Buddhist insight
meditation and psychology, logic in computer science, and cognitive
neuroscience, as consisting of a stream of $configurations$ that is $compound$,
$discrete$, and (non-deterministically) $computable$. Within this context the
notions of self, concentration, mindfulness, and various forms of suffering can
be defined. As an application of this set up, it will be shown how a combined
development of concentration and mindfulness can attenuate and eventually
eradicate some of the forms of suffering.",80,4,576,10.53
979,neuroscience,"A common view in the neuroscience community is that memory is encoded in the
connection strength between neurons. This perception led artificial neural
network models to focus on connection weights as the key variables to modulate
learning. In this paper, we present a prototype for weightless spiking neural
networks that can perform a simple classification task. The memory in this
network is stored in the timing between neurons, rather than the strength of
the connection, and is trained using a Hebbian Spike Timing Dependent
Plasticity (STDP), which modulates the delays of the connection.",93,5,595,39.37
980,neuroscience,"The voltage-conductance equation determines the probability distribution of a
stochastic process describing a fluctuation-driven neuronal network arising in
the visual cortex. Its structure and degeneracy share many common features with
the kinetic Fokker-Planck equation, which has attracted much attention
recently. We prove an L $\infty$ bound on the steady state solution and the
long term convergence of the evolution problem towards this stationary state.
Despite the hypoellipticity property, the difficulty is to treat the boundary
conditions that change type along the boundary. This leads us to use specific
weights in the Alikakos iterations and adapt the relative entropy method.",99,6,691,34.46
981,neuroscience,"Neuromorphic computing exploits the dynamical analogy between many physical
systems and neuron biophysics. Superconductor systems, in particular, are
excellent candidates for neuromorphic devices due to their capacity to operate
in great speeds and with low energy dissipation compared to their silicon
counterparts. In this study we revisit a prior work on Josephson Junction-based
""neurons"" in order to identify the exact dynamical mechanisms underlying the
system's neuron-like properties and reveal new complex behaviors which are
relevant for neurocomputation and the design of superconducting neuromorphic
devices. Our work lies at the intersection of superconducting physics and
theoretical neuroscience, both viewed under a common framework, that of
nonlinear dynamics theory.",107,5,784,1.97
982,neuroscience,"In this article, we discuss the dynamics of the 3-dimensional FitzHugh-Rinzel
(FHR) model and a class of non-homogeneous FitzHugh-Nagumo (Nh-FHN)
Reaction-Diffusion systems. The Nh-FHN models can be used to generate relevant
wave propagation phenomena in Neuroscience context. This gives raise locally to
complex dynamics such as canards, Mixed Mode Oscillations, Hopf-Bifurcations
some of which can be observed in the FHR model.",61,4,429,33.95
983,neuroscience,"Recent research demonstrate that prediction of time series by predictive
recurrent neural networks based on the noisy input generates a smooth
anticipated trajectory. We examine influence of the noise component in both the
training data sets and the input sequences on network prediction quality. We
propose and discuss an explanation of the observed noise compression in the
predictive process. We also discuss importance of this property of recurrent
networks in the neuroscience context for the evolution of living organisms.",79,5,528,34.46
984,neuroscience,"Since four decades ago, that the transcranial magnetic stimulation (TMS)
technique was introduced, the increasing attention of neuroscience researchers
and medical engineers has been focused on the development of this technique and
its use to manage the treatment of a wide range of neurological conditions,
including Alzheimer's disease. The ability of TMS, specifically a substantial
type known as repetitive transcranial magnetic stimulation (rTMS) in changing
the plasticity of the cortex, has been the most important feature that has
created the hopes of controlling Alzheimer's disease with this technique more
than ever.",91,3,627,16.83
985,neuroscience,"Artificial neural networks took a lot of inspiration from their biological
counterparts in becoming our best machine perceptual systems. This work
summarizes some of that history and incorporates modern theoretical
neuroscience into experiments with artificial neural networks from the field of
deep learning. Specifically, iterative magnitude pruning is used to train
sparsely connected networks with 33x fewer weights without loss in performance.
These are used to test and ultimately reject the hypothesis that weight
sparsity alone improves image noise robustness. Recent work mitigated
catastrophic forgetting using weight sparsity, activation sparsity, and active
dendrite modeling. This paper replicates those findings, and extends the method
to train convolutional neural networks on a more challenging continual learning
task. The code has been made publicly available.",122,8,878,28.43
986,neuroscience,"We provide a comprehensive review of the existing literature on
memory-augmented GNNs. We review these works through the lens of psychology and
neuroscience, which has several established theories on how multiple memory
systems and mechanisms operate in biological brains. We propose a taxonomy of
memory-augmented GNNs and a set of criteria for comparing their memory
mechanisms. We also provide critical discussions on the limitations of these
works. Finally, we discuss the challenges and future directions for this area.",78,6,524,30.26
987,neuroscience,"Since their Nobel Prize winning discovery in 2005, grid cells have been
studied extensively by neuroscientists. Their multi-scale periodic firing rates
tiling the environment as the animal moves around has been shown as critical
for path integration. Multiple experiments have shown that grid cells also fire
for other representations such as olfactory, attention mechanisms, imagined
movement, and concept organization potentially acting as a form of neural
recycling and showing the possible brain mechanism for cognitive maps that
Tolman envisioned in 1948. Grid cell integration into artificial neural
networks may enable more robust, generalized, and smarter computers. In this
paper we give an overview of grid cell research since their discovery, their
role in neuroscience and cognitive science, and possible future directions of
artificial intelligence research.",125,6,871,20.72
988,neuroscience,"In the joint paper ""Bridging the neuroscience and physics of time"" Rovelli,
as the physicist coauthor of neuroscientist Dean Buonomano, makes statements
that rely on theoretical frameworks employed when the laws of thermodynamics
and general relativity were discovered. Their reconsideration in the light of
subsequent insights suggests growth of entropy is not the origin of time's
arrow and that a notion of universal simultaneity may exist within general
relativity. This paper is a slightly extended form of my invited contribution
to the forthcoming Frontiers in Psychology special issue ""Physical time within
human time"".",93,4,627,14.63
989,neuroscience,"Several differential equation models have been proposed to explain the
formation of patterns characteristic of the grid cell network. Understanding
the effect of noise on these models is one of the key open questions in
computational neuroscience. In the present work, we continue the analysis of an
SDE system commonly proposed for this aim, which we initiated in a previous
paper. We show that the fluctuations of the empirical measure associated to the
particle system around its mean field limit converge to the solution of a
Langevin SPDE. The interaction between different columns of neurons along the
cortex prescribes a peculiar scaling regime.",103,6,652,42.11
990,neuroscience,"MemComputing is a new model of computation that exploits the non-equilibrium
property-we call 'memory'-of any physical system to respond to external
perturbations by keeping track of how it has reacted at previous times. Its
digital, scalable version maps a finite string of symbols into a finite string
of symbols. In this paper, I will discuss some analogies of the operation of
MemComputing machines-in general, and digital in particular-with a few physical
properties of the biological brain. These analogies could be a source of
inspiration to improve on the design of these machines. In turn, they could
suggest new directions of study in (computational) neuroscience.",104,6,674,33.44
991,neuroscience,"Intelligent automation supports us against cyclones, droughts, and seismic
events with recent technology advancements. Algorithmic learning has advanced
fields like neuroscience, genetics, and human-computer interaction. Time-series
data boosts progress. Challenges persist in adopting these approaches in
traditional fields. Neural networks face comprehension and bias issues. AI's
expansion across scientific areas is due to adaptable descriptors and
combinatorial argumentation. This article focuses on modeling Forest loss using
the VANYA Model, incorporating Prey Predator Dynamics. VANYA predicts forest
cover, demonstrated on Amazon Rainforest data against other forecasters like
Long Short-Term Memory, N-BEATS, RCN.",91,9,724,17.6
992,neuroscience,"Rank-order coding, a form of temporal coding, has emerged as a promising
scheme to explain the rapid ability of the mammalian brain. Owing to its speed
as well as efficiency, rank-order coding is increasingly gaining interest in
diverse research areas beyond neuroscience. However, much uncertainty still
exists about the performance of rank-order coding under noise. Herein we show
what information rates are fundamentally possible and what trade-offs are at
stake. An unexpected finding in this paper is the emergence of a special class
of errors that, in a regime, increase with less noise.",93,6,593,52.6
993,neuroscience,"One major challenge of neuroscience is finding interesting structures in a
seemingly disorganized neural activity. Often these structures have
computational implications that help to understand the functional role of a
particular brain area. Here we outline a unified approach to characterize these
structures by inspecting the representational geometry and the modularity
properties of the recorded activity, and show that this approach can also
reveal structures in connectivity. We start by setting up a general framework
for determining geometry and modularity in activity and connectivity and
relating these properties with computations performed by the network. We then
use this framework to review the types of structure found in recent works on
model networks performing three classes of computations.",117,6,809,22.34
994,neuroscience,"Leveraging recent advances in neuroscience and control theory, this paper
presents a neuromimetic network model with dynamic symmetric connections
governed by Hebbian learning rules. Formal analysis grounded in graph theory
and classical control establishes that this biologically plausible model
exhibits boundedness, stability, and structural controllability given a
generalized sym-cactus structure with multiple control nodes. We prove the
necessity of this topology when there are distributed control inputs.
Simulations using a 14-node generalized sym-cactus network with two input types
validate the model's effectiveness in capturing key neural dynamics.",87,5,662,7.05
995,neuroscience,"Large language models (LLMs) like GPT are often conceptualized as passive
predictors, simulators, or even stochastic parrots. We instead conceptualize
LLMs by drawing on the theory of active inference originating in cognitive
science and neuroscience. We examine similarities and differences between
traditional active inference systems and LLMs, leading to the conclusion that,
currently, LLMs lack a tight feedback loop between acting in the world and
perceiving the impacts of their actions, but otherwise fit in the active
inference paradigm. We list reasons why this loop may soon be closed, and
possible consequences of this including enhanced model self-awareness and the
drive to minimize prediction error by changing the world.",109,5,736,26.85
996,neuroscience,"We explored the mathematical foundations of Recurrent Neural Networks
($\mathtt{RNN}$s) and three fundamental procedures: temporal rescaling,
discretisation and linearisation. These techniques provide essential tools for
characterizing $\mathtt{RNN}$s behaviour, enabling insights into temporal
dynamics, practical computational implementation, and linear approximations for
analysis. We discuss the flexible order of application of these procedures,
emphasizing their significance in modelling and analyzing $\mathtt{RNN}$s for
neuroscience and machine learning applications. We explicitly describe here
under what conditions these procedures can be interchangeable.",77,5,667,-7.34
997,neuroscience,"The ontogeny of cognitive neuroscience has emerged within the hegemony of
substance ontology. Persistent physicalist influences are described through
three developmental hallmarks that yielded epistemic attractors - promoters and
perpetuators of material-discursive practices oriented toward reification and
self-vindication across the interdisciplinary spectrum which, as a whole, has
been driven away from its pretensions to scientific realism. In virtue of a
desire for a radical return thereto, we adopt a metaphysic stance akin to
pragmatism, and briefly make the case that such concerns have sociopolitical
implications extending far beyond the realm of mere philosophical interest.",94,4,688,6.17
998,neuroscience,"Adaptive behavior often requires predicting future events. The theory of
reinforcement learning prescribes what kinds of predictive representations are
useful and how to compute them. This paper integrates these theoretical ideas
with work on cognition and neuroscience. We pay special attention to the
successor representation (SR) and its generalizations, which have been widely
applied both as engineering tools and models of brain function. This
convergence suggests that particular kinds of predictive representations may
function as versatile building blocks of intelligence.",80,6,581,29.86
999,neuroscience,"Inspired by Bayesian approaches to brain function in neuroscience, we give a
simple theory of probabilistic inference for a unified account of reasoning and
learning. We simply model how data cause symbolic knowledge in terms of its
satisfiability in formal logic. The underlying idea is that reasoning is a
process of deriving symbolic knowledge from data via abstraction, i.e.,
selective ignorance. The logical consequence relation is discussed for its
proof-based theoretical correctness. The MNIST dataset is discussed for its
experiment-based empirical correctness.",82,8,570,29.45
1000,topology,We study topological properties of the graph topology.,8,2,54,37.98
1001,topology,"We survey different topologizations of the set $\mathcal{S}(G)$ of all closed
subgroups of a topological group $G$ and demonstrate some applications in
Topological Grous, Model Theory, Geometric Group Theory, Topological Dynamics.",31,2,230,6.17
1002,topology,"In this paper, we introduce the notion of expanding topological space. We
define the topological expansion of a topological space via local
multi-homeomorphism over coproduct topology, and we prove that the coproduct
family associated to any fractal family of topological spaces is expanding. In
particular, we prove that the more a topological space expands, the finer the
topology of its indexed states is. Using multi-homeomorphisms over associated
coproduct topological spaces, we define a locally expandable topological space
and we prove that a locally expandable topological space has a topological
expansion. Specifically, we prove that the expanding fractal manifold is
locally expandable and has a natural topological expansion.",107,6,738,15.91
1003,topology,"In the paper we introduce topological $\mathbb{Z}$-Bruck-Reilly and
topological $\mathbb{Z}$-Bruck extensions of (semi)topological monoids which
are generalizations of topological Bruck-Reilly and topological Bruck
extensions of (semi)topological monoids and study their topologizations. The
sufficient conditions under which the topological $\mathbb{Z}$-Bruck-Reilly
($\mathbb{Z}$-Bruck) extension admits only the direct sum topology and
conditions under which the direct sum topology can be coarsened are given.
Also, topological characterizations of some classes of $I$-bisimple
(semi)topological semigroups are given.",72,4,621,-3.65
1004,topology,"Concept of bi-soft topological spaces is introduced. Several notions of a
soft topological space are generalized to study bi-soft topological spaces.
Separation axioms play a vital role in study of topological spaces. These
concepts have been studied in context of bi-soft topological spaces. There is a
very close relationship between topology and rough set theory. An application
of bi-soft topology is given in rough set theory.",66,7,431,43.39
1005,topology,We study properties of shy maps in digital topology.,9,2,52,53.88
1006,topology,We study several types of multivalued functions in digital topology.,10,2,68,27.49
1007,topology,"It is important to classify covering subgroups of the fundamental group of a
topological space using their topological properties in the topologized
fundamental group. In this paper, we introduce and study some topologies on the
fundamental group and use them to classify coverings, semicoverings, and
generalized coverings of a topological space. To do this, we use the concept of
subgroup topology on a group and discuss their properties. In particular, we
explore which of these topologies make the fundamental group a topological
group. Moreover, we provide some examples of topological spaces to compare
topologies of fundamental groups.",97,6,642,34.86
1008,topology,"We provide an upper bound on the topological complexity of twisted products.
We use it to give an estimate $$TC(X)\le TC(\pi_1(X))+\dim X$$ of the
topological complexity of a space in terms of its dimension and the complexity
of its fundamental group.",41,3,251,50.67
1009,topology,"In this paper we develop star topological and topological group-groupoid
structures of monodromy groupoid and prove that the monodromy groupoid of a
topological group-groupoid is also a topological group-groupoid.",29,2,213,25.12
1010,topology,"For a locally path connected topological space, the topological fundamental
group is discrete if and only if the space is semilocally simply-connected.
While functoriality of the topological fundamental group for arbitrary
topological spaces remains an open question, the topological fundamental group
is always a homogeneous space.",46,3,332,5.83
1011,topology,"In this paper we detect topological Clifford semigroups which are embeddable
into Tychonoff products of topological semilattices and cones over topological
groups. Also we detect topological Clifford semigroups which embed into compact
topological Clifford semigroups.",35,3,268,19.87
1012,topology,"We explore the canonical Grothendieck topology in some specific
circumstances. First we use a description of the canonical topology to get a
variant of Giraud's Theorem. Then we explore the canonical Grothendieck
topology on the categories of sets and topological spaces; here we get a nice
basis for the topology. Lastly, we look at the canonical Grothendieck topology
on the category of $R$-modules.",63,5,401,46.98
1013,topology,"In this paper, we show that every topological group is a strong small loop
transfer space at the identity element. This implies that the quasitopological
fundamental group of a connected locally path connected topological group is a
topological group. Also, we show that every covering space of a connected
locally path connected topological group is a topological group and its
covering map is homomorphism.",64,4,408,32.94
1014,topology,"In this paper, we prove a theorem about embedding of some partially ordered
topological spaces in topological hyperspaces equipped with Fell topology. Then
we give some examples to show that the map defining the embedding may not be
continuous with respect to Vietoris topology or Hausdorff topology equipped on
the hyperspaces.",51,3,328,37.13
1015,topology,"A Hausdorff topological group topology on a group $G$ is the minimum
(Hausdorff) group topology if it is contained in every Hausdorff group topology
on $G$. For every compact metrizable space $X$ containing an open $n$-cell,
$n\ge2$, the homeomorphism group $H(X)$ has no minimum Hausdorff group
topology. The homeomorphism groups of the Cantor set and the Hilbert cube have
no minimum group topology. For every compact metrizable space $X$ containing a
dense open one-manifold, $H(X)$ has the minimum group topology. Some, but not
all, oligomorphic groups have the minimum group topology.",91,6,589,53.0
1016,topology,"We investigate closed subsets (subsemigroups, resp.) of compact-like
topological spaces (semigroups, resp.). We prove that each Hausdorff
topological space can be embedded as a closed subspace into an H-closed
topological space. However, the semigroup of $\omega{\times\omega}$-matrix
units cannot be embedded into a topological semigroup which is a weakly
H-closed topological space. We show that each Hausdorff topological space is a
closed subspace of some $\omega$-bounded pracompact topological space and
describe open dense subspaces of countably pracompact topological spaces. Also,
we construct a pseudocompact topological semigroup which contains the bicyclic
monoid as a closed subsemigroup, providing a positive solution of a problem
posed by Banakh, Dimitrova, and Gutik.",107,8,783,36.49
1017,topology,"In this paper, we introduce the concept of weak fuzzy linear topology on a
fuzzy topological vector space as a generalization of usual weak topology. We
prove that this topology consists of all weakly lower semi-continuous fuzzy
sets on a given vector space when K (R or C) considered with its usual fuzzy
topology. In the case that the topology of K is different from the usual fuzzy
topology, we show that the weak fuzzy topology is not equivalent with the
topology of weakly lower semi-continuous fuzzy sets.",88,4,511,41.74
1018,topology,"This paper is devoted to the study of a natural group topology on the
fundamental group which remembers local properties of spaces forgotten by
covering space theory and weak homotopy type. It is known that viewing the
fundamental group as the quotient of the loop space often fails to result in a
topological group; we use free topological groups to construct a topology which
promotes the fundamental group of any space to topological group structure. The
resulting invariant, denoted $\pi_{1}^{\tau}$, takes values in the category of
topological groups, can distinguish spaces with isomorphic fundamental groups,
and agrees with the quotient fundamental group precisely when the quotient
topology yields a topological group. Most importantly, this choice of topology
allows us to naturally realize free topological groups and pushouts of
topological groups as fundamental groups via topological analogues of classical
results in algebraic topology.",142,5,951,18.52
1019,topology,"There are three important types of structural properties that remain
unchanged under the structural transformation of condensed matter physics and
chemistry. They are the properties that remain unchanged under the structural
periodic transformation-periodic properties. The properties that remain
unchanged under the structural multi scale transformation-fractal properties.
The properties that remain unchanged under the structural continuous
deformation transformation-topological properties. In this paper, we will
describe topological properties and characterizations in three layers: the
first layer is intuitive concept, characterizations and applications, the
second layer is logical physics understanding of topological properties,
characterizations and applications, and the third layer is the nature of
topological properties and its power. Duality and trinity are viewed as
intrinsically topological objects and are recognized as common knowledge shared
among human society activity, mathematics, physics, chemistry, biology and many
other kinds of nature science and technology. Some important methods used so
far to characterize the topological properties, including topological index,
topological order, topological invariant, topology class and the topology
partition are discussed. The theories of molecular topology, topological
quantum matter including topological insulators, topological metal and
topological superconductors and topological quantum computing are reviewed. The
development of the topological duality connection between the qubit and
singularity via topological space time is briefly introduced. We will see the
use of iterated function systems (IFS)to simulate the connection between
singularities and their qubit control codes. The novel applications of topology
in integrated circuits technology are also discussed in this paper.",241,12,1867,-1.52
1020,topology,"As a point of departure it is suggested that Quantum Cosmology is a
topological concept independent from metrical constraints. Methods of
continuous topological evolution and topological thermodynamics are used to
construct a cosmological model of the present universe, using the techniques
based upon Cartan's theory of exterior differential systems. Thermodynamic
domains, which are either Open, Closed, Isolated, or in Equilibrium, can be put
into correspondence with topological systems of Pfaff topological dimension 4,
3, 2 and 1. If the environment of the universe is assumed to be a physical
vacuum of Pfaff topological dimension 4, then continuous but irreversible
topological evolution can cause the emergence of topologically coherent defect
structures of Pfaff topological dimension less than 4. As galaxies and stars
exchange radiation but not matter with the environment, they are emergent
topological defects of Pfaff topological dimension 3 which are far from
equilibrium. DeRham topological theory of period integrals over closed but not
exact exterior differential systems leads to the emergence of quantized,
deformable, but topologically coherent, singular macrostates at all scales. The
method leads to the conjecture that dark matter and energy is represented by
those thermodynamic topological defect structures of Pfaff dimension 2 or less.",198,8,1364,17.37
1021,topology,Topological characterization of torus groups is given.,7,2,54,5.15
1022,topology,"We construct a topological invariant for a Morse-Smale flow on a 3-manifold
and prove that the flows are topologically equivalent iff their invariants are
same.",25,2,160,37.64
1023,topology,"We survey some properties of homotopical and homological $Z_n$-sets in
topological spaces.",12,2,90,8.53
1024,topology,"We present a necessary and sufficient condition for the topological
equivalence of a continuous function on a plane to a projection onto one of
coordinates.",25,2,156,29.18
1025,topology,"We determine the symmetrized topological complexity of the circle, using
primarily just general topology.",14,2,105,-1.96
1026,topology,"We study a topology on a space of functions, called sticking topology, with
the property to be the weakest among the topologies preserving continuity. In
suitable frameworks, this topology preserves borelianity, local integrability,
right continuity and other properties. It is coarser than the locally uniform
convergence and it allows the presence of gliding humps as we show on examples.
We prove relative compactness criteria for this topology and we consider some
extensions.",72,5,480,36.28
1027,topology,"By using topological current theory, we study the inner topological structure
of the topological defects in two-dimensional (2D) crystal. We find that there
are two elementary point defects topological current in two-dimensional
crystal, one for dislocations and the other for disclinations. The topological
quantization and evolution of topological defects in two-dimensional crystals
are discussed. Finally, We compare our theory with Brownian-dynamics
simulations in 2D Yukawa systems.",66,5,488,20.89
1028,topology,"Topological insulator is a recently discovered class of material with
topologically protected surface state. YbB6 is predicted to be moderately
correlated Z2 topological insulator similar to SmB6. Here, I experimentally
test the resistance property of bulk YbB6 to verify its topological property.
By changing the thickness of YbB6, I found out that although the data curves
did not completely conform to the theory of topology, the experimental
observation to the overall trend showed a similar topological phenomenon.",77,5,519,9.59
1029,topology,"In this paper, we will define $\mathcal{I}^{*}$-sequential topology on a
topological space $(X,\tau)$ where $\mathcal{I}$ is an ideal of the subset of
natural numbers $\mathbb{N}$. Besides the basic properties of the
$\mathcal{I}^{*}$-sequential topology, we proved that
$\mathcal{I}^{*}$-sequential topology is finer than $\mathcal{I}$-sequential
topology. Further, we will discus main properties of $\mathcal{I}^{*}$
sequential continuity and $\mathcal{I}^{*}$ sequential compactness.",57,4,486,26.81
1030,topology,"The equivariant movability of topological spaces with an action of a given
topological group $G$ is considered. In particular, the equivariant movability
of topological groups is studied. It is proved that a second countable group
$G$ is Lie if and only if it is equivariantly movable.",46,4,285,39.03
1031,topology,"We study algebraic properties of the Brandt $\lambda^0$-extensions of monoids
with zero and non-trivial homomorphisms between the Brandt
$\lambda^0$-extensions of monoids with zero. We introduce finite, compact
topological Brandt $\lambda^0$-extensions of topological semigroups and
countably compact topological Brandt $\lambda^0$-extensions of topological
inverse semigroups in the class of topological inverse semigroups and establish
the structure of such extensions and non-trivial continuous homomorphisms
between such topological Brandt $\lambda^0$-extensions of topological monoids
with zero. We also describe a category whose objects are ingredients in the
constructions of finite (compact, countably compact) topological Brandt
$\lambda^0$-extensions of topological monoids with zeros.",96,4,795,5.16
1032,topology,"D. K. Biss (Topology and its Applications 124 (2002) 355-371) introduced the
topological fundamental group and presented some interesting basic properties
of the notion. In this article we intend to extend the above notion to homotopy
groups and try to prove some similar basic properties of the topological
homotopy groups. We also study more on the topology of the topological homotopy
groups in order to find necessary and sufficient conditions for which the
topology is discrete. Moreover, we show that studying topological homotopy
groups may be more useful than topological fundamental groups.",92,7,599,31.21
1033,topology,"In this paper we study an s-wave topological SC with a square vortex-lattice.
We proposed a topological Majorana lattice model to describe this topological
state. We found that the Majorana lattice model is really a ""topological SC"" on
the parent topological SC. Such correspondence between the Majorana lattice
model and the topological SC with vortex-lattice is another holographic feature
of the topological state. In addition, the numerical calculations confirm our
theoretical prediction.",72,6,493,31.48
1034,topology,"Topological insulators are new states of quantum matter with metallic
edge/surface states. In this paper, we pointed out that there exists a new type
of particle-hole symmetry-protected topological insulator - topological
hierarchy insulator (THI), a composite topological state of a (parent)
topological insulator and its defect-induced topological mid-gap states. A
particular type of THI is topological fractal insulator, that is a THI with
self-similar topological structure. In the end, we discuss the possible
experimental realizations of THIs.",77,5,550,18.35
1035,topology,"A topological group $X$ is called $duoseparable$ if there exists a countable
set $S\subseteq X$ such that $SUS=X$ for any neighborhood $U\subseteq X$ of the
unit. We construct a functor $F$ assigning to each (abelian) topological group
$X$ a duoseparable (abelain-by-cyclic) topological group $FX$, containing an
isomorphic copy of $X$. In fact, the functor $F$ is defined on the category of
unital topologized magmas. Also we prove that each $\sigma$-compact locally
compact abelian topological group embeds into a duoseparable locally compact
abelian-by-countable topological group.",84,5,584,33.24
1036,topology,"Topological metals possess gapless band structures accompanied with
nontrivial edge states. Topological metals are created from the topological
insulators by adjusting the magnetic flux. Here we propose the time-reversal
symmetry protected topological metal without employing the magnetic flux.
Topological metallic phase presents although the Chern number vanishes. In the
topologically nontrivial phase, three different cases in the metallic phase are
distinguished from the band-touching and in-gap features of the topological
edge states. These findings shed light on the time-reversal symmetric
topological metals and greatly simplify the realization of topological metals.",90,7,678,22.41
1037,topology,"The article is devoted to a structure of topological spaces related with
topological quasigroups. Regular and complete spaces over topological
quasigroups are studied. Separations and embeddings are also investigated for
them. Their homeomorphisms and isomorphisms, relations between
compactifications and completeness are scrutinized over topological
quasigroups. There are investigated applications to families of maps over
topological quasigroups, restrictions of mappings, their openness, continuous
bijections. Necessary theorems about topological quasigroups are proved.",70,7,576,8.84
1038,topology,"The existence theorem for mapping cylinder neighborhoods is discussed as a
prototypical example of controlled topology and its applications. The first of
a projected series developed from lectures at the Summer School on
High-Dimensional Topology, Trieste Italy 2001",38,2,266,26.81
1039,topology,"We find some statements in the language of asymmetric topology and continuous
partial orders which are equivalent to the statements $\kappa < \mathfrak m$ or
$\kappa < \mathfrak p$.",29,2,181,35.61
1040,topology,"The topological index of a surface was previously introduced by the first
author as the topological analogue of the index of an unstable minimal surface.
Here we show that surfaces of arbitrarily high topological index exist.",36,3,225,27.83
1041,topology,"Nonstandard analysis is very complex, so finding a simple description of
infinitesimal points will be useful. In this paper, ultrafilters as
infinitesimal points in a topological space will be proposed, and some
topological concepts is restated by this tools.",39,3,259,26.3
1042,topology,"We give a ""limit-free formula"" simplifying the computation of the topological
entropy for topological automorphisms of totally disconnected locally compact
groups. This result allows us to extend several basic properties of the
topological entropy known to hold for compact groups.",40,3,281,17.34
1043,topology,"In this paper, inspired by the article [5], we introduce the induced
topological pressure for a topological dynamical system. In particular, we
prove a variational principle for the induced topological pressure.",31,3,211,21.9
1044,topology,"We observe a subtle and apparently generally unnoticed difficulty with the
definition of the relative topology on a subset of a topological space, and
with the weak topology defined by a function.",32,2,196,13.62
1045,topology,"In this paper, we prove that both topological Hochschild homology and
topological cyclic homology are sheaves for the fpqc topology on connective
commutative ring spectra, by exploiting the May filtration on topological
Hochschild homology.",34,2,240,11.59
1046,topology,"We define the smooth Lipschitz topology on the moduli space and show that
each conformal class is dense in the moduli space endowed with Gromov-Hausdorff
topology, which offers an answer to the Tuschmann's question.",34,2,215,45.43
1047,topology,"This paper proposes topologically sensitive metaheuristics, and describes
conceptual design of topologically sensitive Variable Neighborhood Search
method (TVNS) and topologically sensitive Electromagnetism Metaheuristic (TEM).",24,2,227,-29.03
1048,topology,"In this paper, it is proved that every topological gyrogroup $G$ is
topologically groupoid isomorphic to a closed subgyrogroup of a connected,
locally connected topological gyrogroup $G^{\bullet}$.",27,2,197,18.69
1049,topology,"This paper discusses the variational principles on subsets for topological
pressure and topological entropy of non-autonomous dynamical systems. We define
the Pesin-Pitskel topological pressure (weighted topological pressure) and the
Bowen topological entropy (weighted Bowen topological entropy) for any subset.
Also, we define the measure-theoretic pressure and the measure-theoretic lower
entropy for all Borel probability measures. Then, we prove variational
principles for topological pressure (topological entropy) which links the
Pesin-Pitskel topological pressure (weighted topological pressure) on an
arbitrary nonempty compact subset to the measure-theoretic pressure of Borel
probability measures for non-autonomous dynamical systems (which links the
Bowen topological entropy (weighted Bowen topological entropy) on an arbitrary
nonempty compact subset to the measure-theoretic lower entropy of Borel
probability measures for non-autonomous dynamical systems).
  Moreover, we show that the Pesin-Pitskel topological pressure (weighted
topological pressure) and the Bowen topological entropy (weighted Bowen
topological entropy) can be determined by the measure-theoretic pressure and
the measure-theoretic lower entropy of Borel probability measures,
respectively. These results extend Feng and Huang's results (Variational
principles for topological entropies of subsets, J. Funct. Anal. (2012)), Ma
and Wen's results (A Billingsley type theorem for Bowen entropy, Comptes Rendus
Mathematique (2008)), and Tang et al. results (Variational principle for
topological pressures on subsets, J. Math. Anal. Appl. (2015)) for classical
dynamical systems to pressures and entropies of non-autonomous dynamical
systems.",220,15,1724,12.87
1050,topology,"A homology and cohomology theory for topological quandles are introduced. The
relation between these (co)homology groups and quandle (co)homology groups are
studied. The 1 - topological quandle cocycles are used to compute state sum
invariants corresponding to knot diagrams.",39,4,275,16.28
1051,topology,"In this paper, we mainly investigate the conditions under which the Scott
topology on the product of two posets is equal to the product of the individual
Scott topologies and under which the Scott topology on a dcpo is sober. Some
such conditions are given.",45,3,257,57.1
1052,topology,"The breakdown of the bulk-boundary correspondence in non-Hermitian (NH)
topological systems is an open, controversial issue. In this paper, to resolve
this issue, we ask the following question: Can a (global) topological invariant
completely describe the topological properties of a NH system as its Hermitian
counterpart? Our answer is no. One cannot use a global topological invariant
(including non-Bloch topological invariant) to accurately characterize the
topological properties of the NH systems. Instead, there exist a new type of
topological invariants that are absence in its Hermitian counterpart -- the
state dependent topological invariants. With the help of the state-dependent
topological invariants, we develop a new topological theory for NH topological
system beyond the general knowledge for usual Hermitian systems and obtain an
exact formulation of the bulk-boundary correspondence, including
state-dependent phase diagram, state-dependent phase transition and anomalous
transport properties (spontaneous topological current). Therefore, these
results will help people to understand the exotic topological properties of
various non-Hermitian systems.",158,7,1171,6.44
1053,topology,"The paper develops a novel analysis of mutual interactions between topology
and soft topology. It is known that each soft topology produces a system of
crisp (parameterized) topologies. The other way round is also possible. Namely,
one can generate a soft topology from a system of crisp topologies. Different
methods of producing soft topologies are discussed by implementing two
formulas. Then, the relationships between the resulting soft topologies are
obtained. With the help of an example, it is demonstrated that one formula is
more constructible than the other. Now, it is reasonable to ask which
(topological) properties of a soft topology can be transferred to the set of
crisp topologies or the opposite. To address this question, we consider the
standard separation axioms and show how well these axioms can be preserved when
moving from a system of crisp topologies to the soft topology generated by it
and contrariwise. Additionally, our findings extend and disprove some results
from the literature.",160,11,1014,46.78
1054,topology,"The topological states of the two-leg and three-leg ladders formed by two
trivial quantum wires with different lattice constants are theoretically
investigated. For the symmetric nearest-neighbor intra-chain hopping two-leg
ladder, the inversion symmetry topological insulator phase with two degenerate
topological edge states appears. When the inversion symmetry is broken, the
topological insulators with one or two topological edge states of different
energies and topological metals with edge states embedded in the bulk states
could emerge dependent on the filling factor. The topological origin of these
topological states in the two-leg ladders is the topological properties of the
Chern insulators and Chern metals. According to the arrangement of two trivial
quantum wires, we construct two types of three-leg ladders. Each type of the
three-leg ladder could be divided into one trivial subspace and one topological
nontrivial subspace by unitary transformation. The topological nontrivial
subspace corresponds to the effective two-leg ladder model. As the filling
factor changes, the system could be in topological insulators or topological
metals phases. These rich topological states in the two-leg and three-leg
ladders could be confirmed by current experimental techniques.",183,10,1287,25.49
1055,topology,"Consider a set $M$ equipped with a structure $*$. We call a natural topology
$T_*$, on $(M,*)$, the topology induced by $*$. For example, a natural topology
for a metric space $(X,d)$ is a topology $T_d$ induced by the metric $d$ and
for a linearly ordered set $(X,<)$ a natural topology should be the topology
$T_<$ that is induced by the order $<$. This fundamental property, for a
topology to be called ""natural"", has been largely ignored while studying
topological properties of spacetime manifolds $(M,g)$ where $g$ is the Lorentz
""metric"", and the manifold topology $T_M$ has been used as a natural topology,
ignoring the spacetime ""metric"" $g$. In this survey we review critically
candidate topologies for a relativistic spacetime manifold, we pose open
questions and conjectures with the aim to establish a complete guide on the
latest results in the field, and give the foundations for future discussions.
We discuss the criticism against the manifold topology, a criticism that was
initiated by people like Zeeman, G\""obel, Hawking-King-McCarthy and others, and
we examine what should be meant by the term ""natural topology"" for a spacetime.
Since the common criticism against spacetime topologies, other than the
manifold topology, claims that there has not been established yet a physical
theory to justify such topologies, we give examples of seemingly physical
phenomena, under the manifold topology, which are actually purely effects
depending on the choice of the topology; the Limit Curve Theorem, which is
linked to singularity theorems in general relativity, and the Theorem of
Gao-Wald type of ""time dilation"" are such examples. }",261,8,1650,25.76
1056,topology,"One of the most significant breakthroughs in physics of the last decade has
been the discovery that materials with non-trivial topological properties for
electronic, electromagnetic, acoustic and mechanical responses can be designed
and manufactured at our will through engineered metamaterials (MMs). Here, we
review the foundation and the state-of-the-art advances of topological
photonics, acoustics and mechanical MMs. We discuss how topological MMs enable
nontrivial wave phenomena in physics, engineering, of great interest for a
broad range of interdisciplinary science disciplines such as classical and
quantum chemistry. We first introduce the foundations of topological materials
and the main concepts behind their peculiar features, including the concepts of
topological charge and geometric phase. We then discuss the topology of
electronic band structures in natural topological materials, like topological
insulators and gapless Dirac and Weyl semimetals. Based on these concepts, we
review the concept, design and response of topologically nontrivial MMs in
photonics and phononics, including topological phases in 2D MMs with and
without time-reversal symmetry, Floquet TIs based on spatial and temporal
modulation, topological phases in 3D MMs, higher-order topological phases in
MMs, non-Hermitian and nonlinear topological MMs and the topological features
of scattering anomalies. We also discuss the topological properties emerging in
other related contexts, such as the topological aspects of chemical reactions
and polaritons. This survey aims at connecting the recent advances in a broad
range of scientific areas associated with topological concepts, and highlights
opportunities offered by topological MMs for the chemistry community at large.",246,9,1768,6.37
1057,topology,"In the light of $\phi$-mapping method and topological current theory, the
topological structure and the topological quantization of arbitrary dimensional
topological defects are obtained under the condition that the Jacobian
$J(\phi/v) \neq 0$. When $J(\phi/v)=0$, it is shown that there exist the
crucial case of branch process. Based on the implicit function theorem and the
Taylor expansion, we detail the bifurcation of generalized topological current
and find different directions of the bifurcation. The arbitrary dimensional
topological defects are found splitting or merging at the degenerate point of
field function $\vec \phi$ but the total charge of the topological defects is
still unchanged.",102,5,704,28.67
1058,topology,"This is an account of one man's view of the current perspective of theory of
topological groups. We survey some recent developments which are, from our
viewpoint, indicative of the future directions, concentrating on actions of
topological groups on compacta, embeddings of topological groups, free
topological groups, and `massive' groups (such as groups of homeomorphisms of
compacta and groups of isometries of various metric spaces).",65,3,437,30.03
1059,topology,"In this paper, we introduce the foundation of a fractal topological space
constructed via a family of nested topological spaces endowed with subspace
topologies, where the number of topological spaces involved in this family is
related to the appearance of new structures on it. The greater the number of
topological spaces we use, the stronger the subspace topologies we obtain. The
fractal manifold model is brought up as an illustration of space that is
locally homeomorphic to the fractal topological space.",81,4,511,35.61
1060,topology,"We study spintronics and spincaloritronics in topological insulators. We show
spintronics effects in 2D topological insulator junctions and 3D topological
insulators coupled to ferromagnets. We also investigate spin polarization on
the surface of a topological insulator induced by a circularly polarized light
and refraction at the junction between two topological insulators. As for
spincaloritronics effects, we show transverse magnetic heat transport and
thermoelectric transport in topological insulators. Finite-size effect in
topological insulators and band structure engineering of interface states of
topological insulators are also discussed.",85,6,652,11.92
1061,topology,"The graph topology $\tau_{\Gamma}$ is the topology on the space $C(X)$ of all
continuous functions defined on a Tychonoff space $X$ inherited from the
Vietoris topology on $X\times \mathbb R$ after identifying continuous functions
with their graphs. It is shown that all completeness properties between
complete metrizability and hereditary Baireness coincide for the graph topology
if and only if $X$ is countably compact; however, the graph topology is
$\alpha$-favorable in the strong Choquet game, regardless of $X$. Analogous
results are obtained for the fine topology on $C(X)$. Pseudocompleteness, along
with properties related to 1st and 2nd countability of $(C(X),\tau_{\Gamma})$
are also investigated.",102,5,711,28.67
1062,topology,"We introduce some canonical topologies induced by actions of topological
groups on groups and rings. For $H$ being a group [or a ring] and $G$ a
topological group acting on $H$ as automorphisms, we describe the finest group
[ring] topology on $H$ under which the action of $G$ on $H$ is continuous. We
also study the introduced topologies in the context of Polish structures. In
particular, we prove that there may be no Hausdorff topology on a group $H$
under which a given action of a Polish group on $H$ is continuous.",92,5,521,56.59
1063,topology,"We study topological properties of phase transition points of topological
quantum phase transitions by assigning a topological invariant defined on a
closed circle or surface surrounding the phase transition point in the
parameter space of momentum and transition driving parameter. By applying our
scheme to the Su-Schrieffer-Heeger model and Haldane model, we demonstrate that
the topological phase transition can be well characterized by the defined
topological invariant of the transition point, which reflects the change of
topological invariants of topologically different phases across the phase
transition point.",87,3,620,1.94
1064,topology,"We study theoretically the topological quantum phase transition in Cavity QED
lattice. We predict the condition for non-topological phase to the topological
phase transition conditions for three different model Hamiltonians in cavity
QED lattice. We study these topological quantum phase transition through
winding number, which is a topological invariant quantity. We argue that the
appearance of topological phase in these systems where the discrete Z 2
symmetry broken. We show that the non-topological state is the vacuum state of
the system where each cavity contains fermionic type excitations from
light-matter interaction whereas the topological state of system contains
Majorana modes of excitations at the end cavity of the lattice.",109,6,742,23.97
1065,topology,"We study the topological band theory of time reversal invariant topological
insulators and interpret the topological $\mathbb{Z}_2$ invariant as an
obstruction in terms of Stiefel--Whitney classes. The band structure of a
topological insulator defines a Pfaffian line bundle over the momentum space,
whose structure group can be reduced to $\mathbb{Z}_2$. So the topological
$\mathbb{Z}_2$ invariant will be understood by the Stiefel--Whitney theory,
which detects the orientability of a principal $\mathbb{Z}_2$-bundle. Moreover,
the relation between weak and strong topological insulators will be understood
based on cobordism theory. Finally, the topological $\mathbb{Z}_2$ invariant
gives rise to a fully extended topological quantum field theory (TQFT).",102,6,758,16.93
1066,topology,"We characterize topological (and uniform) spaces whose free (locally convex)
topological vector spaces have a local $\mathfrak G$-base. A topological space
$X$ has a local $\mathfrak G$-base if every point $x$ of $X$ has a neighborhood
base $(U_\alpha)_{\alpha\in\omega^\omega}$ such that $U_\beta\subset U_\alpha$
for all $\alpha\le\beta$ in $\omega^\omega$. To construct $\mathfrak G$-bases
in free topological vector spaces, we exploit a new description of the topology
of a free topological vector space over a topological (or more generally,
uniform) space.",78,4,562,28.17
1067,topology,"Topological materials in crystal solids, including topological insulators
(TIs), topological crystalline insulators (TCIs), topological Dirac semimetals
(DSMs), topological Weyl semimetals (WSMs), topological Dirac or Weyl nodal
line semimetals (NLSMs) and beyond, are mainly featured with topological,
protected non-trivial surface states, and their bulk phases are insulators or
semimetals with the proper presence of Dirac cones, Weyl nodes or Dirac nodal
lines around the Fermi level. The author suggests a two-step computational
screening strategy of 3D topological materials by mixing chemistry with physics
with the considerations of fully filled bands and band inversion.",92,3,679,7.87
1068,topology,"Persistence modules are a central algebraic object arising in topological
data analysis. The notion of interleaving provides a natural way to measure
distances between persistence modules. We consider various classes of
persistence modules, including many of those that have been previously studied,
and describe the relationships between them. In the cases where these classes
are sets, interleaving distance induces a topology. We undertake a systematic
study the resulting topological spaces and their basic topological properties.",75,6,534,22.41
1069,topology,"Topological states of matter exhibit many novel properties due to the
presence of robust topological invariants such as the Chern index. These global
characteristics pertain to the system as a whole and are not locally defined.
However, local topological markers can distinguish between topological phases,
and they can vary in space. In equilibrium, we show that the topological marker
can be used to extract the critical behavior of topological phase transitions.
Out of equilibrium, we show that the topological marker spreads via a flow of
currents, with a bounded maximum propagation speed. We discuss the
possibilities for measuring the topological marker and its flow in experiment.",106,7,689,36.59
1070,topology,"We study the behavior of fermion spectral functions for the holographic
topological Weyl and nodal line semimetals. We calculate the topological
invariants from the Green functions of both holographic semimetals using the
topological Hamiltonian method, which calculates topological invariants of
strongly interacting systems from an effective Hamiltonian system with the same
topological structure. Nontrivial topological invariants for both systems have
been obtained and the presence of nontrivial topological invariants further
supports the topological nature of the holographic semimetals.",78,4,594,19.71
1071,topology,"We study algebraic and topological properties of subsemigroups of the
hyperspace exp(G) of non-empty compact subsets of a topological group G endowed
with the Vietoris topology and the natural semigroup operation. On this base we
prove that a compact Clifford topological semigroup S is topologically
isomorphic to a subsemigroup of exp(G) for a suitable topological group G if
and only if S is a topological inverse semigroup with zero-dimensional
idempotent semilattice.",71,3,472,18.52
1072,topology,"The exploration of topological superconductivity and Majorana zero modes has
become a rapidly developing field. Many types of proposals to realize
topological superconductors have been presented, and significant advances have
been recently made. In this review, we conduct a survey on the experimental
progress in possible topological superconductors and induced superconductivity
in topological insulators or semimetals as well as artificial structures. The
approaches to inducing superconductivity in topological materials mainly
include high pressure application, the hard-tip point contact method, chemical
doping or intercalation, the use of artificial topological superconductors, and
electric field gating. The evidence supporting topological superconductivity
and signatures of Majorana zero modes are also discussed and summarized.",109,6,840,-1.42
1073,topology,"In this paper we give conditions under which a topological semigroup can be
embedded algebraically and topologically into a compact topological group. We
prove that every feebly compact regular first countable cancellative
commutative topological semigroup with open shifts is a topological group, as
well as every connected locally compact Hausdorff cancellative commutative
topological monoid with open shifts. Finally, we use these results to give
sufficient conditions on a topological semigroup that guarantee it to have
countable cellularity.",77,4,548,11.55
1074,topology,"Digital topology has its own working conditions and sometimes differs from
the normal topology. In the area of topological robotics, we have important
counterexamples in this study to emphasize this red line between a digital
image and a topological space. We indicate that the results on topological
complexities of certain path-connected topological spaces show alterations in
digital images. We also give a result about the digital topological complexity
number using the genus of a digital surface in discrete geometry.",79,5,523,26.0
1075,topology,"In this paper, we examine the relations of two closely related concepts, the
digital Lusternik-Schnirelmann category and the digital higher topological
complexity, with each other in digital images. For some certain digital images,
we introduce $\kappa-$topological groups in the digital topological manner for
having stronger ideas about the digital higher topological complexity. Our aim
is to improve the understanding of the digital higher topological complexity.
We present examples and counterexamples for $\kappa-$topological groups.",73,5,540,10.6
1076,topology,"A topological space $L$ is called a linear ordered topological space (LOTS)
whenever there is a linear order $\leq$ on $L$ such that the topology on $L$ is
generated by the open sets of the form $(a, b)$ with $a < b$ and $a, b \in L
\cup \{ -\infty, +\infty \}$. A topological space $X$ is called a generalized
ordered space (GO-space) whenever $X$ is topologically embeddable in a LOTS.
Main Theorem: Let $X$ be a Hausdorff topological space. Assume that any
continuous image of $X$ is a GO-space. Then $X$ is homeomorphic to a countable
successor ordinal (with the order topology).
  The converse trivially holds.",107,7,615,53.92
1077,topology,"A class of topological spaces is topologically rigid if any two spaces with
the same fundamental group are also homeomorphic. Topological rigidity, in
addition to its intrinsic interest, has been useful for solving abstract
commensurability questions. In this paper, we explore the topological rigidity
of quotients of the Davis complex of certain right angled Coxeter groups by
providing conditions on the defining graphs that obstruct topological rigidity.
Furthermore, we explore why topological rigidity is hard to achieve for
quotients of the Davis complex. Nonetheless, we conclude by introducing
infinitely many infinite topologically rigid subclasses.",94,6,659,27.01
1078,topology,"Topological defects are found in a variety of systems, and their existence
are robust under perturbations due to their topological nature. Here we
introduce a new type of topological defects found in electromagnetic waves:
topological spin defects. Such a defect is associated with a point where the
electromagnetic spin density is zero, and generically have a nontrivial
topological spin texture surrounding the defect point. Due to such spin
texture, a topological spin defect possesses a quantized topological charge. We
provide examples where isolated defect point, periodic or quasi-periodic defect
lattices can be created. Such topological spin defect points may find
applications in 3D imaging and nanoparticle manipulation.",107,7,731,28.03
1079,topology,"The concept of $typed$ $topology$ is introduced. In a typed topological
space, some open sets are assigned ""types"", and topological concepts such as
closure, connectedness can be defined using types. A finite data set in $R^2$
is a typically typed topological space. Clusters calculated by the DBSCAN
algorithm for data clustering can be well represent in a finite typed
topological space. Other concepts such as tracks, port (starting points),
type-p-connectedness, p-closure-connectedness, indexing, branches are also
introduced for a finite typed topological space. Finally, $left-r$ and
$up-left-r$ type open sets are introduced for data sets in $R^2$, so that
tracks, port, branches can be calculated.",104,7,706,45.46
1080,topology,"If $R$ is a topological ring, then it is well known that $R^{\ast}$, the
group of units of $R$, with the subspace topology is not necessarily a
topological group. This fact first leads us to a natural definition: By an
\emph{absolute topological ring} we mean a topological ring such that its group
of units with the subspace topology is a topological group. We prove that every
commutative ring with the $I$-adic topology is an absolute topological ring.
Next we show that for a given topological ring $R$ then $R^{\ast}$ with the
subspace topology $\mathscr{T}$ is a topological group (or equivalently, $R$ is
an absolute topological ring) if and only if $\mathscr{T}=\mathscr{T}_{f}$
where the topology $\mathscr{T}_{f}$ over $R^{\ast}$ is induced by the map
$R^{\ast}\rightarrow R\times R$ which is given by $a\mapsto(a,a^{-1})$. If $G$
is a topological group then every monomial function $G^{n}\rightarrow G$ as
well as if $R$ is a topological ring then every polynomial function
$R^{n}\rightarrow R$ are continuous. In particular, the Boolean ring of every
topological ring with the subspace topology is a topological ring. We prove
that for the $I$-adic topology over a ring $R$, then
$\pi_{0}(R)=R/(\bigcap\limits_{n\geqslant1}I^{n})=t(R)$ where $\pi_{0}(R)$ is
the space of connected components of $R$ and $t(R)$ is the space of irreducible
closed subsets of $R$. We show that if the identity element of a topological
group is dense, then its topology is trivial. As a consequence, a normal
subgroup of a topological group is dense if and only if the topology of the
quotient group is trivial. Finally, we realized that the main result of Koh
\cite{kwangil} as well as its corrected version \cite[Chap II, \S12, Theorem
12.1]{Ursul} are not true, then we corrected this result in the right way.",285,12,1803,45.19
1081,topology,"The topological fundamental group $\pi_{1}^{top}$ is a homotopy invariant
finer than the usual fundamental group. It assigns to each space a
quasitopological group and is discrete on spaces which admit universal covers.
For an arbitrary space $X$, we compute the topological fundamental group of the
suspension space $\Sigma(X_+)$ and find that $\pi_{1}^{top}(\Sigma(X_+))$
either fails to be a topological group or is the free topological group on the
path component space of $X$. Using this computation, we provide an abundance of
counterexamples to the assertion that all topological fundamental groups are
topological groups. A relation to free topological groups allows us to reduce
the problem of characterizing Hausdorff spaces $X$ for which
$\pi_{1}^{top}(\Sigma(X_+))$ is a Hausdorff topological group to some well
known classification problems in topology.",125,6,866,29.18
1082,topology,"Conformational transitions are ubiquitous in biomolecular systems, have
significant functional roles and are subject to evolutionary pressures. Here we
provide a first theoretical framework for topological transition, i.e.
conformational transitions that are associated with changes in molecular
topology. For folded linear biomolecules, arrangement of intramolecular
contacts is identified as a key topological property, termed as circuit
topology. Distance measures are proposed as reaction coordinates to represent
progress along a pathway from initial topology to final topology. Certain
topological classes are shown to be more accessible from a random topology. We
study dynamic stability and pathway degeneracy associated with a topological
reaction and found that off-pathways might seriously hamper evolution to
desired topologies. Finally we present an algorithm for estimating the number
of intermediate topologies visited during a topological reaction. The results
of this study are relevant to, among others, structural studies of RNA and
proteins, analysis of topologically associated domains in chromosomes, and
molecular evolution.",155,11,1147,11.72
1083,topology,"Periodically driven (Floquet) systems have been under active theoretical and
experimental investigations. This paper aims at a systematic study in the
following aspects of Floquet systems: (i) A systematic formulation of
topological invariants of Floquet systems based on the cooperation of topology
and symmetries. Topological invariants are constructed for the ten symmetry
classes in all spatial dimensions, for both homogeneous Floquet systems
(Floquet topological insulators and superconductors) and Floquet topological
defects. Meanwhile, useful representative Dirac Hamiltonians for all the
symmetry classes are obtained and studied. (ii) A general theory of Floquet
topological defects, based on the proposed topological invariants. (iii) Models
and proposals of Floquet topological defects in low dimensions. Among other
defect modes, we investigate Floquet Majorana zero modes and Majorana Pi modes
in vortices of topologically trivial superconductors under a periodic drive. In
addition, we clarified several notable issues about Floquet topological
invariants. Among other issues, we prove the equivalence between the
effective-Hamiltonian-based band topological invariants and the
frequency-domain band topological invariants.",164,10,1239,2.24
1084,topology,"We investigate semigroup topologies on the full transformation monoid T(X) of
an infinite set X. We show that the standard pointwise topology is the weakest
Hausdorff semigroup topology on T(X), show that the pointwise topology is the
unique Hausdorff semigroup topology on T(X) that induces the pointwise topology
on the group of all permutations of X, and construct |X| distinct Hausdorff
semigroup topologies on T(X). In the case where X is countable, we prove that
the pointwise topology is the only Polish semigroup topology on T(X). We also
show that every separable semigroup topology on T(X) is perfect, describe the
compact sets in an arbitrary Hausdorff semigroup topology on T(X), and show
that there are no locally compact perfect Hausdorff semigroup topologies on
T(X) when |X| has uncountable cofinality.",129,5,818,38.69
1085,topology,"Topological interference management (TIM) can obtain degrees of freedom (DoF)
gains with no channel state information at the transmitters (CSIT) except
topological information of network in the interference channel. It was shown
that TIM achieves the optimal symmetric DoF when internal conflict does not
exist among messages. However, it is difficult to assure whether a specific
topology can achieve the optimal DoF without scrutinizing internal conflict,
which requires lots of works. Also, it is hard to design a specific optimal
topology directly from the conventional condition for the optimal DoF. With
these problems in mind, we propose a method to derive maximal topology directly
in TIM, named as alliance construction in K-user interference channel. That is,
it is proved that a topology is maximal if and only if it is derived from
alliance construction. We translate a topology design by alliance construction
in message graph into topology matrix and propose conditions for maximal
topology matrix (MTM). Moreover, we propose a generalized alliance construction
that derives a topology achieving DoF 1/n for n>=3 by generalizing
sub-alliances. A topology matrix can also be used to analyze maximality of
topology with DoF 1/n.",190,10,1240,33.14
1086,topology,"Topological measures and quasi-linear functionals generalize measures and
linear functionals. We define and study deficient topological measures on
locally compact spaces. A deficient topological measure on a locally compact
space is a set function on open and closed subsets which is finitely additive
on compact sets, inner regular on open sets, and outer regular on closed sets.
Deficient topological measures generalize measures and topological measures.
First we investigate positive, negative, and total variation of a signed set
function that is only assumed to be finitely additive on compact sets. These
positive, negative, and total variations turn out to be deficient topological
measures. Then we examine finite additivity, superadditivity, smoothness, and
other properties of deficient topological measures. We obtain methods for
generating new deficient topological measures. We provide necessary and
sufficient conditions for a deficient topological measure to be a topological
measure and to be a measure. The results presented are necessary for further
study of topological measures, deficient topological measures, and
corresponding non-linear functionals on locally compact spaces.",168,11,1200,20.58
1087,topology,"Separability is one of the most basic and important topological properties.
In this paper, the separability in (strongly) topological gyrogroups is
studied. It is proved that every first-countable left {\omega}-narrow strongly
topological gyrogroup is separable. Furthermore, it is shown that if a
feathered strongly topological gyrogroup G is isomorphic to a subgyrogroup of a
separable strongly topological gyrogroup, then G is separable. Therefore, if a
metrizable strongly topological gyrogroup G is isomorphic to a subgyrogroup of
a separable strongly topological gyrogroup, then G is separable, and if a
locally compact strongly topological gyrogroup G is isomorphic to a
subgyrogroup of a separable strongly topological gyrogroup, then G is
separable.",109,6,758,15.51
1088,topology,"There are two prominent applications of the mathematical concept of topology
to the physics of materials: band topology, which classifies different
topological insulators and semimetals, and topological defects that represent
immutable deviations of a solid lattice from its ideal crystalline form. While
these two classes of topological phenomena have generally been treated as
separate topics, recent experimental advancements have begun to probe their
intricate and surprising interactions, in real materials as well as synthetic
metamaterials. Topological lattice defects in topological materials offer a
platform to explore a diverse range of novel phenomena, such as topological
pumping via topological defects, embedded topological phases, synthetic
dimensions, and non-Hermitian skin effects. In this Perspective, we survey the
developments in this rapidly moving field, and give an outlook of its impact on
materials science and applications.",132,5,951,-4.33
1089,topology,"We elaborate that for topological insulators and topological superconductors
described by Dirac models in any dimension and symmetry class, the topological
order can be mapped to lattice sites by a universal topological marker.
Deriving from a recently discovered momentum-space universal topological
invariant, we introduce a topological operator that consists of alternating
projectors to filled and empty lattice eigenstates and the position operators,
multiplied by the Dirac matrices that are omitted in the Hamiltonian. The
topological operator projected to lattice sites yields the topological marker,
whose form is explicitly constructed for every topologically nontrivial
symmetry class from 1D to 3D. The off-diagonal elements of the topological
operator yields a nonlocal topological marker, which decays with a correlation
length that diverges at topological phase transitions, and represents a Wannier
state correlation function. Various prototype examples, including
Su-Schrieffer-Heeger model, Majorana chain, Chern insulators,
Bernevig-Hughes-Zhang model, 2D chiral and helical $p$-wave superconductors,
lattice model of $^{3}$He B-phase, and 3D time-reversal symmetric topological
insulators, etc, are employed to demonstrate the ubiquity of our formalism.",169,6,1273,-5.14
1090,topology,"Topological insulators are characterized by insulating bulk and conducting
surface, the latter is a necessity consequence of the nontrivial topology of
the wavefunctions forming the valence band. This chapter gives a historical
overview of the discovery of topological insulators and a concise description
of the $Z_2$ topology which defines them. The concept of topological insulators
have been extended to various other topologies, giving rise to the recognition
of further topological states of matter such as topological crystalline
insulators and higher-order topological insulators. Representative materials of
topological insulators, their synthesis techniques, and the ways for the
experimental confirmation of the topological nature are introduced. Among the
interesting phenomena derived from topological insulators, topological
superconductivity, Majorana zero modes, and quantum anomalous Hall effect are
briefly discussed.",124,6,935,4.0
1091,topology,"Non-Hermiticity leads to distinctive topological phenomena absent in
Hermitian systems. However, connection between such intrinsic non-Hermitian
topology and Hermitian topology has remained largely elusive. Here, considering
the bulk and boundary as an environment and system, we demonstrate that
anomalous boundary states in Hermitian topological insulators exhibit
non-Hermitian topology. We study the self-energy capturing the particle
exchange between the bulk and boundary, and demonstrate that it detects
Hermitian topology in the bulk and induces non-Hermitian topology at the
boundary. As an illustrative example, we show the non-Hermitian topology and
concomitant skin effect inherently embedded within chiral edge states of Chern
insulators. We also find the emergence of hinge states within effective
non-Hermitian Hamiltonians at surfaces of three-dimensional topological
insulators. Furthermore, we comprehensively classify our correspondence across
all the tenfold symmetry classes of topological insulators and superconductors.
Our work uncovers a hidden connection between Hermitian and non-Hermitian
topology, and provides an approach to identifying non-Hermitian topology in
quantum matter.",157,9,1208,9.28
1092,topology,"We study the interplay between three weak topologies on a topological
semilattice $X$: the weak$^\circ$ topology $\mathcal W^\circ_X$ (generated by
the base consiting of open subsemilattices of $X$), the weak$^\bullet$ topology
$\mathcal W^\bullet_X$ (generated by the subbase consisting of complements to
closed subsemilattices), and the $\mathbb I$-weak topology $\mathcal W_X$
(which is the weakest topology in which all continuous homomorphisms $h:X\to
[0,1]$ remain continuous). Also we study the interplay between the weak
topologies $\mathcal W^\bullet_X$, $\mathcal W^\circ_X$, $\mathcal W_X$ of a
topological semilattice $X$ and the Scott and Lawson topologies $\mathcal S_X$
and $\mathcal L_X$, which are determined by the order structure of the
semilattice.
  We prove that the weak$^\bullet$ topology $\mathcal W^\bullet$ on a Hausdorff
semitopological semilattice $X$ is compact if and only if $X$ is chain-compact
in the sense that each closed chain in $X$ is compact. This result implies that
the Lawson topology $\mathcal L_X$ on a semilattice $X$ is compact if and only
if $X$ is a continuous semilattice if and only if $X$ complete in the sense
that each non-empty chain $C$ in $X$ has $\inf(C)$ and $\sup(C)$ in $X$.
  For a chain-compact Hausdorff topological semilattice $X$ with topology
$\mathcal T_X$ we prove the inclusions $\mathcal W_X\subset\mathcal
L_X\subset\mathcal W^\bullet_X\subset\mathcal T_X$. For a compact topological
semilattice $X$ we prove that $\mathcal T_X=\mathcal W^\bullet_X$ if and only
if $\mathcal T_X=\mathcal L_X$ if and only if $\mathcal T_X=\mathcal L_X$.",231,7,1608,23.94
1093,topology,"The past decade has witnessed significant progress in topological materials
investigation. Symmetry-indicator theory and topological quantum chemistry
provide an efficient scheme to diagnose topological phases from only partial
information of wave functions without full knowledge of topological invariants,
which has resulted in a recent comprehensive materials search. However, not all
topological phases can be captured by this framework, and topological
invariants are needed for a more refined diagnosis of topological phases. In
this study, we present a systematic framework to construct topological
invariants for a large part of symmetry classes, which should be contrasted
with the existing invariants discovered through one-by-one approaches. Our
method is based on the recently developed Atiyah-Hirzebruch spectral sequence
in momentum space. As a demonstration, we construct topological invariants for
time-reversal symmetric spinful superconductors with conventional pairing
symmetries of all space groups, for which symmetry indicators are silent. We
also validate that the obtained quantities work as topological invariants by
computing them for randomly generated symmetric Hamiltonians. Remarkably, the
constructed topological invariants completely characterize $K$-groups in 159
space groups. Our topological invariants for normal conducting phases are
defined under some gauge conditions. To facilitate efficient numerical
simulations, we discuss how to derive gauge-independent topological invariants
from the gauge-fixed topological invariants through some examples. Combined
with first-principles calculations, our results will help us discover
topological materials that could be used in next-generation devices and pave
the way for a more comprehensive topological materials database.",237,12,1808,7.35
1094,topology,"This note contains preliminary calculation of topological types or real
Enriques surfaces. We realize 59 topological types of real Enriques surfaces
(Theorem 6) and show that all other topological types belong to the list of 21
topological types (Theorem 7). In fact, our calculation contains much more
information which is probably useful to constract or prohibit unknown
topological types.",59,4,391,34.56
1095,topology,"The density topology $\cal T$ is a topology on the real line, finer than the
usual topology, having as its open sets the measurable subsets of ${\mathbb
R}$, which are of density 1 at each of their points. The aim of this paper is
to determine which subsets of the density topology are semi-stratifiable,
orthocompact and weakly hereditarily pseudocompact.",59,3,356,33.07
1096,topology,"We comment van Douwen's problems on the Bohr topology of the abelian groups
raised in his paper (The maximal totally bounded group topology on G and the
biggest minimal G-space for Abelian groups G) as well as the steps in the
solution of some of them. New solutions to two of the resolved problems are
also given.",57,3,314,59.47
1097,topology,"This collection of thirty two reviewed articles covers several fields of
General Topology. Several contributions represent invited presentations at the
Ninth Prague Topological Symposium.",24,3,187,0.08
1098,topology,"We introduce a notion of topological quandle. Given a topological quandle $Q$
we associate to every classical link $L$ in $\R ^3$ an invariant $J_Q(L)$ which
is a topological space (defined up to a homeomorphism). The space $J_Q(L)$ can
be interpreted as a space of colourings of a diagram of the link $L$ with
colours from the quandle $Q$.",59,4,340,51.48
1099,topology,"We generalize various notions of stability of invariant sets of dynamical
systems to invariant measures, by defining a topology on the set of measures.
The defined topology is similar, but not topologically equivalent to weak*
topology, and it also differs from topologies induced by the Riesz
Representation Theorem. It turns out that the constructed topology is a
solution of a limit case of a $p$-optimal transport problem, for $p=\infty$.",69,4,442,31.21
1100,topology,"This paper studies the C-compact-open topology on the set C(X) of all
realvalued continuous functions on a Tychonov space X and compares this
topology with several well-known and lesser known topologies. We investigate
the properties C-compact-open topology on the set C(X) such as submetrizable,
metrizable, separable and second countability.",49,3,343,29.69
1101,topology,"In this work, we will introduce the notion of generalized topological groups
using generalized topological structure and generalized continuity defined by
?A. Cs?asz?ar [2]. We will discuss some basic properties of this kind of
structures and connectedness properties of this structures are given. Keywords:
Generalized topology; generalized continuity; generalized topological groups;
generalized connectedness.",53,5,412,11.21
1102,topology,"We show that the strong operator topology, the weak operator topology and the
compact-open topology agree on the space of unitary operators of a infinite
dimensional separable Hilbert space. Moreover, we show that the unitary group
endowed with any of these topologies is a Polish group.",46,3,287,39.67
1103,topology,"Topological entropy is a widely studied indicator of chaos in topological
dynamics. Here we give a generalized definition of topological entropy which
may be applied to set-valued functions. We demonstrate that some of the
well-known results concerning topological entropy of continuous (single-valued)
functions extend naturally to set-valued functions while others must be
altered. We also present sufficient conditions for a set-valued function to
have positive or infinite topological entropy.",69,5,497,20.08
1104,topology,"Dynamic Topological Logic ($\mathcal{DTL}$) is a combination of
$\mathcal{S}${\em 4}, under its topological interpretation, and the temporal
logic $\mathcal{LTL}$ interpreted over the natural numbers. $\mathcal{DTL}$ is
used to reason about properties of dynamical systems based on topological
spaces. Semantics are given by dynamic topological models, which are tuples
$\left <X,\mathcal{T},f,V\right >$, where $\left <X,\mathcal{T}\right >$ is a
topological space, $f$ a function on $X$ and $V$ a truth valuation assigning
subsets of $X$ to propositional variables.",76,4,567,21.02
1105,topology,"These lecture notes on entanglement in topological systems are part of the
48th IFF Spring School 2017 on Topological Matter: Topological Insulators,
Skyrmions and Majoranas at the Forschungszentrum Juelich, Germany. They cover a
short discussion on topologically ordered phases and review the two main tools
available for detecting topological order - the entanglement entropy and the
entanglement spectrum.",58,3,408,25.63
1106,topology,"The aim of this article is to review different generalizations of the the
notion of topological complexity to the equivariant setting. In particular, we
review the relation (or non-relation) between these notions and the topological
complexity of the quotient space and the topological complexity of the fixed
point sets. We give examples of calculations and stress the question: When the
action is free, do we recover the topological complexity of the quotient?",72,3,462,30.2
1107,topology,"The free topological vector space (tvs) $\mathbb{V}(X)$ over a Tychonoff
space $X$ is defined and studied by Sidney A. Morris and the author in [2]. A
description of the topology of the free tvs $\mathbb{V}(X)$ over a uniform
space $X$ is given in [1]. In this note we give a similar but simpler and
clearer description of the topology of free tvs $\mathbb{V}(X)$ over a
Tychonoff space $X$.",68,5,391,62.68
1108,topology,"In this paper, we find at the properties of the family lambda which imply
that the function space C(X,R^alpha) with the lambda-open topology is a
semitopological group (paratopological group, topological group, topological
vector space and other algebraic structures) under the usual operations of
addition and multiplication (and multiplication by scalars).",50,2,358,-4.66
1109,topology,"In this study, we improve the topological complexity computations on digital
images with introducing the digital topological complexity computations of a
surjective and digitally continuous map between digital images. We also reveal
differences in topological complexity computations of maps between digital
images and topological spaces. Moreover, we emphasize the importance of the
adjacency relation on the domain and the range of a digital map in these
computations.",67,4,470,6.54
1110,topology,"A continuous cohomology theory for topological quandles is introduced, and
compared to the algebraic theories. Extensions of topological quandles are
studied with respect to continuous 2-cocycles, and used to show the differences
in second cohomology groups for specific topological quandles. A method of
computing the cohomology groups of the inverse limit is applied to quandles.",55,4,381,19.06
1111,topology,"In this paper, we introduce statistical bounded set on topological vector
space. Also, we consider three classes of bounded operators from topological
vector spaces to ordered topological vector spaces. Moreover, we give relations
between them and order bounded operators. We give algebraic properties of these
operators concerning to the uniform convergence topology.",52,5,368,24.44
1112,topology,"In this article topologies on metagroups are studied. They are related with
generalized $C^*$-algebras over ${\bf R}$ or ${\bf C}$. Homomorphisms and
quotient maps on them are investigated. Structure of topological metagroups is
scrutinized. In particular, topologies on smashed products and smashed twisted
wreath products of metagroups are scrutinized, which are making them
topological metagroups. Moreover, their inverse homomorphism systems are
studied.",62,7,458,44.1
1113,topology,"We provide a formal introduction into the classic theorems of general
topology and its axiomatic foundations in set theory. In this second part we
introduce the fundamental concepts of topological spaces, convergence, and
continuity, as well as their applications to real numbers. Various methods to
construct topological spaces are presented.",50,4,343,20.68
1114,topology,"Weak topologies that yield weak convergence for bounded sequences and nets in
CAT($0$) spaces have been studied in the past. We are here concerned with weak
topologies that yield weak convergence of unbounded sequences and nets. We
analyze two such topologies that generalize the weak topology on Hilbert spaces
and that agree with the strong topology on a CAT($0$) space if and only if the
space is locally compact.",69,4,416,65.05
1115,topology,"We prove Farber's conjecture on the stable topological complexity of
configuration spaces of graphs. The conjecture follows from a general lower
bound derived from recent insights into the topological complexity of
aspherical spaces. Our arguments apply equally to higher topological
complexity.",41,4,295,15.27
1116,topology,"We study topological groups of monotonic autohomeomorphisms on a generalized
ordered space $L$. We find a condition that is necessary and sufficient for the
set of all monotonic autohomeomorphisms on $L$ along with the function
composition and the topology of point-wise convergence to be a topological
group.",47,3,309,30.7
1117,topology,"The discovery of the topological insulators has fueled a surge of interests
in the topological phases in periodic systems. Topological insulators have bulk
energy gap and topologically protected gapless edge states. The edge states in
electronic systems have been detected by observing the transport properties the
Hgte quantum wells. The electromagnetic analogues of such electronic edge
states have been predicted and observed in photonic crystals, coupled
resonators and linear circuits. However, the edge state spectrums of the two
dimensional insulators and their electromagnetic analogues haven't been
directly measured and thus the gaplessness of the edge states hasn't been
experimentally confirmed. Here I show the classical strings are more convenient
choice to study the topological phases than the electromagnetic waves. I found
that classical strings with periodic densities can simulate a variety of
topological phases in condensed matter physics including two dimensional
topological insulators, three dimensional topological semimetals and weak
topological insulators. Because the eigenfrequencies and eigenfunctions of the
strings can be easily measured, not only the gapless edge state spectrum but
also the bulk topological invariant can now be directly observed. Further more
I show the topological phase transitions can be simulated by the strings. My
results show the richness of topological phases of mechanical waves. I
anticipate my work to be a starting point to study the topological properties
of mechanical waves. Even richer topological phases other than those have been
found in electronics systems can be explored when we use more general
mechanical waves e.g. waves in membranes with periodic densities. These phases
may provide guides to hunt novel topological properties in other branches of
science.",268,16,1835,35.17
1118,topology,"We investigate weak and strong structures for generalized topological spaces,
among others products, sums, subspaces, quotients, and the complete lattice of
generalized topologies on a given set. Also we introduce $T_{3.5}$ generalized
topological spaces and give a necessary and sufficient condition for a
generalized topological space to be a $T_{3.5}$ space: they are exactly the
subspaces of powers of a certain natural generalized topology on $[0,1]$. For
spaces with at least two points here we can have even dense subspaces. Also,
$T_{3.5}$ generalized topological spaces are exactly the dense subspaces of
compact $T_4$ generalized topological spaces. We show that normality is
productive for generalized topological spaces. For compact generalized
topological spaces we prove the analogue of the Tychonoff product theorem. We
prove that also Lindel\""ofness (and $\kappa $-compactness) is productive for
generalized topological spaces. On any ordered set we introduce a generalized
topology and determine the continuous maps between two such generalized
topological spaces: for $|X|, |Y| \ge 2$ they are the monotonous maps
continuous between the respective order topologies. We investigate the relation
of sums and subspaces of generalized topological spaces to ways of defining
generalized topological spaces.",189,13,1319,28.64
1119,topology,"Bayesian Markov chain Monte Carlo explores tree space slowly, in part because
it frequently returns to the same tree topology. An alternative strategy would
be to explore tree space systematically, and never return to the same topology.
In this paper, we present an efficient parallelized method to map out the high
likelihood set of phylogenetic tree topologies via systematic search, which we
show to be a good approximation of the high posterior set of tree topologies.
Here `likelihood' of a topology refers to the tree likelihood for the
corresponding tree with optimized branch lengths. We call this method
`phylogenetic topographer' (PT). The PT strategy is very simple: starting in a
number of local topology maxima (obtained by hill-climbing from random starting
points), explore out using local topology rearrangements, only continuing
through topologies that are better than than some likelihood threshold below
the best observed topology. We show that the normalized topology likelihoods
are a useful proxy for the Bayesian posterior probability of those topologies.
By using a non-blocking hash table keyed on unique representations of tree
topologies, we avoid visiting topologies more than once across all concurrent
threads exploring tree space. We demonstrate that PT can be used directly to
approximate a Bayesian consensus tree topology. When combined with an accurate
means of evaluating per-topology marginal likelihoods, PT gives an alternative
procedure for obtaining Bayesian posterior distributions on phylogenetic tree
topologies.",231,11,1556,39.57
1120,topology,"Topological photonics has received extensive attention from researchers
because it provides brand new physical principles to manipulate light. Band
topology of optical materials is characterized using the Berry phase defined by
Bloch states. Until now, the criteria for experimentally probing the
topological phase transition of band topology has always been relatively
lacking in topological physics. Moreover, radiation topology can be aroused by
the far-field polarizations of the radiating Bloch states, which is described
by the Stokes phase. Although such two types of topologies are both related to
Bloch states on the band structure, it is rather surprising that their
development is almost independent. Here, we reveal that the phase transition of
band topology can be probed by the radiation topology. We theoretically design
and experimentally demonstrate such an intriguing phenomenon by constructing
photonic crystals that support optical analogs of quantum spin Hall effects.
The results show that the topological charge of the far-field polarization
vortex changes from +1 to -2 or from -2 to +1 when the band topology changes
from trivial to non-trivial, which provides a new criterion to probe the phase
transition of band topology using radiation topology. Our findings not only
provide an insightful understanding of band topology and radiation topology,
but also can serve as a novel route to manipulate the near and far fields of
light.",221,10,1457,29.59
1121,topology,"Universal topological data of topologically ordered phases can be captured by
topological quantum field theory in continuous space time by taking the limit
of low energies and long wavelengths. While previous continuum
field-theoretical studies of topological orders in $3$D real space focus on
either self-statistics, braiding statistics, shrinking rules, fusion rules or
quantum dimensions, it is yet to systematically put all topological data
together in a unified continuum field-theoretical framework. Here, we construct
the topological $BF$ field theory with twisted terms (e.g., $AAdA$ and $AAB$)
as well as a $K$-matrix $BB$ term, in order to simultaneously explore all such
topological data and reach anomaly-free topological orders. Following the
spirit of the famous $K$-matrix Chern-Simons theory of $2$D topological orders,
we present general formulas and systematically show how the $K$-matrix $BB$
term confines topological excitations, and how self-statistics of particles is
transmuted between bosonic one and fermionic one. In order to reach
anomaly-free topological orders, we explore, within the present continuum
field-theoretical framework, how the principle of gauge invariance
fundamentally influences possible realizations of topological data. More
concretely, we present the topological actions of (i) particle-loop braidings
with emergent fermions, (ii) multiloop braidings with emergent fermions, and
(iii) Borromean-Rings braidings with emergent fermions, and calculate their
universal topological data. Together with the previous efforts, our work paves
the way toward a more systematic and complete continuum field-theoretical
analysis of exotic topological properties of $3$D topological orders. Several
interesting future directions are also discussed.",242,11,1785,10.33
1122,topology,"We study the properties of topological spaces $(X,\tau)$, where $X$ is a
definable set in an o-minimal structure and the topology $\tau$ on $X$ has a
basis that is (uniformly) definable. Examples of such spaces include the
canonical euclidean topology on definable sets, definable order topologies,
definable quotient spaces and definable metric spaces. We use o-minimality to
undertake their study in topological terms, focussing here in particular on
spaces of dimension one. We present several results, given in terms of
piecewise decompositions and existence of definable embeddings and
homeomorphisms, for various classes of spaces that are described in terms of
classical separation axioms and definable analogues of properties such as
separability, compactness and metrizability. For example, we prove that all
Hausdorff one-dimensional definable topologies are piecewise the euclidean,
discrete, or upper or lower limit topology; we give a characterization of all
one-dimensional, regular, Hausdorff definable topologies in terms of spaces
that have a lexicographic ordering or a topology generalizing the Alexandrov
double of the euclidean topology; and we show that, if the underlying structure
expands an ordered field, then any one-dimensional Hausdorff definable topology
that is piecewise euclidean is definably homeomorphic to a euclidean space. As
applications of these results, we prove definable versions of several open
conjectures from set-theoretic topology, due to Gruenhage and Fremlin, on the
existence of a 3-element basis for regular, Hausdorff topologies and on the
nature of perfectly normal, compact, Hausdorff spaces; we obtain universality
results for some classes of Hausdorff and regular topologies; and we
characterize when certain metrizable definable topologies admit a definable
metric.",261,7,1823,1.94
1123,topology,"We present a new generalized topological current in terms of the order
parameter field $\vec \phi$ to describe the topological defect system in O(n)
symmetric time-dependent Ginzburg-Landau model. With the aid of the $%
\phi$-mapping method, the structure of the topological defects and the
topological quantization of their topological charges in TDGL model are
obtained under the condition that the Jacobian $% J(\frac \phi v)\neq 0$. We
show that the topological defects are generated from the zero points of the
order parameter field $\vec \phi$, and the topological charges of these
topological defects are topological quantized in terms of the Hopf indices and
Brouwer degrees of $\phi$-mapping under the condition. When $J(\frac \phi
v)=0$, it is shown that there exist the crucial case of branch process. Based
on the implicit function theorem and the Taylor expansion, we detail the
bifurcation of generalized topological current and find different directions of
the bifurcation. The topological defects in TDGL model are found splitting or
merging at the degenerate point of field function $\vec \phi $ but the total
charge of the topological defects is still unchanged.",183,7,1180,32.57
1124,topology,"This is a survey article on trees, with a modest number of proofs to give a
flavor of the way these topologies can be efficiently handled. Trees are
defined in set-theorist fashion as partially ordered sets in which the elements
below each element are well-ordered. A number of different topologies on trees
are treated, some at considerable length. Two sections deal in some depth with
the coarse and fine wedge topologies, and the interval topology, respectively.
The coarse wedge topology gives a class of supercompact monotone normal
topological spaces, and the fine wedge topology puts a monotone normal,
hereditarily ultraparacompact topology on every tree. The interval topology
gives a large variety of topological properties, some of which depend upon
set-theoretic axioms beyond ZFC. Many of the open problems in this area are
given in the last section.",137,8,863,51.58
1125,topology,"The Isbell, compact-open and point-open topologies on the set
$C(X,\mathbb{R})$ of continuous real-valued maps can be represented as the dual
topologies with respect to some collections $\alpha(X)$ of compact families of
open subsets of a topological space $X$. Those $\alpha(X)$ for which addition
is jointly continuous at the zero function in $C_\alpha(X,\mathbb{R})$ are
characterized, and sufficient conditions for translations to be continuous are
found. As a result, collections $\alpha(X)$ for which
$C_{\alpha}(X,\mathbb{R})$ is a topological vector space are defined
canonically. The Isbell topology coincides with this vector space topology if
and only if $X$ is infraconsonant. Examples based on measure theoretic methods,
that $C_\alpha (X,\mathbb{R})$ can be strictly finer than the compact-open
topology, are given. To our knowledge, this is the first example of a splitting
group topology strictly finer than the compact-open topology.",134,7,950,31.92
1126,topology,"Topological matter is characterized by the presence of a topological BF term
in its long-distance effective action. Topological defects due to the
compactness of the U(1) gauge fields induce quantum phase transitions between
topological insulators, topological superconductors and topological
confinement. In conventional superconductivity, due to spontaneous symmetry
breaking, the photon acquires a mass due to the Anderson-Higgs mechanism. In
this paper we derive the corresponding effective actions for the
electromagnetic field in topological superconductors and topological
confinement phases. In topological superconductors magnetic flux is confined
and the photon acquires a topological mass through the BF mechanism: no
symmetry breaking is involved, the ground state has topological order and the
transition is induced by quantum fluctuations. In topological confinement,
instead, electric charge is linearly confined and the photon becomes a massive
antisymmetric tensor via the St\""uckelberg mechanism. Oblique confinement
phases arise when the string condensate carries both magnetic and electric flux
(dyonic strings). Such phases are characterized by a vortex quantum Hall effect
potentially relevant for the dissipationless transport of information stored on
vortices.",173,9,1284,15.71
1127,topology,"Although topological materials have recently seen tremendous development,
their applications have remained elusive. Simultaneously, there exists
considerable interest in pushing the limits of topological materials, including
the exploration of new forms of topological protection and the establishment of
topologically protected order in non-electronic systems. Here we develop some
novel forms of topological order (i.e. topological charges), primarily the
Euler characteristic as well as manifold class. We further demonstrate that
these topological orders can protect bulk current transmission, even when the
topologically trivial phase possesses an arbitrarily large band gap. Such a
transition between topologically trivial, periodic dispersion and topologically
non-trivial, aperiodic dispersion can be obtained by the anomalous Doppler
shift of waves in a gapped periodic medium. Our work suggests that additional
topological charges may become relevant in moving beyond topological
electronics.",132,9,1002,9.99
1128,topology,"A second-order topological insulator in $d$ dimensions is an insulator which
has no $d-1$ dimensional topological boundary states but has $d-2$ dimensional
topological boundary states. It is an extended notion of the conventional
topological insulator. Higher-order topological insulators have been
investigated in square and cubic lattices. In this paper, we generalize them to
breathing Kagome and pyrochlore lattices. First, we construct a second-order
topological insulator on the breathing Kagome lattice. Three topological
boundary states emerge at the corner of the triangle, realizing a 1/3
fractional charge at each corner. Second, we construct a third-order
topological insulator on the breathing pyrochlore lattice. Four topological
boundary states emerge at the corners of the tetrahedron with a 1/4 fractional
charge at each corner. These higher-order topological insulators are
characterized by the quantized polarization, which constitutes the bulk
topological index. Finally, we study a second-order topological semimetal by
stacking the breathing Kagome lattice.",149,11,1079,30.97
1129,topology,"This paper focuses on various decompositions of topological measures,
deficient topological measures, signed topological measures, and signed
deficient topological measures. These set functions generalize measures and
correspond to certain non-linear functionals. They may assume $\infty$ or
$-\infty$. We introduce the concept of a proper signed deficient topological
measure and show that a signed deficient topological measure can be represented
as a sum of a signed Radon measure and a proper signed deficient topological
measure. We also generalize practically all known results that involve proper
deficient topological measures and proper topological measures on compact
spaces to locally compact spaces. We prove that the sum of two proper
(deficient) topological measures is a proper (deficient) topological measure.
We give a criterion for a (deficient) topological measure to be proper.",127,8,897,19.26
1130,topology,"The Kitaev chain model exhibits topological order that manifests as
topological degeneracy, Majorana edge modes and $Z_{2}$ topological invariance
of the abulk spectrum. This model can be obtained from a transverse field Ising
model(TFIM) using the Jordan-Wigner transformation. TFIM has neither
topological degeneracy nor any edge modes. Topological degeneracy associated
with topological order is central to topological quantum computation. In this
paper we will explore topological protection of the ground state manifold in
the case of Majorana fermion models which exhibit $Z_{2}$ topological order. We
will show that there are at least two different ways to understand this
topological protection of Majorana fermion qubits: one way is based on
fermionic mode operators and the other is based on anti-commuting symmetry
operators. We will also show how these two different ways are related to each
other. We provide a very general approach of understanding the topological
protection of Majorana fermion qubits in the case of lattice Hamiltonians.",156,9,1053,26.3
1131,topology,"In this paper, the core convex topology on a real vector space $X$, which is
constructed just by $X$ operators, is investigated. This topology, denoted by
$\tau_c$, is the strongest topology which makes $X$ into a locally convex
space. It is shown that some algebraic notions $(closure ~ and ~ interior)$
existing in the literature come from this topology. In fact, it is proved that
algebraic interior and vectorial closure notions, considered in the literature
as replacements of topological interior and topological closure, respectively,
in vector spaces not necessarily equipped with a topology, are actually nothing
else than the interior and closure with the respect to the core convex
topology. We reconstruct the core convex topology using an appropriate
topological basis which enables us to characterize its open sets.
  Furthermore, it is proved that $(X,\tau_c)$ is not metrizable when X is
infinite-dimensional, and also it enjoys the Hine-Borel property. Using these
properties, $\tau_c$-compact sets are characterized and a characterization of
finite-dimensionality is provided. Finally, it is shown that the properties of
the core convex topology lead to directly extending various important results
in convex analysis and vector optimization from topological vector spaces to
real vector spaces.",196,9,1313,21.43
1132,topology,"Characterized by bulk Dirac or Weyl cones and surface Fermi-arc states,
topological semimetals have sparked enormous research interest in recent years.
The nanostructures, with large surface-to-volume ratio and easy field-effect
gating, provide ideal platforms to detect and manipulate the topological
quantum states. Exotic physical properties originating from these topological
states endow topological semimetals attractive for future topological
electronics (topotronics). For example, the linear energy dispersion relation
is promising for broadband infrared photodetectors, the spin-momentum locking
nature of topological surface states is valuable for spintronics, and the
topological superconductivity is highly desirable for fault-tolerant qubits.
For real-life applications, topological semimetals in the form of
nanostructures are necessary in terms of convenient fabrication and
integration. Here, we review the recent progresses in topological semimetal
nanostructures and start with the quantum transport properties. Then
topological semimetal-based electronic devices are introduced. Finally, we
discuss several important aspects that should receive great effort in the
future, including controllable synthesis, manipulation of quantum states,
topological field effect transistors, spintronic applications, and topological
quantum computation.",168,9,1358,7.86
1133,topology,"Topological phases of matter are classified based on their Hermitian
Hamiltonians, whose real-valued dispersions together with orthogonal
eigenstates form nontrivial topology. In the recently discovered higher-order
topological insulators (TIs), the bulk topology can even exhibit hierarchical
features, leading to topological corner states, as demonstrated in many
photonic and acoustic artificial materials. Naturally, the intrinsic loss in
these artificial materials has been omitted in the topology definition, due to
its non-Hermitian nature; in practice, the presence of loss is generally
considered harmful to the topological corner states. Here, we report the
experimental realization of a higher-order TI in an acoustic crystal, whose
nontrivial topology is induced by deliberately introduced losses. With local
acoustic measurements, we identify a topological bulk bandgap that is populated
with gapped edge states and in-gap corner states, as the hallmark signatures of
hierarchical higher-order topology. Our work establishes the non-Hermitian
route to higher-order topology, and paves the way to exploring various exotic
non-Hermiticity-induced topological phases.",158,7,1177,2.48
1134,topology,"To capture the global structure of a dynamical system we reformulate dynamics
in terms of appropriately constructed topologies, which we call flow
topologies; we call this process topologization. This yields a description of a
semi-flow in terms of a bi-topological space, with the first topology
corresponding to the (phase) space and the second to the flow topology. A study
of topology is facilitated through discretization, i.e. defining and examining
appropriate finite sub-structures. Topologizing the dynamics provides an
elegant solution to their discretization by discretizing the associated flow
topologies. We introduce Morse pre-orders, an instance of a more general
bi-topological discretization, which synthesize the space and flow topologies,
and encode the directionality of dynamics. We describe how Morse pre-orders can
be augmented with appropriate (co)homological information in order to describe
invariance of the dynamics; this ensemble provides an algebraization of the
semi-flow. An illustration of the main ingredients of the paper is provided by
an application to the theory of discrete parabolic flows. Algebraization yields
a new invariant for positive braids in terms of a bi-graded differential module
which contains Morse theoretic information of parabolic flows.",185,11,1294,25.19
1135,topology,"Whereas point-gap topological phases are responsible for exceptional
phenomena intrinsic to non-Hermitian systems, their realization in quantum
materials is still elusive. Here we propose a simple and universal platform of
point-gap topological phases constructed from Hermitian topological insulators
and superconductors. We show that (d-1)-dimensional point-gap topological
phases are realized by making a boundary in d-dimensional topological
insulators and superconductors dissipative. A crucial observation of the
proposal is that adding a decay constant to boundary modes in d-dimensional
topological insulators and superconductors is topologically equivalent to
attaching a (d-1)-dimensional point-gap topological phase to the boundary. We
furthermore establish the proposal from the extended version of the
Nielsen-Ninomiya theorem, relating dissipative gapless modes to point-gap
topological numbers. From the bulk-boundary correspondence of the point-gap
topological phases, the resultant point-gap topological phases exhibit
exceptional boundary states or in-gap higher-order non-Hermitian skin effects.",139,7,1114,-2.84
1136,topology,"The topological structure of the electric topological current of the locally
gauge invariant Maxwell-Chern-Simons Model and its bifurcation is studied. The
electric topological charge is quantized in term of winding number. The Hopf
indices and Brouwer degree labeled the local topological structure of the
electric topological current. Using $\Phi $-mapping method and implicity
theory, the electric topological current is found generating or annihilating at
the limit points and splitting or merging at the bifurcate points. The total
electric charge holds invariant during the evolution.",84,6,590,29.04
1137,topology,"The concept of `topological right transversal' is introduced to study right
transversals in topological groups. Given any right quasigroup $S$ with a
Tychonoff topology $T$, it is proved that there exists a Hausdorff topological
group in which $S$ can be embedded algebraically and topologically as a right
transversal of a subgroup (not necessarily closed). It is also proved that if a
topological right transversal $(S, T_{S}, T^{S}, \circ)$ is such that $T_{S} =
T^{S}$ is a locally compact Hausdorff topology on $S$, then $S$ can be embedded
as a right transversal of a closed subgroup in a Hausdorff topological group
which is universal in some sense.",106,4,656,35.95
1138,topology,"Phase singularities as topological objects of wave fields appear in a variety
of physical, chemical, and biological scenarios. In this paper, by making use
of the $\phi$-mapping topological current theory, we study the topological
properties of the phase singularities in two and three dimensional space in
details. The topological inner structure of the phase singularities are
obtained, and the topological charge of the phase singularities are expressed
by the topological numbers: Hopf indices and Brouwer degrees. Furthermore, the
topological invariant of the closed and knotted phase singularities in three
dimensional space are also discussed in details.",96,5,661,21.74
1139,topology,"In this paper we develop a sysmatical theory for topological orders by the
projected p-wave superconducting (SC) wave-functions and unify the different
topological orders for spin models into the fermionic picture. We found that
the energy for the fermions at k=(0,0), (0, pi), (pi, 0), (pi, pi) acts as a
topological invariable to characterize 16 universal classes of different
topological orders for the spin models with translation invariance. Based on
the projected p-wave SC wave-functions the topological properties for the known
topological orders in the exact solved spin models are obtained. Finally new
types of topological orders are predicted.",99,5,655,29.38
1140,topology,The note complements topological aspects of the theory of chiral algebras.,11,2,74,26.47
1141,topology,"In this paper we answer the question of T. Banakh and M. Zarichnyi
constructing a copy of the Fr\'echet-Urysohn fan $S_\w$ in a topological group
$G$ admitting a functorial embedding $[0,1]\subset G$. The latter means that
each autohomeomorphism of $[0,1]$ extends to a continuous homomorphism of $G$.
This implies that many natural free topological group constructions (e.g. the
constructions of the Markov free topological group, free abelian topological
group, free totally bounded group, free compact group) applied to a Tychonov
space $X$ containing a topological copy of the space $\IQ$ of rationals give
topological groups containing $S_\w$.",97,8,648,46.57
1142,topology,"We define the notion of {\em classifying space} of a topological stack and
show that every topological stack \X has a classifying space X which is a
topological space well-defined up to weak homotopy equivalence. Under a certain
paracompactness condition on \X, we show that X is actually well-defined up to
homotopy equivalence. These results are formulated in terms of functors from
the category of topological stacks to the (weak) homotopy category of
topological spaces. We prove similar results for (small) diagrams of
topological stacks.",85,5,543,32.94
1143,topology,"We study the topological structure of the direct limit $\glim G_n$ of a tower
of topological groups $(G_n)$ in the category of topological groups and show
that under some conditions on the tower $(G_n)$ the topology of $\glim G_n$
coincides with the topology of the direct limit $\ulim G_n$ of the groups $G_n$
endowed with the Roelcke uniformity in the category of uniform spaces.",64,2,381,6.52
1144,topology,"We study the change in topological entanglement entropy that occurs when a
two-dimensional system in a topologically ordered phase undergoes a transition
to another such phase due to the formation of a Bose condensate. We also
consider the topological entanglement entropy of systems with domains in
different topological phases, and of phase boundaries between these domains. We
calculate the topological entropy of these interfaces and derive two
fundamental relations between the interface topological entropy and the bulk
topological entropies on both sides of the interface.",85,4,579,17.37
1145,topology,"This paper develops a basic theory of H-groups. We introduce a special
quotient of H-groups and extend some algebraic constructions of topological
groups to the category of H-groups and H-maps. We use these constructions to
prove some advantages in topological homotopy groups. Also, we present a family
of spaces that their topological fundamental groups are indiscrete topological
group and find out a family of spaces whose topological fundamental group is a
topological group.",73,5,480,35.98
1146,topology,"Using nonstandard analysis we define a topology on the ring of germs of
functions: $(mathbb R^n,0)\rightarrow(mathbb R,0)$. We prove that this topology
is absolutely convex, Hausdorff, that convergent nets of continuous germs have
continuous germs as limits and that, for continuous germs, ring operations and
compositions are continuous. This topology is not first countable, and, in
fact, we prove that no good first countable topology exists. We give a spectrum
of standard working descriptions for this topology. Finally, we identify this
topological ring as a generalized metric space and examine some consequences.",92,6,620,35.88
1147,topology,"The order topology $\tau_o(P)$ (resp. the sequential order topology
$\tau_{os}(P)$) on a poset $P$ is the topology that has as its closed sets
those that contain the order limits of all their order convergent nets (resp.
sequences). For a von Neumann algebra $M$ we consider the following three
posets: the self-adjoint part $M_{sa}$, the self-adjoint part of the unit ball
$M_{sa}^1$, and the projection lattice $P(M)$. We study the order topology (and
the corresponding sequential variant) on these posets, compare the order
topology to the other standard locally convex topologies on $M$, and relate the
properties of the order topology to the underlying operator-algebraic structure
of $M$.",107,6,694,44.27
1148,topology,"In this review, we discuss recent progress in the explorations of topological
materials beyond topological insulators; specifically, we focus on topological
crystalline insulators and bulk topological superconductors. The basic
concepts, model Hamiltonians, and novel electronic properties of these new
topological materials are explained. The key role of symmetries that underlie
their topological properties is elucidated. Key issues in their materials
realizations are also discussed.",64,5,487,4.47
1149,topology,"We give a foundational account on topological racks and quandles.
Specifically, we define the notions of ideals, kernels, units, and inner
automorphism group in the context of topological racks. Further, we investigate
topological rack modules and principal rack bundles. Central extensions of
topological racks are then introduced providing a first step towards a general
continuous cohomology theory for topological racks and quandles.",62,5,437,21.9
1150,topology,"The $S$ topology on the Skorokhod space was introduced by the author in 1997
and since then it proved to be a useful tool in several areas of the theory of
stochastic processes. The paper brings complementary information on the $S$
topology. It is shown that the convergence of sequences in the $S$ topology
admits a compact description, exhibiting the locally convex character of the
$S$ topology. It is also shown that $S$ is, up to some technicalities, finer
than any linear topology which is coarser than Skorokhod's $J_1$ topology. The
paper contains also definitions of extensions of the $S$ topology to the
Skorokhod space of functions defined on $[0,+\infty)$ and with multidimensional
values.",114,6,701,39.87
1151,topology,"Since it first emerged in Wijsman's seminal work [29], the Wijsman topology
has been intensively studied in the past 50 years. In particular, topological
properties of Wijsman hyperspaces, relationships between the Wijsman topology
and other hyperspace topologies, and applications of the Wijsman topology in
analysis have been explored. However, there are still several fundamental open
problems on this topology. In this article, the author gives a brief survey on
these problems and some up-to-date partial solutions.",76,5,520,26.81
1152,topology,"Let X, Y, and Z be topological modules over a topological ring $R$. In the
first part of the paper, we introduce three different classes of bounded
bigroup homomorphisms from $X\times Y$ into $Z$ with respect to the three
different uniform convergence topologies. We show that these spaces form again
topological modules over $R$. In the second part, we characterize bounded sets
in the arbitrary product of topological groups with respect to the both product
and box topologies.",78,5,479,51.68
1153,topology,"We present a generalization of free fermionic topological insulators that are
composed of topological subsystems of differing dimensionality. We specifically
focus on topological subsystems of nonzero co-dimension are embedded within a
trivial insulating environment. A general procedure is described to isolate and
classify such embedded topological insulators and we present three
representative examples in varying dimensions and symmetry classes. Moreover,
we demonstrate with concrete examples that the presence of periodically
embedded topological insulators in an otherwise trivially classified system can
lead to topologically non-trivial physical phenomena on crystalline defects;
namely, novel topological surface/edge modes at stacking faults and partial
edge dislocations.",101,5,784,-4.97
1154,topology,"Recently Au\ss enhofer and the author independently have shown that the free
abelian topological group $A(\mathbf{s})$ over a convergent sequence
$\mathbf{s}$ does not admit the strongest compatible locally quasi-convex group
topology that gives the first example of a locally quasi-convex abelian group
without a Mackey group topology. In this note we considerably extend this
example by showing that the free abelian topological group $A(X)$ over a
non-discrete zero-dimensional metrizable space $X$ does not have a Mackey group
topology. In particular, for every countable non-discrete metrizable space $X$,
the group $A(X)$ does not have a Mackey group topology.",97,4,666,30.23
1155,topology,"The union of a directed family of topological groups can be equipped with two
noteworthy topologies: the finest topology making each injection continuous,
and the finest group topology making each injection continuous. This begs the
question of whether the two topologies coincide. If the family is countable,
the answer is well known in many cases. We study this question in the context
of so-called long families, which are as far as possible from countable ones.
As a first step, we present answers to the question for families of
group-valued continuous maps and homeomorphism groups, and provide additional
examples.",98,6,621,51.58
1156,topology,"The theory of covering spaces is often used to prove the Nielsen-Schreier
theorem, which states that every subgroup of a free group is free. We apply the
more general theory of semicovering spaces to obtain analogous subgroup
theorems for topological groups: Every open subgroup of a free Graev
topological group is a free Graev topological group. An open subgroup of a free
Markov topological group is a free Markov topological group if and only if it
is disconnected.",78,4,469,45.09
1157,topology,"For the set C(X) of real-valued continuous functions on a Tychonoff space X,
the compact-open topology on C(X) is a ""set-open topology"". This paper studies
the separation and countability properties of the space C(X) having the
topology given by the join of the compact-open topology and an ""open-set
topology"" called the open-point topology, that was introduced in [6].",58,3,370,33.58
1158,topology,"A detailed study of graded frame, graded fuzzy topological system and fuzzy
topological space with graded inclusion is already done in our earlier paper.
The notions of graded fuzzy topological system and fuzzy topological space with
graded inclusion were obtained via fuzzy geometric logic with graded con-
sequence. As an off shoot the notion of graded frame has been developed. This
paper deals with a detailed categorical study of graded frame, graded fuzzy
topological system and fuzzy topological space with graded inclusion and their
interrelation.",85,5,555,41.4
1159,topology,"We show how to define a dynamical topological invariant for general
one-dimensional topological systems after a quantum quench. Focusing on
two-band topological insulators, we demonstrate that the reduced momentum-time
manifold can be viewed as a series of submanifold $S^2$, and thus we are able
to define a dynamical topological invariant on each of the sphere. We also
unveil the intrinsic relation between the dynamical topological invariant and
the difference of topological invariant of the initial and final static
Hamiltonian. By considering some concrete examples, we illustrate the
calculation of the dynamical topological invariant and its geometrical meaning
explicitly.",98,5,682,4.31
1160,topology,"Topological phases are characterised by a topological invariant that remains
unchanged by deformations in the Hamiltonian. Materials exhibiting topological
phases include topological insulators, superconductors exhibiting strong
spin-orbit coupling, transition metal dichalcogenides, which can be made
atomically thin and have direct band gaps, as well as high mobility Weyl and
Dirac semimetals. Devices harnessing topological electron states include
topological (spin) transistors, spin-orbit torque devices, non-linear
electrical and optical systems, and topological quantum bits.",72,4,583,4.82
1161,topology,"The interplay of topology and symmetry in a material's band structure may
result in various patterns of topological states of different dimensionality on
the boundary of a crystal. The protection of these ""higher-order"" boundary
states comes from topology, with constraints imposed by symmetry. We review the
bulk-boundary correspondence of topological crystalline band structures, which
relates the topology of the bulk band structure to the pattern of the boundary
states. Furthermore, recent advances in the K-theoretic classification of
topological crystalline band structures are discussed.",83,5,595,33.44
1162,topology,"In this paper we introduce and study a new topologo-algebraic structure
called a (di)topological unosemigroup. This is a topological semigroup endowed
with continuous unary operations of left and right units (which have certain
continuous division property called the dicontinuity). We show that the class
of ditopological unosemigroups contains all topological groups, all topological
semilattices, all uniformizable topological unoid-semigroups, all compact
topological unosemigroups, and is closed under the operations of taking
subunosemigroup, Tychonoff product, reduced product, semidirect product, and
the Hartman-Mycielski extension.",81,4,641,1.77
1163,topology,"We give the topological obstructions to be a leaf in a minimal lamination by
hyperbolic surfaces whose generic leaf is homeomorphic to a Cantor tree. Then,
we show that all allowed topological types can be simultaneously embedded in
the same lamination. This result, together with results of
Alvarez-Brum-Mart\'inez-Potrie and Blanc, complete the panorama of
understanding which topological surfaces can be leaves in minimal hyperbolic
surface laminations when the topology of the generic leaf is given. In all
cases, all possible topologies can be realized simultaneously.",85,5,573,32.94
1164,topology,"Digital topological methods are often used on computing the topological
complexity of digital images. We give new results on the relation between
reducibility and digital contractibility in order to determine the topological
complexity of a digitally connected finite digital image. We present all
possible cases of the topological complexity TC of a finite digital image in Z
and Z^2$. Finally, we determine the higher topological complexity TC_{n} of
finite irreducible digital images independently of the number of points for n >
1.",82,5,535,17.03
1165,topology,"In this article it is shown that to every non-discrete Hausdorff linear
topology on $\Z$ other metrizable locally quasi-convex group topologies can be
associated which are strictly finer than the linear topology and such that the
character groups coincide. Applying this result to the $p$-adic topology on
$\Z$, we give a negative answer to the question of Dikranjan, whether this
topology is Mackey.",63,3,400,31.04
1166,topology,"In the paper we study pseudocompact primitive topological inverse semigroups.
We describe the structure of pseudocompact primitive topological inverse
semigroups and show that a Tychonoff product of a family of pseudocompact
primitive topological inverse semigroups is a pseudocompact topological space.
Also we prove that the Stone-\v{C}ech compactification of a pseudocompact
primitive topological inverse semigroup is a compact primitive topological
inverse semigroup.",61,4,471,8.57
1167,topology,"Topological photonics has recently been proved a robust framework for
manipulating light. Active topological photonic systems, in particular, enable
richer fundamental physics by employing nonlinear light-matter interactions,
thereby opening a new landscape for applications such as topological lasing.
Here we report an all-dielectric topological insulator laser scheme based on
semiconductor cavities formed by topologically distinct Kagome photonic
crystals. The proposed planar semiconductor Kagome lattice allows broadband
edge states below the light line due to photonic valley hall effect in
telecommunication region, which provides a new route to retrieve nontrivial
photonic topology and to develop integrated topological systems for robust
light generation and transport.",103,5,781,2.99
1168,topology,"Topological defects (TDs) in crystal lattices are elementary lattice
imperfections that cannot be removed by local perturbations, due to their real
space topology. We show that adding TDs into a valley photonic crystal
generates a lattice disclination that acts like a domain wall and hosts
topological edge states. The disclination functions as a freeform waveguide
connecting a pair of TDs of opposite topological charge. This interplay between
the real-space topology of lattice defects and band topology provides a novel
scheme to implement large-scale photonic structures with complex arrangements
of robust topological waveguides and resonators.",94,5,651,30.7
1169,topology,"Recently topologically non-trivial phases have been identified in few
time-reversal invariant systems that lack of inversion symmetry. Using density
functional theory based first-principles calculations, we report a strong
topologically non-trivial phase in chalchopyrite ZnGeSb$_2$, which can act as a
model system of strained HgTe. The calculations reveal the non-zero topological
invariant ($Z_2$), the presence of Dirac cone crossing in the surface spectral
functions with spin-momentum locking. We also show that the application of
moderate hydrostatic pressure ($\sim$7 GPa) induces topological phase
transition from topological non-trivial phase to a topologically trivial phase.
A discontinuity in the tetragonal distortion of non-centrosymmetric ZnGeSb$_2$
plays a crucial role in driving this topological phase transition.",110,6,832,15.31
1170,topology,This is a review of the fundamental concepts of general topology.,11,2,65,43.39
1171,topology,"We first study the higher version of the relative topological complexity by
using the homotopic distance. We also introduced the generalized version of the
relative topological complexity of a topological pair on both the Schwarz genus
and the homotopic distance. With these concepts, we give some inequalities
including the topological complexity and the Lusternik-Schnirelmann category,
the most important parts of the study of robot motion planning in topology.
Finally, by defining the parametrised topological complexity via the homotopic
distance, we present some estimates on the higher setting of this concept.",90,5,618,31.72
1172,topology,"Three-dimensional (3D) topological materials exhibit much richer phenomena
than their lower-dimensional counterparts. Here, we propose self-localized
topological states (i.e., topological solitons) in a 3D nonlinear photonic
Chern insulator. Despite being in the bulk and self-localized in all 3D, the
topological solitons at high-symmetry points K and K' rotate in the same
direction, due to the underlying topology. Specifically, under the saturable
nonlinearity the solitons are stable over a broad frequency range. Our results
highlight how topology and nonlinearity interact with each other and can be
extended to other 3D topological systems.",91,8,648,22.21
1173,topology,"The purpose of this paper is to introduce a new structure `primal'. Primal is
dual to grill. Like ideal, dual of filter, this new structure also generates a
new topology named `primal topology'. We introduce a new operator using primal,
which satisfies Kuratowski's closure axioms. Mainly, we prove that primal
topology is finer than the topology of a primal topological space. We provide
structure of base of primal topology and prove other fundamental results
related to this new structure.",79,7,492,49.62
1174,topology,"In this paper, we give a topological version of Scott convergence theorem for
locally hypercompact spaces. We introduce the notion of
$\mathcal{S}^*_X$-convergence on a $T_0$ topological space $X$, and define the
notion of finitely approximated spaces. Monotone determined spaces are natural
topological extensions of dcpos. The main results are: (1) A monotone
determined space $X$ is a locally hypercompact space iff
$\mathcal{S}^*_X$-convergence is topological. (2) For a $T_0$ space $X$,
$\mathcal{S}^*_X$-convergence is topological iff $X$ is a finitely
approximating space. (3) If the Lawson topology on a monotone determined space
$X$ is compact, then $X$ is a dcpo endowed with the Scott topology.",103,7,705,28.64
1175,topology,"The aim of this paper is to study the profiniteness of compact topological
residuated lattices and the existence of Hausdorff topological residuated
lattices. Firstly, we study profinite residuated lattices and obtain sufficient
and necessary conditions for profiniteness in compact topological residuated
lattices. These conditions include topological and algebraic characterizations.
Moreover, it order to study the existence of Hausdorf topological residuated
lattices, we investigate finiteness conditions in residuated lattices. Finally,
we investigate linear topological residuated lattices and give the class of
residuated lattices that can be endowed with a non-trivial Hausdorff topology.",91,6,697,10.7
1176,topology,"We present new smoothing techniques for topologically embedded surfaces in
smooth 4-manifolds, which give topological isotopy to a smooth surface. As
applications, we prove ""topological = smooth"" results in dimension 4 for
certain disks and spheres modulo isotopy. A key step in our approach is to link
Quinn's smoothing theory with ideas in Gabai's 4-dimensional light bulb theorem
and succeeding developments of Schneiderman-Teichner and Kosanovi\'c-Teichner.
As another application of our smoothing technique, we obtain a topological
version of the Dax invariant which gives topological isotopy obstructions for
topological disks in 4-manifolds.",91,5,648,23.26
1177,topology,"Topological Ramsey theory studies a class of combinatorial topological
spaces, called topological Ramsey spaces, unifying the essential features of
those combinatorial frames where the Ramsey property is equivalent to Baire
property. In this article, we expose a general overview of the combinatorial
structure of topological Ramsey spaces and their main properties, and we
propose an alternative proof of abstract Ellentuck theorem for a large family
of topological Ramsey spaces. Additionally, we present the notion of selective
topological Ramsey space, and generalize Kastanas games in order to
characterize the Baire property for the family of selective topological Ramsey
spaces.",98,4,685,-4.03
1178,topology,"The study of infra-topological spaces focuses on characterizations of
$e^\star$-open sets and nearby open sets in infra-topological spaces. The
$e^\star$-open sets, a variation of open sets, are explored for their unique
properties and relationships within the infra-topological framework.
Additionally, nearby open sets, which capture the notion of points being close
to each other, are investigated to provide a comprehensive understanding of the
topological structure. The research aims to contribute to the broader field of
topology by extending traditional concepts to infra-topological spaces,
offering new perspectives on openness and proximity. The findings not only
deepen our understanding of mathematical structures but also open avenues for
applications in various scientific and engineering disciplines.",111,6,816,15.1
1179,topology,"Generalizing a construction of A. Weil, we introduce a topological invariant
for flows on compact, connected, finite dimensional, abelian, topological
groups. We calculate this invariant for some examples and compare the invariant
with other flow invariants.",36,4,258,25.46
1180,topology,"We show that if U is a hypercover of a topological space X then the natural
map from hocolim U to X is a weak equivalence. This fact is used to construct
topological realization functors for the A^1-homotopy theory of schemes over
real and complex fields.",46,3,255,48.13
1181,topology,This note is a survey of $J$-spaces.,7,2,36,89.75
1182,topology,"A De Rham model for string topology based on the theory of iterated integrals
is presented.",16,2,91,38.32
1183,topology,"A characterization of regular topological fundamental groups yields a `no
retraction theorem' for spaces constructed in similar fashion to the Hawaiian
earring.",22,2,160,6.84
1184,topology,"We show that any homomorphism from the homeomorphism group of a compact
2-manifold, with the compact-open topology, or equivalently, with the topology
of uniform convergence, into a separable topological group is automatically
continuous.",33,2,238,-4.33
1185,topology,"We introduce the notion of negative topological dimension and the notion of
weight for the asymptotic topological dimension. Quantizing of spaces of
negative dimension is applied to linguistic statistics.",29,3,204,14.46
1186,topology,"Based on the notion of a $\Delta$-group(oid), ring-valued invariants of pairs
of topological spaces can be defined in intrinsic topological terms.",21,2,146,33.24
1187,topology,"I briefly discuss a method of obtaining distinct classes of topologically
equivalent knots by developing appropriate computer programs.",18,2,135,10.91
1188,topology,"We propose some problems on the classification of toric manifolds from the
viewpoint of topology and survey related results.",19,2,124,35.27
1189,topology,"We describe the structure of 0-simple countably compact topological inverse
semigroups and the structure of congruence-free countably compact topological
inverse semigroups.",21,2,173,16.32
1190,topology,"We study Michael's lower semifinite topology and Fell's topology on the
collection of all closed limit subsets of a topological space. Special
attention is given to the subfamily of all maximal limit sets.",33,3,205,46.27
1191,topology,"In earlier work we introduced topologically minimal surfaces as the analogue
of geometrically minimal surfaces. Here we strengthen the analogy by showing
that complicated amalgamations act as barriers to low genus, topologically
minimal surfaces.",34,3,246,11.92
1192,topology,"We construct a simple finite-dimensional topological quantum field theory for
compact 3-manifolds with triangulated boundary.",15,2,125,-11.44
1193,topology,"In this note for a topological group $G$, we introduce a bounded subset of
$G$ and we find some relationships of this definition with other topological
properties of $G$.",29,2,170,33.58
1194,topology,"A new class of functions called L-fuzzy weakly Semi-Preopen (Semi-Preclosed)
functions in L-fuzzy topological spaces are introduced in this paper. Some
characterizations of this class and its properties and the relationship with
other classes of functions between L-fuzzy topological spaces are also
obtained.",43,3,309,41.19
1195,topology,"We answer several questions of I.Protasov and E.Zelenyuk concerning
topologies on groups determined by T-sequences. A special attention is paid to
studying the operation of supremum of two group topologies.",30,5,206,55.4
1196,topology,"This is the second chapter in our ""Toric Topology"" book project. Further
chapters are coming. Comments and suggestions are very welcome.",21,4,136,72.83
1197,topology,"We use an alternative definition of topological complexity to show that the
topological complexity of the mapping telescope of a sequence $X_1\rightarrow
X_2\rightarrow X_3\rightarrow...$ is bounded above by $2max{TC(X_i);
i=1,2,...}$.",30,8,235,39.33
1198,topology,"We review some selected recent results concerning selection principles in
topology and their relations with several topological constructions.",18,2,142,2.44
1199,topology,"For each $n\leq 6$, we characterize all the groups which can occur as either
the orientation preserving topological symmetry group or the topological
symmetry group of some embedding of $K_n$ in $S^3$.",32,2,201,30.54
1200,topology,"The bornological convergence structures that have been studied recently as
generalizations of Attouch-Wets convergence define pretopologies on
hyperspaces. In this paper we characterize the topological reflections of these
pretopologies and translate the constructions necessary to define bornological
convergence to a broader spectrum of hyperspace topologies.",45,3,361,6.34
1201,topology,"By means of filters, minimal R_1 and minimal regular topologies are
characterized on suitable intervals consisting of non-trivial R_0 topologies.",20,2,145,17.34
1202,topology,"It is shown that if a $T_2$ topological space contains an uncountable closed
discrete set, then $\omega_1 \times (\omega_1 + 1)$ embeds as a closed subspace
of $(CL(X),\tau_F)$, the hyperspace of nonempty closed subsets of $X$ equipped
with the Fell topology.",41,2,259,47.8
1203,topology,"We introduce the mean topological dimension for random bundle
transformations, and show that continuous bundle random dynamical systems with
finite topological entropy, or the small boundary property have zero mean
topological dimensions.",32,2,238,-3.31
1204,topology,"We compute the higher topological complexity of ordered configuration spaces
of orientable surfaces, thus extending Cohen-Farber's description of the
ordinary topological complexity of those spaces.",25,2,198,-13.13
1205,topology,"Let $T\times X\rightarrow X, (t,x)\mapsto tx$, be a topological semiflow on a
topological space $X$ with phase semigroup $T$. We introduce and discuss in
this paper various transitivity dynamics of $(T,X)$.",31,3,206,47.28
1206,topology,"A discrete non-linear $\sigma$-model is obtained by triangulate both the
space-time $M^{d+1}$ and the target space $K$. If the path integral is given by
the sum of all the complex homomorphisms $\phi: M^{d+1} \to K$, with an
partition function that is independent of space-time triangulation, then the
corresponding non-linear $\sigma$-model will be called topological non-linear
$\sigma$-model which is exactly soluble. Those exactly soluble models suggest
that phase transitions induced by fluctuations with no topological defects
(i.e. fluctuations described by homomorphisms $\phi$) usually produce a
topologically ordered state and are topological phase transitions, while phase
transitions induced by fluctuations with all the topological defects give rise
to trivial product states and are not topological phase transitions. If $K$ is
a space with only non-trivial first homotopy group $G$ which is finite, those
topological non-linear $\sigma$-models can realize all 3+1D bosonic topological
orders without emergent fermions, which are described by Dijkgraaf-Witten
theory with gauge group $\pi_1(K)=G$. Here, we show that the 3+1D bosonic
topological orders with emergent fermions can be realized by topological
non-linear $\sigma$-models with $\pi_1(K)=$ finite groups, $\pi_2(K)=Z_2$, and
$\pi_{n>2}(K)=0$. A subset of those topological non-linear $\sigma$-models
corresponds to 2-gauge theories, which realize and classify bosonic topological
orders with emergent fermions that have no emergent Majorana zero modes at
triple string intersections. The classification of 3+1D bosonic topological
orders may correspond to a classification of unitary fully dualizable fully
extended topological quantum field theories in 4-dimensions.",236,10,1742,16.15
1207,topology,"Several recent papers in digital topology have sought to obtain fixed point
results by mimicking the use of tools from classical topology, such as complete
metric spaces. We show that in many cases, researchers using these tools have
derived conclusions that are incorrect, trivial, or limited.",46,3,294,39.67
1208,topology,"Topological matter has become one of the most important subjects in
contemporary condensed matter physics. Here, I would like to provide a
pedagogical review explaining some of the main ideas, which were pivotal in
establishing topological matter as such an important subject. Specifically, I
explain how the integer quantum Hall state played the role as a prototype for
topological insulator, eventually leading to the concept of topological matter
in general. The topological nature of the integer quantum Hall state is best
represented by the Thouless-Kohmoto-Nightingale-den Nijs, or so-called TKNN
formula, which connects between the Berry phase and the Hall conductivity. The
topological non-triviality of topological insulator stems from the existence of
a Dirac monopole in an appropriate, but often hidden Hamiltonian parameter
space. Interestingly, having the identical Dirac monopole structure, the
Hamiltonian describing the Rabi oscillation bears the essence of topological
insulator. The concept of topological matter has expanded to include
topological semimetals such as Weyl and Dirac semimetals. A final frontier in
the research of topological matter is the interaction-induced topological
phases of matter, namely, the fractional Chern and topological insulators. The
existence of the fractional Chern and topological insulators has been proposed
theoretically by drawing an analogy from the fractional quantum Hall states.
The gist of this proposal is explained along with some of its issues. I
conclude this review by discussing some of the future directions in the
research of topological matter.",235,12,1618,24.37
1209,topology,"In analogy with the classical theory of topological groups, for finitely
complete categories enriched with Grothendieck topologies, we provide the
concepts of localized G-topological space, initial Grothendieck topologies and
continuous morphisms, in order to obtain the concepts of G-topological monoid
and G-topological group objects.",44,2,336,-7.03
1210,topology,"We prove the formula $TC(G\ast H)=\max\{TC(G), TC(H), cd(G\times H)\}$ for
the topological complexity of the free product of discrete groups with
cohomological dimension >2.",24,2,173,30.2
1211,topology,"This is a tutorial in applied and computational topology and topological data
analysis. It is illustrated with numerous computational examples that utilize
Gudhi library. It is under constant development, so please do not consider this
version as final.",38,4,253,24.74
1212,topology,"The article is devoted to microbundles over topological rings. Their
structure, homomorphisms, automorphisms and extensions are studied. Moreover,
compactifications and inverse spectra of microbundles over topological rings
are investigated.",29,4,241,10.87
1213,topology,"In this paper we prove the homotopy lifting property for actions of finite
abelian groups on Hausdorff topological spaces.",19,2,122,43.73
1214,topology,"Convergence theory is an extension of general topology. In contrast with
topology, it is closed under some important operations, like exponentiation.
With all its advantages, convergence theory remains rather unknown. It is an
aim of this paper to make it more familiar to the mathematical community.",46,5,300,34.42
1215,topology,"We show that except for $n = 2$ if a bridge surface for a knot is an index
$n$ topologically minimal surface, then after a perturbation it is still
topologically minimal with index at most $n+1$.",36,2,195,35.95
1216,topology,"In this note we prove that the Fulton-MacPherson compactification of
configuration spaces of smooth manifolds can not be extended to topological
manifolds in a natural manner, using recent work of Chen and Mann.",33,2,211,21.06
1217,topology,"We will characterize topological conjugate one-sided topological Markov
shifts in terms of their subgroups of continuous full groups and subalgebras of
Cuntz--Krieger algebras.",23,2,176,22.75
1218,topology,"We give a new proof of the string topology structure of a compact oriented
surface of genus g greater than or equal to 2, using elementary algebraic
topology. This reproves the result of Vaintrob.",34,3,196,54.22
1219,topology,"In this article, we survey the status of topological Zimmer's conjecture on
matrix group actions on manifolds.",17,2,110,37.3
1220,topology,"We give an upper bound on the topological complexity of varieties
$\mathcal{V}$ obtained as complements in $\mathbb{C}^m$ of the zero locus of a
polynomial. As an application, we determine the topological complexity of
unordered configuration spaces of the plane.",39,3,263,26.3
1221,topology,"We adapt the study of hyperspaces and function spaces from classical topology
to digital topology. We define digital hyperspaces and digital function graphs,
and study some of their relationships and graphical properties.",32,3,221,38.32
1222,topology,"For every finite closure space $X$ one can define a finite topological space
$\operatorname{Top} X$ together with a natural projection $\operatorname{Top}
X\longrightarrow X$. This could allow to apply the techniques of topological
combinatorics to the study of finite closure spaces.",40,3,284,17.34
1223,topology,"In generalization of knot quandles we introduce similar algebraic structures
associated with arbitrary pairs consisting of a path-connected topological
space and its path-connected subspace.",24,2,190,-12.11
1224,topology,"Two (strongly) zero-dimensional Lindel\""of topological groups whose product
has positive covering dimension are constructed. An example of a Lindel\""of
(strongly) zero-dimensional space whose free and free Abelian topological
groups are not strongly zero-dimensional is given.",35,3,276,11.41
1225,topology,"Iron-based superconductors offer an ideal platform for studying topological
superconductivity and Majorana fermions. In this paper, we carry out a
comprehensive study of the band topology and topological surface states of a
number of iron-based superconductors using a combination of density functional
theory (DFT) and dynamical mean field theory. We find that the strong
electronic correlation of Fe 3d electrons plays a crucial role in determining
the band topology and topological surface states of iron-based superconductors.
Electronic correlation not only strongly renormalizes the bandwidth of Fe 3d
electrons, but also shifts the band positions of both Fe 3d and As/Se p
electrons. As a result, electronic correlation moves the DFT-calculated
topological surface states of many iron-based superconductors much closer to
the Fermi level, which is crucial for realizing topological superconducting
surface states and observing Majorana zero modes as well as achieving practical
applications, such as quantum computation. More importantly, electronic
correlation can change the band topology and make some iron-based
superconductors topologically nontrivial with topological surface states
whereas they have trivial band topology and no topological surface states in
DFT calculations. Our paper demonstrates that it is important to take into
account electronic correlation effects in order to accurately determine the
band topology and topological surface states of iron-based superconductors and
other strongly correlated materials.",215,8,1539,6.47
1226,topology,"Let $G$ be a minimal split Kac-Moody group over a valued field {\mathcal{K}.
Motivated by the representation theory of $G$, we define two topologies of
topological group on $G$, which take into account the topology on {\mathcal{K}.",37,3,231,52.7
1227,topology,"In [D. Feng, W. Huang, Variational principle for weighted topological
pressure. J. Math. Pures Appl. (2016)], the authors studied weighted
topological pressure and established a variational principle for it. In this
paper, we introduce the notion of local weighted topological pressure and
generalize Feng and Huang's main results to localized version.",51,9,352,37.3
1228,topology,"We investigate the homotopy type of a certain homogeneous space for a simple
complex algebraic group. We calculate some of its classical topological
invariants and introduce a new one. We also propose several conjectures about
its topological rigidity.",38,4,252,33.2
1229,topology,"We study Farber's topological complexity for monotone symplectic manifolds.
More precisely, we estimate the topological complexity of 4-dimensional
spherically monotone manifolds whose Kodaira dimension is not $-\infty$.",27,3,220,-1.46
1230,topology,"We study groups of homeomorphic bijections on spaces that are finite unions
of compact connected linearly ordered subsets. We prove that all such groups
when endowed with the topology of point-wise convergence are topological
groups. }",36,3,235,45.25
1231,topology,"We give some basic properties of strongly topologically transitive,
supermixing, and hypermixing maps on general topological spaces. Then we
present some other results for which our mappings need to be continuous.",31,3,213,30.36
1232,topology,"This paper surveys some results and methods in topological transformation
groups.",11,2,81,34.93
1233,topology,"For every uncountable cardinal mu there is a ccc Boolean algebra whose
topological density is mu .",17,2,98,38.32
1234,topology,"We give a topological characterization of the n-dimensional pseudo-boundary
of the (2n+1)-dimensional Euclidean space.",14,2,118,6.5
1235,topology,This is a paper in Analytic Topology.,7,2,37,38.99
1236,topology,"In 1975, M. M. Choban introduced a new topology on the set of all closed
subsets of a topological space, similar to the Tychonoff topology but weaker
than it. In 1998, G. Dimov and D. Vakarelov used a generalized version of this
new topology, calling it Tychonoff-type topology. The present paper is devoted
to a detailed study of Tychonoff-type topologies on an arbitrary family M of
subsets of a set X. When M contains all singletons, a description of all
Tychonoff-type topologies O on M is given. The continuous maps of a special
form between spaces of the type (M,O) are described in an isomorphism theorem.
The problem of commutability between hyperspaces and subspaces with respect to
a Tychonoff-type topology} is investigated as well. Some topological properties
of the hyperspaces (M,O) with Tychonoff-type topologies O are briefly
discussed.",138,12,852,57.47
1237,topology,"Problem 540 of J. D. Lawson and M. Mislove in Open Problems in Topology asks
whether the process of taking duals terminate after finitely many steps with
topologies that are duals of each other. The problem for $T_1$ spaces was
already solved by G. E. Strecker in 1966. For certain topologies on hyperspaces
(which are not necessarily $T_1$), the main question was in the positive
answered by Bruce S. Burdick and his solution was presented on The First
Turkish International Conference on Topology in Istanbul in 2000. In this paper
we bring a complete and positive solution of the problem for all topological
spaces. We show that for any topological space $(X,\tau)$ it follows
$\tau^{dd}=\tau^{dddd}$. Further, we classify topological spaces with respect
to the number of generated topologies by the process of taking duals.",134,13,827,57.87
1238,topology,"This is a survey of compactification extension results and problems for a
special class of proximities.",16,2,103,29.86
1239,topology,"We give a complete topological classification of minimal surfaces in
Euclidian three-space.",12,2,91,0.08
1240,topology,We give a brief survey of abelian torsions of 3-manifolds.,10,2,58,78.25
1241,topology,"We survey some results concerning finite group actions on products of
spheres.",12,2,78,59.3
1242,topology,"We revisit the known problem whether each compact topology is contained in a
maximal compact topology and collect some partial answers to this question. For
instance we show that each compact topology is contained in a compact topology
in which convergent sequences have unique limits. We also answer a question of
D.E. Cameron by showing that each sequentially compact topology is contained in
a maximal sequentially compact topology. We finally observe that each sober
compact T_1-topology is contained in a maximal compact topology and that each
sober compact T_1-topology which is locally compact or sequential is the
infimum of a family of maximal compact topologies.",105,7,672,41.7
1243,topology,"This article is a short survey of the history of functional analysis for
topologists.",14,2,85,40.35
1244,topology,"This is a detailed introductory survey of the cohomological dimension theory
of compact metric spaces.",15,2,102,5.49
1245,topology,"We present the set of axioms for topological space with the operation of
boundary as primitive notion.",17,2,102,54.22
1246,topology,"We relate closure operations for ideals and for submodules to non-flat
Grothendieck topologies. We show how a Grothendieck topology on an affine
scheme induces a closure operation in a natural way, and how to construct for a
given closure operation fulfilling certain properties a Grothendieck topology
which induces this operation. In this way we relate the radical to the
surjective topology and the constructible topology, the integral closure to the
submersive topology, to the proper topology and to Voevodsky's h-topology, the
Frobenius closure to the Frobenius topology and the plus closure to the finite
topology. The topologies which are induced by a Zariski filter yield the
closure operations which are studied under the name of hereditary torsion
theories. The Grothendieck topologies enrich the corresponding closure
operation by providing cohomology theories, rings of global sections, concepts
of exactness and of stalks.",140,6,936,26.14
1247,topology,"This paper provides an informal sketch of a proof of the Baez-Dolan cobordism
hypothesis, which provides a classification for extended topological quantum
field theories.",24,2,170,21.74
1248,topology,"It is proved that any infinite Abelian group of infinite exponent admits a
non-discrete reflexive group topology.",17,2,113,45.76
1249,topology,"We provide a simple topological derivation of a formula for the Reidemeister
and the analityc torsion of spheres.",18,2,113,36.28
1250,topology,"In this paper we systematically study a simple class of translation-symmetry
protected topological orders in quantum spin systems using slave-particle
approach. The spin systems on square lattice are translation invariant, but may
break any other symmetries. We consider topologically ordered ground states
that do not spontaneously break any symmetry. Those states can be described by
Z2A or Z2B projective symmetry group. We find that the Z2A translation
symmetric topological orders can still be divided into 16 sub-classes
corresponding to 16 new translation-symmetry protected topological orders. We
introduced four $Z_2$ topological indices $\zeta_{\v{k}}=0,1$ at $\v
{k}=(0,0)$, $(0,\pi)$, $(\pi, 0)$, $(\pi ,\pi)$ to characterize those 16 new
topological orders. We calculated the topological degeneracies and crystal
momenta for those 16 topological phases on even-by-even, even-by-odd,
odd-by-even, and odd-by-odd lattices, which allows us to physically measure
such topological orders. We predict the appearance of gapless fermionic
excitations at the quantum phase transitions between those symmetry protected
topological orders. Our result can be generalized to any dimensions. We find
256 translation-symmetry protected Z2A topological orders for a system on 3D
lattice.",177,11,1284,28.13
1251,topology,"We explore possibilities and limitations of a purely topological approach to
the Dvoretzky Theorem.",14,2,99,14.97
1252,topology,"Conditions on a topological space $X$ under which the space $C(X,\mathbb{R})$
of continuous real-valued maps with the Isbell topology $\kappa $ is a
topological group (topological vector space) are investigated. It is proved
that the addition is jointly continuous at the zero function in
$C_{\kappa}(X,\mathbb{R})$ if and only if $X$ is infraconsonant. This property
is (formally) weaker than consonance, which implies that the Isbell and the
compact-open topologies coincide. It is shown the translations are continuous
in $C_{\kappa}(X,\mathbb{R})$ if and only if the Isbell topology coincides with
the fine Isbell topology. It is proved that these topologies coincide if $X$ is
prime (that is, with at most one non-isolated point), but do not even for some
sums of two consonant prime spaces.",122,6,796,38.45
1253,topology,"The goal of this article is to introduce some beautiful known riddles in
intuitive topology; hoping to make at least some fun for the reader.",25,2,141,54.56
1254,topology,"We investigate how Viro's integral calculus applies for the study of the
topology of stable maps. We also discuss several applications to Morin maps and
complex maps.",27,3,166,49.31
1255,topology,"Topological conformal field theories are defined using only basic results
from the theory of quasiconformal mappings.",16,2,117,4.47
1256,topology,"We prove that every TVS-cone metric space (i.e a cone metric space over a
locally convex topological vector space $E$) is first countable paracompact
topological space and by using Du's results in "" [A note on cone metric fixed
point theory and its equivalence, {Nonlinear Analysis},72(5),2259-2261
(2010)]"", we conclude that every TVS-cone metric space is topologically
isomorphic to a topological metric space. We also show how to construct
comparable metric topologies to TVS-cone metric topologies by using the system
of seminorms generating the topology of the locally convex topological vector
space $E$. When $E$ is a Banach space these metric topologies turn to be
equivalent to the original TVS-cone metric topologies. Even though, we remark
that there are still some fixed point theorems to deal nontrivially with them
in TVS-cone metric spaces. The nonlinear scalarization is used also to prove
some fixed point theorems with nonlinear contractive conditions.",148,7,970,38.15
1257,topology,"In the general context of functorial topologies, we prove that in the lattice
of all group topologies on an abelian group, the infimum between the Bohr
topology and the natural topology is the profinite topology. The profinite
topology and its connection to other functorial topologies is the main
objective of the paper. We are particularly interested in the poset C(G) of all
finite-index subgroups of an abelian group G, since it is a local base for the
profinite topology of G. We describe various features of the poset C(G) (its
cardinality, its cofinality, etc.) and we characterize the abelian groups G for
which C(G)\{G} is cofinal in the poset of all subgroups of G ordered by
inclusion. Finally, for pairs of functorial topologies T, S we define the
equalizer E(T,S), which permits to describe relevant classes of abelian groups
in terms of functorial topologies.",144,7,873,47.12
1258,topology,We survey some results on toric topology.,7,2,41,64.37
1259,topology,"We discuss the thermal (or gravitational) responses in topological
superconductors and in topological phases in general. Such thermal responses
(as well as electromagnetic responses for conserved charge) provide a
definition of topological insulators and superconductors beyond the
single-particle picture. In two-dimensional topological phases, the Str\v{e}da
formula for the electric Hall conductivity is generalized to the thermal Hall
conductivity. Applying this formula to the Majorana surface states of
three-dimensional topological superconductors predicts cross-correlated
responses between the angular momentum and thermal polarization (entropy
polarization). We also discuss a use of D-branes in string theory as a
systematic tool to derive all such topological terms and topological responses.
In particular, we relate the $\mathbb{Z}_2$ index of topological insulators
introduced by Kane and Mele (and its generalization to other symmetry classes
and to arbitrary dimensions) to the K-theory charge of non-BPS D-branes, and
vice versa. We thus establish a link between the stability of non-BPS D-branes
and the topological stability of topological insulators.",159,8,1171,6.13
1260,topology,"We remark some basic facts on homological aspects of involutive Lie
bialgebras and their involutive bimodules, and present some problems on surface
topology related to these facts.",27,2,180,18.69
1261,topology,"We show that a 3-manifold containing an incompressible surface has
topologically minimal surfaces of arbitrary high genus.",17,2,122,20.38
1262,topology,"The Su-Schrieffer-Heeger (SSH) model describes a one-dimensional $Z_{2}$
topological insulator, which has two topological distinct phases corresponding
to two different dimerizations. When spin-orbit coupling is introduced into the
SSH model, we find the structure of the Bloch bands can be greatly changed, and
most interestingly, a new topological phase with single zero-energy bound state
which exhibits non-Abelian statistics at each end emerges, which suggests that
a new topological invariant is needed to fully classify all phases. In a
comparatively large range of parameters, we find that spin-orbit coupling
induces completely flat band with nontrivial topology. For the case with
non-uniform dimerizaton, we find that spin-orbit coupling changes the
symmetrical structure of topological excitations known as solitons and
antisolitons and when spin-orbit coupling is strong enough to induce a
topological phase transition, the whole system is topologically nontrivial but
with the disappearance of solitons and antisolitons, consequently, the system
is a real topological insulator with well-protected end states.",157,5,1123,14.67
1263,topology,"In this paper, the author introduce and study the notion of
pre-{\gamma}-I-open sets in ideal topological space.",17,2,112,54.22
1264,topology,"We examine sufficient conditions for the dual of a topological group to be
metrizable and locally compact.",17,2,106,37.3
1265,topology,"If a finite group acts topologically, faithfully and orientation preservingly
on R^3, then it is isomorphic to a subgroup of SO(3).",21,2,131,33.24
1266,topology,"In this paper we investigate some connections between Topological Dynamics,
the theory of G-Principal Bundles, and the theory of Locally Trivial Groupoids.",22,2,155,15.31
1267,topology,"We continue to investigate applications of $k$-covers in function spaces with
the compact-open topology.",14,2,104,23.43
1268,topology,"We present and prove a topological characterization of geodesic laminations
on hyperbolic surfaces of finite type.",16,2,114,4.47
1269,topology,"We show that if there exists a topologically expansive homeomorphism on a
uniform space, then the space is always a regular space. Through examples we
show that in general composition of topologically expansive homeomorphisms need
not be topological expansive and also that conjugate of topologically expansive
homeomorphism need not be topological expansive. Further, we obtain a
characterization of orbit expansivity in terms of topological expansivity and
conclude that if there exists a topologically expansive homeomorphism on a
compact uniform space then the space must be metrizable. We also study
positively expansive maps on topological space and obtain condition for maps to
be positively topological expansive in terms of finite open cover. Further, we
show that if there exists a continuous, one-to-one, positively topological
expansive map on a compact uniform space, then the space is finite. We also
give an example of a positively topological expansive map on a non--Hausdorff
space.",150,7,999,20.72
1270,topology,"We show that the topological complexity of a finitely generated torsion free
hyperbolic group $\pi$ with $\cd\pi=n$ equals $2n$.",19,2,128,35.27
1271,topology,"For a non-singular real algebraic projective curve, topological restrictions
on a closed motion of a simple real divisor in its linear equivalence class are
found.",25,2,163,20.72
1272,topology,"We introduce the notion of a topological toric manifold and a topological fan
and show that there is a bijection between omnioriented topological toric
manifolds and complete non-singular topological fans. A topological toric
manifold is a topological analogue of a toric manifold and the family of
topological toric manifolds is much larger than that of toric manifolds. A
topological fan is a combinatorial object generalizing the notion of a
simplicial fan in toric geometry.
  Prior to this paper, two topological analogues of a toric manifold have been
introduced. One is a quasitoric manifold and the other is a torus manifold. One
major difference between the previous notions and topological toric manifolds
is that the former support a smooth action of an $S^1$-torus while the latter
support a smooth action of a $\C^*$-torus. We also discuss their relation in
details.",139,8,879,34.36
1273,topology,"Even in spaces of formal power series is required a topology in order to
legitimate some operations, in particular to compute infinite summations. Many
topologies can be exploited for different purposes. Combinatorists and
algebraists may think to usual order topologies, or the product topology
induced by a discrete coefficient field, or some inverse limit topologies.
Analysists will take into account the valued field structure of real or complex
numbers. As the main result of this paper we prove that the topological dual
spaces of formal power series, relative to the class of product topologies with
respect to Hausdorff field topologies on the coefficient field, are all the
same, namely the space of polynomials. As a consequence, this kind of rigidity
forces linear maps, continuous for any (and then for all) of those topologies,
to be defined by very particular infinite matrices similar to row-finite
matrices.",145,7,924,38.45
1274,topology,"If a fintie group G acts topologically and faithfully on R^3, then G is a
subgroup of O(3)",18,1,90,70.13
1275,topology,"We show how topology of a space may lead to tensor fields on (the smooth part
of) moduli spaces of the fundamental group.",23,2,121,73.51
1276,topology,"The discovery of novel topological phase advances our knowledge of nature and
stimulates the development of applications. In non-Hermitian topological
systems, the topology of band touching exceptional points is very important.
Here we propose a real-energy topological gapless phase arising from
exceptional points in one dimension, which has identical topological invariants
as the topological gapless phase arising from degeneracy points. We develop a
graphic approach to characterize the topological phases, where the eigenstates
of energy bands are mapped to the graphs on a torus. The topologies of
different phases are visualized and distinguishable; and the topological
gapless edge state with amplification appropriate for topological lasing exists
in the nontrivial phase. These results are elucidated through a non-Hermitian
Su-Schrieffer-Heeger ladder. Our findings open new way for identifying topology
phase of matter from visualizing the eigenstates.",134,8,965,26.71
1277,topology,"It is often thought that emergent phenomena in topological phases of matter
are destroyed when tuning to a critical point. In particular, topologically
protected edge states supposedly delocalize when the bulk correlation length
diverges. We show that this is not true in general. Edge states of topological
insulators or superconductors remain exponentially localized---despite a
vanishing band gap---if the transition increases the topological index. This
applies to all classes where the topological classification is larger than
$Z_2$, notably including Chern insulators. Moreover, these edge states are
stable to disorder, unlike in topological semi-metals. This new phenomenon is
explained by generalizing band (or mass) inversion---a unifying perspective on
topological insulators---to kinetic inversion. In the spirit of the
bulk-boundary correspondence, we also identify topological invariants at
criticality, which take half-integer values and separate topologically-distinct
universality classes by a multi-critical point. This work enlarges the scope of
topological protection and stability by showing that bulk energy gaps can be
unnecessary. Experimental probes and stability to interactions are discussed.",164,11,1220,12.53
1278,topology,"We prove the topological analogue of the period-index conjecture in each
dimension away from a small set of primes.",19,2,115,52.19
1279,topology,"Superconductors can be classified as topological or not based on whether
time-reversal symmetry (TRS), chiral symmetry, and particle-hole symmetry are
preserved or not. Further, topological superconductors can also be classified
as chiral or helical. In this paper, using Hanbury-Brown and Twiss (HBT) shot
noise correlations and the non-local conductance, we probe metal/2D
unconventional superconductor/metal junctions to understand better the pairing
topological vs. non-topological or helical vs. chiral or nodal vs. gapful. We
see that HBT correlations are asymmetric as a function of bias voltage for
non-topological superconductors, whereas they are symmetric for topological
superconductors irrespective of the barrier strength. Topological
superconductors are associated with Majorana fermions which are important for
topological quantum computation. By distinguishing topological superconductors
from non-topological superconductors, our study will help search for Majorana
fermions, which will aid in designing a topological quantum computer.",137,10,1053,11.82
1280,topology,"We study tightness properties and selective versions of separability in
bitopological function spaces endowed with set-open topologies.",17,2,135,11.92
1281,topology,"Given a topological group $G$ that can be embedded as a topological subgroup
into some topological vector space (over the field of reals) we say that $G$
has invariant linear span if all linear spans of $G$ under arbitrary embeddings
into topological vector spaces are isomorphic as topological vector spaces.
  For an arbitrary set $A$ let $\mathbb{Z}^{(A)}$ be the direct sum of
$|A|$-many copies of the discrete group of integers endowed with the Tychonoff
product topology. We show that the topological group $\mathbb{Z}^{(A)}$ has
invariant linear span. This answers a question of D. Dikranjan et al. in
positive.
  We prove that given a non-discrete sequential space $X$, the free abelian
topological group $A(X)$ over $X$ is an example of a topological group that
embeds into a topological vector space but does not have invariant linear span.",136,8,850,48.43
1282,topology,"Strong light-matter interaction enriches topological photonics by dressing
light with matter, which provides the possibility to realize tuneable
topological devices with immunity to defects. Topological exciton polaritons,
half-light half-matter quasiparticles with giant optical nonlinearity represent
a unique platform for active topological photonics with phase tunability.
Previous demonstrations of exciton polariton topological insulators still
demand cryogenic temperatures and their topological properties are usually
fixed without phase tunability. Here, we experimentally demonstrate a
room-temperature exciton polariton topological insulator with active phase
tunability in a perovskite zigzag lattice. Polarization serves as a degree of
freedom to control the reversible transition between distinct topological
phases, thanks to the polarization-dependent anisotropy in halide perovskite
microcavities. The topologically nontrivial polariton states localized in the
edges persist in the presence of a natural defect, showing strong immunity to
disorder. We further demonstrate that exciton polaritons can condense into the
topological edge states under optical pumping. These results provide an ideal
platform for realizing tuneable topological polaritonic devices with
room-temperature operation, which can find important applications in optical
control, modulation and switching.",174,9,1393,-1.42
1283,topology,"Topological states of matter are characterized by global topological
invariants which change their value across a topological quantum phase
transition. It is commonly assumed that the transition between topologically
distinct noninteracting gapped phases of fermions is necessarily accompanied by
the closing of the band gap as long as the symmetries of the system are
maintained. We show that such a quantum phase transition is possible without
closing the gap in the case of a three-dimensional topological band insulator.
We demonstrate this by calculating the free energy of the minimal model for a
topological insulator, the Bernevig-Hughes-Zhang model, and show that as the
band curvature continuously varies, a jump between the band gap minima
corresponding to the topologically trivial and nontrivial insulators occurs.
Therefore, this first order phase transition is a generic feature of
three-dimensional topological band insulators. For a certain parameter range we
predict a re-entrant topological phase transition. We discuss our findings in
connection with the recent experimental observation of a discontinuous
topological phase transition in a family of topological crystalline insulators.",173,8,1205,12.56
1284,topology,"There is a topological embedding $\iota:\mathbb{S}^1\to\mathbb{R}^5$ such
that $\pi_3(\mathbb{R}^5\setminus\iota(\mathbb{S}^1))=0$. Therefore, no
$3$-sphere can be linked with $\iota(\mathbb{S}^1)$.",17,3,198,-21.76
1285,topology,"This paper proposes a new topology optimization method that applies a
convolutional neural network (CNN), which is one deep learning technique for
topology optimization problems. Using this method, we acquire a structure with
a little higher performance that could not be obtained by the previous topology
optimization method. In particular, in this paper, we solve a topology
optimization problem aimed at maximizing stiffness with a mass constraint,
which is a common type of topology optimization. In this paper, we first
formulate the conventional topology optimization by the solid isotropic
material with penalization method. Next, we formulate the topology optimization
using CNN. Finally, we show the effectiveness of the proposed topology
optimization method by solving a verification example, namely a topology
optimization problem aimed at maximizing stiffness. In this research, as a
result of solving the verification example for a small design area of 16x32
element, we obtain the solution different from the previous topology
optimization method. This result suggests that stiffness information of
structure can be extracted and analyzed for structural design by analyzing the
density distribution using CNN like an image. This suggests that CNN technology
can be utilized in the structural design and topology optimization.",197,10,1339,23.87
1286,topology,"A short survey on applications of algebraic geometry in topological data
analysis.",12,2,82,0.08
1287,topology,"We prove that the topological complexity $\mathrm{TC}(\pi)$ equals
$\mathrm{cd}(\pi\times\pi)$ for certain toral relatively hyperbolic groups
$\pi$.",16,2,148,12.94
1288,topology,"Topological phases of the famous Altland-Zirnbauer (AZ) tenfold classes are
defined on the equilibrium ground states. Whether such equilibrium topological
phases have universal correspondence to far-from-equilibrium quantum dynamics
is a fundamental issue of both theoretical and experimental importance. Here we
uncover the universal topological quench dynamics linking to the equilibrium
topological phases for the complete AZ tenfold classes, with a general
framework being established. We show a fundamental result that a
$d$-dimensional topological phase of the tenfold class, with an integer
invariant or $\mathbb{Z}_{2}$ index defined on high symmetry momenta, is
generically characterized by topology reduced to the highest-order
band-inversion surfaces located at arbitrary discrete momenta of Brillouin
zone. Such dimension-reduced topology is further captured by universal
topological patterns emerging in far-from-equilibrium quantum dynamics by
quenching the system from trivial phase to the topological regime, rendering
the dynamical hallmark of the equilibrium topological phase. This work
establishes a universal dynamical characterization for the complete AZ symmetry
classes of topological phases, which has broad applications in theory and
experiment.",168,7,1271,0.76
1289,topology,"The past decade has witnessed a booming development of topological photonics,
which revolutionizes the methodology for controlling the behavior of light. A
gigantic achievement is to engineer robust confined modes localized at
interfaces between topologically distinct regions, where the optical context
can trigger exotic topological phenomena exclusive to photons. Here, we provide
an experimentally flexible approach to engineering topologically induced
interface states in the visible regime via a unique design of complex
superlattice formed by connecting two component superlattices of distinguished
topological phases. Assisted by the intrinsic pseudospin degree due to the
splitting between TM and TE polarized modes, we attain a precise manipulation
of the spin-dependent topological interface states that can manifest themselves
straightforwardly through transmission spectra. More specifically, since these
topological localized modes stem from the hybridization of artificial photonic
orbitals that are of topological origin as well, they are deemed as a novel
topological effect and thus named as the secondary topological interface
states. Our work develops an innovative and productive strategy to tune
topologically protected localized modes, based on which various applications
such as selective local enhancement can be exploited.",184,7,1348,6.47
1290,topology,"We give a short, topological proof that all graphs admit tree-decompositions
displaying their topological ends.",15,2,111,30.87
1291,topology,"Bulk-boundary correspondence is a fundamental principle for topological
phases where bulk topology determines gapless boundary states. On the other
hand, it has been known that corner or hinge modes in higher order topological
insulators may appear due to ""extrinsic"" topology of the boundaries even when
the bulk topological numbers are trivial. In this paper, we find that Floquet
anomalous boundary states in quantum walks have similar extrinsic topological
natures. In contrast to higher order topological insulators, the extrinsic
topology in quantum walks is manifest even for first-order topological phases.
We present the topological table for extrinsic topology in quantum walks and
illustrate extrinsic natures of Floquet anomalous boundary states in concrete
examples.",112,6,779,31.82
1292,topology,"Since longitudinal spin-spin interaction is ubiquitous in magnetic materials,
it is very interesting to explore the interplay between topology and
longitudinal spin-spin interaction. Here, we examine the role of longitudinal
spin-spin interaction on topological magnon excitations. Remarkably, even for
single-magnon excitations, we discover topological edge states and defect edge
states of magnon excitations in a dimerized Heisenberg XXZ chain and their
topological properties can be distinguished via adiabatic quantum transport. We
uncover topological phase transitions induced by longitudinal spin-spin
interactions whose boundary is analytically obtained via the transfer matrix
method. For multi-magnon excitations, even-magnon bound states are found to be
always topologically trivial, but odd-magnon bound states may be topologically
nontrivial due to the interplay between the transverse dimerization and the
longitudinal spin-spin interaction. For two-dimensional spin systems, the
longitudinal spin-spin interaction contributes to the coexistence of defect
corner states, second-order topological corner states and first-order
topological edge states. Our work opens an avenue for exploring topological
magnon excitations and has potential applications in topological magnon
devices.",167,8,1296,4.92
1293,topology,"In this paper, we pose the concepts of pre-topological groups and some
generalizations of pre-topological groups. First, we systematically investigate
some basic properties of pre-topological groups; in particular, we prove that
each $T_{0}$ pre-topological group is regular and every almost topological
group is completely regular which extends A.A. Markov's theorem to the class of
almost topological groups. Moreover, it is shown that an almost topological
group is $\tau$-narrow if and only if it can be embedded as a subgroup of a
pre-topological product of almost topological groups of weight less than or
equal to $\tau$. Finally, the cardinal invariant, the precompactness and the
resolvability are investigated in the class of pre-topological groups.",112,7,759,31.82
1294,topology,"We show that every topological n-manifold M admits a locally flat closed
embedding $\iota\colon M \hookrightarrow \mathbb{R}^{2n+1}$ and is a retract of
some neighbourhood $U \subseteq \mathbb{R}^{2n+1}$",27,1,203,27.15
1295,topology,"The existence of chiral edge states, corresponding to the nontrivial
bulk-band topology characterized by a non-vanishing topological invariant, and
the manipulation of topological transport via chiral edge states promise
topological electronic/spintronic device applications. Here we predict the
existence, practical realization, topological protection, and topological
switching of spin-gapless valley-filtered chiral edge states, representing a
novel topological Dirac spin-gapless/half-metal phase in antiferromagnetic
honeycomb structures terminated on zigzag edges. We demonstrate that this
phenomenon is realizable if a perpendicular (transverse) electric field is
applied in zigzag nanoribbons with an antiferromagnetic ordering on the
boundary (in the bulk), and the Weber-Fechner type nonlinear behavior is
optimizable by a transverse (perpendicular) electric field. The existence of
spin-gapless valley-filtered chiral edge states, their correspondence with
nontrivial topological character in the bulk, and electric-field-driven
switching of their spin-polarization that is accompanied by switching of
bulk-band topology promise a new strategy for topological spintronics without
spin-orbit interaction.",149,5,1214,-17.15
1296,topology,"We show that any strongly negative amphichiral knot with a trivial Alexander
polynomial is equivariantly topologically slice.",17,2,125,20.38
1297,topology,"Network topology has significant impacts on operational performance of power
systems. While extensive research efforts have been devoted to optimization of
network topology for improving various system performances, the problem of how
to transition from the initial topology to the desired optimal topology
requires study. To address this problem, we propose the concept of optimal
topology transition (OTT). This aims to find the topology transition trajectory
from an initial topology to a desired terminal topology, which optimizes
certain transition performance and satisfies operational constraints. The OTT
problem is further formulated as a mixed-integer program under certain
assumptions. Next, we propose the formulation of transition-embedded topology
optimization that is capable of optimizing network topology and its transition
trajectory simultaneously. Considering the time complexity of directly solving
the mixed-integer programs, an efficient problem-specific solution algorithm is
developed. Finally, numerical studies demonstrate the effectiveness of the
proposed OTT and transition-embedded topology optimization models, as well as
the superiority of the obtained optimal transition trajectories compared to ad
hoc transition trajectories.",167,9,1260,7.96
1298,topology,"In this paper, we introduce round and sleek topological spaces and study
their properties.",14,2,90,57.27
1299,topology,"We discuss a variant of the Banach-Mazur game which has applications to
topological open mapping and closed graph theorems.",19,2,123,43.73
1300,topology,"We show that topological characterization and classification in
$D$-dimensional systems, which are thermodynamically large in only $D-\delta$
dimensions and finite in size in $\delta$ dimensions, is fundamentally
different from that of systems thermodynamically large in all $D$-dimensions:
as $(D-\delta)$-dimensional topological boundary states permeate into a
system's $D$ dimensional bulk with decreasing system size, they hybridize to
create novel topological phases characterized by a set of $\delta+1$
topological invariants, ranging from the $D$-dimensional topological invariant
to the $(D-\delta)$-dimensional topological invariant. The system exhibits
topological response signatures and bulk-boundary correspondences governed by
combinations of these topological invariants taking non-trivial values, with
lower-dimensional topological invariants characterizing fragmentation of the
underlying topological phase of the system thermodynamically large in all
$D$-dimensions. We demonstrate this physics for the paradigmatic Chern
insulator phase, but show its requirements for realization are satisfied by a
much broader set of topological systems.",143,4,1158,-27.71
1301,topology,"Topological acoustics is an emerging field that lies at the intersection of
condensed matter physics, mechanical structural design and acoustics
engineering. It explores the design and construction of novel artificial
structures, such as acoustic metamaterials and phononic crystals, to manipulate
sound waves robustly, taking advantage of topological protection. Early work on
topological acoustics was limited to duplicating topological phases that have
been understood in condensed matter systems, but recent advances have shifted
the paradigm to exploring novel topological concepts that are difficult to
realize in other physical systems, such as various topological semimetal
phases, and topological phases associated with Floquet engineering, fragile
topology, non-Hermiticity and synthetic dimensions. These developments
demonstrate the unique advantages of topological acoustic systems and their
role in developing topological physics. In this Review, we survey the
fundamental mechanisms, basic designs and practical realizations of topological
phases in acoustic systems, and provide an overview of future directions and
potential applications.",153,6,1155,-1.89
1302,topology,"A strongly zero-dimensional topological group containing a closed subgroup of
positive covering dimension is constructed.",15,2,121,-2.98
1303,topology,"Topological materials can host edge and corner states that are protected from
disorder and material imperfections. In particular, the topological edge states
of mechanical structures present unmatched opportunities for achieving robust
responses in wave guiding, sensing, computation, and filtering. However,
determining whether a mechanical structure is topologically nontrivial and
features topologically-protected modes has hitherto relied on theoretical
models. This strong requirement has limited the experimental and practical
significance of topological mechanics to laboratory demonstrations. Here, we
introduce and validate an experimental method to detect the topologically
protected zero modes of mechanical structures without resorting to any modeling
step. Our practical method is based on a simple electrostatic analogy:
topological zero modes are akin to electric charges. To detect them, we
identify elementary mechanical molecules and measure their chiral polarization,
a recently introduced marker of topology in chiral phases. Topological zero
modes are then identified as singularities of the polarization field. Our
method readily applies to any mechanical structure and effectively detects the
edge and corner states of regular and higher-order topological insulators. Our
findings extend the reach of chiral topological phases beyond designer
materials, and allow their direct experimental investigation.",190,11,1427,9.89
1304,topology,"In this paper, we introduce a novel fuzzy structure named ""fuzzy primal"". We
study the essential properties and discuss basic operations on it. A fuzzy
operator (.)$^\diamond$ on the family of all fuzzy sets is introduced here by
applying the q-neighborhood structure to a primal fuzzy topological space along
with the Lukasiewicz disjunction. We explore the main characterizations of
(.)$^\diamond$. Then, we define another fuzzy operator, symbolized by
Cl$^\diamond$, with the utilization of (.)$^\diamond$. These fuzzy operators
are studied in order to deduce a new fuzzy topology from the original one. Such
a new fuzzy topology is called primal fuzzy topology. The fundamental
structure, particularly a fuzzy base that generates primal fuzzy topologies, as
well as many relationships between different fuzzy primals and fuzzy
topologies, are also analyzed. Lastly, the concept of compatibility between
fuzzy primals and fuzzy topologies is introduced, and some equivalent
conditions related to this are examined. It is shown that if a fuzzy primal is
compatible with a fuzzy topology, then the fuzzy base that generates the primal
fuzzy topology is itself a fuzzy topology.",179,14,1178,46.47
1305,topology,"The endomorphism monoid of a model-theoretic structure carries two
interesting topologies: on the one hand, the topology of pointwise convergence
induced externally by the action of the endomorphisms on the domain via
evaluation; on the other hand, the Zariski topology induced within the monoid
by (non-)solutions to equations. For all concrete endomorphism monoids of
$\omega$-categorical structures on which the Zariski topology has been analysed
thus far, the two topologies were shown to coincide, in turn yielding that the
pointwise topology is the coarsest Hausdorff semigroup topology on those
endomorphism monoids. We establish two systematic reasons for the two
topologies to agree, formulated in terms of the model-complete core of the
structure. Further, we give an example of an $\omega$-categorical structure on
whose endomorphism monoid the topology of pointwise convergence and the Zariski
topology differ, answering a question of Elliott, Jonu\v{s}as, Mitchell,
P\'eresse and Pinsker.",144,5,1001,18.02
1306,topology,"In this work, elastic fractal higher-order topological states are
investigated. Bott index is adopted to characterize the topological property of
elastic fractal structures. The topological corner and edge states of elastic
waves in fractal structures are realized theoretically and experimentally.
Different from traditional two-dimension (2D) high-order topological insulators
based on periodic structures, the high-order topological states based on
elastic fractal structures in this work support not only abundant topological
inner corner states and edge states, but also topological outer corner states.
The richness of corner states is much higher than that of topological
insulators based on periodic structures. The strong robustness of the
topological corner states in the fractal structure are verified by introducing
disorders and defects. The topological phenomenon of elastic fractal structures
revealed in this work enriches the topological physics of elastic systems and
breaks the limitation of that relies on periodic elastic structures. The
results have important application prospects in energy harvesting, information
transmissions, elastic energy acquisitions and high-sensitivity detections.",163,9,1213,16.93
1307,topology,"In this paper we present a novel framework for unsupervised topological
clustering resulting in improved loop. In this paper we present a novel
framework for unsupervised topological clustering resulting in improved loop
detection and closure for SLAM. A navigating mobile robot clusters its
traversal into visually similar topologies where each cluster (topology)
contains a set of similar looking images typically observed from spatially
adjacent locations. Each such set of spatially adjacent and visually similar
grouping of images constitutes a topology obtained without any supervision. We
formulate a hierarchical loop discovery strategy that first detects loops at
the level of topologies and subsequently at the level of images between the
looped topologies. We show over a number of traversals across different Habitat
environments that such a hierarchical pipeline significantly improves SOTA
image based loop detection and closure methods. Further, as a consequence of
improved loop detection, we enhance the loop closure and backend SLAM
performance. Such a rendering of a traversal into topological segments is
beneficial for downstream tasks such as navigation that can now build a
topological graph where spatially adjacent topological clusters are connected
by an edge and navigate over such topological graphs.",194,9,1328,21.43
1308,topology,"We study the expressivity of ReLU neural networks in the setting of a binary
classification problem from a topological perspective. Recently, empirical
studies showed that neural networks operate by changing topology, transforming
a topologically complicated data set into a topologically simpler one as it
passes through the layers. This topological simplification has been measured by
Betti numbers, which are algebraic invariants of a topological space. We use
the same measure to establish lower and upper bounds on the topological
simplification a ReLU neural network can achieve with a given architecture. We
therefore contribute to a better understanding of the expressivity of ReLU
neural networks in the context of binary classification problems by shedding
light on their ability to capture the underlying topological structure of the
data. In particular the results show that deep ReLU neural networks are
exponentially more powerful than shallow ones in terms of topological
simplification. This provides a mathematically rigorous explanation why deeper
networks are better equipped to handle complex and topologically rich data
sets.",168,8,1146,13.28
1309,topology,"Topological data analysis is a powerful tool for describing topological
signatures in real world data. An important challenge in topological data
analysis is matching significant topological signals across distinct systems.
In geometry and probability theory, optimal transport formalises notions of
distance and matchings between distributions and structured objects. We propose
to combine these approaches, constructing a mathematical framework for optimal
transport-based matchings of topological features. Building upon recent
advances in the domains of persistent homology and optimal transport for
hypergraphs, we develop a transport-based methodology for topological data
processing. We define measure topological networks, which integrate both
geometric and topological information about a system, introduce a distance on
the space of these objects, and study its metric properties, showing that it
induces a geodesic metric space of non-negative curvature. The resulting
Topological Optimal Transport (TpOT) framework provides a transport model on
point clouds that minimises topological distortion while simultaneously
yielding a geometrically informed matching between persistent homology cycles.",158,8,1207,6.24
1310,topology,"The purpose of this note is to start the systematic analysis of cofinal types
of topological groups.",17,2,100,54.22
1311,topology,"Exploration of nontrivial superconductivity and electronic band topology is
at the core of condensed matter physics and applications to quantum
information. The transition-metal dichalcogenide (TMDC) MoTe$_2$ has been
proposed as an ideal candidate to explore the interplay between topology and
superconductivity, but their studies remain limited because of the
high-pressure environments required to control the topological phase
transition. In this work, we demonstrate the tunable superconductivity and the
resultant higher-order topology of MoTe$_2$ under extreme pressure. In the
pressured T$_d$ phase, Andreev reflection spectroscopy reveals two-gap
features, indicating that the Weyl fermions lead to a topological
$s^{\pm}$-wave multigap superconductivity. On the other hand, the high-pressure
1T$'$ phase presents $p$-wave surface superconductivity emergent from the
second-order topological bands via the bulk-to-surface proximity effect. Our
analysis suggests that the topological hinge states generated from second-order
topological bands evolve into zero-energy Majorana hinge states in the
second-order topological superconductor. These results demonstrate the
potential realization of topological superconductivity in MoTe$_2$, thus
opening a pathway for studying various topological natures of TMDC materials.",169,8,1325,13.17
1312,topology,"We define topologically semiperfect (complete, separated, right linear)
topological rings and characterize them by equivalent conditions. We show that
the endomorphism ring of a module, endowed with the finite topology, is
topologically semiperfect if and only if the module is decomposable as an
(infinite) direct sum of modules with local endomorphism rings. Then we study
structural properties of topologically semiperfect topological rings and prove
that their topological Jacobson radicals are strongly closed and the related
topological quotient rings are topologically semisimple. For the endomorphism
ring of a direct sum of modules with local endomorphism rings, the topological
Jacobson radical is described explicitly as the set of all matrices of
nonisomorphisms. Furthermore, we prove that, over a topologically semiperfect
topological ring, all finitely generated discrete modules have projective
covers in the category of modules, while all lattice-finite contramodules have
projective covers in both the categories of modules and contramodules. We also
show that the topological Jacobson radical of a topologically semiperfect
topological ring is equal to the closure of the abstract Jacobson radical, and
present a counterexample demonstrating that the topological Jacobson radical
can be strictly larger than the abstract one. Finally, we discuss the problem
of lifting idempotents modulo the topological Jacobson radical and the
structure of projective contramodules for topologically semiperfect topological
rings.",214,8,1534,6.58
1313,topology,"A hallmark feature of topologically ordered states of matter is the
dependence of ground state degeneracy (GSD) on the topology of the manifold
determined by the global shape of the system. Although the topology of a
physical system is practically hard to manipulate, recently it was shown that
in certain topologically ordered phases, topological defects can introduce
extra topological GSD. Here the topological defects can be viewed as
effectively changing the topology of the physical system. Previous studies have
been focusing on two spatial dimensions with point-like topological defects. In
three dimensions, line-like topological defects can appear. They are closed
loops in the bulk that can be linked and knotted, effectively leading to
complex three dimensional manifolds in certain topologically ordered states.
This paper studies the properties of such line-defects in a particular context:
the lattice dislocations. We give an analytical construction, together with
support from exact numerical calculations, for the dependence of the GSD on
dislocations of certain doubled versions of the exactly solvable Kitaev's toric
code models in both two and three dimensions. We find that the GSD of the 3d
model depends only on the total number of dislocation loops, no matter how they
are linked or knotted. The results are extended to Z_n generalizations of the
model. Additionally, we consider the phases in which the crystalline orders are
destroyed through proliferation of double dislocations. The resulting phases
are shown to host topological orders described by non-Abelian gauge theories.",242,13,1606,34.05
1314,topology,"In a topological Riesz space there are two types of bounded subsets: order
bounded subsets and topologically bounded subsets. It is natural to ask (1)
whether an order bounded subset is topologically bounded and (2) whether a
topologically bounded subset is order bounded. A classical result gives a
partial answer to (1) by saying that an order bounded subset of a locally solid
Riesz space is topologically bounded. This paper attempts to further
investigate these two questions. In particular, we show that (i) there exists a
non-locally solid topological Riesz space in which every order bounded subset
is topologically bounded; (ii) if a topological Riesz space is not locally
solid, an order bounded subset need not be topologically bounded; (iii) a
topologically bounded subset need not be order bounded even in a locally
convex-solid Riesz space. Next, we show that (iv) if a locally solid Riesz
space has an order bounded topological neighborhood of zero, then every
topologically bounded subset is order bounded; (v) however, a locally
convex-solid Riesz space may not possess an order bounded topological
neighborhood of zero even if every topologically bounded subset is order
bounded; (vi) a pseudometrizable locally solid Riesz space need not have an
order bounded topological neighborhood of zero. In addition, we give some
results about the relationship between order bounded subsets and positive
homogeneous operators.",223,8,1435,22.18
1315,topology,"In this paper the weak topology on a normed space is studied from the
viewpoint of infinite-dimensional topology. Besides the weak topology on a
normed space $X$ (coinciding with the topology of uniform convergence on finite
subsets of the dual space $X^*$), we consider the topology $c$ of uniform
convergence on compact subsets of $X^*$. It is known that this topology
coincides with the weak topology on bounded subsets of $X$, but unlike to the
latter has much better topological properties (e.g., is stratifiable).
  We prove that for normed spaces $X,Y$ with separable duals the spaces
$(X,weak)$, $(Y,weak)$ are sequentially homeomorphic if and only if $\mathcal
W(X)=\mathcal W(Y)$, where $\mathcal W(X)$ is the class of topological spaces
homeomorphic to closed bounded subsets of $(X,weak)$. Moreover, if $X,Y$ are
Banach spaces which are isomorphic to their hyperplanes and have separale
duals, then the spaces $(X,weak)$ and $(Y,weak)$ are sequentially homeomorphic
if and only of the spaces $(X,c)$ and $(Y,c)$ are homeomorphic. To prove this
result, we show that for a normed space $X$ which is isomorphic to its
hyperpane and has separable dual, the space $(X,c)$ (resp. $(X,weak)$) is
(sequentially) homeomorphic to the product $B\times\mathbb R^\infty$ of the
weak unit ball $B$ of $X$ and the linear space $\mathbb R^\infty$ with
countable Hamel basis and the strongest linear topology.",218,10,1404,39.91
1316,topology,"In this paper, a new computational framework based on the topology derivative
concept is presented for evaluating stochastic topological sensitivities of
complex systems. The proposed framework, designed for dealing with high
dimensional random inputs, dovetails a polynomial dimensional decomposition
(PDD) of multivariate stochastic response functions and deterministic topology
derivatives. On one hand, it provides analytical expressions to calculate
topology sensitivities of the first three stochastic moments which are often
required in robust topology optimization (RTO). On another hand, it offers
embedded Monte Carlo Simulation (MCS) and finite difference formulations to
estimate topology sensitivities of failure probability for reliability-based
topology optimization (RBTO). For both cases, the quantification of
uncertainties and their topology sensitivities are determined concurrently from
a single stochastic analysis. Moreover, an original example of two random
variables is developed for the first time to obtain analytical solutions for
topology sensitivity of moments and failure probability. Another 53-dimension
example is constructed for analytical solutions of topology sensitivity of
moments and semi-analytical solutions of topology sensitivity of failure
probabilities in order to verify the accuracy and efficiency of the proposed
method for high-dimensional scenarios. Those examples are new and make it
possible for researchers to benchmark stochastic topology sensitivities of
existing or new algorithms. In addition, it is unveiled that under certain
conditions the proposed method achieves better accuracies for stochastic
topology sensitivities than for the stochastic quantities themselves.",228,10,1728,-4.97
1317,topology,"The bulk-boundary correspondence, which links a bulk topological property of
a material to the existence of robust boundary states, is a hallmark of
topological insulators. However, in crystalline topological materials the
presence of boundary states in the insulating gap is not always necessary since
they can be hidden in the bulk energy bands, obscured by boundary artifacts of
non-topological origin, or, in the case of higher-order topology, they can be
gapped altogether. Crucially, in such systems the interplay between
symmetry-protected topology and the corresponding symmetry defects can provide
a variety of bulk probes to reveal their topological nature. For example, bulk
crystallographic defects, such as disclinations and dislocations, have been
shown to bind fractional charges and/or robust localized bound states in
insulators protected by crystalline symmetries. Recently, exotic defects of
translation symmetry called partial dislocations have been proposed as a probe
of higher-order topology. However, it is a herculean task to have experimental
control over the generation and probing of isolated defects in solid-state
systems; hence their use as a bulk probe of topology faces many challenges.
Instead, here we show that partial dislocation probes of higher-order topology
are ideally suited to the context of engineered materials. Indeed, we present
the first observations of partial-dislocation-induced topological modes in 2D
and 3D higher-order topological insulators built from circuit-based resonator
arrays. While rotational defects (disclinations) have previously been shown to
indicate higher-order topology, our work provides the first experimental
evidence that exotic translation defects (partial dislocations) are bulk
topological probes.",248,10,1777,18.08
1318,topology,"We report finite-size topology in the quintessential time-reversal (TR)
invariant systems, the quantum spin Hall insulator (QSHI) and the
three-dimensional, strong topological insulator (STI): previously-identified
helical or Dirac cone boundary states of these phases hybridize in wire or slab
geometries with one open boundary condition for finite system size, and
additional, topologically-protected, lower-dimensional boundary modes appear
for open boundary conditions in two or more directions. For the
quasi-one-dimensional (q(2-1)D) QSHI, we find topologically-protected,
quasi-zero-dimensional (q(2-2)D) boundary states within the hybridization gap
of the helical edge states, determined from q(2-1)D bulk topology characterized
by topologically non-trivial Wilson loop spectra. We show this finite-size
topology furthermore occurs in 1T'-WTe2 in ribbon geometries with sawtooth
edges, based on analysis of a tight-binding model derived from
density-functional theory calculations, motivating experimental investigation
of our results. In addition, we find quasi-two-dimensional (q(3-1)D)
finite-size topological phases occur for the STI, yielding helical boundary
modes distinguished from those of the QSHI by a non-trivial magneto-electric
polarizability linked to the original 3D bulk STI. Finite-size topological
phases therefore exhibit signatures associated with the non-trivial topological
invariant of a higher-dimensional bulk. Finally, we find the q(3-2)D STI also
exhibits finite-size topological phases, finding the first signs of
topologically-protected boundary modes of codimension greater than 1 due to
finite-size topology. Finite-size topology of four or higher-dimensional
systems is therefore possible in experimental settings without recourse to
thermodynamically large synthetic dimensions.",230,8,1820,-4.23
1319,topology,"In this paper a topological theory of gravity is studied on a four-manifold
using the formalism of Capovilla {\sl et al}. We show that it is fact
equivalent to Anselmi and Fre's topological gravity using the topological
symmetries. Using this formalism gives us a new way to study topological
gravity and the intersection theory of gravitational instantons if the (3+1)
decomposition with respect to local coordinates is performed.",68,4,431,23.05
1320,topology,"We discuss unifying features of topological field theories in 2, 3 and 4
dimensions. This includes relations among enumerative geometry (2d topological
field theory) link invariants (3d Chern-Simons theory) and Donaldson invariants
(4d topological theory).",35,3,256,11.41
1321,topology,"We introduce the notion of a topological geodesic in a 3-manifold. Under
suitable hypotheses on the fundamental group, for instance word-hyperbolicity,
topological geodesics are shown to have the useful properties of, and play the
same role in several applications as, geodesics in negatively curved spaces.
This permits us to obtain virtual rigidity results for 3-manifolds.",55,4,375,27.52
1322,topology,"We present several aspects of the ""topology of meromorphic functions"", which
we conceive as a general theory which includes the topology of holomorphic
functions, the topology of pencils on quasi-projective spaces and the topology
of polynomial functions.",37,2,255,17.0
1323,topology,"We characterize positive topological entropy for quasi-state space
homeomorphisms induced from $C^*$-algebra automorphisms in terms of dynamically
generated subspaces isomorphic to $\ell_1$. This geometric condition is also
used to give a description of the topological Pinsker algebra. In particular we
obtain a geometric characterization of positive entropy for topological
dynamical systems, as well as an analogue for completely positive topological
entropy of Glasner and Weiss's combinatorial characterization of completely
positive Kolmogorov-Sinai entropy.",72,4,564,-12.11
1324,topology,"We exhibit a map f between aspherical spaces X and Y such that f induces an
isomorphism on homotopy groups but, with natural topologies, X and Y fail to
have homeomorphic fundamental groups. Thus the topological fundamental group
has the capacity to distinguish homotopy type when the Whitehead theorem fails.",50,3,309,37.64
1325,topology,"We introduce the notion of a topological higher-rank graph, a unified
generalization of the higher-rank graph and the topological graph. Using
groupoid techniques, we define the Toeplitz and Cuntz-Krieger algebras of
topological higher-rank graphs, and show that the $C^*$-algebras defined are
coherent with the existing theory.",46,3,328,31.21
1326,topology,"\begin{abstrac} Let $(X,T) $ be a topological space, and $^{*}X$ a
non--standard extension of $X$. There is a natural ``standard'' topology
$^{S}T$ on $^{*}X$ generated by $^{*}G$, where $G\in T$. The topological space
$(^{*}X,^{S}T) $ will be used to study compactifications of $(X,T)$ in a
systematic way.",47,4,307,56.25
1327,topology,"For every Tikhonov space $X$ the free abelian topological group $A(X)$ and
the free locally convex vector space $L(X)$ admit a topologically faithful
unitary representation. For compact spaces $X$ this is due to Jorge Galindo.",35,3,226,53.71
1328,topology,"The interplay between quantization and topology is investigated in the frame
of a topological model of electromagnetism proposed by the author. In that
model, the energy of monochromatic electromagnetic radiation in a cubic cavity
is $E=(d/4)\hbar \omega$ where $d$ is a topological index equal to the degree
of a map between two orbifolds.",53,3,340,27.66
1329,topology,"Let $(P,\leq)$ be a partially ordered set and let $\tau$ be a compact
topology on $P$ that is finer than the interval topology. Then $\tau$ is
contained in the order (convergence) topology on $(P,\tau)$. So any Priestley
topology is contained in the order topology.",44,4,265,65.01
1330,topology,"Several mathematicians, including myself, have studied some unifications in
general topological spaces as well as in fuzzy topological spaces. For instance
in our earlier works, using operations on topological spaces, we have tried to
unify some concepts similar to continuity, openness, closedness of functions,
compactness, filter convergence, closedness of graphs, countable compactness
and Lindelof property. In this article, to obtain further unifications, we will
study $\phi_{1,2}$-compactness and relations between $\phi_{1,2}$-compactness,
filters and $\phi_{1,2}$% -closure operator.",75,4,593,12.26
1331,topology,"It is shown that the hyperspace of all nonempty closed subsets $\Cld_{AW}(X)$
of a separable metric space $X$ endowed with the Attouch-Wets topology is
homeomorphic to a separable Hilbert space if and only if the completion of $X$
is proper, locally connected and contains no bounded connected component, $X$
is topologically complete and not locally compact at infinity.",58,2,371,-4.32
1332,topology,"We give a criterium when a linearly ordered topological semilattice is
$H$-closed. We also prove that any linearly ordered $H$-closed topological
semilattice is absolutely $H$-closed and we show that every linearly ordered
semilattice is a dense subsemilattice of an $H$-closed topological semilattice.",42,3,302,24.78
1333,topology,"We define natural topologies on the Colombeau algebras which are compatible
with the algebraic structure. These topologies reduces do Scarpalezos sharp
topologies when restricted. with this we take a positive step towards
topological methods of solving P.D. Equations in Colombeau algebras.
Applications will appear elsewhere.",45,7,326,45.42
1334,topology,"In this paper we analyze the higher topological Hochschild homology of
commutative Thom S-algebras. This includes the case of the classical cobordism
spectra MO, MSO, MU, etc. We consider the homotopy orbits of the torus action
on iterated topological Hochschild homology and we describe the relationship to
topological Andre-Quillen homology.",50,4,343,29.14
1335,topology,"This is the first installment of a book on combinatorial and geometric group
theory from the topological point of view. This is a classical subject. The
installment contains Chapters 1, 3 and 4, and there are nine chapters in total:
1. Combinatorial Complexes 2. Topological Invariants 3. Coverings 4. Galois
Theory 5. Generators and Relations 6. The Topological Dictionary 7. Amalgams 8.
The Arboreal Dictionary 9. Ends.",67,13,421,47.04
1336,topology,"We present a simple-to-apply criterion for recognizing topological groups
that are (locally) homeomorphic to LF-spaces.",15,2,119,-2.98
1337,topology,"In the paper we study (countably) compact and (absolutely) $H$-closed
primitive topological inverse semigroups. We describe the structure of compact
and countably compact primitive topological inverse semigroups and show that
any countably compact primitive topological inverse semigroup embeds into a
compact primitive topological inverse semigroup.",45,3,350,14.8
1338,topology,"We introduce a dual Zariski topology on the spectrum of fully coprime
$R$-submodules of a given duo module $M$ over an associative (not necessarily
commutative) ring $R$. This topology is defined in a way dual to that of
defining the Zariski topology on the prime spectrum of $R$. We investigate this
topology and clarify the interplay between the properties of this space and the
algebraic properties of the module under consideration.",71,4,436,30.5
1339,topology,"We give a definition of compactness in L-fuzzy topological spaces and provide
a characterization of compact L-fuzzy topological spaces, where L is a complete
quasi-monoidal lattice with some additional structures, and we present a
version of Tychonoff's theorem within the category of L-fuzzy topological
spaces.",45,2,312,0.42
1340,topology,"The fundamental groupoid of a space becomes enriched over the category of
topological spaces when the hom-sets are endowed with topologies intimately
related to universal constructions of topological groups. This paper is devoted
to a generalization of classical covering theory in the context of this
construction.",46,3,315,22.75
1341,topology,"In this paper, a brief review of the history of topological insulators is
given. After that,electronic transport experiments in topological
insulator-superconductor hybrid structures, including experimental methods,
physical properties and seemingly contradictory observations are discussed.
Additionally, some new topological insulator hybrid structures are proposed.",43,4,368,-19.19
1342,topology,"The notion of Hausdorff number of a topological space is first introduced in
\cite{bonan}, with the main objective of using this notion to obtain
generalizations of some known bounds for cardinality of topological spaces.
Here we consider this notion from a topological point of view and examine
interrelations of the Hausdorff number with compactness.",54,3,352,27.15
1343,topology,"We construct infinitely many Legendrian links in the standard contact
$\mathbb{R}^3$ with arbitrarily many topologically distinct Lagrangian
fillings. The construction is used to find links in $S^3$ that bound
topologically distinct pieces of algebraic curves in $B^4 \subset
\mathbb{C}^2$, is applied to find contact 3-manifolds with topologically
distinct symplectic fillings, and is generalized to higher dimensions.",56,3,419,17.68
1344,topology,"Topological algebras have properties that extend naturally to those of
topological groups [8, 9], but is it the case that semi-direct products exist
as in the category of groups? Firstly, we express concepts in categorical
language that capture group properties. We then observe the results about
topological groups now extended to varieties of topological algebras. We
conclude showing that for topological algebras obeying certain axioms, there
exist semi-direct products which we caracterize like in [17].",75,4,508,35.47
1345,topology,"Motivated by a result from string topology, we prove a duality in topological
Hochschild homology (THH). The duality relates the THH of an E_1-algebra
spectrum and the THH of its derived Koszul dual algebra under certain
compactness conditions. The result relies on results about module categories
which may be of interest on their own. Finally, we relate this result to
topological field theories and outline some future work.",68,5,427,37.3
1346,topology,"This is a glossary of notions and methods related with the topological theory
of collections of affine planes, including braid groups, configuration spaces,
order complexes, stratified Morse theory, simplicial resolutions, complexes of
graphs, Orlik--Solomon rings, Salvetti complex, matroids, Spanier--Whitehead
duality, twisted homology groups, monodromy theory and multidimensional
hypergeometric functions.
  The emphasis on the most geometrical explanation is done; applications and
analogies in the differential topology are outlined.",67,3,540,-13.3
1347,topology,"Free actions of finite groups on spheres give rise to topological spherical
space forms. The existence and classification problems for space forms have a
long history in the geometry and topology of manifolds. In this article, we
present a survey of some of the main results and a guide to the literature.",52,4,305,53.92
1348,topology,"The electronic bands are classified according to their topology. We compute
the connection and curvature for the electronic bands and show that the
physical properties are determined by topological invariants which are
equivalent to the existence of the zero modes. We apply this method to the
Topological Insulators and Topogical Superconductors.",51,4,347,28.84
1349,topology,"Let $A$ be an abelian topological $G$-module. We give an interpretion for the
second cohomology, $H^{2}(G,A)$, of $G$ with coefficients in $A$. As a result
we show that if $P$ is a projective topological group, then $H^{2}(P,A)=0$ for
every abelian topological $P$-module $A$.",43,4,276,48.5
1350,topology,"In this paper we address the relation between the orbifold fundamental group
and the topology of the underlying space. In particular, under the assumption
that the orbifold fundamental group is equal to the fundamental group of the
underlying space, we prove Poincar\'e Duality for orbifolds of dimension 4 and
5.",50,3,313,37.64
1351,topology,"We extend the functor Sing of singular chains to the category of topological
stacks and establish its main properties. We prove that Sing respects weak
equivalences and takes a morphism of topological stacks that is both a Serre
and a Reedy fibration to a Kan fibration of simplicial sets. When restricted to
the category of topological spaces Sing coincides with the usual singular
functor.",64,4,391,41.4
1352,topology,"In this paper we prove that the Scott topology $\mathfrak S$ on a rooted
non-metric tree $\mathcal T$ is strictly coarser than the weak tree topology.
Moreover, for each $t\in \mathcal T$, we consider a natural order $\preceq_t$
on $\mathcal T$ under which $t$ is the root of $\mathcal T$. Then the weak tree
topology is generated by the union of the Scott topologies $\mathfrak S_t$
associated to $\preceq_t$.",69,4,410,56.59
1353,topology,"We construct simple models for all topological phases of free fermions. These
explicit models can realize all the nontrivial topological phases (with any
possible topological invariant) of the periodic table. Many well known models
for topological insulators and superconductors are special cases of our general
constructions.",46,4,326,22.11
1354,topology,"An old branch of mathematics, Topology, has opened the road to the discovery
of new phases of matter. A hidden topology in the energy spectrum is the key
for novel conducting/insulating properties of topological matter.",35,3,219,36.79
1355,topology,"Let E be a locally solid vector lattice. In this paper, we consider two
particular vector subspaces of the space of all order bounded operators on E.
With the aid of two appropriate topologies, we show that under some conditions,
they establish both, locally solid vector lattices and topologically complete
topological algebras.",52,4,329,37.0
1356,topology,"In this paper we give a new definition of soft topology using elementary
union and elementary intersection although these operations are not
distributive. Also we have shown that this soft topology is different from
Naz's soft topology and studied some basic properties of this new type of soft
topology. Here we use elementary complement of soft sets, though law of
excluded middle is not valid in general for this type of complementation.",72,4,440,38.66
1357,topology,"The topological equivalence classification for linear flows on $\mathbb{R}^n$
had been completely solved by Kuiper and independently Ladis in 1973. However,
Ladis' proof was published in a Russian journal which isn't easily available,
Kuiper's proof is more topological and a little bit subtle. Aiming at
topological conjugacy classification, mainly based on the ideas of Kuiper, we
introduce other techniques and try to present an elementary and self-contained
proof just using linear algebra and elementary topology.",75,4,518,29.18
1358,topology,"Many types of topological indices such as degree-based topological indices,
distance-based topological indices and counting related topological indices are
explored during past recent years. Among degree based topological indices,
Zagreb indices are the oldest one and studied well. In the paper, we define a
generalized multiplicative version of these indices and compute exact formulas
for Polycyclic Aromatic Hydrocarbons and Jagged-Rectangle Benzenoid Systems.",62,4,464,16.62
1359,topology,"We construct a topology on a given algebraically closed field with a
distinguished subfield which is also algebraically closed. This topology is
finer than Zariski topology and it captures the sets definable in the pair of
algebraically closed fields as above; in the sense that definable sets are
exactly the constructible sets in this topology.",55,3,346,35.1
1360,topology,"In this paper Lowen type multi-fuzzy topological space has been introduced
and characterization of topology by its nbd system is studied. Also the product
multi-fuzzy topological space has been introduced and it has been investigated
that 2nd countability and compactness are finitely productive in multi-fuzzy
topological spaces.",47,3,330,13.78
1361,topology,"In this paper we discuss the notion of completeness of topologized posets and
survey some recent results on closedness properties of complete topologized
semilattices.",24,2,167,30.2
1362,topology,"Several recent papers in digital topology have sought to obtain fixed point
results by mimicking the use of tools from classical topology, such as complete
metric spaces and homotopy invariant fixed point theory. We show that in many
cases, researchers using these tools have derived conclusions that are
incorrect or trivial.",51,3,326,37.13
1363,topology,"We indicate how to combine some classical topology (Thom's work on the
Steenrod problem) with some modern topology (simplicial volume) to show that
every map between certain manifolds must have degree zero. We furthermore
discuss a homotopy theoretic interpretation of parts of our proof, using Thom
spaces and Steenrod powers.",50,3,327,29.18
1364,topology,"In this paper we study the reflections of the category of topological and
semitopological semigroups on the category of the class of topological spaces
satisfying separation axioms $T_{0}$, $T_{1}$, $T_{2}$, $T_{3}$ and regular and
we apply its properties for to find conditions under which a topological
semigroup has the Souslin property.",51,2,340,2.79
1365,topology,"We discuss here geometric structures of condensed matters by means of a
fundamental topological method. Any geometric pattern can be universally
represented by a decomposition space of a topological space consisting of the
infinite product space of 0 and 1, in which a partition with a specific
topological structure determines a character of each geometric structure.",56,3,368,17.68
1366,topology,"In this paper we investigate graph inverse semigroups which are subsemigroups
of compact-like topological semigroups. More precisely, we characterise graph
inverse semigroups which admit a compact semigroup topology and describe graph
inverse semigroups which can be embeded densely into CLP-compact topological
semigroups.",42,3,323,24.78
1367,topology,"In this paper, we introduce a thinness in sense to a type of relative
capacity for weighted variable exponent Sobolev space. Moreover, we reveal some
properties of this thinness and consider the relationship with finely open and
finely closed sets. We discuss fine topology and compare this topology with
Euclidean one. Finally, we give some information about importance of the fine
topology in the potential theory.",66,5,416,46.27
1368,topology,"We introduce modulational instability in non-Hermitian systems to study state
conversion of topological edge states. We show that state conversion in
non-Hermitian systems leads to topological pumping, which is a way of
transferring topological edge state from one edge to the opposite edge. In
contrast to Hermitian systems, topological pumping can occur spontaneously in
non-Hermitian systems.",56,4,395,27.11
1369,topology,"We introduce and study some generalizations of regular spaces, which were
motivated by studying continuity properties of functions between (regular)
topological spaces. In particular, we prove that a first-countable Hausdorff
topological space is regular if and only if it does not contain a topological
copy of the Gutik hedgehog.",49,3,331,21.23
1370,topology,"We define a Polish topology inspired from the Gandy-Harrington topology and
show how it can be used to prove Silver's dichotomy theorem while remaining in
the Polish realm. In this topology, a $\Pi^1_1$ equivalence relation decomposes
into a ""sum"" of a clopen relation and a meager one. We characterize it as the
largest regular toplogy with a basis included in $\Sigma^1_1$.",61,4,375,42.41
1371,topology,"In this paper, we give an introduction for rough groups and rough
homomorphisms. Then we present some properties related to topological rough
subgroups and rough subsets. We construct the product of topological rough
groups and give an illustrated example. Then, we define topological rough group
homomorphisms and topological rough group homeomorphisms. Finally, we introduce
a rough action, a rough homogenous space and a rough kernel.",65,6,437,49.82
1372,topology,"We establish upper bounds of the indices of topological Brauer classes over a
closed orientable 8-manifolds. In particular, we verify the Topological
Period-Index Conjecture (TPIC) for topological Brauer classes over closed
orientable 8-manifolds of order not congruent to 2 mod 4. In addition, we
provide a counter-example which shows that the TPIC fails in general for closed
orientable 8-manifolds.",59,4,401,34.56
1373,topology,"In this paper, we continue the study of function spaces equipped with
topologies of (strong) uniform convergence on bornologies initiated by Beer and
Levi \cite{beer-levi:09}. In particular, we investigate some topological
properties these function spaces defined by topological games. In addition, we
also give further characterizations of metrizability and completeness
properties of these function spaces.",55,4,408,27.52
1374,topology,"We show that a positive braid knot has maximal topological 4-genus exactly if
it has maximal signature invariant. As an application, we determine all
positive braid knots with maximal topological 4-genus and compute the
topological 4-genus for all positive braid knots with up to 12 crossings.",46,3,293,39.67
1375,topology,"We introduce the notion of a ""graded topological space"": a topological space
endowed with a sheaf of abelian groups which we think of as a sheaf of
gradings. Any object living on a graded topological space will be graded by
this sheaf of abelian groups. We work out the fundamentals of sheaf theory and
Poincar\'e-Verdier duality for such spaces.",59,4,346,59.94
1376,topology,"Topological full groups originated from the theory of topological dynamical
systems and have been having considerable impact on group theory in recent
years. This text represents an introduction/survey on topological full groups.
After development of the theoretical and historical background, it gives an
account of their significance in topological dynamics and discusses their group
theoretical aspects.",56,4,406,10.19
1377,topology,"This paper presents a combinatorial analog of topological complexity for
finite spaces. We demonstrate that this coincides with the genuine topological
complexity of the original finite space, and constitutes an upper bound for the
topological complexity of its order complex.",40,3,276,17.34
1378,topology,"We investigate the classification of topological quandles on some simple
manifolds. Precisely we classify all Alexander quandle structures, up to
isomorphism, on the real line and the unit circle. For the closed unit interval
$[0, 1]$, we conjecture that there exists only one topological quandle
structure on it, i.e. the trivial one. Some evidences are provided to support
our conjecture.",60,7,390,50.84
1379,topology,"We investigate various classes of metrics on the integers, which induce the
F\""urstenberg topology and establish the connection between the metrics and the
topology. We analyze the norm-like mappings underlying these metrics, with
respect to their efficient computability for natural numbers and the analytic
behavior of sequences under those mappings. Subsequently, we give some
applications to number theory and establish some new propositions at the
intersection of number theory and topology.",71,4,496,22.04
1380,topology,"We show that generically, the degeneracies of a family of Hermitian matrices
depending on three parameters have a conical structure. Our result applies to
the study of topological phases of matter. It implies that adiabatic
deformations of two-dimensional topological insulators come generically with
Dirac-like propagating currents, whose total conductivity equals the chiral
number of conical points.",56,4,402,10.19
1381,topology,"Based on Garner's discovery that topological categories are total categories
enriched in a quantaloid, this paper presents a series of results related to
initial and final density in categorical topology via (co)density in
quantaloid-enriched categories, focusing on (co-)Sierpi\'{n}ski objects, Galois
correspondences and their fixed points.",45,2,342,-8.05
1382,topology,"We endow the set of persistence diagrams with the strong topology (the
topology of countable direct limit of increasing sequence of bounded subsets
considered in the bottleneck distance). The topology of the obtained space is
described.
  Also, we prove that the space of persistence diagrams with the bottleneck
metric has infinite asymptotic dimension in the sense of Gromov.",58,4,377,43.43
1383,topology,"We develop tools to recognize sequential spaces with large inductive
dimension zero. We show the Hawaiian earring group $G$ is 0 dimensional, when
endowed with the quotient topology, inherited from the space of based loops
with the compact open topology. In particular $G$ is $T_4$ and hence inclusion
$G \rightarrow F_M (G)$ is a topological embedding into the free topological
group $F_M (G)$ in the sense of Markov.",68,4,418,48.43
1384,topology,"We study the effect of bulk perturbations of N=(2,2) superconformal minimal
models on topological defects. In particular, symmetries and more general
topological defects which survive the flow to the IR are identified. Our method
is to consider the topological subsector and make use of the Landau-Ginzburg
formulation to describe RG flows and topological defects in terms of matrix
factorizations.",59,4,398,34.56
1385,topology,"We study some interesting properties of Furstenberg's topology of the
integers. We show that it is metrizable, totally disconnected, and (Z,+,.) is a
topological ring with respect to this topology. As an application, we show that
any two disjoint sets of primes can be separated by arithmetic progressions.",48,5,306,50.84
1386,topology,"Known and new results on free Boolean topological groups are collected. An
account of properties which these groups share with free or free Abelian
topological groups and properties specific of free Boolean groups is given.
Special emphasis is placed on the application of set-theoretic methods to the
study of Boolean topological groups.",52,4,338,45.46
1387,topology,"In this note, we show that the category of strongly central series admits
co-induced actions, which means that it is Locally Algebraically Cartesian
Closed. We also show that some co-induction functors exist in the category of
topological groups, and that a convenient category of topological groups is
LACC.",48,3,308,30.2
1388,topology,"We describe the order type of range sets of compact ultrametrics and show
that an ultrametrizable infinite topological space $(X, \tau)$ is compact iff
the range sets are order isomorphic for any two ultrametrics compatible with
the topology $\tau$. It is also shown that an ultrametrizable topology is
separable iff every compatible with this topology ultrametric has at most
countable range set.",62,3,397,31.55
1389,topology,"The concept of gyrogroups is a generalization of groups which do not
explicitly have associativity. Recently, Atiponrat extended the idea of
topological (paratopological) groups to topological (paratopological)
gyrogroups. In this paper, we prove that every regular (Hausdorff) locally
gyroscopic invariant paratopological gyrogroup $G$ is completely regular
(function Hausdorff). These results improve theorems of Banakh and Ravsky for
paratopological groups. Also, we extend the Pontrjagin conditions of
(para)topological groups to (para)topological gyrogroups.",71,6,563,14.76
1390,topology,"A group topology is said to be linear if open subgroups form a base of
neighborhoods of the identity element. It is proved that the existence of a
nondiscrete extremally disconnected group of Ulam nonmeasurable cardinality
with linear topology implies that of a nondiscrete extremally disconnected
group of cardinality at most $2^\omega$ with linear topology.",55,3,359,26.64
1391,topology,"Based on the concepts of $\mathbb{R}$-factorizable topological groups and
$\mathcal{M}$-factorizable topological groups, we introduce four classes of
factorizabilities on topological groups, named
$P\mathcal{M}$-factorizabilities, $Pm$-factorizabilities,
$S\mathcal{M}$-factorizabilities and $PS\mathcal{M}$-factorizabilities,
respectively. Some properties of the four classes of spaces are investigated.",38,3,404,-49.34
1392,topology,"For a topological system with positive topological entropy, we show that the
induced transformation on the set of probability measures endowed with the
weak-$*$ topology has infinite topological mean dimension. We also estimate the
rate of divergence of the entropy with respect to the Wasserstein distance when
the scale goes to zero.",52,3,335,28.17
1393,topology,"In this paper we prove that if $\kappa$ is a singular cardinal with
uncountable cofinality, then every power of a given topological space with
precaliber $\kappa$ has precaliber $\kappa$ as well. Furthermore, if
$\{X_\alpha : \alpha<\lambda\}$ is a family of topological spaces with
precaliber $\kappa$ and $\lambda<cf(\kappa)$, then $\kappa$ is a precaliber for
the topological product $\prod\{X_\alpha : \alpha<\lambda\}$.",59,3,424,17.17
1394,topology,"The Galois group of an infinite Galois extension has a natural topology,
called the Krull topology, which has the important property of being profinite.
It is impossible to talk about Galois representations, and hence the Langlands
Program, without first defining the Krull topology. We explain our
formalisation of this topology, and our proof that it is profinite, in the Lean
3 theorem prover.",63,4,396,41.7
1395,topology,"The classical Buscher rules describe T-duality for metrics and B-fields in a
topologically trivial setting. On the other hand, topological T-duality
addresses aspects of non-trivial topology while neglecting metrics and
B-fields. In this article we develop a new unifying framework for both aspects.",43,4,299,23.12
1396,topology,"For a commutative ring $R$ with unit $1\ne 0$ and a multiplicatively closed
subset $S$ of $R$, we introduce a new topology on the $S$-prime spectrum
$\mathrm{Spec}_SR$ of $R$ called the $S$-flat topology. Our aims is to give an
algebraic descriptions of the topological properties like compactness,
irreducibility, connectivity and noetherianess with respect to this new
topology .",58,3,381,34.09
1397,topology,"In this paper, we study some properties of $*-$open and $*-$closed subsets of
a space. The collection of all $*-$open subsets of a space $X$ form a topology
on $X$ which is denoted by $^{*}O(X)$. We investigate the relations between
topological properties of $X$ with the topology $^{*}O(X)$ and $X$. Also, we
introduce the concept of a $*-$continuous map.",59,5,356,64.91
1398,topology,"We establish the first nontrivial lower bound on the (higher) topological
complexity of the unordered configuration spaces of a general graph. As an
application, we show that, for most graphs, the topological complexity
eventually stabilizes at its maximal possible value, a direct analogue of a
stability phenomenon in the ordered setting first conjectured by Farber. We
estimate the stable range in terms of the number of trivalent vertices.",68,4,443,23.05
1399,topology,"In this paper, we present a general formula for derived sets in general
topology. Consequently, more results can be proved in general topology
involving derived sets and isolated point sets. More specifically, we can prove
that isolated point sets are nowhere dense in general topological space.",46,4,295,47.49
1400,topology,"Two graphs are of the same topological type if they can be mutually embedded
into each other topologically. We show that there are exactly $\aleph_1$
distinct topological types of countable trees. In general, for any infinite
cardinal $\kappa$ there are exactly $\kappa^+$ distinct topological types of
trees of size $\kappa$. This solves a problem of van der Holst from 2005.",60,5,376,56.25
1401,topology,"The finite topological quandles can be represented as $n\times n$ matrices,
recently defined by S. Nelson and C. Wong. In this paper, we first study the
finite topological quandles and we show how to use these matrices to
distinguish all isomorphism classes of finite topological quandles for a given
cardinality $n$. As an application, we classify finite topological quandles
with up to 4 elements.",64,6,399,38.32
1402,topology,"In this paper, we provide sufficient conditions for a space $X$ to satisfy
the Ganea conjecture for topological complexity. To achieve this, we employ two
auxiliary invariants: weak topological complexity in the sense of
Berstein-Hilton, along with a certain stable version of it. Several examples
are discussed",47,3,311,38.62
1403,topology,"Let E be a locally compact second countable Hausdorff space and F the
pertaining family of all closed sets. We endow F respectively with the
Fell-topology, the upper Fell topology or the upper Vietoris-topology and
investigate weak convergence of probability measures on the corresponding
hyperspaces with a focus on the upper Fell topology. The results can be
transferred to distributional convergence of random closed sets in E with
applications to the asymptotic behavior of measurable selection.",76,4,499,28.88
1404,topology,"We present a new generalized topological current in terms of the order
parameter field $\vec \phi$ to describe the arbitrary dimensional topological
defects. By virtue of the $% \phi$-mapping method, we show that the topological
defects are generated from the zero points of the order parameter field $\vec
\phi$, and the topological charges of these topological defects are topological
quantized in terms of the Hopf indices and Brouwer degrees of $\phi$-mapping
under the condition that the Jacobian $% J(\frac \phi v)\neq 0$. When $J(\frac
\phi v)=0$, it is shown that there exist the crucial case of branch process.
Based on the implicit function theorem and the Taylor expansion, we detail the
bifurcation of generalized topological current and find different directions of
the bifurcation. The arbitrary dimensional topological defects are found
splitting or merging at the degenerate point of field function $\vec \phi $ but
the total charge of the topological defects is still unchanged.",154,6,995,32.36
1405,topology,"A topological group is minimal if it does not admit a strictly coarser
Hausdorff group topology. The Roelcke uniformity (or lower uniformity) on a
topological group is the greatest lower bound of the left and right
uniformities. A group is Roelcke-precompact if it is precompact with respect to
the Roelcke uniformity. Many naturally arising non-Abelian topological groups
are Roelcke-precompact and hence have a natural compactification. We use such
compactifications to prove that some groups of isometries are minimal. In
particular, if U_1 is the Urysohn universal metric space of diameter 1, the
group Iso(U_1) of all self-isometries of U_1 is Roelcke-precompact,
topologically simple and minimal. We also show that every topological group is
a subgroup of a minimal topologically simple Roelcke-precompact group of the
form Iso(M), where M is an appropriate non-separable version of the Urysohn
space.",137,8,907,34.66
1406,topology,"A system of differential forms will establish a topology and a topological
structure on a domain of independent variables such that is possible to
determine which maps or processes acting on the system are continuous. Perhaps
the most simple topology is that generated by the existence of a single 1-form
of Action, its Pfaff sequence of exterior differentials, and their
intersections. In such a topology the exterior derivative becomes a limit point
generator in the sense of Kuratowski. The utilization of such techniques in
physical systems is examined. A key feature of the Cartan topology is
determined by the Pfaff dimension (representing the minimum number of functions
to describe the 1-form generator). In particular, when the Pfaff dimension is 3
or more the Cartan topology becomes a disconnected topology, with the existence
of topological torsion and topological parity. Most classical physical
applications are constrained to cases where the Pfaff dimension is 2 or less,
for such is the domain of unique integrability. The more interesting domain of
non-unique solutions requires the existence of topological torsion, and can
lead to an understanding of irreversible processes without the use of
statistics.",189,9,1223,30.6
1407,topology,"We study chains in an $H$-closed topological partially ordered space. We give
sufficient conditions for a maximal chain $L$ in an $H$-closed topological
partially ordered space such that $L$ contains a maximal (minimal) element.
Also we give sufficient conditions for a linearly ordered topological partially
ordered space to be $H$-closed. We prove that any $H$-closed topological
semilattice contains a zero. We show that a linearly ordered $H$-closed
topological semilattice is an $H$-closed topological pospace and show that in
the general case this is not true. We construct an example an $H$-closed
topological pospace with a non-$H$-closed maximal chain and give sufficient
conditions that a maximal chain of an $H$-closed topological pospace is an
$H$-closed topological pospace.",116,7,787,43.43
1408,topology,"We detect topological semigroups that are topological paragroups, i.e., are
isomorphic to a Rees product of a topological group over topological spaces
with a continuous sandwich function. We prove that a simple topological
semigroup $S$ is a topological paragroup if one of the following conditions is
satisfied: (1) $S$ is completely simple and the maximal subgroups of $S$ are
topological groups, (2) $S$ contains an idempotent and the square $S\times S$
is countably compact or pseudocompact, (3) $S$ is sequentially compact or each
power of $S$ is countably compact. The last item generalizes an old Wallace's
result saying that each simple compact topological semigroup is a topological
paragroup.",108,6,703,35.61
1409,topology,"We introduce a functor which associates to every measure preserving system
(X,B,\mu,T) a topological system (C_2(\mu),\tilde{T}) defined on the space of
2-fold couplings of \mu, called the topological lens of T. We show that often
the topological lens ""magnifies"" the basic measure dynamical properties of T in
terms of the corresponding topological properties of \tilde{T}. Some of our
main results are as follows: (i) T is weakly mixing iff \tilde{T} is
topologically transitive (iff it is topologically weakly mixing). (ii) T has
zero entropy iff \tilde{T} has zero topological entropy, and T has positive
entropy iff \tilde{T} has infinite topological entropy. (iii) For T a K-system,
the topological lens is a P-system (i.e. it is topologically transitive and the
set of periodic points is dense; such systems are also called chaotic in the
sense of Devaney).",136,8,864,39.97
1410,topology,"In this work the topological order at finite temperature in two-dimensional
color code is studied. The topological entropy is used to measure the behavior
of the topological order. Topological order in color code arises from the
colored string-net structures. By imposing the hard constrained limit the exact
solution of the entanglement entropy becomes possible. For finite size systems,
by raising the temperature, one type of string-net structure is thermalized and
the associative topological entropy vanishes. In the thermodynamic limit the
underlying topological order is fragile even at very low temperatures. Taking
first the thermodynamic limit and then the zero-temperature limit and vice
versa does not commute, and their difference is related only to the topology of
regions. The contribution of the colors and symmetry of the model in the
topological entropy is also discussed. It is shown how the gauge symmetry of
the color code underlies the topological entropy.",149,10,978,37.71
1411,topology,"In this paper, the following results are proved: (1) $ $ If $E$ is a complete
atomic lattice effect algebra, then $E$ is (o)-continuous iff $E$ is
order-topological iff $E$ is totally order-disconnected iff $E$ is algebraic.
(2) $ $ If $E$ is a complete atomic distributive lattice effect algebra, then
its Frink ideal topology $\tau_{id}$ is Hausdorff topology and $\tau_{id}$ is
finer than its order topology $\tau_{o}$, and $\tau_{id}=\tau_o$ iff 1 is
finite iff every element of $E$ is finite iff $\tau_{id}$ and $\tau_o$ are both
discrete topologies. (3) $ $ If $E$ is a complete (o)-continuous lattice effect
algebra and the operation $\oplus$ is order topology $\tau_o$ continuous, then
its order topology $\tau_{o}$ is Hausdorff topology. (4) $ $ If $E$ is a
(o)-continuous complete atomic lattice effect algebra, then $\oplus$ is order
topology continuous.",137,5,865,30.23
1412,topology,"We define an information topology (I-topology) and a reverse information
topology (rI-topology) on the state space of a C*-subalgebra of Mat(n,C). These
topologies arise from sequential convergence with respect to the relative
entropy. We prove that open disks, with respect to the relative entropy, define
a base for them, while Csiszar has shown in 1967 that the analogue is wrong for
probability measures on a countably infinite set. The I-topology is finer than
the norm topology, it disconnects the convex state space into its faces. The
rI-topology is intermediate between these topologies. We complete two
fundamental theorems of information geometry to the full state space, by taking
the closure in the rI-topology. The norm topology is too coarse for this aim
only for a non-commutative algebra, so its discrepancy to the rI-topology
belongs to the quantum domain. We apply our results to the maximization of the
von Neumann entropy under linear constraints and to the maximization of quantum
correlations.",159,9,1016,42.82
1413,topology,"The dual space of the C*-algebra of bounded uniformly continuous functions on
a uniform space carries several natural topologies. One of these is the
topology of uniform convergence on bounded uniformly equicontinuous sets, or
the UEB topology for short. In the particular case of a topological group and
its right uniformity, the UEB topology plays a significant role in the
continuity of convolution. In this paper we derive a useful characterisation of
bounded uniformly equicontinuous sets on locally compact groups. Then we
demonstrate that for every locally compact group G the UEB topology on the
space of finite Radon measures on G coincides with the right multiplier
topology. In this sense the UEB topology is a generalisation to arbitrary
topological groups of the multiplier topology for locally compact groups. In
the final section we prove results about UEB continuity of convolution.",141,8,898,34.15
1414,topology,"Covering-based rough set theory is a useful tool to deal with inexact,
uncertain or vague knowledge in information systems. Topology, one of the most
important subjects in mathematics, provides mathematical tools and interesting
topics in studying information systems and rough sets. In this paper, we
present the topological characterizations to three types of covering
approximation operators. First, we study the properties of topology induced by
the sixth type of covering lower approximation operator. Second, some
topological characterizations to the covering lower approximation operator to
be an interior operator are established. We find that the topologies induced by
this operator and by the sixth type of covering lower approximation operator
are the same. Third, we study the conditions which make the first type of
covering upper approximation operator be a closure operator, and find that the
topology induced by the operator is the same as the topology induced by the
fifth type of covering upper approximation operator. Forth, the conditions of
the second type of covering upper approximation operator to be a closure
operator and the properties of topology induced by it are established. Finally,
these three topologies space are compared. In a word, topology provides a
useful method to study the covering-based rough sets.",204,11,1342,25.39
1415,topology,"Topological behavior can be masked when disorder is present. A topological
insulator, either intrinsic or interaction induced, may turn gapless when
sufficiently disordered. Nevertheless, the metallic phase that emerges once a
topological gap closes retains several topological characteristics. By
considering the self-consistent disorder-averaged Green function of a
topological insulator, we derive the condition for gaplessness. We show that
the edge states survive in the gapless phase as edge resonances and that,
similar to a doped topological insulator, the disordered topological metal also
has a finite, but non-quantized topological index. We then consider the
disordered Mott topological insulator. We show that within mean-field theory,
the disordered Mott topological insulator admits a phase where the
symmetry-breaking order parameter remains non-zero but the gap is closed, in
complete analogy to 'gapless superconductivity' due to magnetic disorder.",133,8,966,9.89
1416,topology,"The efficiency of contemporary algebraic topology is not optimal since the
category of topological spaces can be made more algebraic by introducing a
profoundly new (-1)-dimensional topological space as a topological join unit.
Thereby synchronizing the category of topological spaces with the structures
within the contemporary category of simplicial complexes as well as with the
structures within the algebraic categories.
  In the category of topological spaces, the empty space {\O} has since long
been given the role as a join unit - ad-hoc though. Since it is {{\O}}, not
{\O}, that is the join unit within the category of simplicial complexes, the
role of {\O} within general topology has to be rectified.
  This article presents an algebraization of Hausdorff's century old definition
of the category of topological spaces as well as some useful algebraic
topological consequences thereof.",137,6,898,18.49
1417,topology,"We discuss systems which have some, but not all of the hallmarks of
topological phases. These systems' topological character is not fully captured
by a local order parameter, but they are also not fully described at low
energies by topological quantum field theories. For such systems, we formulate
the concepts of quasi-topological phases (to be contrasted with true
topological phases), and symmetry-protected quasi-topological phases. We
describe examples of systems in each class and discuss the implications for
topological protection of information and operations. We explain why
topological phases and quasi-topological phases have greater stability than is
sometimes appreciated. In the examples that we discuss, we focus on Ising-type
(a.k.a. Majorana) systems particularly relevant to recent theoretical advances
and experimental efforts.",120,10,848,20.28
1418,topology,"The idea of topological quantum computation is to build powerful and robust
quantum computers with certain macroscopic quantum states of matter called
topologically ordered states. These systems have degenerate ground states that
can be used as robust ""topological qubits"" to store and process quantum
information. However, a topological qubit has not been realized since the
proposed systems either require sophisticated topologically ordered states that
are not available yet, or require complicated geometries that are too difficult
to realize. In this paper, we propose a new experimental setup which can
realize topological qubits in a simple bilayer fractional quantum Hall (FQH)
system with proper electric gate configurations. Compared to previous works,
our proposal is accessible with current experimental techniques and only
involves well-established topological states. Our system can realize a large
class of topological qubits, generalizing the Majorana zero modes studied in
the recent literature to more computationally powerful possibilities. We
propose three tunneling and interferometry experiments to detect the existence
and non-local topological properties of the topological qubits.",168,8,1205,13.28
1419,topology,"We give a self-contained and enriched review about topology properties in the
rapidly growing field of topological states of matter (TSM). This review is
mainly focus on the beautiful interplay of topology mathematics and condensed
matter physics that issuing TSM. Fiber bundle theory is a powerful concept to
describe the non-trivial topology properties underlying the physical system. So
we briefly present some motivation of fiber bundle theory and following that
several effective topological methods have been introduced to judge whether a
fiber bundle is trivial or not. Next, we give some topological invariants that
characterizes the non-trivial TSM in the non-interacting systems in all
dimensions, which is called topological band theory. Following that, we review
and generalize the topological response using topological field theory called
Chern-Simons effective theory.
  Finally, the classification of free-fermion systems have been studied by loop
space and K-theory.",142,8,983,25.49
1420,topology,"In this paper, using the topology on the set of shape morphisms between
arbitrary topological spaces $X$, $Y$, $Sh(X,Y)$, defined by Cuchillo-Ibanez et
al. in 1999, we consider a topology on the shape homotopy groups of arbitrary
topological spaces which make them Hausdorff topological groups. We then
exhibit an example in which $\check{\pi}_k^{top}$ succeeds in distinguishing
the shape type of $X$ and $Y$ while $\check{\pi}_k$ fails, for all $k\in
\Bbb{N}$. Moreover, we present some basic properties of topological shape
homotopy groups, among them commutativity of $\check{\pi}_k^{top}$ with finite
product of compact Hausdorff spaces. Finally, we consider a quotient topology
on the $k$th shape group induced by the $k$th shape loop space and show that it
coincides with the above topology.",120,6,798,47.12
1421,topology,"Topological crystalline insulators are topological insulators whose surface
states are protected by the crystalline symmetry, instead of the time reversal
symmetry. Similar to the first generation of three-dimensional topological
insulators such as Bi2Se3 and Bi2Te3, topological crystalline insulators also
possess surface states with exotic electronic properties such as spin-momentum
locking and Dirac dispersion. Experimentally verified topological crystalline
insulators to date are SnTe, Pb1-xSnxSe, and Pb1-xSnxTe. Because topological
protection comes from the crystal symmetry, magnetic impurities or in-plane
magnetic fields are not expected to open a gap in the surface states in
topological crystalline insulators. Additionally, because they are cubic
structure instead of layered structure, branched structures or strong coupling
with other materials for large proximity effects are possible, which are
difficult with layered Bi2Se3 and Bi2Te3. Thus, additional fundamental
phenomena inaccessible in three-dimensional topological insulators can be
pursued. In this review, topological crystalline insulator SnTe nanostructures
will be discussed. For comparison, experimental results based on SnTe thin
films will be covered. Surface state properties of topological crystalline
insulators will be discussed briefly.",172,10,1326,9.79
1422,topology,"In this paper a toy model of quantum topology is reviewed to study effects of
matter and gauge fields on the topology fluctuations. In the model a collection
of N one dimensional manifolds are considered where a set of boundary
conditions on states of Hilbert space specifies a set of all topologies
perceived by quantum particle and probability of having a specific topology is
determined by a partition function over all the topologies in the context of
noncommutative spectral geometry. In general the topologies will be fuzzy with
the exception of a particular case which is localized by imposing a specific
boundary condition. Here fermions and bosons are added to the model. It is
shown that in the presence of matter, the fuzziness of topology will be
dependent on N, however for large N the dependence is removed similar to the
case without matter. Also turning on a particular background gauge field, can
overcome the fuzziness of topology to reach a localized topology with classical
interpretation. It can be seen that for large N more opportunities can be
provided for choosing the background gauge field to localize the fuzzy
topology.",190,8,1148,35.51
1423,topology,"Topological photonic states, inspired by robust chiral edge states in
topological insulators, have recently been demonstrated in a few photonic
systems, including an array of coupled on-chip ring resonators at communication
wavelengths. However, the intrinsic difference between electrons and photons
determines that the topological protection in time-reversal-invariant photonic
systems does not share the same robustness as its counterpart in electronic
topological insulators. Here, in a designer surface plasmon platform consisting
of tunable metallic sub-wavelength structures, we construct photonic
topological edge states and probe their robustness against a variety of defect
classes, including some common time-reversal-invariant photonic defects that
can break the topological protection, but do not exist in electronic
topological insulators. This is also the first experimental realization of
anomalous Floquet topological edge states, whose topological phase cannot be
predicted by the usual Chern number topological invariants.",137,5,1041,2.82
1424,topology,"We present a comparative theoretical study of the effects of standard
Anderson and magnetic disorders on the topological phases of two-dimensional
Rashba spin-orbit coupled superconductors, with the initial state to be either
topologically trivial or nontrivial. Using the self-consistent Born
approximation approach, we show that the presence of Anderson disorders will
drive a topological superconductor into a topologically trivial superconductor
in the weak coupling limit. Even more strikingly, a topologically trivial
superconductor can be driven into a topological superconductor upon diluted
doping of independent magnetic disorders, which gradually narrow, close, and
reopen the quasi-particle gap in a nontrivial manner. These topological phase
transitions are distinctly characterized by the changes in the corresponding
topological invariants. The central findings made here are also confirmed using
a complementary numerical approach by solving the Bogoliubov-de Gennes
equations self-consistently within a tight-binding model. The present study
offers appealing new schemes for potential experimental realization of
topological superconductors.",152,7,1158,3.5
1425,topology,"Axion electrodynamics, first proposed in the context of particle physics,
manifests itself in condensed matter physics in the topological field theory
description of 3d topological insulators and gives rise to magnetoelectric
effect, where applying magnetic (electric) field $\mathbf{B}(\mathbf{E})$
induces polarization (magnetization) $\mathbf{p}(\mathbf{m})$. We use linear
response theory to study the associated topological current using the
Fu-Kane-Mele model of 3d topological insulators in the presence of
time-dependent uniform weak magnetic field. By computing the dynamical current
susceptibility $\chi^{\mathbf{j}_p\mathbf{j}_p}_{ij}(\omega)$, we discover from
its static limit an `order parameter' of the topological phase transition
between weak topological (or ordinary) insulator and strong topological
insulator, found to be continuous. The
$\chi^{\mathbf{j}_p\mathbf{j}_p}_{ij}(\omega)$ shows a sign-changing
singularity at a critical frequency with suppressed strength in the topological
insulating state. Our results can be verified in current noise experiment on 3d
TI candidate materials for the detection of such topological phase transition.",145,6,1165,-8.73
1426,topology,"Uchillo-Ibanez et al. introduced a topology on the sets of shape morphisms
between arbitrary topological spaces in 1999. In this paper, applying a similar
idea, we introduce a topology on the set of coarse shape morphisms $Sh^*(X,Y)$,
for arbitrary topological spaces $X$ and $Y$. In particular, we can consider a
topology on the coarse shape homotopy group of a topological space $(X,x)$,
$Sh^*((S^k,*),(X,x))=\check{\pi}_k^{*}(X,x)$, which makes it a Hausdorff
topological group. Moreover, we study some properties of these topological
coarse shape homotopoy groups such as second countability, movability and in
particullar, we prove that $\check{\pi}_k^{*^{top}}$ preserves finite product
of compact Hausdorff spaces. Also, we show that for a pointed topological space
$(X,x)$, $\check{\pi}_k^{top}(X,x)$ can be embedded in
$\check{\pi}_k^{*^{top}}(X,x)$.",117,7,859,43.22
1427,topology,"Topological states of matter originate from distinct topological electronic
structures of materials. As for strong topological insulators (STIs), the
topological surface (interface) is a direct consequence of electronic structure
transition between materials categorized to different topological genus.
Therefore, it is fundamentally interesting if such topological character can be
manipulated. Besides tuning the crystal field and the strength of spin-orbital
coupling (e.g., by external strain, or chemical doping), there is currently
rare report on topological state induced in ordinary insulators (OIs) by the
heterostructure of OI/STI. Here we report the observation of a Dirac cone
topological surface state (TSS) induced on the Sb2Se3 layer up to 15 nm thick
in the OI/STI heterostructure, in sharp contrast with the OI/OI heterostructure
where no sign of TSS can be observed. This is evident for an induced
topological state in an OI by heterostructure.",140,9,962,34.26
1428,topology,"It is a simple fact that a subgroup generated by a subset $A$ of an abelian
group is the direct sum of the cyclic groups $\langle a\rangle$, $a\in A$ if
and only if the set $A$ is independent. In [5] the concept of an $independent$
set in an abelian group was generalized to a $topologically$ $independent$
$set$ in a topological abelian group (these two notions coincide in discrete
abelian groups). It was proved that a topological subgroup generated by a
subset $A$ of an abelian topological group is the Tychonoff direct sum of the
cyclic topological groups $\langle a\rangle$, $a\in A$ if and only if the set
$A$ is topologically independent and absolutely Cauchy summable. Further, it
was shown, that the assumption of absolute Cauchy summability of $A$ can not be
removed in general in this result. In our paper we show that it can be removed
in precompact groups.
  In other words, we prove that if $A$ is a subset of a {\em precompact}
abelian group, then the topological subgroup generated by $A$ is the Tychonoff
direct sum of the topological cyclic subgroups $\langle a\rangle$, $a\in A$ if
and only if $A$ is topologically independent. We show that precompactness can
not be replaced by local compactness in this result.",210,8,1233,49.49
1429,topology,"Hopf insulators are intriguing three-dimensional topological insulators
characterized by an integer topological invariant. They originate from the
mathematical theory of Hopf fibration and epitomize the deep connection between
knot theory and topological phases of matter, which distinguishes them from
other classes of topological insulators. Here, we implement a model Hamiltonian
for Hopf insulators in a solid-state quantum simulator and report the first
experimental observation of their topological properties, including fascinating
topological links associated with the Hopf fibration and the integer-valued
topological invariant obtained from a direct tomographic measurement. Our
observation of topological links and Hopf fibration in a quantum simulator
opens the door to probe rich topological properties of Hopf insulators in
experiments. The quantum simulation and probing methods are also applicable to
the study of other intricate three-dimensional topological model Hamiltonians.",132,6,995,-6.09
1430,topology,"The concept of topological fermions, including Weyl and Dirac fermions, stems
from the quantum Hall state induced by a magnetic field, but the definitions
and classifications of topological fermions are formulated without using
magnetic field. It is unclear whether and how the topological information of
topological fermions can be probed once their eigen spectrum is completely
rebuilt by a strong magnetic field. In this work, we provide an answer via
mapping Landau levels (bands) of topological fermions in $d$ dimensions to the
spectrum of a $(d-1)$-dimensional lattice model. The resultant ""Landau lattice""
may correspond to a topological insulator, and its topological property can be
determined by real-space topological invariants. Accordingly, each zero-energy
Landau level (band) inherits the topological stability from the corresponding
topological boundary state of the Landau lattice. The theory is demonstrated in
detail by transforming 2D Dirac fermions under magnetic fields to the
Su-Schrieffer-Heeger models in class AIII, and 3D Weyl fermions to the Chern
insulators in class A.",161,7,1099,27.35
1431,topology,"We give geometric characterisations of patch and Lawson topologies in the
context of predicative point-free topology using the constructive notion of
located subset. We present the patch topology of a stably locally compact
formal topology by a geometric theory whose models are the points of the given
topology that are located, and the Lawson topology of a continuous lattice by a
geometric theory whose models are the located subsets of the given lattice. We
also give a predicative presentation of the frame of perfect nuclei on a stably
locally compact formal topology, and show that it is essentially the same as
our geometric presentation of the patch topology. Moreover, the construction of
Lawson topologies naturally induces a monad on the category of compact regular
formal topologies, which is shown to be isomorphic to the Vietoris monad.",136,5,851,20.05
1432,topology,"Topological semimetals with nodal line are a novel class of topological
matter extending the concept of topological matter beyond topological
insulators and Weyl/Dirac semimetals. Here, we show that a Floquet topological
semimetal with nodal helix can be generated by irradiating graphene or the
surface of a topological insulator with circularly polarized light. Nodal helix
is a form of nodal line running across the Brillouin zone with helical winding.
Specifically, it is shown that the dynamics of irradiated graphene is described
by the time Stark Hamiltonian, which can host a Floquet topological insulator
and a weakly driven Floquet topological semimetal with nodal helix in the high
and low frequency limits, respectively. It is predicted that, at low frequency,
the $\pi$ shift of the Zak phase generates a topological discontinuity along
the projected nodal helix in the momentum spectrum of the Floquet states. At
intermediate frequency, this topological discontinuity can create an
interesting change of patterns in the quasienergy dispersion of the Floquet
states.",162,7,1079,27.15
1433,topology,"Electric circuits are known to realize topological quadrupole insulators. We
explore electric circuits made of capacitors and inductors forming the
breathing Kagome and pyrochlore lattices. They are known to possess three
phases (trivial insulator, higher-order topological insulator and metallic
phases) in the tight-binding model. The topological phase is characterized by
the emergence of zero-energy corner states. A topological phase transition is
induced by tuning continuously the capacitance, which is possible by using
variable capacitors. It is found that the two-point impedance yields huge
resonance peaks when one node is taken at a corner in the topological phase. It
is a good signal to detect a topological phase transition. We also show that
the topological corner resonance is robust against randomness of capacitance
and inductance. Furthermore, the size of electric circuits can be quite small
to realize the topological phase together with topological phase transitions.",144,10,991,38.32
1434,topology,"By using an extended slave-boson method, we draw a global phase diagram
summarizing both magnetic phases and paramagnetic (PM) topological insulating
phases (TI$_s$) in three-dimensional topological Kondo insulator (TKI). By
including electron hopping (EH) up to third neighbor, we identify four strong
topological insulating (STI) phases and two weak topological insulating (WTI)
phases, then the PM phase diagrams characterizing topological transitions
between these TI$_s$ are depicted as functions of EH, $f$-electron energy level
and hybridization constant. We also find an insulator-metal transition from a
STI phase which has surface Fermi rings and spin textures in qualitative
agreement to TKI candidate SmB$_6$. In weak hybridization regime,
antiferromagnetic (AF) order naturally arises in the phase diagrams, and
depending on how the magnetic boundary crosses the PM topological transition
lines, AF phases are classified into AF topological insulator (AFTI) and
non-topological AF insulator (nAFI), according to their $\mathcal{Z}_2$
indices. In two small regions of parameter space, two distinct topological
transition processes between AF phases occur, leading to two types of AFTI,
showing distinguishable surface dispersions around their Dirac points.",176,6,1268,1.91
1435,topology,"Topology manifesting in many branches of physics deepens our understanding on
state of matters. Topological photonics has recently become a rapidly growing
field since artificial photonic structures can be well designed and constructed
to support topological states, especially a promising large-scale
implementation of these states using photonic chips. Meanwhile, due to the
inapplicability of Hall conductance to photons, it is still an elusive problem
to directly measure the integer topological invariants and topological phase
transitions for photons. Here, we present a direct observation of topological
winding numbers by using bulk-state photon dynamics on a chip. Furthermore, we
for the first time experimentally observe the topological phase transition
points via single-photon dynamics. The integrated topological structures,
direct measurement in the single-photon regime and strong robustness against
disorder add the key elements into the toolbox of `quantum topological
photonics' and may enable topologically protected quantum information
processing in large scale.",148,7,1083,12.56
1436,topology,"Topological measures and deficient topological measures generalize Borel
measures and correspond to certain non-linear functionals. We study integration
with respect to deficient topological measures on locally compact spaces. Such
an integration over sets yields a new deficient topological measure if we
integrate a nonnegative vanishing at infinity function; and it produces a
signed deficient topological measure if we use a continuous function on a
compact space. We present many properties of these resulting deficient
topological measures and of signed deficient topological measures. In
particular, they are absolutely continuous with respect to the original
deficient topological measure and Lipschitz continuous. Deficient topological
measures obtained by integration over sets can also be obtained from non-linear
functionals. We show that for a deficient topological measure $ \mu$ that
assumes finitely many values, there is a function $ f $ such that $\int_X f \,
d \mu = 0$, but $\int_X (-f )\, d \mu \neq 0$. We present different criteria
for $\int_X f \, d \mu = 0$. We also prove some convergence results, including
a Monotone convergence theorem.",176,10,1165,27.11
1437,topology,"Based on the tight-binding model calculations and photonic experimental
visualization on graphene, we report the domain-wall-induced gapped topological
kink states and topological corner states. In graphene, domain walls with
gapless topological kink states could be induced either by sublattice symmetry
breaking or by lattice deformation. We find that the coexistence of these two
mechanisms will induce domain walls with gapped topological kink states.
Significantly, the intersection of these two types of domain wall gives rise to
topological corner state localized at the crossing point. Through the
manipulation of domain walls, we show graphene not only a versatile platform
supporting multiple topological corner modes in a controlled manner, but also
possessing promising applications such as fabricating topological quantum dots
composed of gapped topological kink states and topological corner states.",128,6,913,20.11
1438,topology,"A universal feature of topological insulators is that they cannot be
adiabatically connected to an atomic limit, where individual lattice sites are
completely decoupled. This property is intimately related to a topological
obstruction to constructing a localized Wannier function from Bloch states of
an insulator. Here we generalize this characterization of topological phases
toward periodically driven systems. We show that nontrivial connectivity of
hybrid Wannier centers in momentum space and time can characterize various
types of topology in periodically driven systems, which include Floquet
topological insulators, anomalous Floquet topological insulators with
micromotion-induced boundary states, and gapless Floquet states realized with
topological Floquet operators. In particular, nontrivial time dependence of
hybrid Wannier centers indicates impossibility of continuous deformation of a
driven system into an undriven insulator, and a topological Floquet operator
implies an obstruction to constructing a generalized Wannier function which is
localized in real and frequency spaces. Our results pave a way to a unified
understanding of topological states in periodically driven systems as a
topological obstruction in Floquet states.",170,7,1249,-8.02
1439,topology,"Digital topology is part of the ongoing endeavour to understand and analyze
digitized images. With a view to supporting this endeavour, many notions from
algebraic topology have been introduced into the setting of digital topology.
But some of the most basic notions from homotopy theory remain largely absent
from the digital topology literature. We embark on a development of homotopy
theory in digital topology, and define such fundamental notions as function
spaces, path spaces, and cofibrations in this setting. We establish digital
analogues of basic homotopy-theoretic properties such as the homotopy extension
property for cofibrations, and the homotopy lifting property for certain
evaluation maps that correspond to path fibrations in the topological setting.
We indicate that some depth may be achieved by using these homotopy-theoretic
notions to give a preliminary treatment of Lusternik-Schnirelmann category in
the digital topology setting. This topic provides a connection between digital
topology and critical points of functions on manifolds, as well as other topics
from topological dynamics.",162,8,1112,14.19
1440,topology,"Topological measures and deficient topological measures are defined on open
and closed subsets of a topological space, generalize regular Borel measures,
and correspond to (non-linear in general) functionals that are linear on singly
generated subalgebras or singly generated cones of functions. They lack
subadditivity, and many standard techniques of measure theory and functional
analysis do not apply to them. Nevertheless, we show that many classical
results of probability theory hold for topological and deficient topological
measures. In particular, we prove a version of Aleksandrov's Theorem for
equivalent definitions of weak convergence of deficient topological measures.
We also prove a version of Prokhorov's Theorem which relates the existence of a
weakly convergent subsequence in any sequence in a family of topological
measures to the characteristics of being a uniformly bounded in variation and
uniformly tight family. We define Prokhorov and Kantorovich-Rubenstein metrics
and show that convergence in either of them implies weak convergence of
(deficient) topological measures on metric spaces. We also generalize many
known results about various dense and nowhere dense subsets of deficient
topological measures. The present paper constitutes a first step to further
research in probability theory and its applications in the context of
topological measures and corresponding non-linear functionals.",202,9,1422,20.42
1441,topology,"Rapidly growing demands for fast information processing have launched a race
for creating compact and highly efficient optical devices that can reliably
transmit signals without losses. Recently discovered topological phases of
light provide a novel ground for photonic devices robust against scattering
losses and disorder. Combining these topological photonic structures with
nonlinear effects will unlock advanced functionalities such as nonreciprocity
and active tunability. Here we introduce the emerging field of nonlinear
topological photonics and highlight recent developments in bridging the physics
of topological phases with nonlinear optics. This includes a design of novel
photonic platforms which combine topological phases of light with appreciable
nonlinear response, self-interaction effects leading to edge solitons in
topological photonic lattices, nonlinear topological circuits, active photonic
structures exhibiting lasing from topologically-protected modes, and harmonic
generation from edge states in topological arrays and metasurfaces. We also
chart future research directions discussing device applications such as mode
stabilization in lasers, parametric amplifiers protected against feedback, and
ultrafast optical switches employing topological waveguides.",164,7,1286,1.47
1442,topology,"Topological manipulation of waves is at the heart of the cutting-edge
metamaterial researches. Quadrupole topological insulators were recently
discovered in two-dimensional (2D) flux-threading lattices which exhibit
higher-order topological wave trapping at both the edges and corners. Photonic
crystals (PhCs), lying at the boundary between continuous media and discrete
lattices, however, are incompatible with the present quadrupole topological
theory. Here, we unveil quadrupole topological PhCs triggered by a twisting
degree-of-freedom. Using a topologically trivial PhC as the motherboard, we
show that twisting induces quadrupole topological PhCs without flux-threading.
The twisting-induced crystalline symmetry enriches the Wannier polarizations
and lead to the anomalous quadrupole topology. Versatile edge and corner
phenomena are observed by controlling the twisting angles in a lateral
heterostructure of 2D PhCs. Our study paves the way toward topological
twist-photonics as well as the quadrupole topology in the quasi-continuum
regime for phonons and polaritons.",143,9,1079,27.93
1443,topology,"We show that our Universe lives in a topological and non-perturbative vacuum
state full of a large amount of hidden quantum hairs, the hairons. We will
discuss and elaborate on theoretical evidences that the quantum hairs are
related to the gravitational topological winding number in vacuo. Thus, hairons
are originated from topological degrees of freedom, holographically stored in
the de Sitter area. The hierarchy of the Planck scale over the Cosmological
Constant (CC) is understood as an effect of a Topological Memory intrinsically
stored in the space-time geometry. Any UV quantum destabilizations of the CC
are re-interpreted as Topological Phase Transitions, related to the
desapparence of a large ensamble of topological hairs. This process is
entropically suppressed, as a tunneling probability from the N- to the
0-states. Therefore, the tiny CC in our Universe is a manifestation of the rich
topological structure of the space-time. In this portrait, a tiny neutrino mass
can be generated by quantum gravity anomalies and accommodated into a large
N-vacuum state. We will re-interpret the CC stabilization from the point of
view of Topological Quantum Computing. An exponential degeneracy of topological
hairs non-locally protects the space-time memory from quantum fluctuations as
in Topological Quantum Computers.",200,11,1329,25.8
1444,topology,"We study disorder effects in a two-dimensional system with chiral symmetry
and find that disorder can induce a quadrupole topological insulating phase (a
higher-order topological phase with quadrupole moments) from a topologically
trivial phase. Their topological properties manifest in a topological invariant
defined based on effective boundary Hamiltonians, the quadrupole moment, and
zero-energy corner modes. We find gapped and gapless topological phases and a
Griffiths regime. In the gapless topological phase, all the states are
localized, while in the Griffiths regime, the states at zero energy become
multifractal. We further apply the self-consistent Born approximation to show
that the induced topological phase arises from disorder renormalized masses. We
finally introduce a practical experimental scheme with topoelectrical circuits
where the predicted topological phenomena can be observed by impedance
measurements. Our work opens the door to studying higher-order topological
Anderson insulators and their localization properties.",143,8,1049,25.39
1445,topology,"Higher-order topology realizes topologically robust corner modes as a
manifestation of nontriviality. We theoretically propose non-Hermitian skin
effects which stem from second-order topology of chiral-symmetric Hermitian
systems. It is found that the skin modes are localized at the corners. We
demonstrate two types of second-order topological skin effects by
two-dimensional intrinsic and extrinsic second-order topology. The intrinsic
second-order topological skin effect is characterized topologically by bulk
inversion symmetry as well as chiral symmetry. Meanwhile, the extrinsic
second-order topological skin effect occurs from the topological correspondence
between the edges and corners. We show that the non-Hermitian skin modes emerge
by using a relationship between second-order and conventional first-order
topology.",108,8,830,13.54
1446,topology,"We discuss the higher-order topological field theory and response of
topological crystalline insulators with no other symmetries. We show how the
topology and geometry of the system is organised in terms of the elasticity
tetrads which are ground state degrees of freedom labelling lattice topological
charges, higher-form conservation laws and responses on sub-dimensional
manifolds of the bulk system. In a crystalline insulator, they classify
higher-order global symmetries in a transparent fashion. This coincides with
the dimensional hierarchy of topological terms, the multipole expansion, and
anomaly inflow, related to a mixed number of elasticity tetrads and
electromagnetic gauge fields. In the continuum limit of the elasticity tetrads,
the semi-classical expansion can be used to derive the higher-order or embedded
topological responses to global U(1) symmetries, such as electromagnetic gauge
fields with explicit formulas for the higher-order quasi-topological invariants
in terms of the elasticity tetrads and Green's functions. The topological
responses and readily generalized in parameter space to allow for e.g.
multipole pumping. Our simple results further bridge the recently appreciated
connections between topological field theory, higher form symmetries and gauge
fields, fractonic excitations and topological defects with restricted mobility
elasticity in crystalline insulators.",192,10,1405,9.82
1447,topology,"Higher-order topological phase as a generalization of Berry phase attracts an
enormous amount of research. The current theoretical models supporting
higher-order topological phases, however, cannot give the connection between
lower and higher-order topological phases when extending the lattice from lower
to higher dimensions. Here, we theoretically propose and experimentally
demonstrate a topological corner state constructed from the edge states in one
dimensional lattice. The two-dimensional square lattice owns independent
spatial modulation of coupling in each direction, and the combination of edge
states in each direction come up to the higher-order topological corner state
in two-dimensional lattice, revealing the connection of topological phase in
lower and higher dimensional lattices. Moreover, the topological corner states
in two-dimensional lattice can also be viewed as the dimension-reduction from a
four-dimensional topological phase characterized by vector Chern number,
considering two modulation phases as synthetic dimensions in Aubry-Andre-Harper
model discussed as example here. Our work deeps the understanding to
topological phases breaking through the lattice dimension, and provides a
promising tool constructing higher topological phases in higher dimensional
structures.",173,7,1305,8.4
1448,topology,"Quantum simulator with the ability to harness the dynamics of complex quantum
systems has emerged as a promising platform for probing exotic topological
phases. Since the flexibility offered by various controllable quantum systems
has enabled to gain insight into quantum simulation of such complicated
problems, analog quantum simulator has recently shown its feasibility to tackle
problems of exploring topological phases. However, digital quantum simulation
and detection of topological phases still remain elusive. Here, we develop and
experimentally realize the digital quantum simulation of topological phase with
a solid-state quantum simulator at room temperature. Distinct from previous
works dealing with static topological phases, the topological phases emulated
here are Floquet topological phases. Furthermore, we also illustrate the
procedure of digitally simulating a quantum quench and observing the
nonequilibrium dynamics of Floquet topological phases. By means of quantum
quench, the 0- and {\pi}-energy topological invariants are unambiguously
detected through measuring time-averaged spin polarizations. Our experiment
opens up a new avenue to digitally simulate and detect Floquet topological
phases with fast-developed programmable quantum simulators.",171,9,1274,7.45
1449,topology,"Higher-order topological insulators are established as topological
crystalline insulators protected by crystalline symmetries. One celebrated
example is the second-order topological insulator in three dimensions that
hosts chiral hinge modes protected by crystalline symmetries. Since amorphous
solids are ubiquitous, it is important to ask whether such a second-order
topological insulator can exist in an amorphous system without any spatial
order. Here we predict the existence of a secondorder topological insulating
phase in an amorphous system without any crystalline symmetry. Such a
topological phase manifests in the winding number of the quadrupole moment, the
quantized longitudinal conductance and the hinge states. Furthermore, in stark
contrast to the viewpoint that structural disorder should be detrimental to the
higher-order topological phase, we remarkably find that structural disorder can
induce a second-order topological insulator from a topologically trivial phase
in a regular geometry. We finally demonstrate the existence of a second-order
topological phase in amorphous systems with time-reversal symmetry.",154,8,1134,23.77
1450,topology,"Topological phases of light exhibit unique properties beyond the realm of
conventional photonics. In particular the valley-Hall topological insulator has
been realized in a variety of photonic structures because it can be easily
induced by breaking certain lattice symmetries. However, the valley-Chern
numbers are usually fixed by design and the corresponding topological edge
states are forced to propagate in a fixed direction. Here, we propose a
mechanism to induce topological transitions via accidental Dirac points in
metasurfaces composed of interacting dipole emitters/antennas. For a fixed
arrangement of dipoles, we show that the topological phase depends critically
on the surrounding electromagnetic environment which mediates the dipole-dipole
interactions. To access different topological phases we embed the metasurface
inside a cavity waveguide where one can tune the dominant dipolar coupling from
short-range Coulomb interactions to long-range photon-mediated interactions by
reducing the cavity width; this results in a topological transition
characterized by an inversion of the valley-Chern numbers. Consequently, we
show that one can switch the chirality of the topological edge states by
modifying only the electromagnetic environment in which the dipoles are
embedded. This mechanism could have important implications for other
topological phases such as photonic higher-order topological insulators.",196,9,1425,12.77
1451,topology,"Topological edge states are predicted to be responsible for the high
efficient thermoelectric response of topological insulators, currently the best
thermoelectric materials. However, to explain their figure of merit the
coexistence of topological electrons, entropy and phonons can not be considered
independently. In a background that puts together electrodynamics and topology,
through an expression for the topological intrinsic field, we treat
relativistic phonons within the topological surface showing their ability to
modulate the Berry curvature of the bands and then playing a fundamental role
in the thermoelectric effect. Finally, we show how the topological insulators
under such relativistic thermal excitations keep time reversal symmetry
allowing the observation of high figures of merit at high temperatures. The
emergence of this new intrinsic topological field and other constraints are
suitable to have experimental consequences opening new possibilities of
improving the efficiency of this topological effect for their based technology.",147,6,1057,7.79
1452,topology,"Discoveries of topological states and topological materials reshape our
understanding of physics and materials over the last 15 years. First-principles
calculations have been playing a significant role in bridging the theory of
topology and experiments by predicting realistic topological materials. In this
article, we overview the first-principles methodology on topological quantum
materials. First, we unify different concepts of topological states in the same
band inversion scenario. Then, we discuss the topology using first-principles
band structures and newly-established topological materials databases. We
stress challenges in characterizing symmetry-independent Weyl semimetals and
calculating topological surface states, closing with an outlook on the exciting
transport and optical phenomena induced by the topology.",108,7,830,10.91
1453,topology,"The intertwined ferroelectricity and band topology will enable the
non-volatile control of the topological states, which is of importance for
nanoelectrics with low energy costing and high response speed. Nonetheless, the
principle to design the novel system is unclear and the feasible approach to
achieve the coexistence of two parameter orders is absent. Here, we propose a
general paradigm to design 2D ferroelectric topological insulators by sliding
topological multilayers on the basis of first-principles calculations. Taking
trilayer Bi2Te3 as a model system, we show that in the van der Waals multilayer
based 2D topological insulators, the in-plane and out-of-plane ferroelectricity
can be induced through a specific interlayer sliding, to enable the coexistence
of ferroelectric and topological orders. The strong coupling of the order
parameters renders the topological states sensitive to polarization flip,
realizing non-volatile ferroelectric control of topological properties. The
revealed design-guideline and ferroelectric-topological coupling not only are
useful for the fundamental research of the coupled ferroelectric and
topological physics in 2D lattices, but also enable novel applications in
nanodevices.",170,7,1230,8.91
1454,topology,"We experimentally demonstrate topological slow light waveguides in valley
photonic crystals (VPhCs). We employed a bearded interface formed between two
topologically-distinct VPhCs patterned in an air-bridged silicon slab. The
interface supports both topological and non-topological slow light modes below
the light line. By means of optical microscopy, we observed light propagation
in the topological mode in the slow light regime with a group index $n_{\rm g}$
over $30$. Furthermore, we confirmed light transmission via the slow light mode
even under the presence of sharp waveguide bends. In comparison between the
topological and non-topological modes, we found that the topological mode
exhibits much more efficient waveguiding than the trivial one, elucidating
topological protection in the slow light regime. This work paves the way for
exploring topological slow-light devices compatible with existing photonics
technologies.",132,8,935,35.37
1455,topology,"A topological pump enables robust transport of quantized particles when the
system parameters are varied in a cyclic process. In previous studies,
topological pump was achieved inhomogeneous systems guaranteed by a topological
invariant of the bulk band structure when time is included as an additional
synthetic dimension. Recently, bulk-boundary correspondence has been
generalized to the bulk-disclination correspondence, describing the emergence
of topological bounded states in the crystallographic defects protected by the
bulk topology. Here we show the topological pumping can happen between
different disclination states with different chiralities in an inhomogeneous
structure. Based on a generalized understanding of the charge pumping process,
we explain the topological disclination pump by tracing the motion of Wannier
centers in each unit cell. Besides, by constructing two disclination structures
and introducing a symmetry-breaking perturbation, we achieve a topological
pumping between different dislocation cores. Our result opens a route to study
the topological pumping in inhomogeneous topological crystalline systems and
provides a flexible platform for robust energy transport.",163,8,1202,13.99
1456,topology,"Higher-order topological insulators (HOTI) are a novel topological phase
beyond the framework of the conventional bulk-boundary correspondence. In these
peculiar systems, the topologically nontrivial boundary modes are characterized
by a co-dimension of at least two. Despite several promising preliminary
considerations regarding the impact of nonlinearity in such systems, the
flourishing field of experimental HOTI research has thus far been confined to
the linear evolution of topological states. As such, the observation of the
interplay between nonlinearity and the dynamics of higher-order topological
phases in conservative systems remains elusive. In our work, we experimentally
demonstrate nonlinear higher-order topological corner states. Our photonic
platform enables us to observe nonlinear topological corner states as well as
the formation of solitons in such topological structures. Our work paves the
way towards the exploration of topological properties of matter in the
nonlinear regime, and may herald a new class of compact devices that harnesses
the intriguing features of topology in an on-demand fashion.",158,8,1128,23.16
1457,topology,"Despite the progress made in successful prediction of many classes of
weakly-correlated topological materials, it is not clear how a topological
order can emerge from interacting orders and whether or not a charge ordered
topological state can exist in a two-dimensional (2D) material. Here, through
first-principles modeling and analysis, we identify a 2$\times$2 charge density
wave (CDW) phase in monolayer $2H$-NbSe$_2$ that harbors coexisting quantum
spin Hall (QSH) insulator, topological crystalline insulator (TCI) and
topological nodal line (TNL) semimetal states. The topology in monolayer
NbSe$_2$ is driven by the formation of the CDW and the associated
symmetry-breaking periodic lattice distortions and not via a pre-existing
topology. Our finding of an emergent triple-topological state in monolayer
$2H$-NbSe$_2$ will offer novel possibilities for exploring connections between
different topologies and a unique materials platform for controllable
CDW-induced topological states for potential applications in quantum
electronics and spintronics and Majorana-based quantum computing.",148,5,1098,0.08
1458,topology,"Periodic stacking of topologically trivial and non-trivial layers with
opposite symmetry of the valence and conduction bands induces topological
interface states that, in the strong coupling limit, hybridize both across the
topological and normal insulator layers. Using band structure engineering, such
superlattices can be effectively realized using the IV-VI lead tin
chalcogenides. This leads to emergent minibands with a tunable topology as
demonstrated both by theory and experiments. The topological minibands are
proven by magneto-optical spectroscopy, revealing Landau level transitions both
at the center and edges of the artificial superlattice mini Brillouin zone.
Their topological character is identified by the topological phase transitions
within the minibands observed as a function of temperature. The critical
temperature of this transition as well as the miniband gap and miniband width
can be precisely controlled by the layer thicknesses and compositions. This
witnesses the generation of a new fully tunable quasi-3D topological state that
provides a template for realization of magnetic Weyl semimetals and other
strongly interacting topological phases.",165,8,1177,22.14
1459,topology,"The non-trivial topology in the layered $\text{FeTe}_{0.55}\text{Se}_{0.45}$
(FTS) superconductor has been suggested by both theory and experiment to be
strongly dependent on the Te concentration. Motivated by this together with the
Te fluctuations expected from alloy disorder, we develop a simple layered model
for a strong topological insulator that allows us to describe a scenario where
topologically trivial domains permeate the sample. We refer to such a phase as
topological domain disordered and study the local density (LDOS) of the
topological surface states that can be measured using scanning tunneling
spectroscopy (STS) in this phase. We find that topologically trivial domains on
the surface, where one would expect the topological surface state to be absent,
appear as regions of suppressed LDOS surrounded by domain walls with enhanced
LDOS. Furthermore, we show that studying the energy dependence of the STS
should allow us to distinguish the topologically trivial parts of the surface
from other forms of disorder. Finally, we discuss implications of such local
disappearance of the topological surface states for the observation of Majorana
modes in vortices.",177,9,1181,28.88
1460,topology,"Framed combinatorial topology is a novel theory describing combinatorial
phenomena arising at the intersection of stratified topology, singularity
theory, and higher algebra. The theory synthesizes elements of classical
combinatorial topology with a new combinatorial approach to framings. The
resulting notion of framed combinatorial spaces has unexpectedly good behavior
when compared to classical, nonframed combinatorial notions of space. In
discussing this behavior and its contrast with that of classical structures, we
emphasize two broad themes, computability in combinatorial topology and
combinatorializability of topological phenomena. The first theme of
computability concerns whether certain combinatorial structures can be
algorithmically recognized and classified. The second theme of
combinatorializability concerns whether certain topological structures can be
faithfully represented by a discrete structure. Combining these themes, we will
find that in the context of framed combinatorial topology we can overcome a set
of fundamental classical obstructions to the computable combinatorial
representation of topological phenomena.",148,8,1148,-9.17
1461,topology,"The recent research of topological photonics has not only proposed and
realized novel topological phenomena such as one-way broadband propagation and
robust transport of light, but also designed and fabricated photonic devices
with high-performance indexes which are immune to fabrication errors such as
defects or disorders. Photonic crystals, which are periodic optical structures
with the advantages of good light field confinement and multiple adjusting
degrees of freedom, provide a powerful platform to control the flow of light.
With the topology defined in the reciprocal space, photonic crystals have been
widely used to reveal different topological phases of light and demonstrate
topological photonic functionalities. In this review, we present the physics of
topological photonic crystals with different dimensions, models and topological
phases. The design methods of topological photonic crystals are introduced.
Furthermore, we review the applications of topological photonic crystals in
passive and active photonics. These researches pave the way of applying
topological photonic crystals in practical photonic devices.",158,8,1135,14.7
1462,topology,"The higher-order topological insulator (HOTI) is a new type of topological
system which has special bulkedge correspondence compared with conventional
topological insulators. In this work, we propose a scheme to realize Floquet
HOTI in ultracold atom systems. With the combination of periodically
spin-dependent driving of the superlattices and a next-next-nearest-neighbor
d-wave-like anisotropic coupling term between different spin components, a
Floquet second-order topological insulator with four zero-energy corner states
emerges, whose Wannier bands are gapless and exhibit interesting bulk topology.
Furthermore, the anisotropic coupling with nearest-neighbor form will also
induce some intriguing topological phenomena, e.g. non-topologically protected
corner states and topological semimetal for two different types of lattice
structures respectively. Our scheme may give insight into the construction of
different types of higher-order topological insulators in synthetic systems. It
also provides an experimentally feasible platform to research the relations
between different types of topological states and may have a wide range of
applications in future.",154,9,1169,15.31
1463,topology,"Topological phases of matter are featured with exotic edge states. However,
the fractional topological numbers at edges, though predicted long ago by
Jackiw and Rebbi, remain elusive in topological photonic systems. Here, we
report on the observation of fractional topological numbers at the topological
edges and corners in one- and two-dimensional photonic crystals. The fractional
topological numbers are determined via the measurements of the photonic local
density-of-states. In one-dimensional photonic crystals, we witness a rapid
change of the fractional topological number at the edges rising from 0 to 1/2
when the photonic band gap experiences a topological transition, confirming the
well-known prediction of Jackiw and Rebbi. In two-dimensional systems, we
discover that the fractional topological number in the corner region varies
from 0 to 1/2 and 1/4 in different photonic band gap phases. Our study paves
the way toward topological manipulation of fractional quantum numbers in
photonics.",147,8,1006,24.78
1464,topology,"Amorphous topological states, which are independent of the specific spatial
distribution of microscopic constructions, have gained much attention.
Recently, higher-order topological insulators, which are a new class of
topological phases of matter, have been proposed in amorphous systems. Here, we
propose a density-driven higher-order topological phase transition in a
two-dimensional amorphous system. We demonstrate that the amorphous system
hosts a topological trivial phase at low density. With an increase in the
density of lattice sites, the topological trivial phase converts to a
higher-order topological phase characterized by a quantized quadrupole moment
and the existence of topological corner states. Furthermore, we confirm that
the density-driven higher-order topological phase transition is size dependent.
In addition, our results should be general and equally applicable to
three-dimensional amorphous systems. Our findings may greatly enrich the study
of higher-order topological states in amorphous systems.",139,9,1029,28.43
1465,topology,"Topological qubits composed of unpaired Majorana zero-modes are under intense
experimental and theoretical scrutiny in efforts to realize practical quantum
computation schemes. In this work, we show the minimum four \textit{unpaired}
Majorana zero-modes required for a topological qubit according to braiding
schemes and control of entanglement for gate operations are inherent to
multiplicative topological phases, which realize symmetry-protected tensor
products -- and maximally-entangled Bell states -- of unpaired Majorana
zero-modes known as multiplicative Majorana zero-modes. We introduce
multiplicative Majorana zero-modes as topologically-protected boundary states
of both one and two-dimensional multiplicative topological phases, using
methods reliant on multiplicative topology to construct relevant Hamiltonians
from the Kitaev chain model. We furthermore characterize topology in the bulk
and on the boundary with established methods while also introducing techniques
to overcome challenges in characterizing multiplicative topology. In the
process, we explore the potential of these multiplicative topological phases
for an alternative to braiding-based topological quantum computation schemes,
in which gate operations are performed through topological phase transitions.",163,6,1288,-11.98
1466,topology,"A vector topology on a vector space over a topological field is a (not
necessarily Hausdorff) topology by which the addition and scalar multiplication
are continuous. We prove that, if an isomorphism between the lattice of
topologies of two vector spaces preserves vector topologies, then the
isomorphism is induced by a translation, a semilinear isomorphism and the
complement map. As a consequence, if such an isomorphism exists, the
coefficient fields are isomorphic as topological fields and these vector spaces
have the same dimension. We also prove a similar rigidity result for an
isomorphism between the lattice of vector topologies which preserves Hausdorff
vector topologies. These results are obtained by using the fundamental theorems
of affine and projective geometries.",118,6,783,30.6
1467,topology,"The concept of topological superconductivity has attracted immense interest
in the physics community recently for several reasons: First, topological
superconductors represent new phases of matter, topologically distinct from any
other known phase of matter. Second, their discovery would present the first
realization of Majorana zero modes. Third, intrinsic topological
superconductors promise to become an important ingredient for next-generation
quantum technologies. There are a handful of candidates to date considered as
potential intrinsic topological superconductors. All of these display signs of
unconventional, potentially topological superconductivity. However, the results
from different experimental methods are inconclusive. One of the major
challenges in the field of topological superconductivity has been the scarcity
of potential materials, in contrast to the many exciting, theoretical
predictions of properties that could be unraveled by such a discovery.
Currently, it should be far to say that a material that convincingly displays
intrinsic topological superconductivity, and Majorana zero modes, has so far
not been discovered. This perspective aims at summarizing the results of the
most actively discussed potential topological superconductors for chemists.
But, I will also compile the essential physical and chemical design principles
of these materials from a chemists' perspective in order to motivate synthetic
chemists to join the quest for the discovery of the first intrinsic topological
superconductor.",210,11,1539,7.86
1468,topology,"The recent emergence of electromagnetic topological defects has attracted
wide interest in fields from topological photonics to deep-subwavelength
light-mater interactions. Previously, much of the research has focused on
constructing specific topological defects but the fundamental theory describing
the physical mechanisms underlying their formation and transitions is lacking.
Here, we present a spin-orbit coupling based theory describing such mechanisms
for various configurations of spin topological defects in confined
electromagnetic fields. The results reveal that their formation originates from
the conservation of total angular momentum and that their transitions are
determined by anisotropic spin-orbit couplings. By engineering the spin-orbit
couplings, we observe the formation and transitions of Neel-type, twisted-type,
and Bloch-type spin topological defects in confined electromagnetic fields. A
stable Block-type spin topological defect is reported for the first time. Our
theory can also describe the transitions of field topological defects. The
findings enrich the portfolio of electromagnetic topological defects, deepen
our understanding of conserved laws, spin-orbit couplings and transitions of
topological defects in confined electromagnetic systems, and predict
applications in high-density optical data transmissions and chiral quantum
optics.",177,9,1374,6.74
1469,topology,"We present a braided circuit topology framework for investigating topology
and structural phase transitions in aggregates of semiflexible polymers. In the
conventional approach to circuit topology, which specifically applies to single
isolated folded linear chains, the number and arrangement of contacts within
the circuitry of a folded chain give rise to increasingly complex fold
topologies. Another avenue for achieving complexity is through the interaction
and entanglement of two or more folded linear chains. The braided circuit
topology approach describes the topology of such multiple-chain systems and
offers topological measures such as writhe, complexity, braid length, and
isotopy class. This extension of circuit topology to multichains reveals the
interplay between collapse, aggregation, and entanglement. In this work, we
show that circuit topological motif fractions are ideally suited order
parameters to characterise structural phase transitions in entangled systems
that can detect structural re-ordering other measures cannot.",144,7,1048,21.74
1470,topology,"Topology reasoning aims to comprehensively understand road scenes and present
drivable routes in autonomous driving. It requires detecting road centerlines
(lane) and traffic elements, further reasoning their topology relationship,
i.e., lane-lane topology, and lane-traffic topology. In this work, we first
present that the topology score relies heavily on detection performance on lane
and traffic elements. Therefore, we introduce a powerful 3D lane detector and
an improved 2D traffic element detector to extend the upper limit of topology
performance. Further, we propose TopoMLP, a simple yet high-performance
pipeline for driving topology reasoning. Based on the impressive detection
performance, we develop two simple MLP-based heads for topology generation.
TopoMLP achieves state-of-the-art performance on OpenLane-V2 benchmark, i.e.,
41.2% OLS with ResNet-50 backbone. It is also the 1st solution for 1st OpenLane
Topology in Autonomous Driving Challenge. We hope such simple and strong
pipeline can provide some new insights to the community. Code is at
https://github.com/wudongming97/TopoMLP.",152,17,1106,41.66
1471,topology,"We introduce topological skyrmion semimetal phases of matter, characterized
by bulk electronic structures with topological defects in ground state
observable textures over the Brillouin zone (BZ), rather than topological
degeneracies in band structures. We present and characterize toy models for
these novel topological phases, focusing on realizing such topological defects
in the ground state spin expectation value texture over the BZ. We find
generalized Fermi arc bulk-boundary correspondences and chiral anomaly response
signatures, including Fermi arc-like states which do not terminate with
topological band structure degeneracies in the bulk, but rather with
topological defects in the spin texture of bulk insulators. We also consider
novel boundary conditions for topological semimetals, in which the 3D bulk is
mapped to a 2D bulk plus 0D defect. Given the experimental significance of
topological semimetals, our work paves the way to broad experimental study of
topological skyrmion phases and the quantum skyrmion Hall effect.",150,6,1042,24.11
1472,topology,"The integration of topological concepts into electronic energy band theory
has been a transformative development in condensed matter physics. Since then,
this paradigm has broadened its reach, extending to a variety of physical
systems, including open ones. In this study, we employ analogues of the
generalized $n$-dimensional Su-Schrieffer-Heeger model, a cornerstone in
understanding topological insulators and higher-order topological states, to
unveil a dimensional hierarchy of topological states within thermal diffusive
networks. Unlike their electronic counterparts, the topological states in these
networks are characterized by confined temperature profiles of dimension
$(n-d)$ with constant diffusive rates, where $n$ represents the system's
dimension and $d$ is the order of the topological state. Our findings
demonstrate the existence of topological corner states in thermal diffusive
systems up to $n=3$, along with surface and hinge states. We also identify and
discuss an intermediate-order topological phase in the case $n=3$,
characterized by the presence of hinge states but the absence of corner states.
Furthermore, our work delves into the influence of chiral symmetry in these
thermal networks, particularly focusing on topological thermal states with a
near-zero diffusion rate. This research lays the foundation for advanced
thermal management strategies that utilize topological states in multiple
dimensions.",199,9,1437,20.82
1473,topology,"Recent studies on the interplay between band topology and layer degree of
freedom provide an effective way to realize exotic topological phases. Here we
systematically study the $C_6$- and $C_3$-symmetric higher-order topological
phases in bilayer spinless tight-binding lattice models. For concreteness, we
consider bilayer phononic crystals as the realizations of these models. We find
that for mirror-symmetric-stacking bilayer lattices, the interlayer couplings
control the emergence and disappearance of the topological bound states in the
continuum where we consider the corner states as possible bound states in the
bulk continuum. For the bilayer phononic crystals formed by two different
lattices with identical symmetry, the band topology is determined by both the
band topology of each layer as well as their mutual couplings. The bilayer
phononic crystals experience a phase transition from nontrivial to trivial band
topology when the interlayer couplings are gradually increased. Our work
unveils the rich physics and topological phases emerging in bilayer lattice
systems that can be used to engineer interesting phenomena and induce emergent
topological phases.",169,8,1177,21.63
1474,topology,"The topological classification of energy bands has laid the groundwork for
the discovery of various topological phases of matter in recent decades. While
this classification has traditionally focused on real-energy bands, recent
studies have revealed the intriguing topology of complex-energy, or
non-Hermitian bands. For example, the spectral winding of complex-energy bands
can from unique topological structures like braids, holding promise for
advancing quantum computing. However, discussions of complex-energy braids have
been largely limited to the Abelian braid group $\mathbb{B}_2$ for its relative
simplicity, while identifying topological non-Abelian braiding is still
difficult since it has no universal topological invariant for characterization.
Here, we present a machine learning algorithm for the unsupervised
identification of non-Abelian braiding of multiple complex-energy bands. The
consistency with Artin's well-known topological equivalence conditions in
braiding is demonstrated. Inspired by the results from unsupervised learning,
we also introduce a winding matrix as a topological invariant in charactering
the braiding topology and unveiling the bulk-edge correspondence of non-Abelian
braided non-Hermitian bands. Finally, we extend our approach to identify
non-Abelian braiding topology in 2D/3D exceptional semimetals and successfully
address the unknotting problem in an unsupervised manner.",186,9,1423,13.99
1475,topology,"We predict novel topological phases with broken time-reversal symmetry
supporting the coexistence of opposite chiral edge states, which are
fundamentally different from the photonic spin-Hall, valley-Hall, and
higher-order topological phases. We find a fine-grained categorization of Chern
insulators, their band topologies characterized by identical Chern number are
completely different. Furthermore, we prove that different topologies cause
zeros in their Bloch wavefunction overlaps, which imprint the band gap closing
and appear at the degenerate points of topological phase transition. The Bloch
wavefunction overlaps predict the reflection and refraction at a topological
time boundary, and the overlap zeros ensure the existence of vanishing revival
amplitude at critical times even though different topologies before and after
the time boundary have identical Chern number. Our findings create new
opportunities for topological metamaterials, uncover the topological feature
hidden in the time boundary effect as a probe of topology, and open a venue for
the exploration of the rich physics originating from the long-range couplings.",159,6,1142,13.82
1476,topology,"Controlling topological phases of light has allowed experimental observations
of abundant topological phenomena and development of robust photonic devices.
The prospect of more sophisticated controls with topological photonic devices
for practical implementations requires high-level programmability. Here, we
demonstrate a fully programmable topological photonic chip with large-scale
integration of silicon photonic nanocircuits and microresonators. Photonic
artificial atoms and their interactions in our compound system can be
individually addressed and controlled, therefore allowing arbitrary altering of
structural parameters and geometrical configurations for the observations of
dynamic topological phase transitions and diverse photonic topological
insulators. By individually programming artificial atoms on the generic chip,
it has allowed comprehensive statistic characterisations of topological
robustness against relatively weak disorders, as well as counterintuitive
topological Anderson phase transitions induced by strong disorders. Our generic
topological photonic chip that can be rapidly reprogrammed to implement
multifunctionalities, prototypes a flexible and versatile platform for possible
applications across fundamental science and topological technologies.",154,7,1284,-22.3
1477,topology,"Fermi sea in a metal can host exotic quantum topology, which determines its
conductance quantization and is characterized by Euler characteristic $\chi_F$.
Unlike gapped band topology described by the global feature of wave function,
this topology of gapless system is associated with the geometry of Fermi sea,
and thus probing and identifying $\chi_F$ are inherently difficult in
higher-dimensional systems. Here, we propose a dimensional reduction theory for
Fermi sea topology in $d$-dimensional metallic systems, showing that $\chi_F$
can be determined by the feature of so-called reduced critical points on Fermi
surfaces, with theoretical simplicity and observational intuitiveness. We also
reveal a nontrivial correspondence between the Fermi sea topology and the
gapped band topology by using an ingenious mapping, of which $\chi_F$ exactly
equals to the topological invariant of gapped topological phases. This provides
a potential way to capture $\chi_F$ through the topological superconductors.
Our work opens an avenue to characterize and detect the Fermi sea topology
using low-dimensional momentum information.",160,7,1125,18.99
1478,topology,"Fragile topology, akin to twisted bilayer graphene and the exotic phases
therein, is a notable topological class with intriguing properties. However,
due to its unique nature and the lack of bulk-edge correspondence, the
experimental signature of fragile topology has been under debated since its
birth. Here, we demonstrate experimentally that fragile topological phases with
filling anomaly can be probed via screw dislocations, despite that they do not
support gapless edge states. Using a designer hexagonal phononic crystal with a
fragile topological band gap, we find that 1D gapless bound modes can emerge at
a screw dislocation due to the bulk fragile topology. We then establish a
connection between our system and the twisted boundary condition via the gauge
invariance principle and illustrate that such an emergent phenomenon is an
intrinsic property of fragile topological phases with filling anomaly. We
observe experimentally the 1D topological bound states using the pump-probe
measurements of their dispersion and wavefunctions, which unveils a novel
bulk-defect correspondence of fragile topology and a powerful tool for probing
fragile topological phases and materials.",175,7,1188,24.92
1479,topology,"Topological photonics shows considerable promise in revolutionizing photonic
devices through the use of topological phases, leading to innovations like
topological lasers that enhance light control. One of recent breakthroughs is
reducing the size of these systems by utilizing lower-dimensional boundary
states, notably via higher-order topological phases. This paper presents the
first experimental demonstration of topological laser in anomalous quadrupole
topological phase, an instance of higher-order phases. To facilitate this, a
topological nanocavity with quality factor near 6,000 is engineered through a
twisting operation. The topological nature of our system is validated by
calculation of nested Wannier center and the emergency condition of corner
states. Our experimental observations reveal the manifestation of corner states
and the achievement of single-mode pulsed laser, driven by optical gain from
multiple quantum wells at telecommunication wavelengths and at a temperature of
4 K. A lasing threshold of 23 uW and a cold quality factor of 1,500 are deduce
through rate equation. Our work gives a new potential in the application of
topological principles to advance nanophotonic technologies.",172,9,1215,24.27
1480,topology,"In the light of $\phi $--mapping method and topological current theory, the
topological structure and the topological quantization of arbitrary dimensional
topological defects are investigated. It is pointed out that the topological
quantum numbers of the defects are described by the Winding numbers of $\phi
$--mapping which are determined in terms of the Hopf indices and the Brouwer
degrees of $\phi$--mapping. Furthermore, it is shown that all the topological
defects are generated from where $\vec \phi =0$, i.e. from the zero points of
the $\phi $--mapping.",86,6,564,41.19
1481,topology,"A novel U(1) topological gauge field theory for topological defects in liquid
crystals is constructed by considering the U(1) gauge field is invariant under
the director inversion. Via the U(1) gauge potential decomposition theory and
the $\phi$-mapping topological current theory, the decomposition expression of
U(1) gauge field and the unified topological current for monopoles and strings
in liquid crystals are obtained. It is revealed that monopoles and strings are
located in different spatial dimensions and their topological charges are just
the winding numbers of $\phi$-mapping.",85,4,589,25.83
1482,topology,"It is shown that every separable abelian topological group is isomorphic with
a topological subgroup of a monothetic group (that is, a topological group with
a single topological generator). In particular, every separable metrizable
abelian group embeds into a metrizable monothetic group. More generally, we
describe all topological groups that can be embedded into monothetic groups:
they are exactly abelian topological groups of weight $\leq\frak c$ covered by
countably many translations of every nonempty open subset.",76,4,523,28.88
1483,topology,"A groupoid is a small category in which each morphism has an inverse. A
topological groupoid is a groupoid in which both sets of objects and morphisms
have topologies such that all groupoid structure maps are continuous. The
notion of monodromy groupoid of a topological groupoid generalises those of
fundamental groupoid and universal covering. It was earlier proved that the
monodromy of a locally sectionable topological groupoid has a topological
groupoid structure satisfying some properties. In this paper a similar problem
is studied for compatible locally trivial topological groupoids.",89,6,594,44.95
1484,topology,"Finite topological spaces became much more essential in topology, with the
development of computer science. The task of this paper is to study and
investigate some properties of such spaces with the existence of an ordered
relation between their minimal neighborhoods. We introduce notations and
elementary facts known as Alexandroff space. The family of minimal
neighborhoods forms a unique minimal base. We consider T_0 spaces. We give a
link between finite $T_0$ spaces and the related partial order. Finally, we
study some properties of multifunctions and their relationships with connected
ordered topological spaces.",93,8,622,41.06
1485,topology,"Modular forms appear in many facets of mathematics, and have played important
roles in geometry, mathematical physics, number theory, representation theory,
topology, and other areas. Around 1994, motivated by technical issues in
homotopy theory, Mark Mahowald, Haynes Miller and I constructed a topological
refinement of modular forms, which we call {\em topological modular forms}. At
the Zurich ICM I sketched a program designed to relate topological modular
forms to invariants of manifolds, homotopy groups of spheres, and ordinary
modular forms. This program has recently been completed and new directions have
emerged. In this talk I will describe this recent work and how it informs our
understanding of both algebraic topology and modular forms.",113,6,754,31.62
1486,topology,"We study modules over the ring $\widetilde{\C}$ of complex generalized
numbers from a topological point of view, introducing the notions of
$\widetilde{\C}$-linear topology and locally convex $\widetilde{\C}$-linear
topology. In this context particular attention is given to completeness,
continuity of $\widetilde{\C}$-linear maps and elements of duality theory for
topological $\widetilde{\C}$-modules. As main examples we consider various
Colombeau algebras of generalized functions",60,3,485,8.88
1487,topology,"Given a closed orientable surface (\Sigma) of genus at least two, we
establish an affine isomorphism between the convex compact set of
isotopy-invariant topological measures on (\Sigma) and the convex compact set
of additive functions on the set of isotopy classes of certain subsurfaces of
(\Sigma). We then construct such additive functions, and thus isotopy-invariant
topological measures, from probability measures on (\Sigma) together with some
additional data. The map associating topological measures to probability
measures is affine and continuous. Certain Dirac measures map to simple
topological measures, while the topological measures due to Py and Rosenberg
arise from the normalized Euler characteristic.",102,5,719,20.21
1488,topology,"Let $A$ be a partial *-algebra endowed with a topology $\tau$ that makes it
into a locally convex topological vector space $A[\tau]$. Then $A$ is called a
topological partial *-algebra if it satisfies a number of conditions, which all
amount to require that the topology $\tau$ fits with the multiplier structure
of $A$ Besides the obvious cases of topological quasi *-algebras and
CQ*-algebras, we examine several classes of potential topological partial
*-algebras, either function spaces (lattices of $L^p$ spaces on $[0,1]$ or on
$\mathbb R$, amalgam spaces), or partial *-algebras of operators (operators on
a partial inner product space, O*-algebras).",100,3,657,3.81
1489,topology,"We present a way of topologizing sets of Galois types over structures in
abstract elementary classes with amalgamation. In the elementary case, the
topologies thus produced refine the syntactic topologies familiar from first
order logic. We exhibit a number of natural correspondences between the
model-theoretic properties of classes and their constituent models and the
topological properties of the associated spaces. Tameness of Galois types, in
particular, emerges as a topological separation principle.",72,5,508,27.83
1490,topology,"We generalize the topological entanglement entropy to a family of topological
Renyi entropies parametrized by a parameter alpha, in an attempt to find new
invariants for distinguishing topologically ordered phases. We show that,
surprisingly, all topological Renyi entropies are the same, independent of
alpha for all non-chiral topological phases. This independence shows that
topologically ordered ground-state wavefunctions have reduced density matrices
with a certain simple structure, and no additional universal information can be
extracted from the entanglement spectrum.",78,4,578,11.25
1491,topology,"We show that a topological semigroup of finite partial bijections
$\mathscr{I}_\lambda^n$ of an infinite set with a compact subsemigroup of
idempotents is absolutely $H$-closed and any countably compact topological
semigroup does not contain $\mathscr{I}_\lambda^n$ as a subsemigroup. We give
sufficient conditions onto a topological semigroup $\mathscr{I}_\lambda^1$ to
be non-$H$-closed. Also we describe the structure of countably compact Brandt
$\lambda^0$-extensions of topological monoids and study the category of
countably compact Brandt $\lambda^0$-extensions of topological monoids with
zero.",76,4,602,20.42
1492,topology,"We study topological properties of the symmetric inverse topological
semigroup of finite transformations $\mathscr{I}_\lambda^n$ of the rank
$\leqslant n$. We show that the topological inverse semigroup
$\mathscr{I}_\lambda^n$ is algebraically $h$-closed in the class of topological
inverse semigroups. Also we prove that a topological semigroup $S$ with
countably compact square $S\times S$ does not contain the semigroup
$\mathscr{I}_\lambda^n$ for infinite cardinal $\lambda$ and show that the Bohr
compactification of an infinite topological symmetric inverse semigroup of
finite transformations $\mathscr{I}_\lambda^n$ of the rank $\leqslant n$ is the
trivial semigroup.",87,4,675,16.66
1493,topology,"Let E be a topological space and F a uniform space. We introduce a new
topology (in fact a uniform structure) called the V-congergence on the space of
applications from E to F such that C(E,F) is closed for this topology and the
restriction of this topology to C(E,F) is equivalent to pointwise convergence.
In other words this topology is the coarsest preserving continuity. We give a
criterion of convergence for this topology not involving the limit. Among
properties preserved are mesurability and alpha-borelianity for a countable
ordinal alpha.",89,6,550,44.95
1494,topology,"We propose a topological order parameter for interacting topological
insulators, expressed in terms of the full Green's functions of the interacting
system. We show that it is exactly quantized for a time reversal invariant
topological insulator, and it can be experimentally measured through the
topological magneto-electric effect. This topological order parameter can be
applied to both interacting and disordered systems, and used for determining
their phase diagrams.",67,4,472,15.0
1495,topology,"In this note we define fibrations of topological stacks and establish their
main properties. We prove various standard results about fibrations (fiber
homotopy exact sequence, Leray-Serre and Eilenberg-Moore spectral sequences,
etc.). We prove various criteria for a morphism of topological stacks to be a
fibration, and use these to produce examples of fibrations. We prove that every
morphism of topological stacks factors through a fibration and construct the
homotopy fiber of a morphism of topological stacks. When restricted to
topological spaces our notion of fibration coincides with the classical one.",90,7,610,36.28
1496,topology,"We investigate the three-dimensional, time-reversal invariant topological
superconductors with generic interaction by their response to external fields.
The first description is a gravitational topological field theory, which gives
a $Z_2$ classification of topological superconductors, and predicts a
half-quantized thermal Hall effect on the surface. The second description
introduces an s-wave proximity pairing field on the surface, and the associated
topological defects give an integer $Z$ classification of the topological
superconductors.",70,4,546,-2.94
1497,topology,"By using the representational power of Chu spaces we define the notion of a
generalized topological space (or GTS, for short), i.e., a mathematical
structure that generalizes the notion of a topological space. We demonstrate
that these topological spaces have as special cases known topological spaces.
Furthermore, we develop the various topological notions and concepts for GTS.
Moreover, since the logic of Chu spaces is linear logic, we give an
interpretation of most linear logic connectives as operators that yield
topological spaces.",82,7,540,29.45
1498,topology,"In this paper, we study the topology associated to the fractal manifold
model. It turns out that this topology is actually a family of topologies that
gives to the fractal manifold a structure of variable topological space.
Additionally, we prove that using the fractal manifold as model for the
universe dynamic, the universe expansion is intimately correlated to the
variation of the topology.",63,4,395,33.24
1499,topology,"The number of topologies and non-homeomorphic topologies on a fixed finite
set are now known up to $n=18$, $n=16$ but still no complete formula yet
(Sloane). There are one to one correspondence among topologies, preorder and
digraphs. In this article, we enumerate topologies and non-homeomorphic
topologies whose underlying graph is a given finite graph.",54,4,355,53.21
1500,cryptography,"The advantages of post-quantum cryptography over classical cryptography are
covered in this survey. We address several post-quantum cryptography
techniques. We conclude that the deployment of quantum-safe cryptographic
systems is anticipated to be the future of secure communication, and that the
development of post-quantum cryptography is essential to guarantee the security
of sensitive information in the post quantum era.",58,4,426,18.05
1501,cryptography,"We propose to realize visual cryptography in an indirect way with the help of
computer-generated hologram. At present, the recovery method of visual
cryptography is mainly superimposed on transparent film or superimposed by
computer equipment, which greatly limits the application range of visual
cryptography. In this paper, the shares of the visual cryptography were encoded
with computer-generated hologram, and the shares is reproduced by optical
means, and then superimposed and decrypted. This method can expand the
application range of visual cryptography and further increase the security of
visual cryptography.",89,5,620,23.46
1502,cryptography,"This paper presents new properties of Primitive Pythagorean Triples (PPT)
that have relevance in applications where events of different probability need
to be generated and in cryptography.",27,2,189,18.69
1503,cryptography,"In this short note, we address a common misconception at the interface of
probability theory and public-key cryptography.",18,2,121,19.37
1504,cryptography,"Quantum-resistant cryptography is cryptography that aims to deliver
cryptographic functions and protocols that remain secure even if large-scale
fault-tolerant quantum computers are built. NIST will soon announce the first
selected public-key cryptography algorithms in its Post-Quantum Cryptography
(PQC) standardization which is the most important current effort in the field
of quantum-resistant cryptography. This report provides an overview to security
experts who do not yet have a deep understanding of quantum-resistant
cryptography. It surveys the computational model of quantum computers; the
quantum algorithms that affect cryptography the most; the risk of
Cryptographically Relevant Quantum Computers (CRQCs) being built; the security
of symmetric and public-key cryptography in the presence of CRQCs; the NIST PQC
standardization effort; the migration to quantum-resistant public-key
cryptography; the relevance of Quantum Key Distribution as a complement to
conventional cryptography; and the relevance of Quantum Random Number
Generators as a complement to current hardware Random Number Generators.",149,5,1115,-0.23
1505,cryptography,"In this survey we propose to cover the prose of post-quantum cryptography
over classical cryptography. We talk about the various cryptographic methods
that are being practiced to safeguard our information. The future of secure
communication is expected to be the implementation of quantum-safe
cryptographic systems, and that in the post-quantum era, the development of
post-quantum cryptography is essential for ensuring the security of sensitive
data.",65,4,453,24.07
1506,cryptography,"Nowadays, using cryptographic systems play an effective role in security and
safety technologies. One of the most applied kind of cryptography is Symmetric
Cryptography and its applications. New aspects of symmetric Cryptography
methodologies and applications has been presented by this paper. Security-based
networks and some complex technologies such as RFID and parallel security
settings has been intro-duced by using Symmetric Cryptography is the main base
of discussion in this paper. Designing an unique protocol for Symmetric
Cryptography in security networks elements is our focus. Reviewing benefits of
using these methodologies has been pre-sented and discussed in this paper.",98,7,687,29.55
1507,cryptography,"Cryptography plays a pivotal role in safeguarding sensitive information and
facilitating secure communication. Classical cryptography relies on
mathematical computations, whereas quantum cryptography operates on the
principles of quantum mechanics, offering a new frontier in secure
communication. Quantum cryptographic systems introduce novel dimensions to
security, capable of detecting and thwarting eavesdropping attempts. By
contrasting quantum cryptography with its classical counterpart, it becomes
evident how quantum mechanics revolutionizes the landscape of secure
communication.",71,5,589,-14.28
1508,cryptography,"The DNA cryptography is a new and very promising direction in cryptography
research. DNA can be used in cryptography for storing and transmitting the
information, as well as for computation. Although in its primitive stage, DNA
cryptography is shown to be very effective. Currently, several DNA computing
algorithms are proposed for quite some cryptography, cryptanalysis and
steganography problems, and they are very powerful in these areas. However, the
use of the DNA as a means of cryptography has high tech lab requirements and
computational limitations, as well as the labor intensive extrapolation means
so far. These make the efficient use of DNA cryptography difficult in the
security world now. Therefore, more theoretical analysis should be performed
before its real applications.
  In this project, We do not intended to utilize real DNA to perform the
cryptography process; rather, We will introduce a new cryptography method based
on central dogma of molecular biology. Since this method simulates some
critical processes in central dogma, it is a pseudo DNA cryptography method.
The theoretical analysis and experiments show this method to be efficient in
computation, storage and transmission; and it is very powerful against certain
attacks. Thus, this method can be of many uses in cryptography, such as an
enhancement insecurity and speed to the other cryptography methods. There are
also extensions and variations to this method, which have enhanced security,
effectiveness and applicability.",230,13,1512,35.07
1509,cryptography,"With the ever-growing concern for internet security, the field of quantum
cryptography emerges as a promising solution for enhancing the security of
networking systems. In this paper, 20 notable papers from leading conferences
and journals are reviewed and categorized based on their focus on various
aspects of quantum cryptography, including key distribution, quantum bit
commitment, post quantum cryptography, and counterfactual quantum key
distribution. The paper explores the motivations and challenges of employing
quantum cryptography, addressing security and privacy concerns along with
existing solutions. Secure key distribution, a critical component in ensuring
the confidentiality and integrity of transmitted information over a network, is
emphasized in the discussion. The survey examines the potential of quantum
cryptography to enable secure key exchange between parties, even when faced
with eavesdropping, and other applications of quantum cryptography.
Additionally, the paper analyzes the methodologies, findings, and limitations
of each reviewed study, pinpointing trends such as the increasing focus on
practical implementation of quantum cryptography protocols and the growing
interest in postquantum cryptography research. Furthermore, the survey
identifies challenges and open research questions, including the need for more
efficient quantum repeater networks, improved security proofs for continuous
variable quantum key distribution, and the development of quantum resistant
cryptographic algorithms.",202,8,1528,-0.17
1510,cryptography,"We introduce a natural generalization of the golden cryptography, which uses
general unimodular matrices in place of the traditional Q-matrices, and prove
that it preserves the original error correction properties of the encryption.
Moreover, the additional parameters involved in generating the coding matrices
make this unimodular cryptography resilient to the chosen plaintext attacks
that worked against the golden cryptography. Finally, we show that even the
golden cryptography is generally unable to correct double errors in the same
row of the ciphertext matrix, and offer an additional check number which, if
transmitted, allows for the correction.",95,4,657,13.92
1511,cryptography,"Would you like to have your own cryptography method? Experts say you should
not do it. If you think you can develop a better cryptography method anyway. We
present a brief discussion about some well known cryptography methods and how
our model fails against the traditional attacks. We do not want to discourage
anybody, we just want to show that, despite of the importance of developing
better cryptography models, it is a very hard task.",75,5,439,64.71
1512,cryptography,"Previous studies have shown that cryptography is hard for developers to use
and misusing cryptography leads to severe security vulnerabilities. We studied
relevant vulnerability reports on the HackerOne bug bounty platform to
understand what types of cryptography vulnerabilities exist in the wild. We
extracted eight themes of vulnerabilities from the vulnerability reports and
discussed their real-world implications and mitigation strategies. We hope that
our findings alert developers, familiarize them with the dire consequences of
cryptography misuses, and support them in avoiding such mistakes.",83,5,602,16.52
1513,cryptography,"This paper analyzes the performance of Kak's three stage quantum
cryptographic protocol based on public key cryptography against a
man-in-the-middle attack. A method for protecting against such an attack is
presented using certificates distributed by a trusted third party.",39,3,273,43.22
1514,cryptography,"We present simple implementations of Kak's three-stage quantum cryptography
protocol. The case where the transformation is applied to more than one qubit
at the same time is also considered.",29,3,190,48.3
1515,cryptography,"While strictly black and white images have been the basis for visual
cryptography, there has been a lack of an easily implemented format for colour
images. This paper establishes a simple, yet secure way of implementing visual
cryptography with colour, assuming a binary data representation.",45,3,291,31.72
1516,cryptography,"This paper describes how the communicating parties can employ intensity and
state estimation to detect if the eavesdropper has siphoned off and injected
photons in the received communication. This is of relevance in quantum
cryptography based on random rotations of photon polarizations.",42,3,287,24.78
1517,cryptography,"We remark that the Bellare-Rivest protocol for translucent cryptography [J.
Cryptology (1999) 12: 117-139] can not truly enable the government to decrypt
partial encrypted communications.",25,3,187,33.41
1518,cryptography,"In this paper, we present some applications of a difference equation of
degree k in Cryptography and Coding Theory.",19,2,115,43.73
1519,cryptography,"This is a survey of algorithmic problems in group theory, old and new,
motivated by applications to cryptography.",18,2,113,27.83
1520,cryptography,"In 2019 G\'omez described a new public key cryptography scheme based on ideas
from multivariate public key cryptography using hidden irreducible polynomials.
We show that the scheme's design has a flaw which lets an attacker recover the
private key directly from the public key.",44,3,278,40.69
1521,cryptography,"The author taught two courses on cryptography, one at Duke University aimed
at non-mathematics majors and one at Rose-Hulman Institute of Technology aimed
at mathematics and computer science majors. Both tried to incorporate technical
and societal aspects of cryptography, with varying emphases. This paper will
discuss the strengths and weaknesses of both courses and compare the
differences in the author's approach.",61,4,418,33.95
1522,cryptography,"In quantum information, the role of entanglement and disentanglement is
itself a subject of research and debate. Earlier works on quantum cryptography
have almost established that entanglement has no special advantage in quantum
cryptography. In this paper we reveal that entanglement is better ingredient
than disentanglement for our alternative quantum cryptography.",51,4,368,11.92
1523,cryptography,"Cryptography is the science of encrypting the information so that it is
rendered unreadable for an intruder. Cryptographic techniques are of utmost
importance in today's world as the information to be sent might be of
invaluable importance to both the sender and the receiver. Various
cryptographic techniques ensure that even if an intruder intercepts the sent
information, he is not able to decipher it thus render ending it useless for
the intruder. Cryptography can be grouped into two types, that is Symmetric key
cryptography and Asymmetric key cryptography. Symmetric key cryptography uses
the same key for encryption as well as decryption thus making it faster
compared to Asymmetric Key cryptography which uses different keys for
encryption and decryption. Generation of dynamic keys for Symmetric key
cryptography is an interesting field and in this we have tapped this field so
as to generate dynamic keys for symmetric key cryptography. In this work, we
have devised an algorithm for generating dynamic keys for sending messages over
a communication channel and also solving key refreshment problem.",173,8,1111,29.48
1524,cryptography,"This paper presents a quantum mechanical version of the piggy-bank
cryptography protocol. The basic piggybank cryptography idea is to use two
communications: one with the encrypted message, and the other regarding the
encryption transformation which the receiver must decipher first. In the
quantum mechanical version of the protocol, the encrypting unitary
transformation information is sent separately but just deciphering it is not
enough to break the system. The proposed quantum protocol consists of two
stages.",75,5,516,27.01
1525,cryptography,"The piggy bank idea allows one-way encryption of information that can be
accessed only by authorized parties. Here we show how the piggy bank idea can
be used to authenticate parties to counter man-in-the-middle (MIM) attack that
can jeopardize the double-lock cryptography protocol. We call this method
double-signature double lock cryptography and it can be implemented in ways
that go beyond hash-based message authentication.",64,4,429,41.4
1526,cryptography,"Uniquely among the sciences, quantum cryptography has driven both
foundational research as well as practical real-life applications. We review
the progress of quantum cryptography in the last decade, covering quantum key
distribution and other applications.",35,3,257,28.33
1527,cryptography,"This report gives a novel technique of image encryption and authentication by
combining elements of Visual Cryptography and Public Key Cryptography. A
prominent attack involving generation of fake shares to cheat honest users has
been described and a demonstration of the proposed system employing a
centralised server to generate shares and authenticate them on the basis of
requests is made as a counter to the described attack.",67,3,430,29.01
1528,cryptography,"This paper presents a practical method of quantum tomography for decoding the
state of photons in a multistage cryptography protocol. This method works if
the polarization angles are defined on a fixed plane, as is assumed in several
quantum cryptography protocols. We show if there are 2m polarization angles in
a fixed plane, we need m number of filters and m2 number of photons through
each filter.",67,4,401,48.84
1529,cryptography,"The paper explains that post-quantum cryptography is necessary due to the
introduction of quantum computing causing certain algorithms to be broken. We
analyze the different types of post-quantum cryptography, quantum cryptography
and quantum-resistant cryptography, to provide a thorough understanding of the
current solutions to the problems and their limitations. We explain the current
state of quantum computing and how it has changed over time while discussing
possible attacks on both types of post-quantum cryptography. Next, current
post-quantum algorithms are discussed, and implementations are demonstrated.
Lastly, we conclude that due to quantum cryptography's present limitations it
is not a viable solution like it is often presented to be and that it is
currently better to use quantum-resistant cryptography.",117,6,825,30.8
1530,cryptography,"Public-key cryptosystems are suggested based on invariants of groups. We give
also an overview of the known cryptosystems which involve groups.",21,3,143,60.82
1531,cryptography,"This is our Reply to Peres' Comment [quant-ph/9509003] to ""Quantum
Cryptography Based on Orthogonal States"" [Phys. Rev. Lett. 75, 1239 (1995)].",21,5,143,69.28
1532,cryptography,"I present examples of mathematical objects that are of interest for public
key cryptography. Text for the Journ\'ee Annuelle 2007 of the SMF.",23,3,141,59.8
1533,cryptography,"This paper presents certains aspects of the mathematics of Aryabhata that are
of interest to the cryptography community.",18,2,120,27.83
1534,cryptography,"Steganography and Cryptography are two popular ways of sending vital
information in a secret way. One hides the existence of the message and the
other distorts the message itself. There are many cryptography techniques
available; among them AES is one of the most powerful techniques. In
Steganography we have various techniques in different domains like spatial
domain, frequency domain etc. to hide the message. It is very difficult to
detect hidden message in frequency domain and for this domain we use various
transformations like DCT, FFT and Wavelets etc. In this project we are
developing a system where we develop a new technique in which Cryptography and
Steganography are used as integrated part along with newly developed enhanced
security module. In Cryptography we are using AES algorithm to encrypt a
message and a part of the message is hidden in DCT of an image; remaining part
of the message is used to generate two secret keys which make this system
highly secured. Keyword: Cryptography, Steganography, Stego- image, Threshold
Value, DCT Coefficient",171,9,1069,43.73
1535,cryptography,"Novel idea of hierarchical visual cryptography is stated in this paper. The
key concept of hierarchical visual cryptography is based upon visual
cryptography. Visual cryptography encrypts secret information into two pieces
called as shares. These two shares are stacked together by logical XOR
operation to reveal the original secret. Hierarchical visual cryptography
encrypts the secret in various levels. The encryption in turn is expansionless.
The original secret size is retained in the shares at all levels. In this paper
secret is encrypted at two different levels. Four shares are generated out of
hierarchical visual cryptography. Any three shares are collectively taken to
form the key share. All shares generated are meaningless giving no information
by visual inspection. Performance analysis is also obtained based upon various
categories of secrets. The greying effect is completely removed while revealing
the secret Removal of greying effect do not change the meaning of secret.",149,14,994,34.42
1536,cryptography,"The aim of this paper is to elucidate the implications of quantum computing
in present cryptography and to introduce the reader to basic post-quantum
algorithms. In particular the reader can delve into the following subjects:
present cryptographic schemes (symmetric and asymmetric), differences between
quantum and classical computing, challenges in quantum computing, quantum
algorithms (Shor's and Grover's), public key encryption schemes affected,
symmetric schemes affected, the impact on hash functions, and post quantum
cryptography. Specifically, the section of Post-Quantum Cryptography deals with
different quantum key distribution methods and mathematicalbased solutions,
such as the BB84 protocol, lattice-based cryptography, multivariate-based
cryptography, hash-based signatures and code-based cryptography.",103,4,821,2.82
1537,cryptography,An overview on current developments in post quantum cryptography,9,1,64,28.5
1538,cryptography,"We use extensions of tropical algebras as platforms for very efficient public
key exchange protocols.",15,2,101,30.87
1539,cryptography,"With the development of Shor's algorithm, some nondeterministic polynomial
(NP) time problems (e.g. prime factorization problems and discrete logarithm
problems) may be solved in polynomial time. In recent years, although some
homomorphic encryption algorithms have been proposed based on prime
factorization problems, the algorithms may be cracked by quantum computing
attacks. Therefore, this study proposes a post-quantum cryptography (PQC)-based
homomorphic encryption method which includes the homomorphic encryption
function based on a code-based cryptography method for avoiding quantum
computing attacks. Subsection 3.2 proposes mathematical models to prove the
feasibility of the proposed method, and Subsection 3.3 gives calculation
examples to present the detailed steps of the proposed method. In experimental
environments, the mainstream cryptography methods (i.e. RSA cryptography and
elliptic curve cryptography (ECC)) have been compared, and the results show
that the encryption time and decryption time of the proposed method are shorter
than other cryptography methods. Furthermore, the proposed method is designed
based on a non-negative matrix factorization problem (i.e. a NP problem) for
resisting quantum computing attacks.",168,15,1246,29.04
1540,cryptography,"This article presets a review of the achievements rapidly developing field of
cryptography - public-key cryptography based on the lattice theory. Paper
contains the necessary basic concepts and the major problems of the lattice
theory, as well as together with the description on the benefits of this
cryptography class - the properties of the reliability to quantum computers and
full homomorphism, the shortcomings of specific implementations.",66,3,445,5.16
1541,cryptography,"In this paper, we have proposed a public key cryptography using recursive
block matrices involving generalized Fibonacci numbers over a finite field Fp.
For this, we define multinacci block matrices, a type of upper triangular
matrix involving multinacci matrices at diagonal places and obtained some of
its algebraic properties. Moreover, we have set up a method for key element
agreement at end users, which makes the cryptography more efficient. The
proposed cryptography comes with a large keyspace and its security relies on
the Discrete Logarithm Problem(DLP).",86,5,566,32.73
1542,cryptography,"Entanglement-measurement attack is a well-known attack in quantum
cryptography. In quantum cryptography protocols, eavesdropping checking can
resist this attack. There are two known eavesdropping checking methods. One is
to use decoy photon technology for eavesdropping checking. The other is to use
the entanglement correlation of two groups of non-orthogonal entangled states
for eavesdropping checking. In this paper, we prove the security against
entanglement-measurement attack for the qudit-system-based quantum cryptography
protocols which use the two methods for eavesdropping checking. Our security
proof is useful to improve the eavesdropping checking method used in quantum
cryptography protocols.",94,8,708,32.49
1543,cryptography,"These lecture notes have been written for courses given at \'Ecole normale
sup\'erieure de Lyon and summer school 2022 in post-quantum cryptography that
took place in the university of Budapest. Our objective is to give a general
introduction to the foundations of code-based cryptography which is currently
known to be secure even against quantum adversaries. In particular we focus our
attention to the decoding problem whose hardness is at the ground of the
security of many cryptographic primitives, the most prominent being McEliece
and Alekhnovich' encryption schemes.",87,4,574,33.58
1544,cryptography,"In the field of Computer Science and Information Technology Internet of
Things (IoT) is one of the emerging technologies. In IoT environment several
devices are interconnected and transmit data among them. There may be some
security vulnerability arise within the IoT environment. Till date, IoT has not
been widely accepted due to its security flaws. Hence to keep the IoT
environment most robust, we propose a stable security framework of IoT with
Elliptic Curve Cryptography (ECC) using DNA Encoding. The ECC is most
lightweight cryptography technique among other well known public key
cryptography techniques. To increase encryption complexity, DNA encoding
mechanism of DNA computing with ECC is preceded.",108,8,710,38.92
1545,cryptography,"Cryptography has a pivotal role in securing our digital world. Nonetheless,
it is a challenging topic to learn. In this paper, we show that despite its
complex nature, dyslexia$-$a learning disorder that influences reading and
writing skills$-$does not hinder one's ability to comprehend cryptography. In
particular, we conducted a gameful workshop with 14 high-school dyslexic
students and taught them fundamental encryption methods. The students engaged
well, learned the techniques, and enjoyed the training. We conclude that with a
proper approach, dyslexia cannot hinder learning a complex subject such as
cryptography.",90,7,624,39.33
1546,cryptography,"In many of the cryptography applications like password or IP address
encryption schemes, symmetric cryptography is useful. In these relatively
simpler applications of cryptography, asymmetric cryptography is difficult to
justify on account of the computational and implementation complexities
associated with asymmetric cryptography. Symmetric schemes make use of a single
shared key known only between the two communicating hosts. This shared key is
used both for the encryption as well as the decryption of data. This key has to
be small in size besides being a subset of a potentially large keyspace making
it convenient for the communicating hosts while at the same time making
cryptanalysis difficult for the potential attackers. In the present work, an
abstract Rossler nonlinear dynamical machine has been described first. The
Rossler system exhibits chaotic dynamics for certain values of system
parameters and initial conditions. The chaotic dynamics of the Rossler system
with its apparently erratic and irregular characteristics and extreme
sensitivity to the initial conditions has been used for the design of the
cryptographic key in an attempt to increase the confusion and the challenge for
the potential attackers.",184,9,1230,31.21
1547,cryptography,"The paper aims to do a survey along with a comparative analysis of the
various cryptography libraries that are applicable in the field of Internet of
Things (IoT). The first half of the paper briefly introduces the various
cryptography libraries available in the field of cryptography along with a list
of all the algorithms contained within the libraries. The second half of the
paper deals with cryptography libraries specifically aimed for application in
the field of Internet of Things. The various libraries and their performance
analysis listed down in this paper are consolidated from various sources with
the aim of providing a single comprehensive repository for reference to the
various cryptography libraries and the comparative analysis of their features
in IoT.",121,5,774,32.26
1548,cryptography,"Post-quantum cryptography is inevitable. National Institute of Standards and
Technology (NIST) starts standardizing quantum-resistant public-key
cryptography (aka post-quantum cryptography). The reason is that investment in
quantum computing is blooming which poses significant threats to our currently
deployed cryptographic algorithms. As a security engineer, to prepare for the
apocalypse in advance, I've been watching the development of quantum computers
and post-quantum cryptography closely. Never mind, I simply made up an excuse
to study these fascinating scientific fields. However, they are extremely hard
to understand, at least to an amateur like me. This article shares with you my
notes with the hope that you will have an intuitive understanding of the
beautiful and mind-blowing quantum algorithms and post-quantum cryptography.
Update: Multivariate signature scheme Rainbow is broken by Ward Beullens.
Supersingular Isogeny Diffie-Hellman protocol (SIDH) is broken by Wouter
Castryck and Thomas Decru",140,9,1018,30.26
1549,cryptography,"Smaller, smarter and faster edge devices in the Internet of things era
demands secure data analysis and transmission under resource constraints of
hardware architecture. Lightweight cryptography on edge hardware is an emerging
topic that is essential to ensure data security in near-sensor computing
systems such as mobiles, drones, smart cameras, and wearables. In this article,
the current state of memristive cryptography is placed in the context of
lightweight hardware cryptography. The paper provides a brief overview of the
traditional hardware lightweight cryptography and cryptanalysis approaches. The
contrast for memristive cryptography with respect to traditional approaches is
evident through this article, and need to develop a more concrete approach to
developing memristive cryptanalysis to test memristive cryptographic approaches
is highlighted.",119,6,863,21.94
1550,cryptography,"Research has shown that cryptography concepts are hard to understand for
developers, and secure use of cryptography APIs is challenging for mainstream
developers. We have developed a fluent API named FluentCrypto to ease the
secure and correct adoption of cryptography in the Node.js JavaScript runtime
environment. It provides a task-based solution i.e., it hides the low-level
complexities that involve using the native Node.js cryptography API, and it
relies on the rules that crypto experts specify to determine a secure
configuration of the API. We conducted an initial study and found that
FluentCrypto is hard to misuse even for developers who lack cryptography
knowledge, and compared to the standard Node.js crypto API, it is easier to use
for developers and helps them to develop secure solutions in a shorter time.",129,10,825,46.67
1551,cryptography,"In recent years, the elliptic curve Qu-Vanstone (ECQV) implicit certificate
scheme has found application in security credential management systems (SCMS)
and secure vehicle-to-everything (V2X) communication to issue pseudonymous
certificates. However, the vulnerability of elliptic-curve cryptography (ECC)
to polynomial-time attacks posed by quantum computing raises concerns. In order
to enhance resistance against quantum computing threats, various post-quantum
cryptography methods have been adopted as standard (e.g. Dilithium) or
candidate standard methods (e.g. McEliece cryptography), but state of the art
has proven to be challenging to implement implicit certificates using
lattice-based cryptography methods. Therefore, this study proposes a
post-quantum cryptography McEliece-Chen (PQCMC) based on an efficient random
invertible matrix generation method to issue pseudonymous certificates with
less computation time. The study provides mathematical models to validate the
key expansion process for implicit certificates. Furthermore, comprehensive
security evaluations and discussions are conducted to demonstrate that distinct
implicit certificates can be linked to the same end entity. In experiments, a
comparison is conducted between the certificate length and computation time to
evaluate the performance of the proposed PQCMC. This study demonstrates the
viability of the implicit certificate scheme based on PQC as a means of
countering quantum computing threats.",194,13,1482,17.94
1552,cryptography,"The advent of quantum computing poses a profound threat to traditional
cryptographic systems, exposing vulnerabilities that compromise the security of
digital communication channels reliant on RSA, ECC, and similar classical
encryption methods. Quantum algorithms, notably Shor's algorithm, exploit the
inherent computational power of quantum computers to efficiently solve
mathematical problems underlying these cryptographic schemes. In response,
post-quantum cryptography (PQC) emerged as a critical field aimed at developing
resilient cryptographic algorithms impervious to quantum attacks. This paper
delineates the vulnerabilities of classical cryptographic systems to quantum
attacks, elucidates the principles of quantum computing, and introduces various
PQC algorithms such as lattice-based cryptography, code-based cryptography,
hash-based cryptography, and multivariate polynomial cryptography. Highlighting
the importance of PQC in securing digital communication amidst quantum
computing advancements, this research underscores its pivotal role in
safeguarding data integrity, confidentiality, and authenticity in the face of
emerging quantum threats.",142,6,1163,-16.58
1553,cryptography,"Lectures on classical and quantum cryptography. Contents: Private key
cryptosystems. Elements of number theory. Public key cryptography and RSA
cryptosystem. Shannon`s entropy and mutual information. Entropic uncertainty
relations. The no cloning theorem. The BB84 quantum cryptographic protocol.
Security proofs. Bell`s theorem. The EPRBE quantum cryptographic protocol.",46,12,371,15.54
1554,cryptography,"This note describes some cryptographic issues related to multi-located
parties. In general, multi-located parties make it difficult for the
eavesdropper to mount the man-in-the-middle attack. Conversely, they make it
easier to address problems such as joint encryption and error correction
coding. It is easier to implement the three-stage quantum cryptography
protocol.",51,5,370,33.1
1555,cryptography,"Visual Cryptography is a secret sharing scheme that uses the human visual
system to perform computations. This paper presents a recursive hiding scheme
for 3 out of 5 secret sharing. The idea used is to hide smaller secrets in the
shares of a larger secret without an expansion in the size of the latter.",54,4,304,61.67
1556,cryptography,"This article presets a review of lattice problems. Paper contains the main
eighteen problems with their reductions and referents to his cryptography
application. As an example of reduction, we detail analyze connection between
SVP and CVP. Moreover, we give an Ajtai theorem and demonstrate its role in
lattice based cryptography.",50,5,330,41.87
1557,cryptography,"This is a chapter on quantum cryptography for the book ""A Multidisciplinary
Introduction to Information Security"" to be published by CRC Press in
2011/2012. The chapter aims to introduce the topic to undergraduate-level and
continuing-education students specializing in information and communication
technology.",42,3,311,7.86
1558,cryptography,"This paper analyzes the performance of Kak's quantum cryptography protocol
when intensity monitoring is used to detect the presence of Eve during
transmission. Some difficulties related to interception to obtain useful data
from the transmission are discussed. The analysis shows the resilience of the
protocol towards the man-in-the-middle attack.",49,4,348,29.55
1559,cryptography,"We present a new quantum bit commitment (QBC) protocol based on
counterfactual quantum cryptography. We analyze the security of this protocol,
find that it can resist the attack presented by QBC's no-go theorem. Our
protocol is simple, and probably give a new way of constructing QBC protocol.",47,4,293,38.62
1560,cryptography,"In a series of recent papers, Hirota and Yuen claim to have identified a
fundamental flaw in the theory underlying quantum cryptography, which would
invalidate existing security proofs. In this short note, we sketch their
argument and show that their conclusion is unjustified --- it originates from a
confusion between necessary and sufficient criteria for secrecy.",56,3,366,18.18
1561,cryptography,"We discuss a class of cellular automata (CA) able to produce long random
strings, starting from short ""seed"" strings. The approach uses two principles
borrowed from cryptography: diffusion and confusion. We show numerically that
the strings are pseudo-random using three approaches based on: Fourier
transform, entropy estimation, and compression. An application to cryptography
is also included with the corresponding Python code.",61,5,431,39.03
1562,cryptography,"We give a decoding algorithm for a class of error-correcting codes, which can
be used in the DHH-cryptosystem, which is a candidate for post-quantum
cryptography, since it is of McEliece type. Furthermore, we implement the
encryption and decryption algorithms for this cryptosystem and investigate its
performance.",46,3,314,39.67
1563,cryptography,"We design a model of Post Quantum Cryptography (PQC) Quantum Federated
Learning (QFL). We develop a framework with a dynamic server selection and
study convergence and security conditions. The implementation and results are
publicly available1.",35,4,244,34.22
1564,cryptography,"We suggest the usage of algebraic subsets instead of subgroups in public-key
cryptography. In particular, we present the subset version of two protocols
introduced by Shpilrain and Ushakov with some examples in ascending
HNN-extensions of free-abelian groups and discuss their resistance to length
and distance based attacks. We also introduce several new group theoretic
problems arising from this work.",59,4,404,34.56
1565,cryptography,"For a recent student conference, the authors developed a day-long design
problem and competition suitable for engineering, mathematics and science
undergraduates. The competition included a cryptography problem, for which a
workshop was run during the conference. This paper describes the competition,
focusing on the cryptography problem and the workshop. Notes from the workshop
and code for the computer programs are made available via the Internet. The
results of a personal self-evaluation (PSE) are described.",74,6,515,31.07
1566,cryptography,"Quantum cryptography is a new method for secret communications offering the
ultimate security assurance of the inviolability of a Law of Nature. In this
paper we shall describe the theory of quantum cryptography, its potential
relevance and the development of a prototype system at Los Alamos, which
utilises the phenomenon of single-photon interference to perform quantum
cryptography over an optical fiber communications link.",63,3,428,5.66
1567,cryptography,"We discuss the unambiguous measurement of quantum nonorthogonal states in
connection with the quantum cryptography. We show that checking a ratio of null
one to signal is essential in detecting a certain kind of eavesdropping in the
case of two nonorthogonal states quantum cryptography. We prove that it is not
needed in the case of the four states quantum cryptography.",60,4,371,51.18
1568,cryptography,"Pseudo-Random Bit Generation (PRBG) is required in many aspects of
cryptography as well as in other applications of modern security engineering.
In this work, PRBG based on 2D symmetrical chaotic mappings of logistic type is
considered. The sequences generated with a chaotic PRBG of this type, are
statistically tested and the computational effectiveness of the generators is
estimated. Considering this PRBG valid for cryptography, the size of the
available key space is also calculated. Different cryptographic applications
can be suitable to this PRBG, being a stream cipher probably the most immediate
of them.",93,6,615,27.22
1569,cryptography,"The vast parallelism, exceptional energy efficiency and extraordinary
information inherent in DNA molecules are being explored for computing, data
storage and cryptography. DNA cryptography is a emerging field of cryptography.
In this paper a novel encryption algorithm is devised based on number
conversion, DNA digital coding, PCR amplification, which can effectively
prevent attack. Data treatment is used to transform the plain text into cipher
text which provides excellent security",69,4,487,20.08
1570,cryptography,"In the distrustful quantum cryptography model the different parties have
conflicting interests and do not trust one another. Nevertheless, they trust
the quantum devices in their labs. The aim of the device-independent approach
to cryptography is to do away with the necessity of making this assumption,
and, consequently, significantly increase security. In this paper we enquire
whether the scope of the device-independent approach can be extended to the
distrustful cryptography model, thereby rendering it `fully' distrustful. We
answer this question in the affirmative by presenting a device-independent
(imperfect) bit-commitment protocol, which we then use to construct a
device-independent coin flipping protocol.",101,6,721,17.13
1571,cryptography,"Cryptography is the study of techniques for ensuring the secrecy and
authentication of the information. Public-key encryption schemes are secure
only if the authenticity of the public-key is assured. Elliptic curve
arithmetic can be used to develop a variety of elliptic curve cryptography
(ECC) schemes including key exchange, encryption and digital signature. The
principal attraction of elliptic curve cryptography compared to RSA is that it
offers equal security for a smaller key-size, thereby reducing the processing
overhead. In the present paper we propose a new encryption algorithm using some
Elliptic Curve over finite fields",94,5,636,27.01
1572,cryptography,"We study position-based cryptography in the quantum setting. We examine a
class of protocols that only require the communication of a single qubit and 2n
bits of classical information. To this end, we define a new model of
communication complexity, the garden-hose model, which enables us to prove
upper bounds on the number of EPR pairs needed to attack such schemes. This
model furthermore opens up a way to link the security of position-based quantum
cryptography to traditional complexity theory.",80,5,500,34.26
1573,cryptography,"We believe that there is no real data protection without our own tools.
Therefore, our permanent aim is to have more of our own codes. In order to
achieve that, it is necessary that a lot of young researchers become interested
in cryptography. We believe that the encoding of cryptographic algorithms is an
important step in that direction, and it is the main reason why in this paper
we present a software implementation of finding the inverse element, the
operation which is essentially related to both ECC (Elliptic Curve
Cryptography) and the RSA schemes of digital signature.",97,5,580,46.81
1574,cryptography,"In this paper it has been developed an algorithm for cryptography, using the
Mellin's transform. Cryptography is very important to protect data to ensure
that two people, using an insecure channel, may communicate in a secure way. In
the present age, ensure the communications will essential to shared data that
have to be protected. The original message is a plain text, and the encrypted
form as cipher text. The cipher text message contains all the information of
the plain text, but is cannot be read from a human without a key and a method
to decrypt it.",97,6,559,60.24
1575,cryptography,"We present the Foundational Cryptography Framework (FCF) for developing and
checking complete proofs of security for cryptographic schemes within a proof
assistant. This is a general-purpose framework that is capable of modeling and
reasoning about a wide range of cryptographic schemes, security definitions,
and assumptions. Security is proven in the computational model, and the proof
provides concrete bounds as well as asymptotic conclusions. FCF provides a
language for probabilistic programs, a theory that is used to reason about
programs, and a library of tactics and definitions that are useful in proofs
about cryptography. The framework is designed to leverage fully the existing
theory and capabilities of the Coq proof assistant in order to reduce the
effort required to develop proofs.",120,6,800,30.2
1576,cryptography,"Bogopolski, Martino and Ventura in [BMV10] introduced a general criteria to
construct groups extensions with unsolvable conjugacy problem using short exact
sequences. We prove that such extensions have always solvable word problem.
This makes the proposed construction a systematic way to obtain finitely
presented groups with solvable word problem and unsolvable conjugacy problem.
It is believed that such groups are important in cryptography. For this, and as
an example, we provide an explicit construction of an extension of Thompson
group F and we propose it as a base for a public key cryptography protocol.",94,6,614,35.47
1577,cryptography,"This presentation focuses on differences between quantum computing and
quantum cryptography. Both are discussed related to classical computer systems
in terms of vulnerability. Research concerning quantum cryptography is analyzed
in terms of work done by the University of Cambridge in partnership with a
division of Toshiba, and also attacks demonstrated by Swedish researchers
against QKD of energy-time entangled systems. Quantum computing is covered in
terms of classical cryptography related to weaknesses presented by Shor's
algorithm. Previous classical vulnerabilities also discussed were conducted by
Israeli researchers as a side-channel attack using parabolic curve microphones,
which has since been patched.",98,6,719,17.74
1578,cryptography,"The mathematical problems and their solutions of the Third International
Students' Olympiad in Cryptography NSUCRYPTO'2016 are presented. We consider
mathematical problems related to the construction of algebraic immune vectorial
Boolean functions and big Fermat numbers, problems about secrete sharing
schemes and pseudorandom binary sequences, biometric cryptosystems and the
blockchain technology, etc. Two open problems in mathematical cryptography are
also discussed and a solution for one of them proposed by a participant during
the Olympiad is described. It was the first time in the Olympiad history.",85,5,609,24.48
1579,cryptography,"Type-two constructions abound in cryptography: adversaries for encryption and
authentication schemes, if active, are modeled as algorithms having access to
oracles, i.e. as second-order algorithms. But how about making cryptographic
schemes themselves higher-order? This paper gives an answer to this question,
by first describing why higher-order cryptography is interesting as an object
of study, then showing how the concept of probabilistic polynomial time
algorithm can be generalized so as to encompass algorithms of order strictly
higher than two, and finally proving some positive and negative results about
the existence of higher-order cryptographic primitives, namely authentication
schemes and pseudorandom functions.",99,5,729,20.92
1580,cryptography,"This paper studies the problem of Zero-Knowledge Protocol (ZKP) and elliptic
curve cryptographic implementation in a computationally limited environment,
such as, the smart cards, using Java Card. Besides that, it is explained how
the zero-knowledge protocol was selected to implement it on a smart card and
how the benchmarking was conducted to select this protocol. The paper also
shows a theoretical development to implement the ZKP protocol using elliptic
curve cryptography. Keywords: Authentication; Zero-knowledge; Cryptography;
Elliptic Curve; Java card; Smart cards",81,4,574,17.03
1581,cryptography,"Multiplication is one of the most important operation in Elliptic Curve
Cryptography (ECC) arithmetic. For point addition and point doubling in ECC
scalar (integer) multiplication is required. In higher order classical
(standard) multiplication many intermediate operations are required. Reduced
operation in multiplication will increase the functional speed of ECC
arithmetic. These goals can be achieved using ancient multiplication algorithm
namely Nikhilam Sutra. Nikhilam Sutra is one of the Sutra (algorithm) within 16
Vedic mathematics Sutras (algorithms). Nikhilam Sutra is efficient for
multiplying two large decimal numbers. The Sutra reduces multiplication of two
large numbers into two smaller numbers multiplication. The functional speed of
Elliptic Curve Cryptography can be increased using Nikhilam method for scalar
multiplication.",115,10,847,24.64
1582,cryptography,"Cryptography is known as a challenging topic for developers. We studied
StackOverflow posts to identify the problems that developers encounter when
using Java Cryptography Architecture (JCA) for symmetric encryption. We
investigated security risks that are disseminated in these posts, and we
examined whether ChatGPT helps avoid cryptography issues. We found that
developers frequently struggle with key and IV generations, as well as padding.
Security is a top concern among developers, but security issues are pervasive
in code snippets. ChatGPT can effectively aid developers when they engage with
it properly. Nevertheless, it does not substitute human expertise, and
developers should remain alert.",101,8,704,23.02
1583,cryptography,"Artin's braid groups have been recently suggested as a new source for
public-key cryptography. In this paper we propose the first undeniable
signature schemes using the conjugacy problem and the decomposition problem in
the braid groups which are believed to be hard problems.",43,3,276,41.19
1584,cryptography,"This note presents variations on the Fibonacci universal code, that may also
be called the Gopala-Hemachandra code, that can have applications in source
coding as well as in cryptography.",29,2,187,42.04
1585,cryptography,"This paper introduces a variation on Kak's three-stage quanutm key
distribution protocol which allows for defence against the man in the middle
attack. In addition, we introduce a new protocol, which also offers similar
resiliance against such an attack.",39,3,254,43.22
1586,cryptography,"We present a new approach to simulate quantum cryptography protocols using
event-based processes. The method is validated by simulating the BB84 protocol
and the Ekert protocol, both without and with the presence of an eavesdropper.",35,3,232,36.79
1587,cryptography,"This paper examines the randomness of d-sequences, which are decimal
sequences to an arbitrary base. Our motivation is to check their suitability
for application to cryptography, spread-spectrum systems and use as
pseudorandom sequence.",33,3,236,29.35
1588,cryptography,"An algorithm is presented that in context of public key use of Elliptic Curve
Cryptography allows discovery of the private key in worst case O(n).",25,2,146,46.1
1589,cryptography,"Commutative encryption is a useful but rather strict notion in cryptography.
In this paper, we deny a loose variation of commutative
encryption-commutative-like encryption and give an example: the generalization
of ElGamal scheme. The application of the new variation is also discussed.",41,4,286,23.73
1590,cryptography,"We employ tropical algebras as platforms for several cryptographic schemes
that would be vulnerable to linear algebra attacks were they based on ""usual""
algebras as platforms.",26,2,175,28.17
1591,cryptography,"Cryptography and simulation of systems require that events of pre-defined
probability be generated. This paper presents methods to generate target
probability events based on the oblivious transfer protocol and target
probabilistic sequences using probability distribution functions.",36,3,283,-6.02
1592,cryptography,"Cryptography is a theory of secret functions. Category theory is a general
theory of functions. Cryptography has reached a stage where its structures
often take several pages to define, and its formulas sometimes run from page to
page. Category theory has some complicated definitions as well, but one of its
specialties is taming the flood of structure. Cryptography seems to be in need
of high level methods, whereas category theory always needs concrete
applications. So why is there no categorical cryptography? One reason may be
that the foundations of modern cryptography are built from probabilistic
polynomial-time Turing machines, and category theory does not have a good
handle on such things. On the other hand, such foundational problems might be
the very reason why cryptographic constructions often resemble low level
machine programming. I present some preliminary explorations towards
categorical cryptography. It turns out that some of the main security concepts
are easily characterized through the categorical technique of *diagram
chasing*, which was first used Lambek's seminal `Lecture Notes on Rings and
Modules'.",171,10,1136,37.2
1593,cryptography,"This paper proposes a PKINIT_AS Kerberos V5 authentication system to use
public key cryptography and a method to implement the gssapi_krb authentication
method and secured Internet service using it in IPSec VPN",32,1,210,22.08
1594,cryptography,"In this paper we generalize the definition of a multilinear map to arbitrary
groups and develop a novel idea of multilinear cryptosystem using nilpotent
group identities.",26,2,170,19.71
1595,cryptography,"Motivated by questions in cryptography, we look for diophantine equations
that are hard to solve but for which determining the number of solutions is
easy.",25,2,155,46.1
1596,cryptography,"Stream ciphers play important role in cryptography. In this paper we do a
survey on stream ciphers.Various possible attacks are analyzed.",21,4,137,47.45
1597,cryptography,"SIS problem has numerous applications in cryptography. Known algorithms for
solving that problem are exponential in complexity. A new algorithm is
suggested in this note, its complexity is sub-exponential for a range of
parameters.",34,4,231,34.63
1598,cryptography,"We examine two public key exchange protocols proposed recently by Grigoriev
and Shpilrain (arXiv:1811.06386), which use tropical algebra. We introduce a
fast attack on the first protocol, and we show that the second protocol cannot
be implemented as described.",39,4,260,41.36
1599,cryptography,"We report our experience of an extracurricular online intervention on
cryptography principles in 10th grade. This paper's first goal is to present
the learning path we designed, influenced by cryptography core ideas rather
than technical knowledge. We will detail how we used Snap! (a visual
programming language) to realize hands-on activities: programming playgrounds
to experiment with cryptosystems and their limits, and interactive support for
an unplugged activity on the Diffie-Hellman key exchange. The second goal is to
evaluate our intervention in terms of both student perceptions and learning of
core cryptography ideas. The students appreciated the course and felt that,
despite being remote, it was fun, interesting, and engaging. They said the
course helped them understand the role of cryptography, CS, and Math in society
and sparked their interest, especially in cryptography and CS. The third goal
is to discuss what worked well and areas of improvement. Pedagogically, remote
teaching caused high ""instructor blindness"" and prevented us from giving the
optimal amount of guidance during the exploration activities with Snap!
playgrounds, making them sometimes too challenging for total programming
novices. On the other hand, the ""remote-unplugged"" Diffie-Hellman worked well:
it embodies a coherent metaphor that engaged the students and made them grasp
this groundbreaking protocol. The students praised the activities as engaging,
even when challenging. The final assessment showed that the core cryptography
ideas were well understood.",227,12,1559,45.25
1600,cryptography,"Modern information communications use cryptography to keep the contents of
communications confidential. RSA (Rivest-Shamir-Adleman) cryptography and
elliptic curve cryptography, which are public-key cryptosystems, are widely
used cryptographic schemes. However, it is known that these cryptographic
schemes can be deciphered in a very short time by Shor's algorithm when a
quantum computer is put into practical use. Therefore, several methods have
been proposed for quantum computer-resistant cryptosystems that cannot be
cracked even by a quantum computer. A simple implementation of LWE-based
lattice cryptography based on the LWE (Learning With Errors) problem requires a
key length of $O(n^2)$ to ensure the same level of security as existing
public-key cryptography schemes such as RSA and elliptic curve cryptography. In
this paper, we attacked the Ring-LWE (RLWE) scheme, which can be implemented
with a short key length, with a modified LLL (Lenstra-Lenstra-Lov\'asz) basis
reduction algorithm and investigated the trend in the degree of field extension
required to generate a secure and small key. Results showed that the
lattice-based cryptography may be strengthened by employing Cullen or Mersenne
prime numbers as the degree of field extension.",181,8,1258,28.27
1601,cryptography,"We use tropical algebras as platforms for a very efficient digital signature
protocol. Security relies on computational hardness of factoring one-variable
tropical polynomials; this problem is known to be NP-hard.",30,3,213,22.41
1602,cryptography,"Regarding minimal assumptions, most of classical cryptography is known to
depend on the existence of One-Way Functions (OWFs). However, recent evidence
has shown that this is not the case when considering quantum resources. Besides
the well known unconditional security of Quantum Key Distribution, it is now
known that computational cryptography may be built on weaker primitives than
OWFs, e.g., pseudo-random states [JLS18], one-way state generators [MY23], or
EFI pairs of states [BCQ23]. We consider a new quantum resource,
pseudo-entanglement, and show that the existence of EFI pairs, one of the
current main candidates for the weakest computational assumption for
cryptography (necessary for commitments, oblivious transfer, secure multi-party
computation, computational zero-knowledge proofs), implies the existence of
pseudo-entanglement, as defined by [ABF+24, ABV23] under some reasonable
adaptations. We prove this by constructing a new family of pseudo-entangled
quantum states given only EFI pairs. Our result has important implications for
the field of computational cryptography. It shows that if pseudo-entanglement
does not exist, then most of cryptography cannot exist either. Moreover, it
establishes pseudo-entanglement as a new minimal assumption for most of
computational cryptography, which may pave the way for the unification of other
assumptions into a single primitive. Finally, pseudo-entanglement connects
physical phenomena and efficient computation, thus, our result strengthens the
connection between cryptography and the physical world.",216,12,1571,24.17
1603,cryptography,"In contemporary cryptographic systems, secret keys are usually exchanged by
means of methods, which suffer from mathematical and technology inherent
drawbacks. That could lead to unnoticed complete compromise of cryptographic
systems, without a chance of control by its legitimate owners. Therefore a need
for innovative solutions exists when truly and reliably secure transmission of
secrets is required for dealing with critical data and applications. Quantum
Cryptography (QC), in particular Quantum Key Distribution (QKD) can answer that
need.
  The business white paper (BWP) summarizes how secret key establishment and
distribution problems can be solved by quantum cryptography. It deals with
several considerations related to how the quantum cryptography innovation could
contribute to provide business effectiveness. It addresses advantages and also
limitations of quantum cryptography, proposes a scenario case study, and
invokes standardization related issues. In addition, it answers most frequently
asked questions about quantum cryptography.",144,9,1055,19.37
1604,cryptography,"Since security is one of the most important issues, the evolve of
cryptography and cryptographic analysis are considered as the fields of
on-going research. The latest development on this field is DNA cryptography. It
has emerged after the disclosure of computational ability of Deoxyribo Nucleic
Acid (DNA). DNA cryptography uses DNA as the computational tool along with
several molecular techniques to manipulate it. Due to very high storage
capacity of DNA, this field is becoming very promising. Currently it is in the
development phase and it requires a lot of work and research to reach a mature
stage. By reviewing all the potential and cutting edge technology of current
research, this paper shows the directions that need to be addressed further in
the field of DNA cryptography.",127,8,788,44.64
1605,cryptography,"An information is a message which is received and understood. Information can
be sent one person to another over a long range but the process of sending
information must be done in a secure way especially in case of a private
message. Mathematicians and Engineers have historically relied on different
algorithmic techniques to secure messages and signals. Cryptography, to most
people, is concerned with keeping communications private. Indeed, the
protection of sensitive communications has been the emphasis of cryptography
throughout much of its history. Sometimes it is safer to send a message using
an image and thus cryptography can also be done using images during an
emergency. The need to extract information from images and interpret their
contents has been one of the driving factors in the development of image
processing and cryptography during the past decades. In this paper, a simple
cryptographic method was used to decode a message which was in an image and it
was done using a popular computational software.",164,9,1027,42.21
1606,cryptography,"The secure instantiation of the random oracle is one of the major open
problems in modern cryptography. We investigate this problem using concepts and
methods of algorithmic randomness. In modern cryptography, the random oracle
model is widely used as an imaginary framework in which the security of a
cryptographic scheme is discussed. In the random oracle model, the
cryptographic hash function used in a cryptographic scheme is formulated as a
random variable uniformly distributed over all possibility of the function,
called the random oracle. The main result of this paper is to show that, for
any secure signature scheme in the random oracle model, there exists a specific
computable function which can instantiate the random oracle while keeping the
security originally proved in the random oracle model. In modern cryptography
the generic group model is used also for a similar purpose to the random oracle
model. We show that the same results hold for the generic group model. In the
process of proving the results, we introduce the notion of effective security,
demonstrating the importance of this notion in modern cryptography.",181,9,1140,31.62
1607,cryptography,"Cryptography is the science that secures data and communication over the
network by applying mathematics and logic to design strong encryption methods.
In the modern era of e-business and e-commerce the protection of
confidentiality, integrity and availability (CIA triad) of stored information
as well as of transmitted data is very crucial. Deoxyribonucleic acid (DNA) is
a genetic molecule consisting of two linked strands that wind around each other
to form a double helical structure. The backbone of each strand is made of
alternating deoxyribose sugar and phosphate groups. To each sugar one of four
bases are attached i.e., adenine (A), cytosine (C), guanine (G) and thymine
(T). DNA molecules, having the capacity to store, process and transmit
information, inspires the idea of DNA cryptography. It is the rapid emerging
unconventional techniques which combines the chemical characteristics of
biological DNA sequences with classical cryptography to ensure non-vulnerable
transmission of data. This innovative method is based on the notion of DNA
computing. The methodologies of DNA cryptography are not coded mathematically;
thus, it could be too secure to be cracked easily.",179,12,1186,36.39
1608,cryptography,"These lectures notes were written for a summer school on Mathematics for
post-quantum cryptography in Thi\`es, Senegal. They try to provide a guide for
Masters' students to get through the vast literature on elliptic curves,
without getting lost on their way to learning isogeny based cryptography. They
are by no means a reference text on the theory of elliptic curves, nor on
cryptography; students are encouraged to complement these notes with some of
the books recommended in the bibliography.
  The presentation is divided in three parts, roughly corresponding to the
three lectures given. In an effort to keep the reader interested, each part
alternates between the fundamental theory of elliptic curves, and applications
in cryptography. We often prefer to have the main ideas flow smoothly, rather
than having a rigorous presentation as one would have in a more classical book.
The reader will excuse us for the inaccuracies and the omissions.",151,8,951,49.55
1609,cryptography,"The current implementation of TLS involves your browser displaying a padlock,
and a green bar, after successfully verifying the digital signature on the TLS
certificate. Proposed is a solution where your browser's response to successful
verification of a TLS certificate is to display a login window. That login
window displays the identity credentials from the TLS certificate, to allow the
user to authenticate Bob. It also displays a 'user-browser' shared secret i.e.
a specific picture from your hard disk. This is not SiteKey, the image is
shared between the computer user and their browser. It is never transmitted
over the internet. Since sandboxed websites cannot access your hard disk this
image cannot be counterfeited by phishing websites. Basically if you view the
installed software component of your browser as an actor in the cryptography
protocol, then the solution to phishing attacks is classic cryptography, as
documented in any cryptography textbook.",150,11,970,46.06
1610,cryptography,"Ring signature is a kind of group-oriented signature. It allows a member of a
group to sign messages on behalf of the group without revealing his/her
identity. Certificateless public key cryptography was first introduced by
Al-Riyami and Paterson in Asiacrypt 2003. In certificateless cryptography, it
does not require the use of certificates to guarantee the authenticity of
users' public keys. Meanwhile, certificateless cryptography does not have the
key escrow problem, which seems to be inherent in the Identity-based
cryptography. In this paper, we propose a concrete certificateless ring
signature scheme. The security models of certificateless ring signature are
also formalized. Our new scheme is provably secure in the random oracle model,
with the assumption that the Computational Diffie-Hellman problem is hard. In
addition, we also show that a generic construction of certificateless ring
signature is insecure against the key replacement attack defined in our
security models.",146,10,991,38.11
1611,cryptography,"Securing information transmission is critical today. However, with rapidly
developing powerful quantum technologies, conventional cryptography techniques
are becoming more prone to attacks each day. New techniques in the realm of
quantum cryptography to preserve security against powerful attacks are slowly
emerging. What is important though now is the fidelity of the cryptography,
because security with massive processing power is not worth much if it is not
correct. Focusing on this issue, we propose a method to enhance the fidelity of
quantum cryptography using maximally entangled qubit pairs. For doing so, we
created a graph state along a path consisting of all the qubits of ibmqx4 and
ibmq_16_melbourne respectively and we measure the strength of the entanglement
using negativity measurement of the qubit pairs. Then, using the qubits with
maximal entanglement, we send the modified encryption key to the receiver. The
key is modified by permutation and superdense coding before transmission. The
receiver reverts the process and gets the actual key. We carried out the
complete experiment in the IBM Quantum Experience project. Our result shows a
15% to 20% higher fidelity of encryption and decryption than a random selection
of qubits.",191,12,1251,36.89
1612,cryptography,"Due to successful applications of data analysis technologies in many fields,
various institutions have accumulated a large amount of data to improve their
services. As the speed of data collection has increased dramatically over the
last few years, an increasing number of users are growing concerned about their
personal information. Therefore, privacy preservation has become an urgent
problem to be solved. Differential privacy as a strong privacy preservation
tool has attracted significant attention. In this survey, we focus on improving
utility of between differentially private mechanisms through technologies
related to cryptography. In particular, we firstly focus on how to improve
utility through anonymous communication. Then, we summarize how to improve
utility by combining differentially private mechanisms with homomorphic
encryption schemes. Next, we summarize hardness results of what is impossible
to achieve for differentially private mechanisms' utility from the view of
cryptography. Differential privacy borrowed intuitions from cryptography and
still benefits from the progress of cryptography. To summarize the
state-of-the-art and to benefit future researches, we are motivated to provide
this survey.",171,11,1228,20.28
1613,cryptography,"Prior research has shown that cryptography is hard to use for developers. We
aim to understand what cryptography issues developers face in practice. We
clustered 91954 cryptography-related questions on the Stack Overflow website,
and manually analyzed a significant sample (i.e., 383) of the questions to
comprehend the crypto challenges developers commonly face in this domain. We
found that either developers have a distinct lack of knowledge in understanding
the fundamental concepts, \eg OpenSSL, public-key cryptography or password
hashing, or the usability of crypto libraries undermined developer performance
to correctly realize a crypto scenario. This is alarming and indicates the need
for dedicated research to improve the design of crypto APIs.",110,8,756,27.52
1614,cryptography,"Previous studies have shown that developers regularly seek advice on online
forums to resolve their cryptography issues. We investigated whether users who
are active in cryptography discussions also use cryptography in practice. We
collected the top 1% of responders who have participated in crypto discussions
on Stack Overflow, and we manually analyzed their crypto contributions to open
source projects on GitHub. We could identify 319 GitHub profiles that belonged
to such crypto responders and found that 189 of them used cryptography in their
projects. Further investigation revealed that the majority of analyzed users
(i.e., 85%) use the same programming languages for crypto activity on Stack
Overflow and crypto contributions on GitHub. Moreover, 90% of the analyzed
users employed the same concept of cryptography in their projects as they
advised about on Stack Overflow.",133,9,883,43.73
1615,cryptography,"Traditional and lightweight cryptography primitives and protocols are
insecure against quantum attacks. Thus, a real-time application using
traditional or lightweight cryptography primitives and protocols does not
ensure full-proof security. Post-quantum Cryptography is important for the
Internet of Things (IoT) due to its security against Quantum attacks. This
paper offers a broad literature analysis of post-quantum cryptography for IoT
networks, including the challenges and research directions to adopt in
real-time applications. The work draws focus towards post-quantum cryptosystems
that are useful for resource-constraint devices. Further, those quantum attacks
are surveyed, which may occur over traditional and lightweight cryptographic
primitives.",98,7,761,21.09
1616,cryptography,"We know the classical public cryptographic algorithms are based on certain
NP-hard problems such as the integer factoring in RSA and the discrete
logarithm in Diffie-Hellman. They are going to be vulnerable with
fault-tolerant quantum computers. We also know that the uncertainty principle
for quantum bits or qubits such as quantum key distribution or QKD based on the
quantum uncertainty principle offers the information theoretical security. The
interesting implication with the paradigm shifts from classical computing to
quantum computing is that the NP-hardness used for classical cryptography may
shift to the uncertainty principles for quantum cryptography including quantum
symmetric encryption, post-quantum cryptography, as well as quantum encryption
in phase space for coherent optical communications. This paper would like to
explore those so-called generalized uncertainty principles and explain what
their implications are for quantum security. We identified three generalized
uncertainty principles offering quantum security: non-commutability between
permutation gates, non-commutability between the displacement and phase shift
operators for coherent states, and the modular Diophantine Equation Problem in
general linear algebra for post-quantum cryptography.",171,7,1278,8.71
1617,cryptography,"How could quantum cryptography help us achieve what are not achievable in
classical cryptography? In this work we consider the following problem, which
we call succinct RSPV for classical functions (SRC). Suppose $f$ is a function
described by a polynomial time classical Turing machine, which is public; the
client would like to sample a random $x$ as the function input and use a
protocol to send $f(x)$ to the server. What's more, (1) when the server is
malicious, what it knows in the passing space should be no more than $f(x)$;
(2) the communication should be succinct (that is, independent to the running
time of evaluating $f$). Solving this problem in classical cryptography seems
to require strong cryptographic assumptions.
  We show that, perhaps surprisingly, it's possible to solve this problem with
quantum techniques under much weaker assumptions. By allowing for quantum
communication and computations, we give a protocol for this problem assuming
only collapsing hash functions [Unr16]. Our work conveys an interesting message
that quantum cryptography could outperform classical cryptography in a new type
of problems, that is, to reduce communications in meaningful primitives without
using heavy classical cryptographic assumptions.",190,8,1253,38.86
1618,cryptography,"Ever since the link between nonlinear science and cryptography became
apparent, the problem of applying chaotic dynamics to the construction of
cryptographic systems has gained a broad audience and has been the subject of
thousands of papers. Yet, the field has not found its place in mainstream
cryptography, largely due to persistent weaknesses in the presented systems.
The goal of this paper is to help remedy this problem in two ways. The first is
by providing a new algorithm that can be used to attack -- and hence test the
security of -- stream ciphers based on the iteration of a chaotic map of the
interval. The second is to cast discrete dynamical systems problems in a modern
cryptographic and complexity theoretic language, so that researchers working in
chaos-based cryptography can begin designing cryptographic protocols that have
a better chance of meeting the extreme standards of modern cryptography.",148,6,919,33.38
1619,cryptography,"Traditionally, ""Cryptography"" is a benediction to information processing and
communications, it helps people to store information securely and the private
communications over long distances. Cryptovirology is the study of applications
of cryptography to build the malicious software. It is an investigation, how
modern cryptographic tools and paradigms can be used to strengthen, develop and
improve new malicious software attacks. Cryptovirology attacks have been
categorized as : give malware enhanced privacy and be more robust against
reverse-engineering, secondly give the attacker enhanced anonymity while
communicating with deployed malware. This paper presents the idea of
""Cryptovirology"" which introduce a twist on how cryptography can also be used
offensively. Being offensive means, it can be used to mount extortion based
attacks that cause loss of access to information, loss of confidentiality, and
information leakage, tasks which cryptography usually prevents. Also analyze
threats and attacks that misuse of cryptography can cause when combined with
fraudulent software (viruses, Trojans). Public-key cryptography is very
essential for the attacks that based on cryptovirology. This paper also suggest
some of the countermeasures, mechanisms to cope with and prevent such attacks.
Even if the attackers actions on the host machine are being monitored, it still
cannot be proven beyond reasonable doubt that he or she is the attacker; and it
is an ""originator-concealing attack"". Evidence should be collected from the
""author's own system which was used for the attack"". These attacks have
implications on how the use of cryptographic tools and techniques should be
audited and managed in general purpose computing environments, and imply that
access to the cryptographic tools should be in well control of the system(such
as API routines).",272,13,1857,31.62
1620,cryptography,"Quantum cryptography uses techniques and ideas from physics and computer
science. The combination of these ideas makes the security proofs of quantum
cryptography a complicated task. To prove that a quantum-cryptography protocol
is secure, assumptions are made about the protocol and its devices. If these
assumptions are not justified in an implementation then an eavesdropper may
break the security of the protocol. Therefore, security is crucially dependent
on which assumptions are made and how justified the assumptions are in an
implementation of the protocol.
  This thesis is primarily a review that analyzes and clarifies the connection
between the security proofs of quantum-cryptography protocols and their
experimental implementations. In particular, we focus on quantum key
distribution: the task of distributing a secret random key between two parties.
We provide a comprehensive introduction to several concepts: quantum mechanics
using the density operator formalism, quantum cryptography, and quantum key
distribution. We define security for quantum key distribution and outline
several mathematical techniques that can either be used to prove security or
simplify security proofs. In addition, we analyze the assumptions made in
quantum cryptography and how they may or may not be justified in
implementations.
  Along with the review, we propose a framework that decomposes
quantum-key-distribution protocols and their assumptions into several classes.
Protocol classes can be used to clarify which proof techniques apply to which
kinds of protocols. Assumption classes can be used to specify which assumptions
are justified in implementations and which could be exploited by an
eavesdropper. Two contributions of the author are discussed: the security
proofs of two two-way quantum-key-distribution protocols and an intuitive proof
of the data-processing inequality.",270,15,1886,26.51
1621,cryptography,"The recent application of the principles of quantum mechanics to cryptography
has led to a remarkable new dimension in secret communication. As a result of
these new developments, it is now possible to construct cryptographic
communication systems which detect unauthorized eavesdropping should it occur,
and which give a guarantee of no eavesdropping should it not occur.
  CONTENTS P3. Cryptographic systems before quantum cryptography P7. Preamble
to quantum cryptography P10. The BB84 quantum cryptographic protocol without
noise P16. The BB84 quantum cryptographic protocol with noise P19..The B92
quantum cryptographic protocol P21. EPR quantum cryptographic protocols P25.
Other protocols P25. Eavesdropping stategies and counter measures P26.
Conclusion P29. Appendix A. The no cloning theorem P30. Appendix B. Proof that
an undetectable eavesdropper can obtain no information from the B92 protocol
P31. Appendix C. Part of a Rosetta stone for quantum mechanics P44. References",141,20,985,35.13
1622,cryptography,"We assess the potential of quantum cryptography as a technology. We highlight
the fact that academia and real world have rather different perspectives and
interests. Then, we describe the various real life forces (different types of
users, vendors of crypto-systems, conventional cryptographers, governments)
behind the decision of the adoption (or rejection) of quantum cryptography and
their different interests. Various roadblocks to the widespread application of
quantum cryptography are discussed. Those roadblocks can be fundamental,
technological, psychological, commercial or political and many of them have
nothing to do with the security of quantum key distribution. We argue that the
future success of quantum cryptography as a technology in the marketplace lies
in our ability to appreciate and to overcome those roadblocks and to answer
real world criticisms on the subject.",129,7,887,24.27
1623,cryptography,"A significant branch of classical cryptography deals with the problems which
arise when mistrustful parties need to generate, process or exchange
information. As Kilian showed a while ago, mistrustful classical cryptography
can be founded on a single protocol, oblivious transfer, from which general
secure multi-party computations can be built.
  The scope of mistrustful quantum cryptography is limited by no-go theorems,
which rule out, inter alia, unconditionally secure quantum protocols for
oblivious transfer or general secure two-party computations. These theorems
apply even to protocols which take relativistic signalling constraints into
account. The best that can be hoped for, in general, are quantum protocols
computationally secure against quantum attack. I describe here a method for
building a classically certified bit commitment, and hence every other
mistrustful cryptographic task, from a secure coin tossing protocol. No
security proof is attempted, but I sketch reasons why these protocols might
resist quantum computational attack.",149,8,1055,24.48
1624,cryptography,"Quantum Cryptography is on the verge of commercial application. One of its
greatest limitations is over long distance - secret key rates are low and the
longest fibre over which any key has been exchanged is currently 100 km. We
investigate the quantum relay, which can increase the maximum distance at which
quantum cryptography is possible. The relay splits the channel into sections,
and sends a different photon across each section, increasing the signal to
noise ratio. The photons are linked as in teleportation, with entangled photon
pairs and Bell measurements. We show that such a scheme could allow
cryptography over hundreds of kilometers with today's detectors. It could not,
however, improve the rate of key exchange over distances where the standard
single section scheme already works. We also show that reverse key
reconciliation, previously used in continuous variable quantum cryptography,
gives a secure key over longer distances than forward key reconciliation.",152,9,981,43.83
1625,cryptography,"In this paper, we investigate the best pixel expansion of the various models
of visual cryptography schemes. In this regard, we consider visual cryptography
schemes introduced by Tzeng and Hu [13]. In such a model, only minimal
qualified sets can recover the secret image and that the recovered secret image
can be darker or lighter than the background. Blundo et al. [4] introduced a
lower bound for the best pixel expansion of this scheme in terms of minimal
qualified sets. We present another lower bound for the best pixel expansion of
the scheme. As a corollary, we introduce a lower bound, based on an induced
matching of hypergraph of qualified sets, for the best pixel expansion of the
aforementioned model and the traditional model of visual cryptography realized
by basis matrices. Finally, we study access structures based on graphs and we
present an upper bound for the smallest pixel expansion in terms of strong
chromatic index.",156,9,942,51.68
1626,cryptography,"Chaotic cryptography is based on the properties of chaos as source of
entropy. Many different schemes have been proposed to take advantage of those
properties and to design new strategies to encrypt information. However, the
right and efficient use of chaos in the context of cryptography requires a
thorough knowledge about the dynamics of the selected chaotic system. Indeed,
if the final encryption system reveals enough information about the underlying
chaotic system it could be possible for a cryptanalyst to get the key, part of
the key or some information somehow equivalent to the key just analyzing those
dynamical properties leaked by the cryptosystem. This paper shows what those
dynamical properties are and how a cryptanalyst can use them to prove the
inadequacy of an encryption system for the secure exchange of information. This
study is performed through the introduction of a series of mathematical tools
which should be the basic framework of cryptanalysis in the context of digital
chaos-based cryptography.",161,7,1028,35.81
1627,cryptography,"Current security model in Global System for Mobile Communications (GSM)
predominantly use symmetric key cryptography. The rapid advancement of Internet
technology facilitates online trading, banking, downloading, emailing using
resource-constrained handheld devices such as personal digital assistants and
cell phones. However, these applications require more security than the present
GSM supports. Consequently, a careful design of GSM security using both
symmetric and asymmetric key cryptography would make GSM security more
adaptable in security intensive applications. This paper presents a secure and
efficient protocol for GSM security using identity based cryptography. The
salient features of the proposed protocol are (i) authenticated key exchange;
(ii) mutual authentication amongst communicating entities; and (iii) user
anonymity. The security analysis of the protocol shows its strength against
some known threats observed in conventional GSM security.",129,8,968,10.5
1628,cryptography,"Biometrics deal with automated methods of identifying a person or verifying
the identity of a person based on physiological or behavioral characteristics.
Visual cryptography is a secret sharing scheme where a secret image is
encrypted into the shares which independently disclose no information about the
original secret image. As biometric template are stored in the centralized
database, due to security threats biometric template may be modified by
attacker. If biometric template is altered authorized user will not be allowed
to access the resource. To deal this issue visual cryptography schemes can be
applied to secure the iris template. Visual cryptography provides great means
for helping such security needs as well as extra layer of authentication.",115,7,761,26.61
1629,cryptography,"We give new arguments in support of \emph{signed quantum key establishment},
where quantum cryptography is used in a public-key infrastructure that provides
the required authentication. We also analyze more thoroughly than previous
works the benefits that quantum key establishment protocols have over certain
classical protocols, motivated in part by the various objections to quantum key
establishment that are sometimes raised. Previous knowledge of quantum
cryptography on the reader's part is not required for this article, as the
definition of ""quantum key establishment"" that we use is an entirely classical
and black-box characterization (one need only trust that protocols satisfying
the definition exist).",102,4,715,11.59
1630,cryptography,"Chaotic cryptography describes the use of chaos theory (in particular
physical dynamical systems working in chaotic regime as part of communication
techniques and computation algorithms) to perform different cryptographic tasks
in a cryptographic system. In the end, the question is, can chaotic systems
provide alternative techniques able to enhance cryptographic algorithms?. This
chapter can be a worthy material to guide the reader in order to answer himself
this question. Thus, the objective of this chapter is to give a general vision
of what chaotic cryptography is and a comprehensive example that illustrates
the main techniques used in this field.",99,5,658,29.38
1631,cryptography,"The paper presents the implementation of a quantum cryptography protocol for
secure communication between servers in the cloud. As computing power
increases, classical cryptography and key management schemes based on
computational complexity become increasingly susceptible to brute force and
cryptanalytic attacks. Current implementations of quantum cryptography are
based on the BB84 protocol, which is susceptible to siphoning attacks on the
multiple photons emitted by practical laser sources. The three-stage protocol,
whose implementation is described in this paper, is a departure from
conventional practice and it obviates some of the known vulnerabilities of the
current implementations of quantum cryptography. This paper presents an
implementation of the three-stage quantum communication protocol in free-space.
To the best of the authors' knowledge, this is the first implementation of a
quantum protocol where multiple photons can be used for secure communication.",136,7,978,14.59
1632,cryptography,"Most current research on quantum cryptography requires transmission and
reception of single photons that creates severe implementation challenges and
limits range. This paper argues for the development of threshold quantum
cryptography protocols in which the system is secure so long as the number of
photons being exchanged between Alice and Bob is below a specified threshold.
We speak of a (p-k-n) threshold system where if the number of photons exchanged
is less than p, the system is completely secure, when it is between p and k,
the system is partially secure, and when it exceeds k, the system is insecure.
The BB84 protocol is (1-1-1) whereas the three-stage protocol appears to be
(p-4p-n), where p is the least number of photons necessary to determine the
polarization state of identically prepared photons. New quantum cryptography
systems should be sought that provide greater flexibility in the choice of p
and k.",149,6,927,41.23
1633,cryptography,"Cryptography is an art and science of secure communication. Here the sender
and receiver are guaranteed the security through encryption of their data, with
the help of a common key. Both the parties should agree on this key prior to
communication. The cryptographic systems which perform these tasks are designed
to keep the key secret while assuming that the algorithm used for encryption
and decryption is public. Thus key exchange is a very sensitive issue. In
modern cryptographic algorithms this security is based on the mathematical
complexity of the algorithm. But quantum computation is expected to
revolutionize computing paradigm in near future. This presents a challenge
amongst the researchers to develop new cryptographic techniques that can
survive the quantum computing era. This paper reviews the radical use of
quantum mechanics for cryptography.",132,10,863,39.63
1634,cryptography,"Data that is transient over an unsecured wireless network is always
susceptible to being intercepted by anyone within the range of the wireless
signal. Hence providing secure communication to keep the user information and
devices safe when connected wirelessly has become one of the major concerns.
Quantum cryptography provides a solution towards absolute communication
security over the network by encoding information as polarized photons, which
can be sent through the air. This paper explores on the aspect of application
of quantum cryptography in wireless networks. In this paper we present a
methodology for integrating quantum cryptography and security of IEEE 802.11
wireless networks in terms of distribution of the encryption keys.",111,7,743,27.32
1635,cryptography,"Quantum cryptography is the art and science of exploiting quantum mechanical
effects in order to perform cryptographic tasks. While the most well-known
example of this discipline is quantum key distribution (QKD), there exist many
other applications such as quantum money, randomness generation, secure two-
and multi-party computation and delegated quantum computation. Quantum
cryptography also studies the limitations and challenges resulting from quantum
adversaries---including the impossibility of quantum bit commitment, the
difficulty of quantum rewinding and the definition of quantum security models
for classical primitives. In this review article, aimed primarily at
cryptographers unfamiliar with the quantum world, we survey the area of
theoretical quantum cryptography, with an emphasis on the constructions and
limitations beyond the realm of QKD.",118,5,863,-0.78
1636,cryptography,"Quantum communication has demonstrated its usefulness for quantum
cryptography far beyond quantum key distribution. One domain is two-party
cryptography, whose goal is to allow two parties who may not trust each other
to solve joint tasks. Another interesting application is position-based
cryptography whose goal is to use the geographical location of an entity as its
only identifying credential. Unfortunately, security of these protocols is not
possible against an all powerful adversary. However, if we impose some
realistic physical constraints on the adversary, there exist protocols for
which security can be proven, but these so far relied on the knowledge of the
quantum operations performed during the protocols. In this work we give
device-independent security proofs of two-party cryptography and Position
Verification for memoryless devices under different physical constraints on the
adversary. We assess the quality of the devices by observing a Bell violation
and we show that security can be attained for any violation of the
Clauser-Holt-Shimony-Horne inequality.",158,8,1082,23.16
1637,cryptography,"In this paper, through considering lightweight cryptography, we present a
comparative realization of MDS matrices used in the VLSI implementations of
lightweight cryptography. We verify the MixColumn/MixNibble transformation
using MDS matrices and propose reliability approaches for thwarting natural and
malicious faults. We note that one other contribution of this work is to
consider not only linear error detecting codes but also recomputation
mechanisms as well as fault space transformation (FST) adoption for lightweight
cryptographic algorithms. Our intention in this paper is to propose reliability
and error detection mechanisms (through linear codes, recomputations, and FST
adopted for lightweight cryptography) to consider the error detection schemes
in designing beforehand taking into account such algorithmic security. We also
posit that the MDS matrices applied in the MixColumn (or MixNibble)
transformation of ciphers to protect ciphers against linear and differential
attacks should be incorporated in the cipher design in order to reduce the
overhead of the applied error detection schemes. Finally, we present a
comparative implementation framework on ASIC to benchmark the VLSI hardware
implementation presented in this paper.",175,7,1249,8.0
1638,cryptography,"The Ukraine power grid cyberattacks remind us that the smart Internet of
Things (IoT) can help us control our light-bulbs, but if under attacks it might
also take us into darkness. Nowadays, many literatures have tried to address
the concerns on IoT security, but few of them take into consideration the sever
threats to IoT coming from the advances of quantum computing. As a promising
candidate for the future post-quantum cryptography standard, lattice-based
cryptography enjoys the advantages of strong security guarantees and high
efficiency, which make it extremely suitable for IoT applications. In this
paper, we summarize the advantages of lattice-based cryptography and the state
of art of their implementations for IoT devices.",113,5,738,34.29
1639,cryptography,"Data security is required when communications over untrusted networks takes
place. Security tools such as cryptography and steganography are applied to
achieve such objectives, but both have limitations and susceptible to attacks
if they were used individually. To overcome these limitations, we proposed a
powerful and secured system based on the integration of cryptography and
steganography. The secret message is encrypted with blowfish cipher and visual
cryptography. Finally, the encrypted data is embedded into two innocent cover
images for future transmission. An extended analysis was made to prove the
efficiency of the proposed model by measuring Mean-Square-Error (MSE),
Peak-Signal-to-noise-Ratio (PSNR), and image histogram. The robustness was
examined by launching statistical and 8-bit plane visual attacks. The proposed
model provides a secure mean to transmit or store highly classified data that
could be applied to the public security sector.",138,9,962,28.54
1640,cryptography,"Certificateless cryptography can be considered as an intermediate solution to
overcome the issues in traditional public key infrastructure (PKI) and
identity-based public key cryptography (ID-PKC). There exist a vast number of
certificateless signature (CLS) schemes in the literature; however, most of
them are not efficient enough to be utilized in limited resources environments
such as Internet of things (IoT) or Healthcare Wireless Sensor Networks (HWSN).
Recently, two lightweight CLS schemes have been proposed by Karati et al. and
Kumar et al. to be employed in IoT and HWSNs, respectively. While both schemes
are claimed to be existentially unforgeable, in this paper, we show that both
these signatures can easily be forged. More specifically, it is shown that 1)
in Karati et al.'s scheme, a type 1 adversary, considered in certificateless
cryptography, can generate a valid partial private key corresponding to any
user of its choice and as a consequence, it can forge any users' signature on
any message of its choice, and 2) in Kumar et al.'s scheme, both types of
adversaries which are considered in certificateless cryptography are able to
forge any signer's signature on an arbitrary message.",189,10,1210,50.16
1641,cryptography,"The main purpose of this paper is to give an overview over the theory of
abelian varieties, with main focus on Jacobian varieties of curves reaching
from well-known results till to latest developments and their usage in
cryptography. In the first part we provide the necessary mathematical
background on abelian varieties, their torsion points, Honda-Tate theory,
Galois representations, with emphasis on Jacobian varieties and hyperelliptic
Jacobians. In the second part we focus on applications of abelian varieties on
cryptography and treating separately, elliptic curve cryptography, genus 2 and
3 cryptography, including Diffie-Hellman Key Exchange, index calculus in Picard
groups, isogenies of Jacobians via correspondences and applications to discrete
logarithms. Several open problems and new directions are suggested.",117,5,827,16.36
1642,cryptography,"This article addresses code-based cryptography and is designed to depict the
complete outline of a code based public key cryptosystem. This report includes
basic mathematics and fundamentals of coding theory which are useful for
studying code-based cryptography. Here, we briefly describe the first scheme of
code based public key cryptosystems given by R. J. McEliece in 1978 and its
improved version given by H. Niederreiter in 1986. We discuss the hard problems
of coding theory which are used in code based cryptography and some classic
attacks on it like information-set decoding (ISD). Successful implementation of
the ISD attack on McEliece cryptosystem for some small parameters set is
executed and the code for the same is provided in the Appendix. This report
elaborates a key encapsulation mechanism (KEM), namely Classic McEliece, based
on algebraic coding theory to establish a symmetric key for two users.",143,10,919,44.85
1643,cryptography,"With the emergence of 5G, Internet of Things (IoT) has become a center of
attraction for almost all industries due to its wide range of applications from
various domains. The explosive growth of industrial control processes and the
industrial IoT, imposes unprecedented vulnerability to cyber threats in
critical infrastructure through the interconnected systems. This new security
threats could be minimized by lightweight cryptography, a sub-branch of
cryptography, especially derived for resource-constrained devices such as RFID
tags, smart cards, wireless sensors, etc. More than four dozens of lightweight
cryptography algorithms have been proposed, designed for specific
application(s). These algorithms exhibit diverse hardware and software
performances in different circumstances. This paper presents the performance
comparison along with their reported cryptanalysis, mainly for lightweight
block ciphers, and further shows new research directions to develop novel
algorithms with right balance of cost, performance and security
characteristics.",142,7,1055,22.04
1644,cryptography,"Steganography is a process that hides secrete message or secrete hologram or
secrete video or secrete image whose mere presence within the source data
should be undetectable and use for transmitting secret information over public
media. Visual cryptography is a cryptographic technique in which no
cryptographic computation is needed at the decryption end and the decryption is
performed by the human visual system (HVS). In this paper, both Steganography
and visual cryptography have been selected to provide more secure data
transmission over the public media with less hazard of computation. This
technique generates shares with less space overhead as well as without
increasing the computational complexity compared to existing techniques and may
provide better security. It is also easy to implement like other techniques of
visual cryptography. Finally, experimental results are given to establish the
security criteria.",137,7,926,31.41
1645,cryptography,"Confidentiality, Integrity, and Availability are basic goals of security
architecture. To ensure CIA, many authentication scheme has been introduced in
several years. Currently deployment of Public Key Infrastructure (PKI) is a
most significant solution. PKI involving exchange key using certificates via a
public channel to a authenticate users in the cloud infrastructure. It is
exposed to widespread security threats such as eavesdropping, the man in the
middle attack, masquerade et al. Quantum cryptography is of the most prominent
fields in the modern world of information security. Quantum cryptography is
considered to be a future replica of classical cryptography along with a vital
stance to break existing classical cryptography. This paper aims to look into
basic security architecture in place currently and further it tries to
introduce a new proposed security architecture for cloud computing environment,
which makes use of the knowledge of Quantum Mechanics and current advances in
research in Quantum Computing, to provide a more secure architecture.",158,9,1068,26.0
1646,cryptography,"NSUCRYPTO is the unique cryptographic Olympiad containing scientific
mathematical problems for professionals, school and university students from
any country. Its aim is to involve young researchers in solving curious and
tough scientific problems of modern cryptography. From the very beginning, the
concept of the Olympiad was not to focus on solving olympic tasks but on
including unsolved research problems at the intersection of mathematics and
cryptography. The Olympiad history starts in 2014. In 2019, it was held for the
sixth time. In this paper, problems and their solutions of the Sixth
International Olympiad in cryptography NSUCRYPTO'2019 are presented. We
consider problems related to attacks on ciphers and hash functions, protocols,
Boolean functions, Dickson polynomials, prime numbers, rotor machines, etc. We
discuss several open problems on mathematical countermeasures to side-channel
attacks, APN involutions, S-boxes, etc. The problem of finding a collision for
the hash function Curl27 was partially solved during the Olympiad.",151,10,1052,37.5
1647,cryptography,"[Background] Previous research has shown that developers commonly misuse
cryptography APIs. [Aim] We have conducted an exploratory study to find out how
crypto APIs are used in open-source Java projects, what types of misuses exist,
and why developers make such mistakes. [Method] We used a static analysis tool
to analyze hundreds of open-source Java projects that rely on Java Cryptography
Architecture, and manually inspected half of the analysis results to assess the
tool results. We also contacted the maintainers of these projects by creating
an issue on the GitHub repository of each project, and discussed the misuses
with developers. [Results] We learned that 85% of Cryptography APIs are
misused, however, not every misuse has severe consequences. Developer feedback
showed that security caveats in the documentation of crypto APIs are rare,
developers may overlook misuses that originate in third-party code, and the
context where a Crypto API is used should be taken into account. [Conclusion]
We conclude that using Crypto APIs is still problematic for developers but
blindly blaming them for such misuses may lead to erroneous conclusions.",177,8,1154,37.34
1648,cryptography,"The field of quantum information is becoming more known to the general
public. However, effectively demonstrating the concepts underneath quantum
science and technology to the general public can be a challenging job. We
investigate, extend, and much expand here ""quantum candies"" (invented by
Jacobs), a pedagogical model for intuitively describing some basic concepts in
quantum information, including quantum bits, complementarity, the no-cloning
principle, and entanglement. Following Jacob's quantum candies description of
the well known quantum key distribution protocol BB84, we explicitly
demonstrate various additional quantum cryptography protocols using quantum
candies in an approachable manner. The model we investigate can be a valuable
tool for science and engineering educators who would like to help the general
public to gain more insights about quantum science and technology: most parts
of this paper, including many protocols for quantum cryptography, are expected
to be easily understandable by a layperson without any previous knowledge of
mathematics, physics, or cryptography.",154,6,1100,6.37
1649,cryptography,"Importance of Elliptic Curves in Cryptography was independently proposed by
Neal Koblitz and Victor Miller in 1985.Since then, Elliptic curve cryptography
or ECC has evolved as a vast field for public key cryptography (PKC) systems.
In PKC system, we use separate keys to encode and decode the data. Since one of
the keys is distributed publicly in PKC systems, the strength of security
depends on large key size. The mathematical problems of prime factorization and
discrete logarithm are previously used in PKC systems. ECC has proved to
provide same level of security with relatively small key sizes. The research in
the field of ECC is mostly focused on its implementation on application
specific systems. Such systems have restricted resources like storage,
processing speed and domain specific CPU architecture.",128,9,817,46.78
1650,cryptography,"Methods of quantum mechanics promise information-theoretic security for
various protocols in cryptography. However, impossibility of some cryptographic
applications such as standard bit commitment, oblivious transfer, multiparty
secure computations and ideal coin tossing in quantum regime leaves an obvious
question on the completeness of quantum cryptography. Instead of using wide
range of rules and techniques for a variety of cryptographic applications, we
demonstrate here a unified structure for quantum cryptography based on quantum
non-local correlations. The unified framework achieves same goals in
information-theoretic way as classical cryptography does with computational
hardness. To cover the broad range of cryptographic applications, we show that
the framework (i) assures secrecy by providing encryption completely
unintelligible to eavesdroppers, (ii) guarantees that input from distant
parties is concealed unless they are willing to reveal, (iii) assures binding,
(iv) allows splitting information between several parties securely and more
generally, (v) evades both quantum and classical attacks from internal as well
as external eavesdropping.",156,6,1167,5.97
1651,cryptography,"With the advent of advanced technology, IoT introduces a vast number of
devices connecting with each other and collecting a sheer volume of data. Thus,
the demands of IoT security is paramount. Cryptography is being used to secure
the networks for authentication, confidentiality, data integrity and access
control. However, due to the resource constraint nature of IoT devices, the
traditional cryptographic protocols may not be suited in all IoT environments.
Researchers, as a result, have been proposing various lightweight cryptographic
algorithms and protocols. In this paper, we discuss the state of the art
lightweight cryptographic protocols for IoT networks and present a comparative
analysis of the existing protocols. In doing so, this paper has classified the
most current algorithm into two parts, such as symmetric and asymmetric
lightweight cryptography. Additionally, we consider several recent developed
block cipher and stream cipher algorithms. Furthermore, various research
challenges of lightweight cryptography have been addressed.",151,10,1054,29.04
1652,cryptography,"Modern cryptography is essential to communication and information security
for performing all kinds of security actions, such as encryption,
authentication, and signature. However, the exposure possibility of keys poses
a great threat to almost all modern cryptography. This article proposes a
key-fusing framework, which enables a high resilience to key exposure by fusing
multiple imperfect keys. The correctness of the scheme is strictly verified
through a toy model that is general enough to abstract the physical-layer key
generation (PLKG) mechanisms. Analysis and results demonstrate that the
proposed scheme can dramatically reduce secret outage probability, so that key
sources with even high exposure probability can be practically beneficial for
actual secret communication. Our framework paves the way for achieving
information-theoretic security by integrating various key sources, such as
physical layer key generation, lattice-based cryptography, and quantum
cryptography.",136,7,987,6.13
1653,cryptography,"Quantum cryptography exploits principles of quantum physics for the secure
processing of information. A prominent example is secure communication, i.e.,
the task of transmitting confidential messages from one location to another.
The cryptographic requirement here is that the transmitted messages remain
inaccessible to anyone other than the designated recipients, even if the
communication channel is untrusted. In classical cryptography, this can usually
only be guaranteed under computational hardness assumptions, e.g., that
factoring large integers is infeasible. In contrast, the security of quantum
cryptography relies entirely on the laws of quantum mechanics. Here we review
this physical notion of security, focusing on quantum key distribution and
secure communication.",107,11,781,15.57
1654,cryptography,"In order to provide a coherent overview of cyber security research, the
Scopus academic abstract and citation database was mined to create a citation
graph of 98,373 authors active in the field between 1949 and early 2020. The
Louvain community detection algorithm was applied to the graph in order to
identify existing research communities. The analysis discovered twelve
top-level communities: access control, authentication, biometrics, cryptography
(I & II), cyber-physical systems, information hiding, intrusion detection,
malwares, quantum cryptography, sensor networks, and usable security. These
top-level communities were in turn composed of a total of 80 sub-communities.
The analysis results are presented for each community in descriptive text,
sub-community graphs, and tables with, for example, the most-cited papers and
authors. A comparison between the detected communities and topical areas
defined by other related work, is also presented, demonstrating a greater
researcher emphasis on cryptography, quantum cryptography, information hiding
and biometrics, at the expense of laws and regulation, risk management and
governance, and security software lifecycle.",163,7,1179,10.23
1655,cryptography,"We formalize the simulation paradigm of cryptography in terms of category
theory and show that protocols secure against abstract attacks form a symmetric
monoidal category, thus giving an abstract model of composable security
definitions in cryptography. Our model is able to incorporate computational
security, set-up assumptions and various attack models such as colluding or
independently acting subsets of adversaries in a modular, flexible fashion. We
conclude by using string diagrams to rederive the security of the one-time pad
and no-go results concerning the limits of bipartite and tripartite
cryptography, ruling out e.g., composable commitments and broadcasting.",96,6,675,13.28
1656,cryptography,"The goal of this survey paper is to provide an introduction to chaos
synchronization using nonlinear observers and its applications in cryptography.
I start with an overview of cryptography. Then, I recall the basics of chaos
theory and how to use chaotic systems for cryptography, with an introduction to
the problem of chaos synchronization. Then, I present the theory of non-linear
observers, which is used for the synchronization of chaotic systems. I start
with an explanation of the observability problem. Then, I introduce some of the
classical observers: Kalman filter, Luenberger observer, Extended Kalman
filter, Thau's observer, and High gain observer. I finish by introducing the
more advanced observers: Adaptive observers, Unknown inputs observers, Sliding
mode observers and ANFIS (Adaptive Neuro-Fuzzy Inference Systems) observers.",124,8,847,36.59
1657,cryptography,"We surveyed 97 developers who had used cryptography in open-source projects,
in the hope of identifying developer security and cryptography practices. We
asked them about individual and company-level practices, and divided
respondents into three groups (i.e., high, medium, and low) based on their
level of knowledge. We found differences between the high-profile developers
and the other two groups. For instance, high-profile developers have more years
of experience in programming, have attended more security and cryptography
courses, have more background in security, are highly concerned about security,
and tend to use security tools more than the other two groups. Nevertheless, we
observed worrisome patterns among all participants such as the high usage of
unreliable sources like Stack Overflow, and the low rate of security tool
usage.",125,8,847,33.44
1658,cryptography,"The improvements on quantum technology are threatening our daily
cybersecurity, as a capable quantum computer can break all currently employed
asymmetric cryptosystems. In preparation for the quantum-era the National
Institute of Standards and Technology (NIST) has initiated in 2016 a
standardization process for public-key encryption (PKE) schemes,
key-encapsulation mechanisms (KEM) and digital signature schemes. In 2023, NIST
made an additional call for post-quantum signatures. With this chapter we aim
at providing a survey on code-based cryptography, focusing on PKEs and
signature schemes. We cover the main frameworks introduced in code-based
cryptography and analyze their security assumptions. We provide the
mathematical background in a lecture notes style, with the intention of
reaching a wider audience.",114,7,819,26.81
1659,cryptography,"Quantum computer is no longer a hypothetical idea. It is the worlds most
important technology and there is a race among countries to get supremacy in
quantum technology. Its the technology that will reduce the computing time from
years to hours or even minutes. The power of quantum computing will be a great
support for the scientific community. However, it raises serious threats to
cybersecurity. Theoretically, all the cryptography algorithms are vulnerable to
attack. The practical quantum computers, when available with millions of qubits
capacity, will be able to break nearly all modern public-key cryptographic
systems. Before the quantum computers arrive with sufficient qubit capacity, we
must be ready with quantum-safe cryptographic algorithms, tools, techniques,
and deployment strategies to protect the ICT infrastructure. This paper
discusses in detail the global effort for the design, development, and
standardization of various quantum-safe cryptography algorithms along with the
performance analysis of some of the potential quantum-safe algorithms. Most of
the quantum-safe algorithms need more CPU cycles, higher runtime memory, and
large key size. The objective of the paper is to analyze the feasibility of the
various quantum-safe cryptography algorithms.",186,12,1280,28.94
1660,cryptography,"Non-Stop University CRYPTO is the International Olympiad in Cryptography that
was held for the eight time in 2021. Hundreds of university and school
students, professionals from 33 countries worked on mathematical problems in
cryptography during a week. The aim of the Olympiad is to attract attention to
curious and even open scientific problems of modern cryptography. In this
paper, problems and their solutions of the Olympiad'2021 are presented. We
consider 19 problems of varying difficulty and topics: ciphers, online
machines, passwords, binary strings, permutations, quantum circuits, historical
ciphers, elliptic curves, masking, implementation on a chip, etc. We discuss
several open problems on quantum error correction, finding special permutations
and s-Boolean sharing of a function, obtaining new bounds on the distance to
affine vectorial functions.",124,7,866,33.54
1661,cryptography,"Ever since its inception, cryptography has been caught in a vicious circle:
Cryptographers keep inventing methods to hide information, and cryptanalysts
break them, prompting cryptographers to invent even more sophisticated
encryption schemes, and so on. But could it be that quantum information
technology breaks this circle? At first sight, it looks as if it just lifts the
competition between cryptographers and cryptanalysts to the next level. Indeed,
quantum computers will render most of today's public key cryptosystems
insecure. Nonetheless, there are good reasons to believe that cryptographers
will ultimately prevail over cryptanalysts. Quantum cryptography allows us to
build communication schemes whose secrecy relies only on the laws of physics
and some minimum assumptions about the cryptographic hardware - leaving
basically no room for an attack. While we are not yet there, this article
provides an overview of the principles and state of the art of quantum
cryptography, as well as an assessment of current challenges and prospects for
overcoming them.",160,7,1071,39.97
1662,cryptography,"We develop matrix cryptography based on linear recurrent sequences of any
order that allows securing encryption against brute force and chosen plaintext
attacks. In particular, we solve the problem of generalizing error detection
and correction algorithms of golden cryptography previously known only for
recurrences of a special form. They are based on proving the checking relations
(inequalities satisfied by the ciphertext) under the condition that the analog
of the golden $Q$-matrix has the strong Perron-Frobenius property. These
algorithms are proved to be especially efficient when the characteristic
polynomial of the recurrence is a Pisot polynomial. Finally, we outline
algorithms for generating recurrences that satisfy our conditions.",106,6,748,24.58
1663,cryptography,"Public-key cryptography has become a popular way to motivate the teaching of
concepts in elementary number theory, abstract algebra, and introduction to
proof courses, as well as in cryptography courses. Unfortunately, many experts
expect quantum computers to make common forms of public-key cryptography
obsolete in the near future. Fortunately, there are several systems being
evaluated to replace RSA and the other systems we currently use. While some of
the systems are too complicated to be good examples in introductory courses,
others are either quite manageable or have simplified versions which are
manageable. This article gives a tour of the main types of systems under
consideration and the teaching resources available for instructors who want to
teach them.",117,6,771,30.8
1664,cryptography,"We formalize the simulation paradigm of cryptography in terms of category
theory and show that protocols secure against abstract attacks form a symmetric
monoidal category, thus giving an abstract model of composable security
definitions in cryptography. Our model is able to incorporate computational
security, set-up assumptions and various attack models such as colluding or
independently acting subsets of adversaries in a modular, flexible fashion. We
conclude by using string diagrams to rederive the security of the one-time pad,
correctness of Diffie-Hellman key exchange and no-go results concerning the
limits of bipartite and tripartite cryptography, ruling out e.g., composable
commitments and broadcasting. On the way, we exhibit two categorical
constructions of resource theories that might be of independent interest: one
capturing resources shared among multiple parties and one capturing resource
conversions that succeed asymptotically.",133,7,954,10.64
1665,cryptography,"With the surge of the powerful quantum computer, lattice-based cryptography
proliferated the latest cryptography hardware implementation due to its
resistance against quantum computers. Among the computational blocks of
lattice-based cryptography, the random errors produced by the sampler play a
key role in ensuring the security of these schemes. This paper proposes an
integral architecture for the sampler, which can reduce the overall resource
consumption by reusing the multipliers and adders within the modular polynomial
computation. For instance, our experimental results show that the proposed
design can effectively reduce the discrete Ziggurat sampling method in DSP
usage.",96,5,685,21.74
1666,cryptography,"We propose a cryptography-inspired model for nonlocal correlations. Following
the celebrated De Broglie-Bohm theory, we model nonlocal boxes as realistic
systems with instantaneous signalling at the hidden variable level. By
introducing randomness in the distribution of the hidden variable, the
superluminal signalling model is made compatible with the operational
no-signalling condition. As the design mimics the famous symmetric key
encryption system called {\it One Time Pads} (OTP), we call this the OTP model
for nonlocal boxes. We demonstrate utility of this model in several esoteric
examples related to the nonclassicality of nonlocal boxes. In particular, the
breakdown of communication complexity using nonlocal boxes can be better
understood in this framework. Furthermore, we discuss the Van Dam protocol and
show its connection to homomorphic encryption in cryptography. We also discuss
possible ways of encapsulating quantum realizable nonlocal correlations within
this framework and show that the principle of Information Causality imposes
further constraints at the hidden variable level. Present work thus
orchestrates the results in classical cryptography to improve our understanding
of nonlocal correlations and welcomes further research to this connection.",179,10,1279,17.44
1667,cryptography,"We present a usability study of the Ascon 1.2 family of cryptographic
algorithms. As far as we know, this is the first published experimental
evaluation aimed at a cryptographic design (i.e. not a specific API) with the
purpose of informing which aspects to standardise. While the results show the
general difficulty of choosing and applying cryptographic algorithms, there are
some more specific insights. These include the possibility of confusing
multiple variants, the relevance of small interfaces, and the desire for
higher-level wrapper functions (e.g. for protocols). Overall, many questions
are still open, including how usability could be integrated into the design and
evaluation of cryptographic algorithms. Our main takeaway is that lightweight
usable cryptography is an open research area that deserves greater focus. For
the review of NISTIR 7977, the standardisation process of Ascon as a FIPS, and
when exploring potential future SPs, the key criterion of usability should be
based on realistic user testing and on triangulation from other methods.",161,13,1065,36.39
1668,cryptography,"Elliptic curve cryptography (ECC) is a remarkable mathematical tool that
offers the same level of security as traditional public-key cryptography (PKC)
with a significantly smaller key size and lower computational requirements. The
use of pairing on elliptic curves has emerged as a vibrant field of research
that provides enhanced security measures for the next generation of
cryptographic systems. This thesis explores using ECC and Pairing-Based
Cryptosystems (PBC) as effective mathematical tools for achieving high-security
levels with minimal key size and computation cost. Specifically, the research
aims to analyze Pairing-Friendly Elliptic Curves (PF-EC) and their practicality
in resource-constrained environments. It proposes solutions to some of the
limitations of existing applications of pairing-based cryptography. The thesis
begins by presenting a comprehensive framework for constructing PF-EC and
evaluating the practical security of several families of pairing-friendly
curves. The study then explores the limitations of Identity-Based Encryption
(IBE), a recognized application of pairing-based cryptography. It proposes
mechanisms to address issues such as key escrow, secure key issuing, user
slandering, and key abusing problems. The proposed solutions include an
Escrow-Free Identity-Based Encryption (EF-IBE) scheme secured against
confidentiality and an Escrow-Free Identity-Based Signature (EF-IBS) scheme
that is forgeable and secure.",194,10,1462,15.71
1669,cryptography,"Every year the International Olympiad in Cryptography Non-Stop University
CRYPTO (NSUCRYPTO) offers mathematical problems for university and school
students and, moreover, for professionals in the area of cryptography and
computer science. The mail goal of NSUCRYPTO is to draw attention of students
and young researchers to modern cryptography and raise awareness about open
problems in the field. We present problems of NSUCRYPTO'22 and their solutions.
There are 16 problems on the following topics: ciphers, cryptosystems,
protocols, e-money and cryptocurrencies, hash functions, matrices, quantum
computing, S-boxes, etc. They vary from easy mathematical tasks that could be
solved by school students to open problems that deserve separate discussion and
study. So, in this paper, we consider several open problems on three-pass
protocols, public and private keys pairs, modifications of discrete logarithm
problem, cryptographic permutations and quantum circuits.",135,7,969,31.72
1670,cryptography,"Traditional AI methodologies necessitate centralized data collection, which
becomes impractical when facing problems with network communication, data
privacy, or storage capacity. Federated Learning (FL) offers a paradigm that
empowers distributed AI model training without collecting raw data. There are
different choices for providing privacy during FL training. One of the popular
methodologies is employing Homomorphic Encryption (HE) - a breakthrough in
privacy-preserving computation from Cryptography. However, these methods have a
price in the form of extra computation and memory footprint. To resolve these
issues, we propose an innovative framework that synergizes permutation-based
compressors with Classical Cryptography, even though employing Classical
Cryptography was assumed to be impossible in the past in the context of FL. Our
framework offers a way to replace HE with cheaper Classical Cryptography
primitives which provides security for the training process. It fosters
asynchronous communication and provides flexible deployment options in various
communication topologies.",147,9,1096,10.6
1671,cryptography,"In recent years, quantum computers and Shor quantum algorithm have posed a
threat to current mainstream asymmetric cryptography methods (e.g. RSA and
Elliptic Curve Cryptography (ECC)). Therefore, it is necessary to construct a
Post-Quantum Cryptography (PQC) method to resist quantum computing attacks.
Therefore, this study proposes a PQC-based neural network that maps a
code-based PQC method to a neural network structure and enhances the security
of ciphertexts with non-linear activation functions, random perturbation of
ciphertexts, and uniform distribution of ciphertexts. In practical experiments,
this study uses cellular network signals as a case study to demonstrate that
encryption and decryption can be performed by the proposed PQC-based neural
network with the uniform distribution of ciphertexts. In the future, the
proposed PQC-based neural network could be applied to various applications.",128,8,909,32.94
1672,cryptography,"In the resource-constrained world of the digital landscape, lightweight
cryptography plays a critical role in safeguarding information and ensuring the
security of various systems, devices, and communication channels. Its efficient
and resource-friendly nature makes it the ideal solution for applications where
computational power is limited. In response to the growing need for
platform-specific implementations, NIST issued a call for standardization of
Lightweight cryptography algorithms in 2018. Ascon emerged as the winner of
this competition. NIST initially established general evaluation criteria for a
standard lightweight scheme including security strength, mitigation against
side-channel and fault-injection attacks, and implementation efficiency. To
verify the security claims, evaluating the individual components used in any
cryptographic algorithm is a crucial step. The quality of a substitution box
(S-box) significantly impacts the overall security of a cryptographic
primitive. This paper analyzes the S-boxes of six finalists in the NIST
Lightweight Cryptography (LWC) standardization process. We evaluate them based
on well-established cryptographic properties. Our analysis explores how these
properties influence the S-boxes' resistance against known cryptanalytic
attacks and potential implementation-specific vulnerabilities, thus reflecting
on their compliance with NIST's security requirements.",182,11,1423,10.7
1673,cryptography,"On July 5, 2022, the National Institute of Standards and Technology announced
four possible post-quantum cryptography standards, three of them are based on
lattice theory and the other one is based on Hash function. It is well-known
that the security of the lattice cryptography relies on the hardness of the
shortest vector problem (SVP) and the closest vector problem (CVP). In fact,
the SVP is a sphere packing problem and the CVP is a sphere covering problem.
Furthermore, both SVP and CVP are equivalent to arithmetic problems of positive
definite quadratic forms. This paper will briefly introduce the post-quantum
cryptography and show its connections with sphere packing, sphere covering, and
positive definite quadratic forms.",114,6,735,48.33
1674,cryptography,"Cellular Automata (CA) have been extensively used to implement symmetric
cryptographic primitives, such as pseudorandom number generators and S-boxes.
However, most of the research in this field, except the very early works, seems
to be published in non-cryptographic venues. This phenomenon poses a problem of
relevance: are CA of any use to cryptographers nowadays? This paper provides
insights into this question by briefly outlining the history of CA-based
cryptography. In doing so, the paper identifies some shortcomings in the
research addressing the design of symmetric primitives exclusively from a CA
standpoint, alongside some recommendations for future research. Notably, the
paper remarks that researchers working in CA and cryptography often tackle
similar problems, albeit under different perspectives and terminologies. This
observation indicates that there is still ample room for fruitful
collaborations between the CA and cryptography communities in the future.",139,7,980,25.9
1675,cryptography,"Neural cryptography is based on a competition between attractive and
repulsive stochastic forces. A feedback mechanism is added to neural
cryptography which increases the repulsive forces. Using numerical simulations
and an analytic approach, the probability of a successful attack is calculated
for different model parameters. Scaling laws are derived which show that
feedback improves the security of the system. In addition, a network with
feedback generates a pseudorandom bit sequence which can be used to encrypt and
decrypt a secret message.",81,6,548,29.65
1676,cryptography,"An Extended Visual Cryptography Scheme (EVCS) was proposed by Ateniese et al.
[3] to protect a binary secret image with meaningful (innocent-looking) shares.
This is implemented by concatenating an extended matrix to each basis matrix.
The minimum size of the extended matrix was obtained from a hypergraph coloring
model and the scheme was designed for binary images only [3]. In this paper, we
give a more concise derivation for this matrix extension for color images.
Furthermore, we present a (k, n) scheme to protect multiple color images with
meaningful shares. This scheme is an extension of the (n, n) VCS for multiple
binary images proposed in Droste scheme [2].",109,8,671,47.18
1677,cryptography,"Visual cryptography schemes have been introduced in 1994 by Naor and Shamir.
Their idea was to encode a secret image into $n$ shadow images and to give
exactly one such shadow image to each member of a group $P$ of $n$ persons.
Whereas most work in recent years has been done concerning the problem of
qualified and forbidden subsets of $P$ or the question of contrast optimizing,
in this paper we study extended visual cryptography schemes, i.e. shared secret
systems where any subset of $P$ shares its own secret.",89,6,515,57.3
1678,cryptography,"This paper shows that Physics is very close to the substitution-diffusion
paradigm of symmetric ciphers. Based on this analogy, we propose a new
cryptographic algorithm. Statistical Physics gives design principles to devise
fast, scalable and secure encryption systems. In particular, increasing space
dimension and considering larger data blocks improve both speed and security,
allowing us to reach high throughput (larger than 10Gb/s on dedicated HW). The
physical approach enlarges the way to look at cryptography and is expected to
bring new tools and concepts to better understand and quantify security
aspects.",91,6,617,36.08
1679,cryptography,"Noise causes severe difficulties in implementing quantum computing and
quantum cryptography. Several schemes have been suggested to reduce this
problem, mainly focusing on quantum computation. Motivated by quantum
cryptography, we suggest a coding which uses $N$ quantum bits ($N=n^2$) to
encode one quantum bit, and reduces the error exponentially with $n$. Our
result suggests the possibility of distributing a secure key over very long
distances, and maintaining quantum states for very long times. It also provides
a new quantum privacy amplification against a strong adversary.",85,6,582,37.3
1680,cryptography,"In quantum cryptography, the level of security attainable by a protocol which
implements a particular task $N$ times bears no simple relation to the level of
security attainable by a protocol implementing the task once. Useful partial
security, and even near-perfect security in an appropriate sense, can be
obtained for $N$ copies of a task which itself cannot be securely implemented.
We illustrate this with protocols for quantum bit string commitment and quantum
random number generation between mistrustful parties.",79,4,520,19.4
1681,cryptography,"Weak coherent states as a photon source for quantum cryptography have limit
in secure data rate and transmission distance because of the presence of
multi-photon events and loss in transmission line. Two-photon events in a
coherent state can be taken out by a two-photon interference scheme. We
investigate the security issue of utilizing this modified coherent state in
quantum cryptography. A 4 dB improvement in secure data rate or a nearly
two-fold increase in transmission distance over the coherent state are found.
With a recently proposed and improved encoding strategy, further improvement is
possible.",94,6,611,43.93
1682,cryptography,"Based on quantum encryption, we present a new idea for quantum public-key
cryptography (QPKC) and construct a whole theoretical framework of a QPKC
system. We show that the quantum-mechanical nature renders it feasible and
reasonable to use symmetric keys in such a scheme, which is quite different
from that in conventional public-key cryptography. The security of our scheme
is analyzed and some features are discussed. Furthermore, the state-estimation
attack to a prior QPKC scheme is demonstrated.",76,5,502,35.27
1683,cryptography,"At ISCAS'2005, Yen et al. presented a new chaos-based cryptosystem for
multimedia transmission named ""Multimedia Cryptography System"" (MCS). No
cryptanalytic results have been reported so far. This paper presents a
differential attack to break MCS, which requires only seven chosen plaintexts.
The complexity of the attack is O(N), where $N$ is the size of plaintext.
Experimental results are also given to show the real performance of the
proposed attack.",69,7,456,42.88
1684,cryptography,"Up to now, for efficiency reasons cryptographic algorithm has been written in
an imperative language. But to get acquaintance with a functional programming
language a question arises: functional programming offers some new for secure
communication or not? This article investigates this question giving an
overview on some cryptography algorithms and presents how the RSA encryption in
the functional language Clean can be implemented and how can be measured the
efficiency of a certain application.",74,3,499,29.48
1685,cryptography,"In this work, pseudorandom sequence generators based on finite fields have
been analyzed from the point of view of their cryptographic application. In
fact, a class of nonlinear sequence generators has been modelled in terms of
linear cellular automata. The algorithm that converts the given generator into
a linear model based on automata is very simple and is based on the
concatenation of a basic structure. Once the generator has been linearized, a
cryptanalytic attack that exploits the weaknesses of such a model has been
developed. Linear cellular structures easily model sequence generators with
application in stream cipher cryptography.",99,6,646,34.46
1686,cryptography,"In this paper, the systematisation and classification of modern quantum
technologies of information security against cyber-terrorist attack are carried
out. The characteristic of the basic directions of quantum cryptography from
the viewpoint of the quantum technologies used is given. A qualitative analysis
of the advantages and disadvantages of concrete quantum protocols is made. The
current status of the problem of practical quantum cryptography use in
telecommunication networks is considered. In particular, a short review of
existing commercial systems of quantum key distribution is given.",84,6,599,20.58
1687,cryptography,"An algorithm is presented which implements a probabilistic attack on the
key-exchange protocol based on permutation parity machines. Instead of
imitating the synchronization of the communicating partners, the strategy
consists of a Monte Carlo method to sample the space of possible weights during
inner rounds and an analytic approach to convey the extracted information from
one outer round to the next one. The results show that the protocol under
attack fails to synchronize faster than an eavesdropper using this algorithm.",80,4,528,27.45
1688,cryptography,"Leveraging quantum mechanics, cryptographers have devised provably secure key
sharing protocols. Despite proving the security in theory, real-world
application falls short of the ideal. Last year, cryptanalysts completed an
experiment demonstrating a successful eavesdropping attack on commercial
quantum key distribution (QKD) systems. This attack exploits a weakness in the
typical real-world implementation of quantum cryptosystems. Cryptanalysts have
successfully attacked several protocols. In this paper, we examine the Kak
quantum cryptography protocol and how it may perform under such attacks.",79,7,602,15.78
1689,cryptography,"One of the main problems in cryptography is to give criteria to provide good
comparators of cipher systems. The security of a cipher system must include the
security of the algorithm, the security of the key generator and management
module (see [BM94], [CM97],[Mau92a]) and the security of the cryptographic key
agreement protocol (see [Mau93a],[MC94],[Mau93b],[Mau92b]). This paper gives
show the necessary mathematical background to estimate the most important
cryptographic measures of the key generators and of the unconditionally key
agreement protocols. These cryptographic measures are the Shannon entropy (for
the key generator module) and Renyi entropy of order alpha for the key
agreement protocol.",103,5,708,28.37
1690,cryptography,"Privacy Preserving Data Mining is a method which ensures privacy of
individual information during mining. Most important task involves retrieving
information from multiple data bases which is distributed. The data once in the
data warehouse can be used by mining algorithms to retrieve confidential
information. The proposed framework has two major tasks, secure transmission
and privacy of confidential information during mining. Secure transmission is
handled by using elliptic curve cryptography and data distortion for privacy
preservation ensuring highly secure environment.",80,6,579,12.94
1691,cryptography,"This paper reports a variant of the three-stage quantum cryptography protocol
which can be used in low intensity laser output regimes. The variant, which
tracks the intensity of the laser beam at the intermediate stages, makes the
task of the eavesdropper harder than the standard K06 protocol. The constraints
on the iAQC protocol are much less than those on BB84 and in principle it can
not only be used for key distribution but also for direct bitwise encryption of
data. The iAQC protocol is an improvement on the K06 protocol in that it makes
it harder for the eavesdropper to monitor the channel.",103,5,602,53.75
1692,cryptography,"In auction theory, cryptography has been used to achieve anonymity of the
participants, security and privacy of the bids, secure computation and to
simulate mediator (auctioneer). Auction theory focuses on revenue and
Cryptography focuses on security and privacy. Involving Cryptography at base
level, to enhance revenue gives entirely new perspective and insight to Auction
theory, thereby achieving the core goals of auction theory. In this report, we
try to investigate an interesting field of study in Auction Theory using
Cryptographic primitives.",81,5,552,17.03
1693,cryptography,"We introduce a generalized Anshel-Anshel-Goldfeld (AAG) key establishment
protocol (KEP) for magmas. This leads to the foundation of non-associative
public-key cryptography (PKC), generalizing the concept of non-commutative PKC.
We show that left selfdistributive systems appear in a natural special case of
a generalized AAG-KEP for magmas, and we propose, among others instances,
concrete realizations using $f$-conjugacy in groups and shifted conjugacy in
braid groups. We discuss the advantages of our schemes compared with the
classical AAG-KEP based on conjugacy in braid groups.",82,5,585,25.29
1694,cryptography,"Cryptography is an important field in the area of data encryption. There are
different cryptographic techniques available varying from the simplest to
complex. One of the complex symmetric key cryptography techniques is using Data
Encryption Standard Algorithm. This paper explores a unique approach to
generation of key using fingerprint. The generated key is used as an input key
to the DES Algorithm",62,5,402,41.97
1695,cryptography,"General cryptographic schemes are presented where keys can be one-time or
ephemeral. Processes for key exchange are derived. Public key cryptographic
schemes based on the new systems are easily established. Authentication and
signature schemes are implemented. The schemes are an advance on group ring
techniques and are easily implemented but highly secure. They may be integrated
with error-correcting coding schemes so that encryption/coding and
decryption/decoding may be done simultaneously.",69,7,496,34.42
1696,cryptography,"Quantum discord is the minimal bipartite resource which is needed for a
secure quantum key distribution, being a cryptographic primitive equivalent to
non-orthogonality. Its role becomes crucial in device-dependent quantum
cryptography, where the presence of preparation and detection noise
(inaccessible to all parties) may be so strong to prevent the distribution and
distillation of entanglement. The necessity of entanglement is re-affirmed in
the stronger scenario of device-independent quantum cryptography, where all
sources of noise are ascribed to the eavesdropper.",79,4,574,19.4
1697,cryptography,"We use various laws of classical physics to offer several solutions of Yao's
millionaires' problem without using any one-way functions. We also describe
several informationally secure public key encryption protocols, i.e., protocols
secure against passive computationally unbounded adversary. This introduces a
new paradigm of decoy-based cryptography, as opposed to ""traditional""
complexity-based cryptography. In particular, our protocols do not employ any
one-way functions.",62,7,477,16.59
1698,cryptography,"Ensuring security is something that is not easily done as many of the demands
of network security conflict with the demands of mobile networks, majorly
because of the nature of the mobile devices (e.g. low power consumption, low
processing load). The study of secure distributed key agreement has great
theoretical and practical significance. Securing Mobile Ad-hoc Networks using
Distributed Public-key Cryptography in pairing with Mobile Ad hoc Networks and
various protocols are essential for secure communications in open and
distributed environment.",81,6,554,25.49
1699,cryptography,"We propose an alternative quantum cryptography protocol using the quantum
interference effect. The efficiency of creating sifted key can reach 100\% in
principle, which is higher than previous protocols. Especially, compared with
the typical quantum key distribution, the present scheme does not require the
authorized parties to check their bases. Because the potential eavesdropper can
only access part of the quantum system, the proposed scheme has natural
practical security advantages. The scheme can be implemented with current
technologies and opens promising possibilities for quantum cryptography.",85,6,606,28.84
1700,cryptography,"The Unshared Secret Key Cryptography (USK), recently proposed by the authors,
guarantees Shannon's ideal secrecy and perfect secrecy for MIMO wiretap
channels, without requiring secret key exchange. However, the requirement of
infinite constellation inputs limits its applicability to practical systems. In
this paper, we propose a practical USK scheme using finite constellation
inputs. The new scheme is based on a cooperative jamming technique, and is
valid for the case where the eavesdropper has more antennas than the
transmitter. We show that Shannon's ideal secrecy can be achieved with an
arbitrarily small outage probability.",93,6,635,27.22
1701,cryptography,"In todays world, Cloud computing has attracted research communities as it
provides services in reduced cost due to virtualizing all the necessary
resources. Even modern business architecture depends upon Cloud computing .As
it is a internet based utility, which provides various services over a network,
it is prone to network based attacks. Hence security in clouds is the most
important in case of cloud computing. Cloud Security concerns the customer to
fully rely on storing data on clouds. That is why Cloud security has attracted
attention of the research community. This paper will discuss securing the data
in clouds by implementing key agreement, encryption and signature
verification/generation with hyperelliptic curve cryptography.",111,8,743,38.42
1702,cryptography,"In the last few years the world in which Quantum Cryptography evolves has
deeply changed. On the one side the revelations of Snowden, though he said
nothing really new, made the world more aware of the importance to protect
sensitive data from all kinds of adversaries, including sometimes ""friends."" On
the other side, breakthroughs in quantum computation, in particular in
superconducting qubits and surface-codes, made it possible that in 15 to 25
years there might be a quantum machine able to break today's codes. This
implies that in order to protect today's data over a few decades, one has to
act now and use some quantum-safe cryptography.",107,5,648,52.73
1703,cryptography,"Although practised as an art and science for ages, cryptography had to wait
until the mid-twentieth century before Claude Shannon gave it a strong
mathematical foundation. However, Shannon's approach was rooted is his own
information theory, itself inspired by the classical physics of Newton and
Einstein. But our world is ruled by the laws of quantum mechanics. When
quantum-mechanical phenomena are taken into account, new vistas open up both
for codemakers and codebreakers. Is quantum mechanics a blessing or a curse for
the protection of privacy? As we shall see, the jury is still out!",95,5,592,46.98
1704,cryptography,"Cryptompress, a new 128-bit (initial) private-key cryptography algorithm is
proposed. It uses a block size of at least 30 bits and increments prior key
size to additional 32 bits on each unsuccessful attempt of any means, including
bruteforcing, further changing a specific portion of the cyphertext using the
reformed Feistel network. Encryption process results from a proposed
compression sequence developed using lookup table and shift operations followed
by key generation. Eventually, four matrixes named add-sub matrix, reduced
matrix, sequence matrix and term matrix are obtained which ultimately forms a
cyphertext.",90,5,623,31.72
1705,cryptography,"Wireless Sensor Network (WSN) is consisting of independent and distributed
sensors to monitor physical or environmental conditions, such as temperature,
sound, pressure, etc. The most crucial and fundamental challenge facing WSN is
security. Due to minimum capacity in-term of memory cost, processing and
physical accessibility to sensors devices the security attacks are problematic.
They are mostly deployed in open area, which expose them to different kinds of
attacks. In this paper, we present an illustration of different attacks and
vulnerabilities in WSN. Then we describe and analyze security requirement,
countermeasures based on cryptography mechanisms in literature. Finally, we
present possible directions in future research.",104,8,738,22.51
1706,cryptography,"Based on the firm laws of physics rather than unproven foundations of
mathematical complexity, quantum cryptography provides a radically different
solution for encryption and promises unconditional security. Quantum
cryptography systems are typically built between two nodes connected to each
other through fiber optic. This chapter focuses on quantum cryptography systems
operating over free-space optical channels as a cost-effective and license-free
alternative to fiber optic counterparts. It provides an overview of the
different parts of an experimental free-space quantum communication link
developed in the Spanish National Research Council (Madrid, Spain).",89,5,665,15.0
1707,cryptography,"As long as human beings exist on this earth, there will be confidential
images intended for limited audience. These images have to be transmitted in
such a way that no unauthorized person gets knowledge of them. DNA sequences
play a vital role in modern cryptography and DNA sequence based cryptography
renders a helping hand for transmission of such confidential images over a
public insecure channel as the intended recipient alone can decipher them. This
paper outlines an integrated encryption scheme based on DNA sequences and
scrambling according to magic square of doubly even order pattern. Since there
is negligible correlation between the original and encrypted image this method
is robust against any type of crypt attack.",116,6,733,39.47
1708,cryptography,"We present Clio, an information flow control (IFC) system that transparently
incorporates cryptography to enforce confidentiality and integrity policies on
untrusted storage. Clio insulates developers from explicitly manipulating keys
and cryptographic primitives by leveraging the policy language of the IFC
system to automatically use the appropriate keys and correct cryptographic
operations. We prove that Clio is secure with a novel proof technique that is
based on a proof style from cryptography together with standard programming
languages results. We present a prototype Clio implementation and a case study
that demonstrates Clio's practicality.",91,5,655,14.49
1709,cryptography,"In this paper we discuss the Hidden Subgroup Problem (HSP) in relation to
post-quantum group-based cryptography. We review the relationship between HSP
and other computational problems discuss an optimal solution method, and review
the known results about the quantum complexity of HSP. We also overview some
platforms for group-based cryptosystems. Notably, efficient algorithms for
solving HSP in such infinite group platforms are not yet known.",65,5,447,38.01
1710,cryptography,"Public-key cryptography algorithms, especially elliptic curve cryptography
(ECC) and elliptic curve digital signature algorithm (ECDSA) have been
attracting attention from many researchers in different institutions because
these algorithms provide security and high performance when being used in many
areas such as electronic-healthcare, electronic-banking, electronic-commerce,
electronic-vehicular, and electronic-governance. These algorithms heighten
security against various attacks and at the same time improve performance to
obtain efficiencies (time, memory, reduced computation complexity, and energy
saving) in an environment of the constrained source and large systems. This
paper presents detailed and a comprehensive survey of an update of the ECDSA
algorithm in terms of performance, security, and applications.",104,4,825,-6.06
1711,cryptography,"A large number of quantum location verification protocols have been proposed.
All existing protocols in this field are based on symmetric cryptography where
verifiers and the prover use the same secret key. The prover obtains secret key
from different verifiers, in pieces through public channels, which may result
in security compromise. In this paper, we give a formulism to prove
information-theoretic position-based quantum cryptography is possible in
asymmetric quantum setting. We propose a quantum location verification protocol
based on asymmetric quantum cryptographic where two different keys will be
used.",89,6,616,28.03
1712,cryptography,"Based on the detection loophole-free photon key distribution (PKD) compatible
with classical optical systems, an optical key distribution (OKD) protocol is
presented for unconditionally secured cryptography in fiber-optic
communications networks using addressable continuous phase basis, where each
communication channel is composed of paired transmission lines. The
unconditional security in OKD lies in quantum superposition between the paired
lines of each channel. The continuous phase basis in OKD can be applied for
one-time-pad optical cryptography in networks, whose network address capacity
is dependent upon the robustness of OKD to channel noises.",90,4,658,7.19
1713,cryptography,"This paper presents a configurable lattice cryptography processor which
enables quantum-resistant security protocols for IoT. Efficient sampling
architectures, coupled with a low-power SHA-3 core, provide two orders of
magnitude energy savings over software. A single-port RAM-based NTT
architecture is proposed, which provides ~124k-gate area savings. This is the
first ASIC implementation which demonstrates multiple lattice-based protocols
proposed for NIST post-quantum standardization.",61,5,490,22.11
1714,cryptography,"In this article, we have proposed a public key cryptography using Affine-Hill
cipher with a generalized Fibonacci matrix(called multinacci matrix). Also
proposed a key establishment(exchange of key matrix $K=Q_{\lambda}^{k}$ of
order $\lambda\times\lambda$ for encryption-decryption) scheme with the help of
multinacci sequences under prime modulo. In this scheme, instead of exchanging
key matrix, we need to exchange the only pair of numbers $(\lambda, k)$, which
reduces the time complexity as well as space complexity and comes with a large
key-space.",79,4,555,36.32
1715,cryptography,"We study the impact of finite-size effects on the security of thermal one-way
quantum cryptography. Our approach considers coherent/squeezed states at the
preparation stage, on the top of which the sender adds trusted thermal noise.
We compute the key rate incorporating finite-size effects, and we obtain the
security threshold at different frequencies. As expected finite-size effects
deteriorate the performance of thermal quantum cryptography. Our analysis is
useful to quantify the impact of this degradation on relevant parameters like
tolerable attenuation, transmission frequencies at which one can achieve
security.",88,6,624,28.23
1716,cryptography,"In this article, we propose a method to construct self orthogonal matrix,
orthogonal matrix and anti orthogonal matrix over the finite field. Orthogonal
matrices has numerous applications in cryptography, so here we demonstrate the
application of weighted orthogonal matrix into cryptography. Using the proposed
method of construction we see that it is very easy to transmit the private key
and can easily convert the encrypted message into original message and at the
same time it will be difficult to get the key matrix for intruder.",85,4,535,25.83
1717,cryptography,"Researchers in the past have shown that Symmetric key cryptography is
generally considered infeasible and public key cryptography, at times, fails to
provide sufficient security and integrity to data. In contrast to this
prejudice, our paper presents a novel approach that establishes security to
data through encryption techniques like RSA and more importantly it identifies
a randomized path to route messages from source to the destination and ensures
that packets are delivered safely even when intermediate nodes are attacked by
identifying alternate paths between source and the destination.",88,3,597,9.9
1718,cryptography,"In this paper, we propose an elliptic curve key generation processor over
GF(2m) and GF(P) with Network-on-Chip (NoC) design scheme based on binary
scalar multiplication algorithm. Over the Two last decades, Elliptic Curve
Cryptography (ECC) has gained increasing acceptance in the industry and the
academic community. This interest is mainly caused by the same level of
security with relatively small keys provided by ECC comparing to large key size
in Rivest Shamir Adleman (RSA). Parallelism can be utilized in different
hierarchy levels as shown in many publications. By using NoC, a new method with
the reduced latency of point multiplication (with parallel field arithmetic) is
introduced in this paper.",109,6,709,40.89
1719,cryptography,"The families of bijective transformations $G_n$ of affine space $K^n$ over
general commutative ring $K$ of increasing order with the property of stability
will be constructed. Stability means that maximal degree of elements of cyclic
subgroup generated by the transformation of degree $d$ is bounded by $d$. In
the case $K=F_q$ these transformations of $K^n$ can be of an exponential order.
We introduce large groups formed by quadratic transformations and numerical
encryption algorithm protected by secure protocol of Noncommutative
Cryptography. The construction of transformations is presented in terms of
walks on Double Schubert Graphs.",94,6,642,27.01
1720,cryptography,"In this expository article we present an overview of the current
state-of-the-art in post-quantum group-based cryptography. We describe several
families of groups that have been proposed as platforms, with special emphasis
in polycyclic groups and graph groups, dealing in particular with their
algorithmic properties and cryptographic applications. We then, describe some
applications of combinatorial algebra in fully homomorphic encryption. In the
end we discussing several open problems in this direction.",70,5,509,28.33
1721,cryptography,"With the rapid development of quantum computers the currently secure
cryptographic protocols may not stay that way. Quantum mechanics provides means
to create an inherently secure communication channel that is protected by the
laws of physics and not by the computational hardness of certain mathematical
problems. This paper is a non-technical overview of quantum key distribution,
one of the most well-known application of quantum cryptography, a type of
cryptography poised to exploit the laws of quantum mechanics directly.",78,4,527,19.71
1722,cryptography,"Data Encryption Standard (DES) is based on the Feistel block cipher,
developed in 1971 by IBM cryptography researcher Horst Feistel. DES uses 16
rounds of the Feistel structure. But with the changes in recent years, the
internet is starting to be used more to connect devices to each other. These
devices can range from powerful computing devices, such as desktop computers
and tablets, to resource constrained devices, When it comes to these
constrained devices, using a different key for each round cryptography
algorithms fail to provide necessary security and performance.",90,5,576,48.64
1723,cryptography,"Since 2016, NIST has been assessing lightweight encryption methods, and, in
2022, NIST published the final 10: ASCON, Elephant, GIFT-COFB, Grain128-AEAD,
ISAP, Photon-Beetle, Romulus, Sparkle, TinyJambu, and Xoodyak. At the time that
the article was written, NISC announced ASCOn as the chosen method that will be
published as NIST'S lightweight cryptography standard later in 2023. In this
article, we provide a comparison between these methods in terms of energy
efficiency, time for encryption, and time for hashing.",77,4,519,45.39
1724,cryptography,"In this study, a new sort of transform known as (Kuffi- Abbas- Jawad
transform) or KAJ- integral transformation is introduced. We introduce and
explore important KAJ- transformation features and applications in
cryptography. KAJ- transformation is used for encryption and inverse KAJ-
transformation is used for decryption; an example is provided to illustrate the
encryption and decryption of the given data.",60,4,409,34.26
1725,cryptography,"The Discrete Logarithm Problem (DLP) for elliptic curves has been extensively
studied since, for instance, it is the core of the security of cryptosystems
like Elliptic Curve Cryptography (ECC). In this paper, we present an attack to
the DLP for elliptic curves based on its connection to the problem of lifting,
by using the exponential map for elliptic curves and its inverse over $
\mathbb{Z} / p^k \mathbb{Z} $. Additionally, we show that hyperelliptic curves
are resistant to this attack, meaning that these latter curves offer a higher
level of security compared to the classic elliptic curves used in cryptography.",100,4,621,30.23
1726,cryptography,"Threshold digital signatures enable a distributed execution of signature
functionalities and will play a crucial role in the security of emerging
decentralized next-generation networked systems and applications. In this
paper, we provide a comprehensive and systematic survey of threshold and
distributed signatures with advanced features. Our survey encompasses threshold
signatures in conventional and post-quantum cryptography (PQC) settings and
captures custom-design and standard signatures (e.g., conventional NIST and
NIST-PQC). We examine both generic (via secure multi-party computation) and
custom thresholding techniques for a myriad of signature families while
investigating exotic signatures, real-life applications, and potential future
research direction.",97,7,770,1.02
1727,cryptography,"We investigate the link between position-based quantum cryptography (PBQC)
and holography established in [MPS19] using holographic quantum error
correcting codes as toy models. If the ""temporal"" scaling of the AdS metric is
inserted by hand into the toy model via the bulk Hamiltonian interaction
strength we recover a toy model with consistent causality structure. This leads
to an interesting implication between two topics in quantum information: if
position-based cryptography is secure against attacks with small entanglement
then there are new fundamental lower bounds for resources required for one
Hamiltonian to simulate another.",92,4,638,14.93
1728,cryptography,"Device-independent (DI) quantum cryptography aims at providing secure
cryptography with minimal trust in, or characterisation of, the underlying
quantum devices. An essential step in DI protocols is randomness extraction (or
privacy amplification) which requires the honest parties to have a seed of
additional bits with sufficient entropy and statistical independence of any
bits generated during the protocol. In this work we introduce a method for
extraction in DI protocols which does not require a seed and is secure against
computationally unbounded quantum adversary. The key idea is to use the Bell
violation of the raw data, instead of its min-entropy, as the extractor
promise.",104,5,687,19.71
1729,cryptography,"Multivariate Cryptography is one of the main candidates for Post-quantum
Cryptography. Multivariate schemes are usually constructed by applying two
secret affine invertible transformations $\mathcal S,\mathcal T$ to a set of
multivariate polynomials $\mathcal{F}$ (often quadratic). The secret
polynomials $\mathcal{F}$ posses a trapdoor that allows the legitimate user to
find a solution of the corresponding system, while the public polynomials
$\mathcal G=\mathcal S\circ\mathcal F\circ\mathcal T$ look like random
polynomials. The polynomials $\mathcal G$ and $\mathcal F$ are said to be
affine equivalent. In this article, we present a more general way of
constructing a multivariate scheme by considering the CCZ equivalence, which
has been introduced and studied in the context of vectorial Boolean functions.",113,6,816,23.16
1730,cryptography,"A number of questions associated with practical implementations of quantum
cryptography systems having to do with unconditional secrecy, computational
loads and effective secrecy rates in the presence of perfect and imperfect
sources are discussed. The different types of unconditional secrecy, and their
relationship to general communications security, are discussed in the context
of quantum cryptography. In order to actually carry out a quantum cryptography
protocol it is necessary that sufficient computational resources be available
to perform the various processing steps, such as sifting, error correction,
privacy amplification and authentication. We display the full computer machine
instruction requirements needed to support a practical quantum cryptography
implementation. We carry out a numerical comparison of system performance
characteristics for implementations that make use of either weak coherent
sources of light or perfect single photon sources, for eavesdroppers making
individual attacks on the quantum channel characterized by different levels of
technological capability. We find that, while in some circumstances it is best
to employ perfect single photon sources, in other situations it is preferable
to utilize weak coherent sources. In either case the secrecy level of the final
shared cipher is identical, with the relevant distinguishing figure-of-merit
being the effective throughput rate.",198,8,1424,8.91
1731,cryptography,"The implications of sufficiently large quantum computers for widely used
public-key cryptography is well-documented and increasingly discussed by the
security community. An April 2016 report by the National Institute of Standards
and Technology (NIST), notably, calls out the need for new standards to replace
cryptosystems based on integer factorization and discrete logarithm problems,
which have been shown to be vulnerable to Shor's quantum algorithm for prime
factorization. Specifically, widely used RSA, ECDSA, ECDH, and DSA
cryptosystems will need to be replaced by post-quantum cryptography (PQC)
alternatives (also known as quantum-resistant or quantum-safe cryptography).
Failure to transition before sufficiently powerful quantum computers are
realized will jeopardize the security of public key cryptosystems which are
widely deployed within communication protocols, digital signing mechanisms,
authentication frameworks, and more. To avoid this, NIST has actively led a PQC
standardization effort since 2016, leveraging a large and international
research community.
  On January 31-February 1, 2019, the Computing Community Consortium (CCC) held
a workshop in Washington, D.C. to discuss research challenges associated with
PQC migration. Entitled, ""Identifying Research Challenges in Post Quantum
Cryptography Migration and Cryptographic Agility"", participants came from three
distinct yet related communities: cryptographers contributing to the NIST PQC
standards effort, applied cryptographers with expertise in creating
cryptographic solutions and implementing cryptography in real-world settings,
and industry practitioners with expertise in deploying cryptographic standards
within products and compute infrastructures. Discussion centered around two key
themes: identifying constituent challenges in PQC migration and imagining a new
science of ""cryptographic agility"".",245,11,1890,10.03
1732,cryptography,"Quantum computing and quantum communications are exciting new frontiers in
computing and communications. Indeed, the massive investments made by the
governments of the US, China, and EU in these new technologies are not a secret
and are based on the expected potential of these technologies to revolutionize
communications, computing, and security. In addition to several field trials
and hero experiments, a number of companies such as Google and IBM are actively
working in these areas and some have already reported impressive demonstrations
in the past few years. While there is some skepticism about whether quantum
cryptography will eventually replace classical cryptography, the advent of
quantum computing could necessitate the use of quantum cryptography as the
ultimate frontier of secure communications. This is because, with the amazing
speeds demonstrated with quantum computers, breaking cryptographic keys might
no longer be a daunting task in the next decade or so. Hence, quantum
cryptography as the ultimate frontier in secure communications might not be
such a far-fetched idea. It is well known that Heisenberg's Uncertainty
Principle is essentially a ""negative result"" in Physics and Quantum Mechanics.
It turns out that Heisenberg's Uncertainty Principle, one of the most
interesting results in Quantum Mechanics, could be the theoretical basis and
the main scientific principle behind the ultimate frontier in quantum
cryptography or secure communications in conjunction with Quantum Entanglement.",223,9,1520,26.24
1733,cryptography,"While advances in quantum computing promise new opportunities for scientific
advancement (e.g., material science and machine learning), many people are not
aware that they also threaten the widely deployed cryptographic algorithms that
are the foundation of today's digital security and privacy. From mobile
communications to online banking to personal data privacy, literally billions
of Internet users rely on cryptography every day to ensure that private
communications and data stay private. Indeed, the emergence and growth of the
public Internet and electronic commerce was arguably enabled by the invention
of public-key cryptography. The key advantage offered by public-key
cryptography is that it allows two parties who have never communicated
previously to nevertheless establish a secure, private, communication channel
over a non-private network (e.g., the Internet).
  Recent advances in quantum computing signal that we are on the cusp of our
next cryptographic algorithm transition, and this transition to post-quantum
cryptography will be more complicated and impact many more systems and
stakeholders, than any of the prior migrations. This transition represents a
major disruption within the IT industry and will broadly impact nearly every
domain of our digital lives, from global commerce to social media to government
and more. Cryptographic algorithm transitions take time and involve an
extensive coordination effort across many stakeholders who are involved in
building and operating the world's compute infrastructure. By preparing now for
the upcoming transition to these new algorithms, we can ensure a more orderly,
less costly, and minimally disruptive changeover.",244,13,1693,18.59
1734,cryptography,"Starting from the one-way group action framework of Brassard and Yung (Crypto
'90), we revisit building cryptography based on group actions. Several previous
candidates for one-way group actions no longer stand, due to progress both on
classical algorithms (e.g., graph isomorphism) and quantum algorithms (e.g.,
discrete logarithm).
  We propose the general linear group action on tensors as a new candidate to
build cryptography based on group actions. Recent works
(Futorny--Grochow--Sergeichuk, Lin. Alg. Appl., 2019) suggest that the
underlying algorithmic problem, the tensor isomorphism problem, is the hardest
one among several isomorphism testing problems arising from areas including
coding theory, computational group theory, and multivariate cryptography. We
present evidence to justify the viability of this proposal from comprehensive
study of the state-of-art heuristic algorithms, theoretical algorithms, and
hardness results, as well as quantum algorithms.
  We then introduce a new notion called pseudorandom group actions to further
develop group-action based cryptography. Briefly speaking, given a group $G$
acting on a set $S$, we assume that it is hard to distinguish two distributions
of $(s, t)$ either uniformly chosen from $S\times S$, or where $s$ is randomly
chosen from $S$ and $t$ is the result of applying a random group action of
$g\in G$ on $s$. This subsumes the classical decisional Diffie-Hellman
assumption when specialized to a particular group action. We carefully analyze
various attack strategies that support the general linear group action on
tensors as a candidate for this assumption.
  Finally, we establish the quantum security of several cryptographic
primitives based on the one-way group action assumption and the pseudorandom
group action assumption.",261,18,1802,32.43
1735,cryptography,"Two neural networks which are trained on their mutual output bits show a
novel phenomenon: The networks synchronize to a state with identical time
dependent weights. It is shown how synchronization by mutual learning can be
applied to cryptography: secret key exchange over a public channel.",46,3,291,39.67
1736,cryptography,"Artin's braid groups have been recently suggested as a new source for
public-key cryptography. In this paper we propose the first group signature
schemes based on the conjugacy problem, decomposition problem and root problem
in the braid groups which are believed to be hard problems.",45,3,284,48.64
1737,cryptography,"This paper presents an introduction to the Aryabhata algorithm for finding
multiplicative inverses and solving linear congruences, both of which have
applications in cryptography. We do so by the use of the least absolute
remainders. The exposition of the Aryabhata algorithm provided here can have
performance that could exceed what was described recently by Rao and Yang.",57,4,373,35.27
1738,cryptography,"This paper explains the recent developments in security and encryption. The
Butterfly cipher and quantum cryptography are reviewed and compared. Examples
of their relative uses are discussed and suggestions for future developments
considered. In addition application to network security together with a
substantial review of classification of encryption systems and a summary of
security weaknesses are considered.",57,5,414,14.66
1739,cryptography,"This paper modifies Kak's three-stage protocol so that it can guarantee
secure transmission of information. Although avoiding man-in-the-middle attack
is our primary objective in the introduction of classical authentication inside
the three-stage protocol, we also benefit from the inherent advantages of the
chosen classical authentication protocol. We have tried to implement ideas like
key distribution center, session key, time-stamp, and nonce, within the quantum
cryptography protocol.",66,4,491,15.31
1740,cryptography,"In cryptography, encryption is the process of obscuring information to make
it unreadable without special knowledge. This is usually done for secrecy, and
typically for confidential communications. Encryption can also be used for
authentication, digital signatures, digital cash e.t.c. In this paper we are
going to examine and analyse all these topics in detail.",54,7,363,32.39
1741,cryptography,"It has been shown that the predictions of some new phenomena (e.g.,
teleportation and cryptography) are based on some assumptions added to the
quantum-mechanical model or modifying some of its basic axioms. The hitherto
experiments presented as a support of the mentioned phenomena may be hardly
regarded as sufficient, as they may be interpreted alternatively on the basis
of simple interference processes.",62,5,407,25.08
1742,cryptography,"Quantum cryptography could well be the first application of quantum mechanics
at the individual quanta level. The very fast progress in both theory and
experiments over the recent years are reviewed, with emphasis on open questions
and technological issues.",39,3,257,34.76
1743,cryptography,"We study optimal eavesdropping in quantum cryptography with three-dimensional
systems, and show that this scheme is more secure than protocols using
two-dimensional states. We generalize the according eavesdropping
transformation to arbitrary dimensions, and discuss the connection with optimal
quantum cloning.",40,3,311,17.34
1744,cryptography,"We propose a quantum transmission based on bi-photons which are
doubly-entangled both in polarisation and phase. This scheme finds a natural
application in quantum cryptography, where we show that an eventual
eavesdropper is bound to introduce a larger error on the quantum communication
than for a single entangled bi-photon communication, when steeling the same
information.",55,3,376,26.64
1745,cryptography,"We perform a comparison of two protocols for generating a cryptographic key
composed from d-valued symbols: one exploiting a string of independent qubits
and another one utilizing d-level systems prepared in states belonging to d+1
mutually unbiased bases. We show that the protocol based on qubits is optimal
for quantum cryptography, since it provides higher security and higher key
generation rate.",61,3,401,23.6
1746,cryptography,"We prove that in the BB84 quantum cryptography protocol Alice and Bob do not
need to make random bases-choice for each qubit: they can keep the same bases
for entire blocks of qubits. It suffices that the raw key consists of many such
qubit-blocks. The practical advantage of reducing the need for random number is
emphasized.",56,4,326,69.41
1747,cryptography,"A new quantum cryptography protocol, based on all unselected states of a
qubit as a sort of alphabet with continuous set of letters, is proposed. Its
effectiveness is calculated and shown to be essentially higher than those of
the other known protocols.",42,3,253,41.7
1748,cryptography,"We propose and discuss a specific scheme allowing to realize a Quantum
Cryptography qutrit protocol. This protocol exploits the polarization
properties of single frequency and single spatial mode biphotons.",29,3,206,22.92
1749,cryptography,"Quantum cryptography is reviewed, first using entanglement both for the
intuition and for the experimental realizations. Next, the implementation is
simplified in several steps until it becomes practical. At this point
entanglement has disappeared. This method can be seen as a lesson of Applied
Physics. Finally, security issues, e.g. photon number splitting attacks, and
counter-measures are discussed.",57,8,404,36.45
1750,cryptography,"Though all-or-nothing oblivious transfer and one-out-of-two oblivious
transfer are equivalent in classical cryptography, we here show that due to the
nature of quantum cryptography, a protocol built upon secure quantum
all-or-nothing oblivious transfer cannot satisfy the rigorous definition of
quantum one-out-of-two oblivious transfer.",43,2,337,-14.48
1751,cryptography,Elementary review article on quantum cryptography.,6,2,50,-27.68
1752,cryptography,"A conjugate code pair is defined as a pair of linear codes such that one
contains the dual of the other. The conjugate code pair represents the
essential structure of the corresponding Calderbank-Shor-Steane (CSS) quantum
code. It is argued that conjugate code pairs are applicable to quantum
cryptography in order to motivate studies on conjugate code pairs.",57,4,359,52.19
1753,cryptography,"We describe how to modify the BB84 protocol for quantum cryptography in order
to make it deterministic. We study both theoretical and experimental aspects of
this issue, showing that the new scheme is as secure as the old one, more
efficient on small-scale distances, and within the range of current technology.",51,3,311,37.13
1754,cryptography,"This paper analyzes the security of a recently-proposed signal encryption
scheme based on a filter bank. A very critical weakness of this new signal
encryption procedure is exploited in order to successfully recover the
associated secret key.",37,3,242,27.32
1755,cryptography,"This note considers reciprocal of primes in binary representation and shows
that the conjecture that 0s exceed 1s in most cases continues to hold for
primes less one million. The conjecture has also been tested for ternary
representation with similar results. Some applications of this result to
cryptography are discussed.",50,4,323,46.06
1756,cryptography,"We introduce a problem setting which we call ``the freedom fighters'
problem''. It subtly differs from the prisoners' problem. We propose a
steganographic method that allows Alice and Bob to fool Wendy the warden in
this setting. Their messages are hidden in encryption keys. The recipient has
no prior knowledge of these keys, and has to cryptanalyze ciphertexts in order
to recover them. We show an example of the protocol and give a partial security
analysis.",76,7,462,58.58
1757,cryptography,"This paper presents a recursive hiding scheme for 2 out of 3 secret sharing.
In recursive hiding of secrets, the user encodes additional information about
smaller secrets in the shares of a larger secret without an expansion in the
size of the latter, thereby increasing the efficiency of secret sharing. We
present applications of our proposed protocol to images as well as text.",63,4,380,41.7
1758,cryptography,"Braids groups provide an alternative to number theoretic public cryptography
and can be implemented quite efficiently. The paper proposes five signature
schemes: Proxy Signature, Designated Verifier, Bi-Designated Verifier,
Designated Verifier Proxy Signature And Bi-Designated Verifier Proxy Signature
scheme based on braid groups. We also discuss the security aspects of each of
the proposed schemes.",54,4,402,10.91
1759,cryptography,"The discrete logarithm problem is one of the backbones in public key
cryptography. In this paper we study the discrete logarithm problem in the
group of circulant matrices over a finite field. This gives rise to secure and
fast public key cryptosystems.",42,4,253,65.73
1760,cryptography,"We report experimental studies on the effect of the depolarizing quantum
channel on weak-pulse BB84 and SARG04 quantum cryptography. The experimental
results show that, in real world conditions in which channel depolarization
cannot be ignored, BB84 should perform better than SARG04.",41,3,284,33.75
1761,cryptography,"This paper summarizes basic properties of PPTs and shows that each PPT
belongs to one of six different classes. Mapping an ordered sequence of PPTs
into a corresponding sequence of these six classes makes it possible to use
them in cryptography. We pose problems whose solution would facilitate such
cryptographic application.",51,4,326,45.76
1762,cryptography,"We propose a novel high-speed stream cipher encryption scheme based on the
true random key generated by a chaotic semiconductor laser. A 5-Gbits/s
non-return-to-zero plaintext is successfully encrypted and decrypted using this
cryptography. The scheme can be applied in the areas of real-time high-speed
physical encryption.",46,4,324,30.57
1763,cryptography,"We present an approach to generalization of practical Identity-Based
Encryption scheme of Boneh and Franklin. In particular we show how the protocol
could be used on finite modular lattices and as a special case on vector spaces
over finite field. The original proof of security for this protocol does not
hold in this general algebraic structure, thus this is still a work in
progress.",64,4,386,49.86
1764,cryptography,"This paper investigates the randomness properties of a function of the
divisor pairs of a natural number. This function, the antecedents of which go
to very ancient times, has randomness properties that can find applications in
cryptography, key distribution, and other problems of computer science. It is
shown that the function is aperiodic and it has excellent autocorrelation
properties.",59,4,391,34.56
1765,cryptography,"In this work, a new digital signature based on elliptic curves is presented.
We established its efficiency and security. The method, derived from a variant
of ElGamal signature scheme, can be seen as a secure alternative protocol if
known systems are completely broken.",43,4,269,48.5
1766,cryptography,"In this paper we present a new efficient algorithm for factoring the RSA and
the Rabin moduli in the particular case when the difference between their two
prime factors is bounded. As an extension, we also give some theoretical
results on factoring integers.",43,3,258,41.19
1767,cryptography,"This paper presents results on generalized public key cryptography with
exponentials modulo primes and composite numbers where the mapping is not
one-to-one and the uniqueness is achieved by additional side information. Such
transformations may be used for oblivious transfer and generate events of
specific probabilities.",45,3,322,23.26
1768,cryptography,"A method for non-abelian Cramer-Shoup cryptosystem is presented. The role of
decision and search is explored, and the platform of solvable/polycyclic group
is suggested. In the process we review recent progress in non-abelian
cryptography and post some open problems that naturally arise from this path of
research.",47,4,315,55.54
1769,cryptography,"This paper presents 10-point and 12-point versions of the recently introduced
number theoretic Hilbert (NHT) transforms. Such transforms have applications in
signal processing and scrambling. Polymorphic solutions with respect to
different moduli for each of the two cases have been found. The multiplicity of
solutions for the same moduli increases their applicability to cryptography.",54,5,386,32.39
1770,cryptography,"This paper presents new results in the theory of number theoretic Hilbert
(NHT) transforms. New polymorphic solutions have been found for the 14-point
and 16-point transforms. Several transform pairs are computed and solutions
found for which the sequence and the transform have the same shape. The
multiplicity of solutions for the same moduli increases their applicability to
cryptography.",58,5,391,48.3
1771,cryptography,"This paper presents a class of random orthogonal sequences associated with
the number theoretic Hilbert transform. We present a constructive procedure for
finding the random sequences for different modulus values. These random
sequences have autocorrelation function that is zero everywhere excepting at
the origin. These sequences may be used as keys and in other cryptography
applications.",56,5,391,31.89
1772,cryptography,"This survey provides a comparative overview of code-based signature schemes
with respect to security and performance. Furthermore, we explicitly describe
serveral code-based signature schemes with additional properties such as
identity-based, threshold ring and blind signatures.",35,3,279,19.87
1773,cryptography,"In this work is proposed a method using orthogonal matrix transform
properties to encrypt and decrypt a message. It will be showed how to use
matrix functions to create complex encryptions. Because orthogonal matrix are
always diagonalizable on R, and the exponential of a diagonal matrix is easy to
compute, the exponential of orthogonal matrix will be used to encrypt text
messages.",62,4,384,42.0
1774,cryptography,"This paper presents a survey of key distribution schemes for wireless sensor
networks. This survey includes the new approach of key distribution using the
piggy bank method. Different Network architectures and different key
pre-distribution schemes are described. The survey includes the use of the
piggy bank approach to cryptography in which part of the key is pre-distributed
and the remainder is varied in the application.",65,5,426,46.47
1775,cryptography,"Gaussian elimination is used in special linear groups to solve the word
problem. In this paper, we extend Gaussian elimination to unitary groups. These
algorithms have an application in building a public-key cryptosystem, we
demonstrate that.",36,4,242,50.84
1776,cryptography,"We propose a novel proof technique that can be applied to attack a broad
class of problems in computational complexity, when switching the order of
universal and existential quantifiers is helpful. Our approach combines the
standard min-max theorem and convex approximation techniques, offering
quantitative improvements over the standard way of using min-max theorems as
well as more concise and elegant proofs.",61,3,412,23.6
1777,cryptography,"Xinyu et al. proposed a public key exchange protocol, which is based on the
NTRU-lattice based cryptography. In this paper, we show how Xinyu et al.'s
NTRU-KE: A lattice based key exchange protocol can be broken, under the
assumption that a man-in-the middle attack is used for extracting private keys
of users who participate in the key exchange protocol.",59,5,356,64.91
1778,cryptography,"In this paper, we present a simple bare-bones solution of a Zero-Knowledge
authentication protocol which uses non-commutative algebra and a variation of
the generalized symmetric decomposition problem (GSDP) as a one-way function.
The cryptographic security is assured as long the GSDP problem is
computationally hard to solve in non-commutative algebraic structures and
belongs currently to the PQC category as no quantum computer attack is likely
to exists.",67,3,459,3.63
1779,cryptography,"In this research work, security concepts are formalized in steganography, and
the common paradigms based on information theory are replaced by another ones
inspired from cryptography, more practicable are closer than what is usually
done in other cryptographic domains. These preliminaries lead to a first proof
of a cryptographically secure information hiding scheme.",53,3,368,19.2
1780,cryptography,"We present a key recovery attack against Y. Wang's Random Linear Code
Encryption (RLCE) scheme recently submitted to the NIST call for post-quantum
cryptography. This attack recovers the secret key for all the short key
parameters proposed by the author.",40,4,254,57.98
1781,cryptography,"In this short note, we develop a novel idea of a bilinear cryptosystem using
the discrete logarithm problem in matrices. These matrices come from a linear
representation of a finite $p$-group of class 2. We discuss an example at the
end.",41,4,237,57.57
1782,cryptography,This paper has been withdrawn for modification.,7,2,47,38.99
1783,cryptography,"We explore further the hardness of the non-dual discrete variant of the
Ring-LWE problem for various number rings, give improved attacks for certain
rings satisfying some additional assumptions, construct a new family of
vulnerable Galois number fields, and apply some number theoretic results on
Gauss sums to deduce the likely failure of these attacks for 2-power cyclotomic
rings and unramified moduli.",61,2,405,-7.37
1784,cryptography,"A new approach to discretization of the Duffing equation is presented.
Integrable discrete maps are obtained by using well-studied encrypting
operations in elliptic curve cryptography and, therefore, they do not depend
upon standard small parameter assumption.",36,3,260,27.83
1785,cryptography,"Cybersecurity awareness can be viewed as the level of appreciation,
understanding or knowledge of cybersecurity or information security aspects.
Such aspects include cognizance of cyber risks and threats, but also
appropriate protection measures.",33,3,246,3.97
1786,cryptography,"We describe random processes (with binary alphabet) whose entropy is less
than 1 (per letter), but they mimic true random process, i.e., by definition,
generated sequence can be interpreted as the result of the flips of a fair coin
with sides that are labeled 0 and 1. It gives a possibility to construct Random
Number Generators which possess theoretical guarantees. This, in turn, is
important for applications such as those in cryptography.",72,6,443,44.75
1787,cryptography,"We consider the $k$-error linear complexity of binary sequences derived from
Eluer quotients modulo $2p$ ($p>3$ is an odd prime), recently introduced by J.
Zhang and C. Zhao. We adopt certain decimal sequences to determine the values
of $k$-error linear complexity for all $k>0$. Our results indicate that such
sequences have good stability from the viewpoint of cryptography.",58,6,376,48.3
1788,cryptography,"A homomorphic public key crypto-scheme based on the Boolean Satisfiability
Problem is proposed. The public key is a SAT formula satisfied by the private
key. Probabilistic encryption generates functions implied to be false by the
public key XOR the message bits. A zero-knowledge proof is used to provide
signatures.",49,5,316,42.07
1789,cryptography,"We study the isogenies of certain abelian varieties over finite fields with
non-commutative endomorphism algebras with a view to potential use in
isogeny-based cryptography. In particular, we show that any two such abelian
varieties with endomorphism rings maximal orders in the endomorphism algebra
are linked by a cyclic isogeny of prime degree.",52,3,347,28.17
1790,cryptography,"We show (almost) separation between certain important classes of Boolean
functions. The technique that we use is to show that the total influence of
functions in one class is less than the total influence of functions in the
other class. In particular, we show (almost) separation of several classes of
Boolean functions which have been studied in the coding theory and cryptography
from classes which have been studied in combinatorics and complexity theory.",73,4,459,38.35
1791,cryptography,"In a previous paper we generalized the definition of a multilinear map to
arbitrary groups and introduced two multiparty key-exchange protocols using
nilpotent groups. In this paper we have a closer look at the protocols and will
address some incorrect cryptanalysis which have been proposed.",45,3,292,31.72
1792,cryptography,"This paper considers a federated learning system composed of a central
coordinating server and multiple distributed local workers, all having access
to trusted execution environments (TEEs). In order to ensure that the untrusted
workers correctly perform local learning, we propose a new TEE-based approach
that also combines techniques from applied cryptography, smart contract and
game theory. Theoretical analysis and implementation-based evaluations show
that, the proposed approach is secure, efficient and practical.",71,4,522,13.58
1793,cryptography,"Security reputation metrics (aka. security metrics) quantify the security
levels of organization (e.g., hosting or Internet access providers) relative to
comparable entities. They enable benchmarking and are essential tools for
decision and policy-making in security, and may be used to govern and steer
responsible parties towards investing in security when economic or other
decision-making factors may drive them to do otherwise.",61,6,432,13.65
1794,cryptography,"In 1991 the first public key protocol involving automaton groups has been
proposed. In this paper we give a survey about algorithmic problems around
automaton groups which may have potential applications in cryptography. We then
present a new public key protocol based on the conjugacy search problem in some
families of automaton groups. At the end we offer open problems that could be
of interest of group theorists and computer scientists in this direction.",74,5,460,44.24
1795,cryptography,"A recent publication by the NSA assessing the usability of quantum
cryptography has generated significant attention, concluding that this
technology is not recommended for use. Here, we reply to this criticism and
argue that some of the points raised are unjustified, whereas others are
problematic now but can be expected to be resolved in the foreseeable future.",57,3,364,25.63
1796,cryptography,"The cryptosystem RSA is a very popular cryptosystem in the study of
Cryptography. In this article, we explore how the idea of a primitive mth root
of unity in a ring can be integrated into the Discrete Fourier Transform,
leading to the development of new cryptosystems known as RSA-DFT and RSA-HGR.",51,3,298,45.59
1797,cryptography,"These notes are a brief introduction to the RSA algorithm and modular
arithmetic. They are intended for an undergraduate audience.",20,3,130,44.41
1798,cryptography,The paper was retracted.,4,2,24,50.5
1799,cryptography,"In this tutorial, selected topics of cryptology and of computational
complexity theory are presented. We give a brief overview of the history and
the foundations of classical cryptography, and then move on to modern
public-key cryptography. Particular attention is paid to cryptographic
protocols and the problem of constructing the key components of such protocols
such as one-way functions. A function is one-way if it is easy to compute, but
hard to invert. We discuss the notion of one-way functions both in a
cryptographic and in a complexity-theoretic setting. We also consider
interactive proof systems and present some interesting zero-knowledge
protocols. In a zero-knowledge protocol one party can convince the other party
of knowing some secret information without disclosing any bit of this
information. Motivated by these protocols, we survey some complexity-theoretic
results on interactive proof systems and related complexity classes.",140,9,950,28.33
1800,cryptography,"We explain how a differential fault analysis (DFA) works on AES 128, 192 or
256 bits.",16,2,85,72.16
1801,cryptography,I transform the trapdoor problem of HFE into a linear algebra problem.,12,2,70,50.84
1802,cryptography,"This article describes in depth several ways of exploiting buffer overflows
in the UNIX operating systems.",16,2,106,38.32
1803,cryptography,"In this document, a formal approach to encrypt, decrypt, transmit and receive
information using colors is explored. A piece of information consists of set of
symbols with a definite property imposed on the generating set. The symbols are
usually encoded using ascii scheme. A linear to 3d transformation is presented.
The change of axis from traditional xyz to rgb is highlighted and its effect
are studied. A point in this new axis is then represented as a unique color and
a vector or matrix is associated with it, making it amenable to standard vector
or matrix operations. A formal notion on hybrid cryptography is introduced as
the algorithm lies on the boundary of symmetric and asymmetric cryptography. No
discussion is complete, without mentioning reference to communication aspects
of secure information in a channel. Transmission scheme pertaining to light as
carrier is introduced and studied. Key-exchanges do not come under the scope of
current frame of document.",156,11,976,47.18
1804,cryptography,"We examine the security of existing radio navigation protocols and attempt to
define secure, scalable replacements.",16,2,115,4.47
1805,cryptography,"The binomial multichannel algorithm is proposed. Some its properties are
discussed.",11,3,83,23.59
1806,cryptography,"We describe a practical implementation of the modular eballot system proposed
in ref.[1]",13,2,88,24.44
1807,cryptography,"We present a perfectly secure cipher system based on the concept of fake bits
which has never been used in either classical or quantum cryptography.",25,2,148,46.1
1808,cryptography,"The paper has been withdrawn by the author since the protocol is not new. It
is just the oldest version of BB84.",22,3,112,85.69
1809,cryptography,"This note presents a practical cryptography protocol for transmitting
classical and quantum information secretly and directly.",16,2,126,4.47
1810,cryptography,"BBN, Harvard, and Boston University are building the DARPA Quantum Network,
the world's first network that delivers end-to-end network security via
high-speed Quantum Key Distribution, and testing that Network against
sophisticated eavesdropping attacks. The first network link has been up and
steadily operational in our laboratory since December 2002. It provides a
Virtual Private Network between private enclaves, with user traffic protected
by a weak-coherent implementation of quantum cryptography. This prototype is
suitable for deployment in metro-size areas via standard telecom (dark) fiber.
In this paper, we introduce quantum cryptography, discuss its relation to
modern secure networks, and describe its unusual physical layer, its
specialized quantum cryptographic protocol suite (quite interesting in its own
right), and our extensions to IPsec to integrate it with quantum cryptography.",126,6,902,20.52
1811,cryptography,"We discuss foundation of quantum mechanics (interpretations, superposition,
principle of complementarity, locality, hidden variables) and quantum
information theory.",18,2,165,-48.32
1812,cryptography,This paper has been withdrawn.,5,2,30,83.32
1813,cryptography,"A single photon source (SPS) is very important for quantum computation. In
particular, it is essential for secured quantum cryptography. But there is no
perfect SPS in reality. Therefore, probabilistic SPS where probability of
simultaneous emission of two, three, four and more photon is less than the
emission of a single photon are used. Since classical photon always comes in
bunch, the required single photon source must be nonclassical. In the
well-known antibunched state the rate of simultaneous emission of two photon is
less than that of single photon. But the requirement of quantum cryptography is
a multiphoton version of the antibunched state or the higher order antibunched
state. Recently we have reported a mathematical criterion for higher order
antibunching. Here we have shown that any proposal for SPS to be used in
quantum cryptography should satisfy this criterion. We have studied four wave
mixing as a possible candidate of single photon source.",153,11,969,47.49
1814,cryptography,This paper has been withdrawn,5,1,29,83.32
1815,cryptography,This paper has been withdrawn,5,1,29,83.32
1816,cryptography,This paper has been withdrawn,5,1,29,83.32
1817,cryptography,"A survey on algorithms for computing discrete logarithms in Jacobians of
curves over finite fields.",15,2,99,47.79
1818,cryptography,"Recently, Rawat and Saxena proposed a method for protecting data using
``Disclaimer Statement''. This paper presents some issues and several flaws in
their proposal.",24,3,165,50.84
1819,cryptography,Ethemba provides a framework and demonstrator for TPM applications.,9,2,67,36.96
1820,cryptography,"Some open questions related to prime reciprocal digit frequencies with
potential applications to cryptography are presented.",16,2,124,4.47
1821,cryptography,"A new protocol for 1-2 (String) Oblivious Transfer is proposed. The protocol
uses 5 rounds of message exchange.",18,3,111,62.34
1822,cryptography,A recursive random number generator using prime reciprocals is described.,10,2,73,10.56
1823,cryptography,"We consider the security of continuous-variable quantum cryptography as we
approach the classical-limit, i.e., when the unknown preparation noise at the
sender's station becomes significantly noisy or thermal (even by as much as
10,000 times the variance of the vacuum mode). We show that, provided the
channel transmission losses do not exceed 50%, the security of quantum
cryptography is not dependent on the channel transmission, and is therefore,
incredibly robust against significant amounts of excess preparation noise. We
extend these results to consider for the first time quantum cryptography at
wavelengths considerably longer than optical and find that regions of security
still exist all the way down to the microwave.",110,6,730,35.1
1824,cryptography,"In this article, we review several aspects of composability in the context of
quantum cryptography. The first part is devoted to key distribution. We discuss
the security criteria that a quantum key distribution protocol must fulfill to
allow its safe use within a larger security application (e.g., for secure
message transmission). To illustrate the practical use of composability, we
show how to generate a continuous key stream by sequentially composing rounds
of a quantum key distribution protocol. In a second part, we take a more
general point of view, which is necessary for the study of cryptographic
situations involving, for example, mutually distrustful parties. We explain the
universal composability framework and state the composition theorem which
guarantees that secure protocols can securely be composed to larger
applications",127,8,845,27.72
1825,cryptography,"This expository essay introduces randomness and computation to a lay
audience.",11,2,78,1.09
1826,cryptography,"Randomized algorithm that achieves multi-valued Byzantine agreement with high
probability, and achieves optimal complexity.",14,2,123,-1.96
1827,cryptography,"In this note, we present a complete characterization of the utility metrics
that allow for non-trivial differential privacy guarantees.",19,2,135,18.35
1828,cryptography,"Certificateless public key cryptography simplifies the complex certificate
management in the traditional public key cryptography and resolves the key
escrow problem in identity-based cryptography. Many certificateless
authenticated key agreement protocols using bilinear pairings have been
proposed. But the relative computation cost of the pairing is approximately
twenty times higher than that of the scalar multiplication over elliptic curve
group. Recently, several certificateless authenticated key agreement protocols
without pairings were proposed to improve the performance. In this paper, we
propose a new certificateless authenticated key agreement protocol without
pairing. The user in our just needs to compute five scale multiplication to
finish the key agreement. We also show the proposed protocol is secure in the
random oracle model.",117,8,850,20.68
1829,cryptography,"Nowadays security in communication is increasingly important to the network
communication because many categories of data are required restriction on
authorization of access, modify, delete and insert. Quantum cryptography is one
of the solutions that use property of polarization to ensure that transmitted
data is not tampered. The research paper provides the mechanism that enhances
the data security in quantum cryptography during exchange of information. In
first phase detailed explanation of Quantum key distribution's BB84 protocol is
given. BB84 protocol is used as the basis for the mechanism. In next phase the
proposed mechanism is explained. The proposed mechanism combines BB84 protocol
at two levels, from sender to receiver and then from receiver to sender.
Moreover, a logic circuit is used to combine the bits hence to reduce the
probability of eavesdropping. The key obtained can be used to exchange the
information securely further it can help in encryption and decryption of
crucial data. Double level BB84 mechanism will help in information
reconciliation as well as privacy amplification. In future the proposed
mechanism will be very beneficial where unconditional security is required
during key and other secret information exchange",189,11,1258,28.64
1830,cryptography,"This essay discusses the main privacy, security and trustability issues with
the Internet of Things.",15,2,100,30.87
1831,cryptography,"We discuss a procedure, which should be called Lenstra's fix, for producing
secure RSA moduli even when the random number generation is very poor.",24,2,146,55.58
1832,cryptography,"The interleaving of chaos and cryptography has been the aim of a large set of
works since the beginning of the nineties. Many encryption proposals have been
introduced to improve conventional cryptography. However, many proposals
possess serious problems according to the basic requirements for the secure
exchange of information. In this paper we highlight some of the main problems
of chaotic cryptography by means of the analysis of a very recent chaotic
cryptosystem based on a one round Substitution Permutation Network. More
specifically, we show that it is not possible to avoid the security problems of
that encryption architecture just by including a chaotic system as core of the
derived encryption system.",112,6,716,40.28
1833,cryptography,"Developed structural scheme implementation of an integrated security and
formulated principles for the creation and development of an effective system
of information security.",23,2,175,-11.1
1834,cryptography,"The article discribe methods of verifing the conditions of access in computer
systems based on Take-Grant protection model.",18,2,123,36.28
1835,cryptography,"Cryptographic mechanisms are used in a wide range of applications, including
email clients, web browsers, document and asset management systems, where
typical users are not cryptography experts. A number of empirical studies have
demonstrated that explicit, user-visible cryptographic mechanisms are not
widely used by non-expert users, and as a result arguments have been made that
cryptographic mechanisms need to be better hidden or embedded in end-user
processes and tools. Other mechanisms, such as HTTPS, have cryptography
built-in and only become visible to the user when a dialogue appears due to a
(potential) problem. This paper surveys deployed and potential technologies in
use, examines the social and legal context of broad classes of users, and from
there, assesses the value and issues for those users.",124,5,818,31.55
1836,cryptography,"The goal of this chapter is to present a survey of homomorphic encryption
techniques and their applications. After a detailed discussion on the
introduction and motivation of the chapter, we present some basic concepts of
cryptography. The fundamental theories of homomorphic encryption are then
discussed with suitable examples. The chapter then provides a survey of some of
the classical homomorphic encryption schemes existing in the current
literature. Various applications and salient properties of homomorphic
encryption schemes are then discussed in detail. The chapter then introduces
the most important and recent research direction in the filed - fully
homomorphic encryption. A significant number of propositions on fully
homomorphic encryption is then discussed. Finally, the chapter concludes by
outlining some emerging research trends in this exicting field of cryptography.",127,9,888,30.06
1837,cryptography,"Consider a protocol in which Belinda seals a (classical) message. She gives
the resulting sealed message to Charlie, who can either unseal and read the
message or return it unopened to Belinda. If he returns it unopened, Belinda
should be able to verify that Charlie neither read the message nor made a copy
that would allow him to read it later. Such a protocol is impossible with
classical cryptography: Charlie can copy a message and do anything he likes to
that copy without damaging the original. With quantum cryptography, on the
other hand, the no cloning theorem implies that Charlie cannot simply copy a
message and unseal the copy.
  Abstract In this paper, I prove that any conventional quantum cryptographic
protocol can give at best a very weak security guarantee. However, quantum
cryptography in conjunction with classical functions that can only be inverted
by humans (i.e. CAPTCHAs) can potentially give exponential security.",152,10,942,43.73
1838,cryptography,"In general, DRM (Digital Rights Management) system is responsible for the
safe distribution of digital content, however, DRM system is achieved with
individual function modules of cryptography, watermarking and so on. In this
typical system flow, it has a problem that all original digital contents are
temporarily disclosed with perfect condition via decryption process. In this
paper, we propose the combination of the differential codes and fragile
fingerprinting (DCFF) method based on incomplete cryptography that holds
promise for a better compromise between practicality and security for emerging
digital rights management applications. Experimental results with simulation
confirmed that DCFF keeps compatibility with standard JPEG codec, and revealed
that the proposed method is suitable for DRM in the network distribution
system.",119,5,840,15.85
1839,cryptography,"This is an unscientific introduction to basic radio frequency system OPSEC
aspects that I have found to be overlooked and lacking in high security system
deployments that may have benefited from them.",32,2,200,22.08
1840,cryptography,This article summarizes recent trends in mobile biometrics.,8,2,59,29.52
1841,cryptography,"We propose a set of benchmarks for evaluating the practicality of software
obfuscators which rely on provably-secure methods for functional obfuscation.",21,2,152,7.86
1842,cryptography,"One of the most important consideration techniques when one want to solve the
protecting of digital signal is the golden matrix. The golden matrices can be
used for creation of a new kind of cryptography called the golden cryptography.
Many research papers have proved that the method is very fast and simple for
technical realization and can be used for cryptographic protection of digital
signals. In this paper, we introduce a technique of encryption based on
combination of haar wavelet and golden matrix. These combinations carry out
after compression data by adaptive Huffman code to reduce data size and remove
redundant data. This process will provide multisecurity services. In addition
Message Authentication Code (MAC) technique can be used to provide
authentication and the integrity of this scheme. The proposed scheme is
accomplished through five stages, the compression data, key generation,
encryption stage, the decryption stage and decompression at communication ends.",150,9,986,43.93
1843,cryptography,"We explore the emerging field of {\em Cybersecurity Dynamics}, a candidate
foundation for the Science of Cybersecurity.",17,2,119,11.92
1844,cryptography,We argue that emergent behavior is inherent to cybersecurity.,9,2,61,11.58
1845,cryptography,We discuss a matrix public key cryptosystem and its numerical implementation.,11,2,77,18.01
1846,cryptography,Not really.,2,2,11,35.61
1847,cryptography,"The recent progress in DNA sequencing will probably revolutionize the world
of electronic. Hence, we went from DNA sequencing that only research centers
could realize, to portable, tiny and inexpensive tools. So, it is likely that
in a few years these DNA sequencers will be included in our smartphones.
  The purpose of this paper is to support this revolution, by using the DNA
cryptography, hash functions and social networks. The first application will
introduce a mutual entity authentication protocol in order to help waifs,
refugees, and victims of human trafficking to find their biological parents
online.
  The second application will also use the DNA cryptography and the social
networks to protect whistleblowers' actions. For example, this method will
allow whistleblowers to securely broadcast on social networks, their
information with one grape.",131,8,861,44.03
1848,cryptography,"We show that defensive distillation is not secure: it is no more resistant to
targeted misclassification attacks than unprotected neural networks.",21,2,146,16.32
1849,cryptography,Is secure deletion of data still a problem?,8,1,43,71.82
1850,cryptography,"Learning with Errors is one of the fundamental problems in computational
learning theory and has in the last years become the cornerstone of
post-quantum cryptography. In this work, we study the quantum sample complexity
of Learning with Errors and show that there exists an efficient quantum
learning algorithm (with polynomial sample and time complexity) for the
Learning with Errors problem where the error distribution is the one used in
cryptography. While our quantum learning algorithm does not break the LWE-based
encryption schemes proposed in the cryptography literature, it does have some
interesting implications for cryptography: first, when building an LWE-based
scheme, one needs to be careful about the access to the public-key generation
algorithm that is given to the adversary; second, our algorithm shows a
possible way for attacking LWE-based encryption by using classical samples to
approximate the quantum sample state, since then using our quantum learning
algorithm would solve LWE.",151,4,1007,11.96
1851,cryptography,"We introduce a framework for graphical security proofs in device-independent
quantum cryptography using the methods of categorical quantum mechanics. We are
optimistic that this approach will make some of the highly complex proofs in
quantum cryptography more accessible, facilitate the discovery of new proofs,
and enable automated proof verification. As an example of our framework, we
reprove a previous result from device-independent quantum cryptography: any
linear randomness expansion protocol can be converted into an unbounded
randomness expansion protocol. We give a graphical proof of this result, and
implement part of it in the Globular proof assistant.",96,5,666,13.28
1852,cryptography,"The conventional cryptography solutions are ill-suited to strict memory, size
and power limitations of resource-constrained devices, so lightweight
cryptography solutions have been specifically developed for this type of
applications. In this domain of cryptography, the term lightweight never refers
to inadequately low security, but rather to establishing the best balance to
maintain sufficient security. This paper presents the first comprehensive
survey evaluation of lightweight block ciphers in terms of their speed, cost,
performance, and balanced efficiency in hardware implementation, and
facilitates the comparison of studied ciphers in these respects. The cost of
lightweight block ciphers is evaluated with the metric of Gate Equivalent
(Fig.1), their speed with the metric of clock-cycle-per-block (Fig.2), their
performance with the metric of throughput (Fig.3) and their balanced efficiency
with the metric of Figure of Merit (Fig.4). The results of these evaluations
show that SIMON, SPECK, and Piccolo are the best lightweight block ciphers in
hardware implementation.(Abstract)",152,10,1096,35.27
1853,cryptography,"Several recent works have proposed and implemented cryptography as a means to
preserve privacy and security of patients health data. Nevertheless, the
weakest point of electronic health record (EHR) systems that relied on these
cryptographic schemes is key management. Thus, this paper presents the
development of privacy and security system for cryptography-based-EHR by taking
advantage of the uniqueness of fingerprint and iris characteristic features to
secure cryptographic keys in a bio-cryptography framework. The results of the
system evaluation showed significant improvements in terms of time efficiency
of this approach to cryptographic-based-EHR. Both the fuzzy vault and fuzzy
commitment demonstrated false acceptance rate (FAR) of 0%, which reduces the
likelihood of imposters gaining successful access to the keys protecting
patients protected health information. This result also justifies the
feasibility of implementing fuzzy key binding scheme in real applications,
especially fuzzy vault which demonstrated a better performance during key
reconstruction.",148,7,1074,21.02
1854,cryptography,"In this paper we present the Sampling Privacy mechanism for privately
releasing personal data. Sampling Privacy is a sampling based privacy mechanism
that satisfies differential privacy.",26,3,186,15.98
1855,cryptography,"In this paper, we have introduced the notion of ""Principle of Need-to- Act"".
This principle is essential towards developing secure systems, security
solutions and analyzing security of a solution.",29,3,196,22.92
1856,cryptography,"This paper presents applicability of Strong Stationary Times (SST) techniques
in the area of cryptography. The applicability is in three areas:
  *) Propositions of a new class of cryptographic algorithms (pseudo-random
permutation generators) which do not run for the predefined number of steps.
Instead, these algorithms stop according to a stopping rule defined as SST, for
which one can obtain provable properties:
  *** results are perfect samples from uniform distribution,
  *** immunity to timing attacks (no information about the resulting
permutation leaks through the information about the number of steps SST
algorithm
  *) We show how one can leverage properties of SST-based algorithms to
construct an implementation (of a symmetric encryption scheme) which is immune
to the timing-attack by reusing implementations which are not secure against
timing-attacks. In symmetric key cryptography researchers mainly focus on
constant time (re)implementations. Our approach goes in a different direction
and explores ideas of input masking. *) Analysis of idealized (mathematical)
models of existing cryptographic schemes -- i.e., we improve a result by
Mironov ((Not So) Random Shuffles of RC4; Advances in Cryptology -- CRYPTO
2002)",181,8,1241,29.28
1857,cryptography,"This is a companion report to Bittau et al. We restate and prove security of
the Stash Shuffle.",18,3,95,70.8
1858,cryptography,"In this paper, we present Velocity, a decentralized market deployed on
Ethereum for trading a custom type of derivative option. To enable the smart
contract to work, we also implement a price fetching tool called PriceGeth. We
present this as a case study, noting challenges in development of the system
that might be of independent interest to whose working on smart contract
implementations. We also apply recent academic results on the security of the
Solidity smart contract language in validating our codes security. Finally, we
discuss more generally the use of smart contracts in modelling financial
derivatives.",97,6,619,43.32
1859,cryptography,"Quantum cryptography has attracted much attention in recent years. In most
existing quantum cryptographic protocols, players usually need the full quantum
power of generating, manipulating or measuring quantum states. Semiquantum
cryptography was proposed to deal with the issue that some players require only
partial quantum power, such as preparing or measuring quantum states in the
classical basis, which simplifies the implementations of quantum cryptography.
However, the efficiency of the existing semiquantum cryptographic protocols was
relatively low from a practical point of view. In this paper, we devise some
new semiquantum key distribution (SQKD) protocols which highly improve the
efficiency of the most well-known SQKD protocols [Phys. Rev. Lett. 99, 140501
(2007) & Phys. Rev. A 79, 052312 (2009)]. By letting players select their
actions asymmetrically, the efficiency of our new protocols can be made
asymptotically close to 100%. Besides, one of our proposed protocols also
utilizes the discarded X-SIFT bits in the original SQKD protocol, which further
improves the efficiency of SQKD. We prove that the proposed SQKD protocols are
completely robust against the most general attack.",177,14,1204,36.69
1860,cryptography,No.,1,2,3,121.22
1861,cryptography,"Machine learning techniques have had a long list of applications in recent
years. However, the use of machine learning in information and network security
is not new. Machine learning and cryptography have many things in common. The
most apparent is the processing of large amounts of data and large search
spaces. In its varying techniques, machine learning has been an interesting
field of study with massive potential for application. In the past three
decades, machine learning techniques, whether supervised or unsupervised, have
been applied in cryptographic algorithms, cryptanalysis, steganography, among
other data-security-related applications. This paper presents an updated survey
of applications of machine learning techniques in cryptography and
cryptanalysis. The paper summarizes the research done in these areas and
provides suggestions for future directions in research.",126,9,888,38.52
1862,cryptography,"We put forward the idea that classical blockchains and smart contracts are
potentially useful primitives not only for classical cryptography, but for
quantum cryptography as well. Abstractly, a smart contract is a functionality
that allows parties to deposit funds, and release them upon fulfillment of
algorithmically checkable conditions, and can thus be employed as a formal tool
to enforce monetary incentives. In this work, we give the first example of the
use of smart contracts in a quantum setting. We describe a simple hybrid
classical-quantum payment system whose main ingredients are a classical
blockchain capable of handling stateful smart contracts, and quantum lightning,
a strengthening of public-key quantum money introduced by Zhandry [Eurocrypt
2019]. Our hybrid payment system uses quantum states as banknotes and a
classical blockchain to settle disputes and to keep track of the valid serial
numbers. It has several desirable properties: it is decentralized, requiring no
trust in any single entity; payments are as quick as quantum communication,
regardless of the total number of users; when a quantum banknote is damaged or
lost, the rightful owner can recover the lost value.",184,7,1201,31.85
1863,cryptography,"Previous research has shown that crypto APIs are hard for developers to
understand and difficult for them to use. They consequently rely on unvalidated
boilerplate code from online resources where security vulnerabilities are
common.
  We analyzed 2,324 open-source Java projects that rely on Java Cryptography
Architecture (JCA) to understand how crypto APIs are used in practice, and what
factors account for the performance of developers in using these APIs. We found
that, in general, the experience of developers in using JCA does not correlate
with their performance. In particular, none of the factors such as the number
or frequency of committed lines of code, the number of JCA APIs developers use,
or the number of projects they are involved in correlate with developer
performance in this domain.
  We call for qualitative studies to shed light on the reasons underlying the
success of developers who are expert in using cryptography. Also, detailed
investigation at API level is necessary to further clarify a developer
obstacles in this domain.",166,8,1057,30.5
1864,cryptography,"We present a proposal for an undeniable signature scheme based in
supersingular hyperelliptic curves of genus 2.",17,2,112,28.84
1865,cryptography,"Smartphones are quickly moving toward complementing or even replacing
traditional car keys. We advocate a role-based access control policy mixed with
attributes that facilitates access to various functionalities of vehicular
on-board units from smartphones. We use a rights-based access control policy
for in-vehicle functionalities similar to the case of a file allocation table
of a contemporary OS, in which read, write or execute operations can be
performed over various vehicle functions. Further, to assure the appropriate
security, we develop a protocol suite using identity-based cryptography and we
rely on group signatures that preserve the anonymity of group members for
assuring privacy and traceability. To prove the feasibility of our approach, we
develop a proof-of-concept implementation with modern smartphones, aftermarket
Android head-units and test computational feasibility on a real-world
in-vehicle controller. Our implementation relies on state-of-the-art
cryptography, including traditional building blocks and more modern
pairing-friendly curves, that facilitate the adoption of group signatures and
identity-based cryptography in automotive-based scenarios.",158,7,1184,2.48
1866,cryptography,"We propose a hash function based on arithmetic coding and public-key
cryptography. The resistance of the hash function to second preimage attack,
collision and differential cryptanalysis is based on the properties of
arithmetic coding as a non-linear dynamical system. The resistance of the hash
function to first preimage attack is based on the public-key cryptography. The
new hash function uses the strength of HMAC with the difference that it didn't
need a secret key for calculating the hash (in this step, it uses one, two or
three public -keys) and in the classical attack, an adversary need to break the
public key algorithm or to have all the secret keys to perform his attack.",114,5,686,42.55
1867,cryptography,A comparison of web privacy protection techniques,7,1,49,22.07
1868,cryptography,"We show how voltage glitching can cause timing violations in CMOS behavior.
Then we attack a real, security hardened, consumer device to gain code
execution and dump the secure boot ROM.",31,3,186,55.74
1869,cryptography,Explaining Cybersecurity with Films and the Arts,7,1,48,30.53
1870,cryptography,"We introduce some preliminaries about game theory and information security.
Then surveying a subset of the literature, we identify opportunities for future
research.",23,3,165,9.04
1871,cryptography,"Cryptographic standards serve two important goals: making different
implementations interoperable and avoiding various known pitfalls in commonly
used schemes. This chapter discusses Public-Key Cryptography Standards (PKCS)
which have significant impact on the use of public key cryptography in
practice. PKCS standards are a set of standards, called PKCS #1 through #15.
These standards cover RSA encryption, RSA signature, password-based encryption,
cryptographic message syntax, private-key information syntax, selected object
classes and attribute types, certification request syntax, cryptographic token
interface, personal information exchange syntax, and cryptographic token
information syntax. The PKCS standards are published by RSA Laboratories.
Though RSA Laboratories solicits public opinions and advice for PKCS standards,
RSA Laboratories retain sole decision-making authority on all aspects of PKCS
standards. PKCS has been the basis for many other standards such as S/MIME.",130,8,989,18.76
1872,cryptography,"In symmetric key cryptography the sender as well as the receiver possess a
common key. Asymmetric key cryptography involves generation of two distinct
keys which are used for encryption and decryption correspondingly. The sender
converts the original message to cipher text using the public key while the
receiver can decipher this using his private key. This is also called Public
Key Cryptography. For every public key there can exist only one private key
that can decipher the encrypted text. Security of RSA Algorithm can be
compromised using mathematical attack, by guessing the factors of a large
number. It may also be compromised if one can guess the private key. In
accordance with the mathematical attack, we propose a secure algorithm in this
paper. In this algorithm, we try to eliminate the distribution of n which is
the large number whose factors if found compromises the RSA algorithm. We also
present a comparative analysis of the proposed algorithm with the RSA
algorithm.",161,11,990,46.67
1873,cryptography,"Pairing based cryptography is in a dangerous position following the
breakthroughs on discrete logarithms computations in finite fields of small
characteristic. Remaining instances are built over finite fields of large
characteristic and their security relies on the fact that the embedding field
of the underlying curve is relatively large. How large is debatable. The aim of
our work is to sustain the claim that the combination of degree 3 embedding and
too small finite fields obviously does not provide enough security. As a
computational example, we solve the DLP on a 170-bit MNT curve, by exploiting
the pairing embedding to a 508-bit, degree-3 extension of the base field.",108,6,680,41.09
1874,cryptography,"Optical physical unclonable keys are currently considered to be rather
promising candidates for the development of entity authentication protocols,
which offer security against both classical and quantum adversaries. In this
work we investigate the robustness of a continuous-variable protocol, which
relies on the scattering of coherent states of light from the key, against
three different types of intercept-resend emulation attacks. The performance of
the protocol is analysed for a broad range of physical parameters, and our
results are compared to existing security bounds.",83,4,580,17.98
1875,cryptography,"Steganography is an art of obscuring data inside another quotidian file of
similar or varying types. Hiding data has always been of significant importance
to digital forensics. Previously, steganography has been combined with
cryptography and neural networks separately. Whereas, this research combines
steganography, cryptography with the neural networks all together to hide an
image inside another container image of the larger or same size. Although the
cryptographic technique used is quite simple, but is effective when convoluted
with deep neural nets. Other steganography techniques involve hiding data
efficiently, but in a uniform pattern which makes it less secure. This method
targets both the challenges and make data hiding secure and non-uniform.",111,8,761,38.42
1876,cryptography,"Historically, Elliptic Curve Cryptography (ECC) is an active field of applied
cryptography where recent focus is on high speed, constant time, and formally
verified implementations. While there are a handful of outliers where all these
concepts join and land in real-world deployments, these are generally on a
case-by-case basis: e.g. a library may feature such X25519 or P-256 code, but
not for all curves. In this work, we propose and implement a methodology that
fully automates the implementation, testing, and integration of ECC stacks with
the above properties. We demonstrate the flexibility and applicability of our
methodology by seamlessly integrating into three real-world projects: OpenSSL,
Mozilla's NSS, and the GOST OpenSSL Engine, achieving roughly 9.5x, 4.5x,
13.3x, and 3.7x speedup on any given curve for key generation, key agreement,
signing, and verifying, respectively. Furthermore, we showcase the efficacy of
our testing methodology by uncovering flaws and vulnerabilities in OpenSSL, and
a specification-level vulnerability in a Russian standard. Our work bridges the
gap between significant applied cryptography research results and deployed
software, fully automating the process.",175,13,1209,34.86
1877,cryptography,"In conventional cryptography, information-theoretically secure message
authentication can be achieved by means of universal hash functions, and
requires that the two legitimate users share a random secret key, which is
twice as long as the message. We address the question as of whether quantum
resources can offer any advantage over classical unconditionally secure message
authentication codes. It is shown that passive prepare-and-measure quantum
message-authentication schemes cannot do better than their classical
counterparts. Subsequently we present an interactive entanglement-assisted
scheme, which ideally allows for the authentication of classical messages with
a classical key, which is as long as the message.",99,5,722,20.92
1878,cryptography,"Polynomial multiplication is a bottleneck in most of the public-key
cryptography protocols, including Elliptic-curve cryptography and several of
the post-quantum cryptography algorithms presently being studied. In this
paper, we present a library of various large integer polynomial multipliers to
be used in hardware cryptocores. Our library contains both digitized and
non-digitized multiplier flavours for circuit designers to choose from. The
library is supported by a C++ generator that automatically produces the
multipliers' logic in Verilog HDL that is amenable for FPGA and ASIC designs.
Moreover, for ASICs, it also generates configurable and parameterizable
synthesis scripts. The features of the generator allow for a quick generation
and assessment of several architectures at the same time, thus allowing a
designer to easily explore the (complex) optimization search space of
polynomial multiplication.",129,7,917,15.81
1879,cryptography,"This paper presents a low-latency hardware accelerator for modular polynomial
multiplication for lattice-based post-quantum cryptography and homomorphic
encryption applications. The proposed novel modular polynomial multiplier
exploits the fast finite impulse response (FIR) filter architecture to reduce
the computational complexity of the schoolbook modular polynomial
multiplication. We also extend this structure to fast $M$-parallel
architectures while achieving low-latency, high-speed, and full hardware
utilization. We comprehensively evaluate the performance of the proposed
architectures under various polynomial settings as well as in the Saber scheme
for post-quantum cryptography as a case study. The experimental results show
that our proposed modular polynomial multiplier reduces the computation time
and area-time product, respectively, compared to the state-of-the-art designs.",112,6,895,-2.03
1880,cryptography,"We show that it is impossible to prove that the outcome of a quantum
measurement is random.",17,2,91,62.68
1881,cryptography,"Cryptography is the science of using mathematics to encrypt and decrypt data.
Cryptography enables you to store sensitive information or transmit it across
insecure networks so that it cannot be read by anyone except the intended
recipient. While cryptography is the science of securing data, cryptanalysis is
the science of analyzing and breaking secure communication. Classical
cryptanalysis involves an interesting combination of analytical reasoning,
application of mathematical tools and pattern finding. The objectives of the
proposed work are to propose a new cryptographic method based on the special
matrix called the Hilbert matrix for authentication and confidentiality and to
propose a model for confidentiality and authentication using a combination of
symmetric and public cryptosystems. Further, it is extended to shared key
cryptosystems with the concept of digital enveloping using a session key. In
the present work an algorithm for shared key encryption is developed using
Hilbert matrix cryptosystem. In this the block chaining modes of operation have
been used to tackle the issues of confusion and diffusion.",167,9,1130,24.88
1882,cryptography,"We propose a polynomial-time attack on the hHB protocol, showing that the
protocol does not attain the claimed security. Our attack is based on the GRS
attack.",27,3,159,57.77
1883,cryptography,"Neural cryptography is the application of artificial neural networks in the
subject of cryptography. The functionality of this solution is based on a tree
parity machine. It uses artificial neural networks to perform secure key
exchange between network entities. This article proposes improvements to the
synchronization of two tree parity machines. The improvement is based on
learning artificial neural network using input vectors which have a wider range
of values than binary ones. As a result, the duration of the synchronization
process is reduced. Therefore, tree parity machines achieve common weights in a
shorter time due to the reduction of necessary bit exchanges. This approach
improves the security of neural cryptography",111,8,735,40.45
1884,cryptography,"Lattice-based cryptography is one of the leading proposals for post-quantum
cryptography. The Shortest Vector Problem (SVP) is arguably the most important
problem for the cryptanalysis of lattice-based cryptography, and many
lattice-based schemes have security claims based on its hardness. The best
quantum algorithm for the SVP is due to Laarhoven [Laa16 PhD] and runs in
(heuristic) time $2^{0.2653d + o(d)}$. In this article, we present an
improvement over Laarhoven's result and present an algorithm that has a
(heuristic) running time of $2^{0.2570 d + o(d)}$ where $d$ is the lattice
dimension. We also present time-memory trade-offs where we quantify the amount
of quantum memory and quantum random access memory of our algorithm. The core
idea is to replace Grover's algorithm used in [Laa16 PhD] in a key part of the
sieving algorithm by a quantum random walk in which we add a layer of local
sensitive filtering.",147,9,923,58.92
1885,cryptography,"The International Olympiad in Cryptography NSUCRYPTO is the unique Olympiad
containing scientific mathematical problems for professionals, school and
university students from any country. Its aim is to involve young researchers
in solving curious and tough scientific problems of modern cryptography. In
2020, it was held for the seventh time. Prizes and diplomas were awarded to 84
participants in the first round and 49 teams in the second round from 32
countries. In this paper, problems and their solutions of NSUCRYPTO'2020 are
presented. We consider problems related to attacks on ciphers and hash
functions, protocols, permutations, primality tests, etc. We discuss several
open problems on JPEG encoding, Miller -- Rabin primality test, special bases
in the vector space, AES-GCM. The problem of a modified Miller -- Rabin
primality test was solved during the Olympiad. The problem for finding special
bases was partially solved.",142,10,937,47.18
1886,cryptography,"Indistinguishable laser pulse is important in realization of qubits in
quantum cryptography. Implementation of such cryptography in automotive
framework needs to be compact and cheap. However, modern implementation of
quantum cryptography is bulky and expensive. Significant effort has been put
into to reduce the form factor of quantum cryptography implementation. We
report a compact, low cost, indistinguishable, sub-nanosecond pulse generator
with adjusted delay and amplitude using a Fabry-Perot laser diode. The approach
was derived based on algebraic topology formulation of electrical network, and
the implementation is time dependent perturbation of a constant current node,
generating tun-able, sub-nanosecond excitation with constant pre-bias.
Parameters for simulation model for the laser diode was obtained considering
effect of spontaneous emission and relaxation oscillation. The shortest pulse
was measured to have FWHM of 496ps.",129,9,945,21.29
1887,cryptography,"Cryptography techniques are essential for a robust and stable security design
of a system to mitigate the risk of external attacks and thus improve its
efficiency. Wireless Sensor Networks (WSNs) play a pivotal role in sensing,
monitoring, processing, and accumulating raw data to enhance the performance of
the actuators, micro-controllers, embedded architectures, IoT devices, and
computing machines to which they are connected. With so much threat of
potential adversaries, it is essential to scale up the security level of WSN
without affecting its primary goal of seamless data collection and
communication with relay devices. This paper intends to explore the past and
ongoing research activities in this domain. An extensive study of these
algorithms referred here, are studied and analyzed. Based on these findings
this paper will illustrate the best possible cryptography algorithms which will
be most suited to implement the security aspects of the WSN and protect it from
any threat and reduce its vulnerabilities. This study will pave the way for
future research on this topic since it will provide a comprehensive and
holistic view of the subject.",180,8,1160,36.93
1888,cryptography,"Relativistic cryptography is a proposal for achieving unconditional security
that exploits the fact that no information carrier can travel faster than the
speed of light. It is based on space-time constraints but doesn't require
quantum hardware. Nevertheless, it was unclear whether this proposal is
realistic or not. Recently, Alikhani et al. [ABC+21] performed an
implementation of a relativistic zero-knowledge for NP. Their implemented
scheme shows the feasibility of relativistic cryptography but it is only secure
against classical adversaries. In this work, we present a new relativistic
protocol for NP which is secure against quantum adversaries and which is
efficient enough so that it can be implemented on everyday laptops and internet
connections. We use Stern's zero-knowledge scheme for the Syndrome Decoding
problem, which was used before in post-quantum cryptography. The main technical
contribution is a generalization of the consecutive measurement framework of
[CL17] to prove the security of our scheme against quantum adversaries, and we
perform an implementation that demonstrates the feasibility and efficiency of
our proposed scheme.",168,10,1159,35.57
1889,cryptography,"We present a novel cryptography architecture based on memristor crossbar
array, binary hypervectors, and neural network. Utilizing the stochastic and
unclonable nature of memristor crossbar and error tolerance of binary
hypervectors and neural network, implementation of the algorithm on memristor
crossbar simulation is made possible. We demonstrate that with an increasing
dimension of the binary hypervectors, the non-idealities in the memristor
circuit can be effectively controlled. At the fine level of controlled crossbar
non-ideality, noise from memristor circuit can be used to encrypt data while
being sufficiently interpretable by neural network for decryption. We applied
our algorithm on image cryptography for proof of concept, and to text
en/decryption with 100% decryption accuracy despite crossbar noises. Our work
shows the potential and feasibility of using memristor crossbars as an
unclonable stochastic encoder unit of cryptography on top of their existing
functionality as a vector-matrix multiplication acceleration device.",146,7,1047,12.97
1890,cryptography,"The development of large quantum computers will have dire consequences for
cryptography. Most of the symmetric and asymmetric cryptographic algorithms are
vulnerable to quantum algorithms. Grover's search algorithm gives a square root
time boost for the searching of the key in symmetric schemes like AES and 3DES.
The security of asymmetric algorithms like RSA, Diffie Hellman, and ECC is
based on the mathematical hardness of prime factorization and discrete
logarithm. The best classical algorithms available take exponential time.
Shor's factoring algorithm can solve the problems in polynomial time. Major
breakthroughs in quantum computing will render all the present-day widely used
asymmetric cryptosystems insecure. This paper analyzes the vulnerability of the
classical cryptosystems in the context of quantum computers discusses various
post-quantum cryptosystem families, discusses the status of the NIST
post-quantum cryptography standardization process, and finally provides a
couple of future research directions in this field.",145,9,1042,36.18
1891,cryptography,"Selecting a library out of numerous candidates can be a laborious and
resource-intensive task. We present the $crypto_{lib}$ index, a tool for
decision-makers to choose the best fitting cryptography library for a given
context. To define our index, 15 library attributes were synthesized from
findings based on a literature review and interviews with decision-makers.
These attributes were afterwards validated and weighted via an online survey.
In order to create the index value for a given library, the individual
attributes are assessed using given evaluation criteria associated with the
respective attribute. As a proof of concept and to give a practical usage
example, the derivation of the $crypto_{lib}$ values for the libraries Bouncy
Castle and Tink are shown in detail. Overall, by tailoring the weighting of the
$crypto_{lib}$ attributes to their current use case, decision-makers are
enabled to systematically select a cryptography library fitting best to their
software project at hand in a guided, repeatable and reliable way.",157,8,1042,31.82
1892,cryptography,"In this paper, we propose to use a skew dihedral group ring given by the
group $D_{2n}$ and the finite field $\mathbb{F}_{q^2}$ for public-key
cryptography. Using the ambient space $\mathbb{F}_{q^{2}}^{\theta} D_{2n}$ and
a group homomorphism $\theta: D_{2n} \rightarrow
\mathrm{Aut}(\mathbb{F}_{q^2})$, we introduce a key exchange protocol and
present an analysis of its security. Moreover, we explore the properties of the
resulting skew group ring $\mathbb{F}_{q^{2}}^{\theta} D_{2n}$, exploiting them
to enhance our key exchange protocol. We also introduce a probabilistic
public-key scheme derived from our key exchange protocol and obtain a key
encapsulation mechanism (KEM) by applying a well-known generic transformation
to our public-key scheme. Finally, we present a proof-of-concept implementation
of our cryptographic constructions. To the best of our knowledge, this is the
first paper that proposes a skew dihedral group ring for public-key
cryptography.",134,7,968,40.38
1893,cryptography,"Cryptography has been extensively used in Android applications to guarantee
secure communications, conceal critical data from reverse engineering, or
ensure mobile users' privacy. Various system-based and third-party libraries
for Android provide cryptographic functionalities, and previous works mainly
explored the misuse of cryptographic API in benign applications. However, the
role of cryptographic API has not yet been explored in Android malware. This
paper performs a comprehensive, longitudinal analysis of cryptographic API in
Android malware. In particular, we analyzed $603\,937$ Android applications
(half of them malicious, half benign) released between $2012$ and $2020$,
gathering more than 1 million cryptographic API expressions. Our results reveal
intriguing trends and insights on how and why cryptography is employed in
Android malware. For instance, we point out the widespread use of weak hash
functions and the late transition from insecure DES to AES. Additionally, we
show that cryptography-related characteristics can help to improve the
performance of learning-based systems in detecting malicious applications.",156,9,1139,26.3
1894,cryptography,"Quantum cryptography is the field of cryptography that explores the quantum
properties of matter. Its aim is to develop primitives beyond the reach of
classical cryptography or to improve on existing classical implementations.
Although much of the work in this field is dedicated to quantum key
distribution (QKD), some important steps were made towards the study and
development of quantum oblivious transfer (QOT). It is possible to draw a
comparison between the application structure of both QKD and QOT primitives.
Just as QKD protocols allow quantum-safe communication, QOT protocols allow
quantum-safe computation. However, the conditions under which QOT is actually
quantum-safe have been subject to a great amount of scrutiny and study. In this
review article, we survey the work developed around the concept of oblivious
transfer in the area of theoretical quantum cryptography, with an emphasis on
some proposed protocols and their security requirements. We review the
impossibility results that daunt this primitive and discuss several quantum
security models under which it is possible to prove QOT security.",169,9,1120,33.14
1895,cryptography,"The survey presents the evolution of Short Weierstrass elliptic curves after
their introduction in cryptography. Subsequently, this evolution resulted in
the establishment of present elliptic curve computational standards. We discuss
the chronology of attacks on Elliptic Curve Discrete Logarithm Problem and
investigate their countermeasures to highlight the evolved selection criteria
of cryptographically safe elliptic curves. Further, two popular deterministic
and random approaches for selection of Short Weierstrass elliptic curve for
cryptography are evaluated from computational, security and trust perspectives
and a trend in existent computational standards is demonstrated. Finally,
standard and non-standard elliptic curves are analysed to add a new insight
into their usability. There is no such survey conducted in past to the best of
our knowledge.",118,7,863,17.64
1896,cryptography,"Short Weierstrass's elliptic curves with underlying hard Elliptic Curve
Discrete Logarithm Problems was widely used in Cryptographic applications. This
paper introduces a new security notation 'trusted security' for computation
methods of elliptic curves for cryptography. Three additional ""trusted security
acceptance criteria"" is proposed to be met by the elliptic curves aimed for
cryptography. Further, two cryptographically secure elliptic curves over 256
bit and 384 bit prime fields are demonstrated which are secure from ECDLP, ECC
as well as trust perspectives. The proposed elliptic curves are successfully
subjected to thorough security analysis and performance evaluation with respect
to key generation and signing/verification and hence, proven for their
cryptographic suitability and great feasibility for acceptance by the
community.",116,6,848,14.09
1897,cryptography,"Why study Lattice-based Cryptography? There are a few ways to answer this
question. 1. It is useful to have cryptosystems that are based on a variety of
hard computational problems so the different cryptosystems are not all
vulnerable in the same way. 2. The computational aspects of lattice-based
cryptosystem are usually simple to understand and fairly easy to implement in
practice. 3. Lattice-based cryptosystems have lower encryption/decryption
computational complexities compared to popular cryptosystems that are based on
the integer factorisation or the discrete logarithm problems. 4. Lattice-based
cryptosystems enjoy strong worst-case hardness security proofs based on
approximate versions of known NP-hard lattice problems. 5. Lattice-based
cryptosystems are believed to be good candidates for post-quantum cryptography,
since there are currently no known quantum algorithms for solving lattice
problems that perform significantly better than the best-known classical
(non-quantum) algorithms, unlike for integer factorisation and (elliptic curve)
discrete logarithm problems. 6. Last but not least, interesting structures in
lattice problems have led to significant advances in Homomorphic Encryption, a
new research area with wide-ranging applications.",172,14,1266,24.27
1898,cryptography,"The no-cloning theorem asserts that, unlike classical information, quantum
information cannot be copied. This seemingly undesirable phenomenon is
harnessed in quantum cryptography. Uncloneable cryptography studies settings in
which the impossibility of copying is a desired property, and achieves forms of
security that are classically unattainable. The first example discovered and
analyzed was in the context of cash. On the one hand, we want users to hold the
cash; on the other hand, the cash should be hard to counterfeit. Quantum money
uses variants of the no-cloning theorem to make counterfeiting impossible.
  In the past decade, this field developed in various directions: several
flavors of quantum money, such as classically verifiable, locally verifiable,
semi-quantum, quantum coins, and quantum lightning were constructed. New
uncloneable primitives were introduced, such as uncloneable signatures, quantum
copy protection for classical software, pseudorandom states, and several
uncloneable forms of encryption. This work is a gentle introduction to these
topics.",152,10,1079,28.94
1899,cryptography,"We propose to study equivalence relations between phenomena in high-energy
physics and the existence of standard cryptographic primitives, and show the
first example where such an equivalence holds. A small number of prior works
showed that high-energy phenomena can be explained by cryptographic hardness.
Examples include using the existence of one-way functions to explain the
hardness of decoding black-hole Hawking radiation (Harlow and Hayden 2013,
Aaronson 2016), and using pseudorandom quantum states to explain the hardness
of computing AdS/CFT dictionary (Bouland, Fefferman and Vazirani, 2020).
  In this work we show, for the former example of black-hole radiation
decoding, that it also implies the existence of secure quantum cryptography. In
fact, we show an existential equivalence between the hardness of black-hole
radiation decoding and a variety of cryptographic primitives, including
bit-commitment schemes and oblivious transfer protocols (using quantum
communication). This can be viewed (with proper disclaimers, as we discuss) as
providing a physical justification for the existence of secure cryptography. We
conjecture that such connections may be found in other high-energy physics
phenomena.",172,8,1220,21.13
1900,cryptography,"We present public-private key cryptosystem which utilizes the fact that
checking whether a partial automaton is carefully synchronizing is
$PSPACE$-complete, even in the case of a binary alphabet.",28,2,196,26.14
1901,cryptography,"Masking is a well-known and provably secure countermeasure against
side-channel attacks. However, due to additional redundant computations,
integrating masking schemes is expensive in terms of performance. The
performance overhead of integrating masking countermeasures is heavily
influenced by the design choices of a cryptographic algorithm and is often not
considered during the design phase.
  In this work, we deliberate on the effect of design choices on integrating
masking techniques into lattice-based cryptography. We select Scabbard, a suite
of three lattice-based post-quantum key-encapsulation mechanisms (KEM), namely
Florete, Espada, and Sable. We provide arbitrary-order masked implementations
of all the constituent KEMs of the Scabbard suite by exploiting their specific
design elements. We show that the masked implementations of Florete, Espada,
and Sable outperform the masked implementations of Kyber in terms of speed for
any order masking. Masked Florete exhibits a $73\%$, $71\%$, and $70\%$
performance improvement over masked Kyber corresponding to the first-, second-,
and third-order. Similarly, Espada exhibits $56\%$, $59\%$, and $60\%$ and
Sable exhibits $75\%$, $74\%$, and $73\%$ enhanced performance for first-,
second-, and third-order masking compared to Kyber respectively. Our results
show that the design decisions have a significant impact on the efficiency of
integrating masking countermeasures into lattice-based cryptography.",200,11,1470,25.8
1902,cryptography,"Quantum key distribution (QKD) was conceived by Charles Bennett and Gilles
Brassard in December of 1984. In the ensuing 39 years QKD systems have been
deployed around the world to provide secure encryption for terrestrial as well
as satellite communication. In 2016 the National Institute of Standards and
Technology (NIST) began a program to standardize a series of quantum resistant
algorithms to replace our current encryption standards thereby protecting
against future quantum computers breaking public key cryptography. This program
is known as post quantum cryptography or PQC. One of the tenets of
cybersecurity is to use an approach that simultaneously provides multiple
protections known as defense-in-depth. This approach seeks to avoid single
points of failure. The goal of this paper is to examine the suitability of a
hybrid QKD / PQC defense-in-depth strategy. A focus of the paper will be to
examine the sufficiency of initial QKD hardware authentication (entity source
authentication) which is necessary to guard against man-in-the-middle attacks.",160,9,1064,34.36
1903,cryptography,"Allowing a compromised device to receive privacy-sensitive sensor readings,
or to operate a safety-critical actuator, carries significant risk. Usually,
such risks are mitigated by validating the device's security state with remote
attestation, but current remote attestation protocols are not suitable when the
beneficiary of attestation, the relying party, is a constrained device such as
a small sensor or actuator. These devices typically lack the power and memory
to operate public-key cryptography needed by such protocols, and may only be
able to communicate with devices in their physical proximity, such as with the
controller whose security state they wish to evaluate. In this paper, we
present a remote platform attestation protocol suitable for relying parties
that are limited to symmetric-key cryptography and a single communication
channel. We show that our protocol, including the needed cryptography and
message processing, can be implemented with a code size of 6 KB and validate
its security via model checking with the ProVerif tool.",158,6,1054,14.02
1904,cryptography,"In classical cryptography, one-way functions are widely considered to be the
minimal computational assumption. However, when taking quantum information into
account, the situation is more nuanced. There are currently two major
candidates for the minimal assumption: the search quantum generalization of
one-way functions are one-way state generators (OWSG), whereas the decisional
variant are EFI pairs. A well-known open problem in quantum cryptography is to
understand how these two primitives are related. A recent breakthrough result
of Khurana and Tomer (STOC'24) shows that OWSGs imply EFI pairs, for the
restricted case of pure states.
  In this work, we make progress towards understanding the general case. To
this end, we define the notion of inefficiently-verifiable one-way state
generators (IV-OWSGs), where the verification algorithm is not required to be
efficient, and show that these are precisely equivalent to EFI pairs, with an
exponential loss in the reduction. Significantly, this equivalence holds also
for mixed states. Thus our work establishes the following relations among these
fundamental primitives of quantum cryptography: (mixed) OWSGs => (mixed)
IV-OWSGs $\equiv_{\rm exp}$ EFI pairs, where $\equiv_{\rm exp}$ denotes
equivalence up to exponential security of the primitives.",187,10,1308,33.54
1905,cryptography,"The current blockchain system for cryptocurrency exchanges primarily employs
elliptic curve cryptography (ECC) for generating key pairs in wallets, and
elliptic curve digital signature algorithms (ECDSA) for generating signatures
in transactions. Consequently, with the maturation of quantum computing
technology, the current blockchain system faces the risk of quantum computing
attacks. Quantum computers may potentially counterfeit signatures produced by
ECDSA. Therefore, this study analyzes the vulnerabilities of the current
blockchain system to quantum computing attacks and proposes a post-quantum
cryptography (PQC)-based blockchain system to enhance security by addressing
and improving each identified weakness. Furthermore, this study proposes
PQC-based wallets and PQC-based transactions, utilizing PQC digital signature
algorithms to generate PQC-based signatures for the inputs in PQC-based
transactions, thereby preventing signatures from being counterfeited by quantum
computing. Experimental results demonstrate that the efficiency of the
Dilithium algorithm, a PQC digital signature algorithm, in producing wallets,
generating signatures, and verifying signatures surpasses that of ECDSA in the
current blockchain system. Furthermore, the Dilithium algorithm also exhibits a
higher security level.",167,8,1316,4.92
1906,cryptography,"Nowadays, predominant asymmetric cryptographic schemes are considered to be
secure because discrete logarithms are believed to be hard to be computed. The
algorithm of Shor can effectively compute discrete logarithms, i.e. it can
brake such asymmetric schemes. But the algorithm of Shor is a quantum algorithm
and at the time this algorithm has been invented, quantum computers that may
successfully execute this algorithm seemed to be far out in the future. The
latter has changed: quantum computers that are powerful enough are likely to be
available in a couple of years. In this article, we first describe the relation
between discrete logarithms and two well-known asymmetric security schemes, RSA
and Elliptic Curve Cryptography. Next, we present the foundations of
lattice-based cryptography which is the bases of schemes that are considered to
be safe against attacks by quantum algorithms (as well as by classical
algorithms). Then we describe two such quantum-safe algorithms (Kyber and
Dilithium) in more detail. Finally, we give a very brief and selective overview
of a few actions currently taken by governments and industry as well as
standardization in this area. The article especially strives towards being
self-contained: the required mathematical foundations to understand
post-quantum cryptography are provided and examples are given.",204,12,1354,42.31
1907,cryptography,"This survey is the first work on the current standard for lightweight
cryptography, standardized in 2023. Lightweight cryptography plays a vital role
in securing resource-constrained embedded systems such as deeply-embedded
systems (implantable and wearable medical devices, smart fabrics, smart homes,
and the like), radio frequency identification (RFID) tags, sensor networks, and
privacy-constrained usage models. National Institute of Standards and
Technology (NIST) initiated a standardization process for lightweight
cryptography and after a relatively-long multi-year effort, eventually, in Feb.
2023, the competition ended with ASCON as the winner. This lightweight
cryptographic standard will be used in deeply-embedded architectures to provide
security through confidentiality and integrity/authentication (the dual of the
legacy AES-GCM block cipher which is the NIST standard for symmetric key
cryptography). ASCON's lightweight design utilizes a 320-bit permutation which
is bit-sliced into five 64-bit register words, providing 128-bit level
security. This work summarizes the different implementations of ASCON on
field-programmable gate array (FPGA) and ASIC hardware platforms on the basis
of area, power, throughput, energy, and efficiency overheads. The presented
work also reviews various differential and side-channel analysis attacks (SCAs)
performed across variants of ASCON cipher suite in terms of algebraic,
cube/cube-like, forgery, fault injection, and power analysis attacks as well as
the countermeasures for these attacks. We also provide our insights and visions
throughout this survey to provide new future directions in different domains.
This survey is the first one in its kind and a step forward towards
scrutinizing the advantages and future directions of the NIST lightweight
cryptography standard introduced in 2023.",253,11,1855,20.42
1908,cryptography,"QUIC is a new network protocol standardized in 2021. It was designed to
replace the TCP/TLS stack and is based on UDP. The most current web standard
HTTP/3 is specifically designed to use QUIC as transport protocol. QUIC claims
to provide secure and fast transport with low-latency connection establishment,
flow and congestion control, reliable delivery, and stream multiplexing. To
achieve the security goals, QUIC enforces the usage of TLS 1.3. It uses
authenticated encryption with additional data (AEAD) algorithms to not only
protect the payload but also parts of the header. The handshake relies on
asymmetric cryptography, which will be broken with the introduction of powerful
quantum computers, making the use of post-quantum cryptography inevitable. This
paper presents a detailed evaluation of the impact of cryptography on QUIC
performance. The high-performance QUIC implementations LSQUIC, quiche, and
MsQuic are evaluated under different aspects. We break symmetric cryptography
down to the different security features. To be able to isolate the impact of
cryptography, we implemented a NOOP AEAD algorithm which leaves plaintext
unaltered. We show that QUIC performance increases by 10 to 20% when removing
packet protection. The header protection has negligible impact on performance,
especially for AES ciphers. We integrate post-quantum cryptographic algorithms
into QUIC, demonstrating its feasibility without major changes to the QUIC
libraries by using a TLS library that implements post-quantum algorithms.
Kyber, Dilithium, and FALCON are promising candidates for post-quantum secure
QUIC, as they have a low impact on the handshake duration. Algorithms like
SPHINCS+ with larger key sizes or more complex calculations significantly
impact the handshake duration and cause additional issues in our measurements.",267,18,1835,37.6
1909,cryptography,"In discrete logarithm based cryptography, a method by Pohlig and Hellman
allows solving the discrete logarithm problem efficiently if the group order is
known and has no large prime factors. The consequence is that such groups are
avoided. In the past, there have been proposals for cryptography based on
cyclic infrastructures. We will show that the Pohlig-Hellman method can be
adapted to certain cyclic infrastructures, which similarly implies that certain
infrastructures should not be used for cryptography. This generalizes a result
by M\""uller, Vanstone and Zuccherato for infrastructures obtained from
hyperelliptic function fields.
  We recall the Pohlig-Hellman method, define the concept of a cyclic
infrastructure and briefly describe how to obtain such infrastructures from
certain function fields of unit rank one. Then, we describe how to obtain
cyclic groups from discrete cyclic infrastructures and how to apply the
Pohlig-Hellman method to compute absolute distances, which is in general a
computationally hard problem for cyclic infrastructures. Moreover, we give an
algorithm which allows to test whether an infrastructure satisfies certain
requirements needed for applying the Pohlig-Hellman method, and discuss whether
the Pohlig-Hellman method is applicable in infrastructures obtained from number
fields. Finally, we discuss how this influences cryptography based on cyclic
infrastructures.",201,10,1414,40.38
1910,cryptography,"There is currently an intersection in the research of game theory and
cryptography. Generally speaking, there are two aspects to this partnership.
First there is the application of game theory to cryptography. Yet, the purpose
of this paper is to focus on the second aspect, the converse of the first, the
application of cryptography to game theory. Chiefly, there exist a branch of
non-cooperative games which have a correlated equilibrium as their solution.
These equilibria tend to be superior to the conventional Nash equilibria. The
primary condition for a correlated equilibrium is the presence of a mediator
within the game. This is simply a neutral and mutually trusted entity. It is
the role of the mediator to make recommendations in terms of strategy profiles
to all players, who then act (supposedly) on this advice. Each party privately
provides the mediator with the necessary information, and the referee responds
privately with their optimized strategy set. However, there seem to be a
multitude of situations in which no mediator could exist. Thus, games modeling
these sorts of cases could not use these entities as tools for analysis. Yet,
if these equilibria are in the best interest of players, it would be rational
to construct a machine, or protocol, to calculate them. Of course, this machine
would need to satisfy some standard for secure transmission between a player
and itself. The requirement that no third party could detect either the input
or strategy profile would need to be satisfied by this scheme. Here is the
synthesis of cryptography into game theory; analyzing the ability of the
players to construct a protocol which can be used successfully in the place of
a mediator.",279,17,1710,45.35
1911,cryptography,"A novel cryptography method based on the Lorenz's attractor chaotic system is
presented. The proposed algorithm is secure and fast, making it practical for
general use. We introduce the chaotic operation mode, which provides an
interaction among the password, message and a chaotic system. It ensures that
the algorithm yields a secure codification, even if the nature of the chaotic
system is known. The algorithm has been implemented in two versions: one
sequential and slow and the other, parallel and fast. Our algorithm assures the
integrity of the ciphertext (we know if it has been altered, which is not
assured by traditional algorithms) and consequently its authenticity. Numerical
experiments are presented, discussed and show the behavior of the method in
terms of security and performance. The fast version of the algorithm has a
performance comparable to AES, a popular cryptography program used commercially
nowadays, but it is more secure, which makes it immediately suitable for
general purpose cryptography applications. An internet page has been set up,
which enables the readers to test the algorithm and also to try to break into
the cipher in.",184,10,1164,42.31
1912,cryptography,"In this paper secured wireless communication using fuzzy logic based high
speed public key cryptography (FLHSPKC) has been proposed by satisfying the
major issues likes computational safety, power management and restricted usage
of memory in wireless communication. Wireless Sensor Network (WSN) has several
major constraints likes inadequate source of energy, restricted computational
potentiality and limited memory. Though conventional Elliptic Curve
Cryptography (ECC) which is a sort of public key cryptography used in wireless
communication provides equivalent level of security like other existing public
key algorithm using smaller parameters than other but this traditional ECC does
not take care of all these major limitations in WSN. In conventional ECC
consider Elliptic curve point p, an arbitrary integer k and modulus m, ECC
carry out scalar multiplication kP mod m, which takes about 80% of key
computation time on WSN. In this paper proposed FLHSPKC scheme provides some
novel strategy including novel soft computing based strategy to speed up scalar
multiplication in conventional ECC and which in turn takes shorter
computational time and also satisfies power consumption restraint, limited
usage of memory without hampering the security level. Performance analysis of
the different strategies under FLHSPKC scheme and comparison study with
existing conventional ECC methods has been done.",205,7,1408,11.38
1913,cryptography,"Intensive work on quantum computing has increased interest in quantum
cryptography in recent years. Although this technique is characterized by a
very high level of security, there are still challenges that limit the
widespread use of quantum key distribution. One of the most important problem
remains secure and effective mechanisms for the key distillation process. This
article presents a new idea for a key reconciliation method in quantum
cryptography. This proposal assumes the use of mutual synchronization of
artificial neural networks to correct errors occurring during transmission in
the quantum channel. Users can build neural networks based on their own string
of bits. The typical value of the quantum bit error rate does not exceed a few
percent, therefore the strings are similar and also users' neural networks are
very similar at the beginning of the learning process. It has been shown that
the synchronization process in the new solution is much faster than in the
analogous scenario used in neural cryptography. This feature significantly
increases the level of security because a potential eavesdropper cannot
effectively synchronize their own artificial neural networks in order to obtain
information about the key. Therefore, the key reconciliation based on the new
idea can be a secure and efficient solution.",206,11,1335,42.11
1914,cryptography,"Public key cryptography protocols, such as RSA and elliptic curve
cryptography, will be rendered insecure by Shor's algorithm when large-scale
quantum computers are built. Cryptographers are working on quantum-resistant
algorithms, and lattice-based cryptography has emerged as a prime candidate.
However, high computational complexity of these algorithms makes it challenging
to implement lattice-based protocols on low-power embedded devices. To address
this challenge, we present Sapphire - a lattice cryptography processor with
configurable parameters. Efficient sampling, with a SHA-3-based PRNG, provides
two orders of magnitude energy savings; a single-port RAM-based number
theoretic transform memory architecture is proposed, which provides 124k-gate
area savings; while a low-power modular arithmetic unit accelerates polynomial
computations. Our test chip was fabricated in TSMC 40nm low-power CMOS process,
with the Sapphire cryptographic core occupying 0.28 mm2 area consisting of 106k
logic gates and 40.25 KB SRAM. Sapphire can be programmed with custom
instructions for polynomial arithmetic and sampling, and it is coupled with a
low-power RISC-V micro-processor to demonstrate NIST Round 2 lattice-based
CCA-secure key encapsulation and signature protocols Frodo, NewHope, qTESLA,
CRYSTALS-Kyber and CRYSTALS-Dilithium, achieving up to an order of magnitude
improvement in performance and energy-efficiency compared to state-of-the-art
hardware implementations. All key building blocks of Sapphire are constant-time
and secure against timing and simple power analysis side-channel attacks. We
also discuss how masking-based DPA countermeasures can be implemented on the
Sapphire core without any changes to the hardware.",232,12,1738,24.78
1915,cryptography,"Standardization of Post-Quantum Cryptography (PQC) was started by NIST in
2016 and has proceeded to its second elimination round. The upcoming standards
are intended to replace (or supplement) current RSA and Elliptic Curve
Cryptography (ECC) on all targets, including lightweight, embedded, and mobile
systems. We present an energy requirement analysis based on extensive
measurements of PQC candidate algorithms on a Cortex M4 - based reference
platform. We relate computational (energy) costs of PQC algorithms to their
data transmission costs which are expected to increase with new types of public
keys and ciphertext messages. The energy, bandwidth, and latency needs of PQC
algorithms span several orders of magnitude, which is substantial enough to
impact battery life, user experience, and application protocol design. We
propose metrics and guidelines for PQC algorithm usage in IoT and mobile
systems based on our findings. Our evidence supports the view that fast
structured-lattice PQC schemes are the preferred choice for cloud-connected
mobile devices in most use cases, even when per-bit data transmission energy
cost is relatively high.",171,8,1153,29.89
1916,cryptography,"Side-channel attacks are an unpredictable risk factor in cryptography.
Therefore, continuous observations of physical leakages are essential to
minimise vulnerabilities associated with cryptographic functions. Lightweight
cryptography is a novel approach in progress towards internet-of-things (IoT)
security. Thus, it would provide sufficient data and privacy protection in such
a constrained ecosystem. IoT devices are resource-limited in terms of data
rates (in kbps), power maintainability (battery) as well as hardware and
software footprints (physical size, internal memory, RAM/ROM). Due to the
difficulty in handling conventional cryptographic algorithms, lightweight
ciphers consist of small key sizes, block sizes and few operational rounds.
Unlike in the past, affordability to perform side-channel attacks using
inexpensive electronic circuitries is becoming a reality. Hence, cryptanalysis
of physical leakage in these emerging ciphers is crucial. Among existing
studies, power analysis seems to have enough attention in research, whereas
other aspects such as electromagnetic, timing, cache and optical attacks
continue to be appropriately evaluated to play a role in forensic analysis.
  As a result, we started analysing electromagnetic emission leakage of an
ultra-lightweight block cipher, PRESENT. According to the literature, PRESENT
promises to be adequate for IoT devices, and there still seems not to exist any
work regarding correlation electromagnetic analysis (CEMA) of it. Firstly, we
conducted simple electromagnetic analysis in both time and frequency domains
and then proceeded towards CEMA attack modelling. This paper provides a summary
of the related literature (IoT, lightweight cryptography, side-channel attacks
and EMA), our methodology, current outcomes and future plans for the optimised
results.",250,14,1835,26.61
1917,cryptography,"The existence of one-way functions is one of the most fundamental assumptions
in classical cryptography. In the quantum world, on the other hand, there are
evidences that some cryptographic primitives can exist even if one-way
functions do not exist. We therefore have the following important open problem
in quantum cryptography: What is the most fundamental element in quantum
cryptography? In this direction, Brakerski, Canetti, and Qian recently defined
a notion called EFI pairs, which are pairs of efficiently generatable states
that are statistically distinguishable but computationally indistinguishable,
and showed its equivalence with some cryptographic primitives including
commitments, oblivious transfer, and general multi-party computations. However,
their work focuses on decision-type primitives and does not cover search-type
primitives like quantum money and digital signatures. In this paper, we study
properties of one-way state generators (OWSGs), which are a quantum analogue of
one-way functions. We first revisit the definition of OWSGs and generalize it
by allowing mixed output states. Then we show the following results. (1) We
define a weaker version of OWSGs, weak OWSGs, and show that they are equivalent
to OWSGs. (2) Quantum digital signatures are equivalent to OWSGs. (3)
Private-key quantum money schemes (with pure money states) imply OWSGs. (4)
Quantum pseudo one-time pad schemes imply both OWSGs and EFI pairs. (5) We
introduce an incomparable variant of OWSGs, which we call secretly-verifiable
and statistically-invertible OWSGs, and show that they are equivalent to EFI
pairs.",235,13,1617,36.18
1918,cryptography,"The no-cloning principle of quantum mechanics enables us to achieve amazing
unclonable cryptographic primitives, which is impossible in classical
cryptography. However, the security definitions for unclonable cryptography are
tricky. Achieving desirable security notions for unclonability is a challenging
task. In particular, there is no indistinguishable-secure unclonable encryption
and quantum copy-protection for single-bit output point functions in the
standard model. To tackle this problem, we introduce and study relaxed but
meaningful security notions for unclonable cryptography in this work. We call
the new security notion one-out-of-many unclonable security.
  We obtain the following results.
  - We show that one-time strong anti-piracy secure secret key single-decryptor
encryption (SDE) implies one-out-of-many indistinguishable-secure unclonable
encryption.
  - We construct a one-time strong anti-piracy secure secret key SDE scheme in
the standard model from the LWE assumption.
  - We construct one-out-of-many copy-protection for single-bit output point
functions from one-out-of-many indistinguishable-secure unclonable encryption
and the LWE assumption.
  - We construct one-out-of-many unclonable predicate encryption (PE) from
one-out-of-many indistinguishable-secure unclonable encryption and the LWE
assumption.
  Thus, we obtain one-out-of-many indistinguishable-secure unclonable
encryption, one-out-of-many copy-protection for single-bit output point
functions, and one-out-of-many unclonable PE in the standard model from the LWE
assumption. In addition, our one-time SDE scheme is the first SDE scheme that
does not rely on any oracle heuristics and strong assumptions such as
indistinguishability obfuscation and witness encryption.",221,14,1767,12.22
1919,cryptography,"This paper presents the design, implementation, and evaluation of a new
framework called CryptoScratch, which extends the Scratch programming
environment with modern cryptographic algorithms (e.g., AES, RSA, SHA-256)
implemented as visual blocks. Using the simple interface of CryptoScratch, K-12
students can study how to use cryptographic algorithms for services like
confidentiality, authentication, and integrity protection; and then use these
blocks to build complex modern cryptographic schemes (e.g., Pretty Good
Privacy, Digital Signatures). In addition, we present the design and
implementation of a Task Block that provides students instruction on various
cryptography problems and verifies that they have successfully completed the
problem. The task block also generates feedback, nudging learners to implement
more secure solutions for cryptographic problems. An initial usability study
was performed with 16 middle-school students where students were taught basic
cryptographic concepts and then asked to complete tasks using those concepts.
Once students had knowledge of a variety of basic cryptographic algorithms,
they were asked to use those algorithms to implement complex cryptographic
schemes such as Pretty Good Privacy and Digital Signatures. Using the
successful implementation of the cryptographic and task blocks in Scratch, the
initial testing indicated that $\approx 60\%$ of the students could quickly
grasp and implement complex cryptography concepts using CryptoScratch, while
$\approx 90\%$ showed comfort with cryptography concepts and use-cases. Based
on the positive results from the initial testing, a larger study of students is
being developed to investigate the effectiveness across the socioeconomic
spectrum.",241,13,1749,30.09
1920,cryptography,"Blockchain and other Distributed Ledger Technologies (DLTs) have evolved
significantly in the last years and their use has been suggested for numerous
applications due to their ability to provide transparency, redundancy and
accountability. In the case of blockchain, such characteristics are provided
through public-key cryptography and hash functions. However, the fast progress
of quantum computing has opened the possibility of performing attacks based on
Grover's and Shor's algorithms in the near future. Such algorithms threaten
both public-key cryptography and hash functions, forcing to redesign
blockchains to make use of cryptosystems that withstand quantum attacks, thus
creating which are known as post-quantum, quantum-proof, quantum-safe or
quantum-resistant cryptosystems. For such a purpose, this article first studies
current state of the art on post-quantum cryptosystems and how they can be
applied to blockchains and DLTs. Moreover, the most relevant post-quantum
blockchain systems are studied, as well as their main challenges. Furthermore,
extensive comparisons are provided on the characteristics and performance of
the most promising post-quantum public-key encryption and digital signature
schemes for blockchains. Thus, this article seeks to provide a broad view and
useful guidelines on post-quantum blockchain security to future blockchain
researchers and developers.",192,9,1397,38.66
1921,cryptography,"We call quantum security the area of IT security dealing with scenarios where
one or more parties have access to quantum hardware. This encompasses both the
fields of post-quantum cryptography (that is, traditional cryptography
engineered to be resistant against quantum adversaries), and quantum
cryptography (that is, security protocols designed to be natively run on a
quantum infrastructure, such as quantum key distribution).
  In this work, we propose the first systematic classification of quantum
security scenarios, and for each of them we recall the main tools and results,
as well as presenting new ones. We achieve this goal by identifying four
distinct quantum security classes, or domains, each of them encompassing the
security notions and constructions related to a particular scenario. We start
with the class QS0, which is `classical cryptography' (meaning that no quantum
scenario is considered). Regarding post-quantum cryptography, we introduce the
class QS1, where we discuss in detail the problems arising when designing a
classical cryptographic object meant to be resistant against adversaries with
local quantum computing power, and we provide a classification of the possible
quantum security reductions in this scenario when considering provable
security. In respect to hybrid classical-quantum models, in the security class
QS2 we discuss in detail the possible scenarios where these scenarios arise,
and what a correct formalization should be in terms of quantum oracle access.
Finally, in the class QS3 we consider all those cryptographic constructions
designed to run natively on quantum hardware.
  We believe that the framework we introduce in this work will be a valuable
tool for the scientific community in addressing the challenges arising when
formalizing sound constructions and notions of security in the quantum world.",277,10,1860,23.29
1922,cryptography,"In modern cryptography, block encryption is a fundamental cryptographic
primitive. However, it is impossible for block encryption to achieve the same
security as one-time pad. Quantum mechanics has changed the modern
cryptography, and lots of researches have shown that quantum cryptography can
outperform the limitation of traditional cryptography.
  This article proposes a new constructive mode for private quantum encryption,
named $\mathcal{EHE}$, which is a very simple method to construct quantum
encryption from classical primitive. Based on $\mathcal{EHE}$ mode, we
construct a quantum block encryption (QBE) scheme from pseudorandom functions.
If the pseudorandom functions are standard secure, our scheme is
indistinguishable encryption under chosen plaintext attack. If the pseudorandom
functions are permutation on the key space, our scheme can achieve perfect
security. In our scheme, the key can be reused and the randomness cannot, so a
$2n$-bit key can be used in an exponential number of encryptions, where the
randomness will be refreshed in each time of encryption. Thus $2n$-bit key can
perfectly encrypt $O(n2^n)$ qubits, and the perfect secrecy would not be broken
if the $2n$-bit key is reused for only exponential times.
  Comparing with quantum one-time pad (QOTP), our scheme can be the same secure
as QOTP, and the secret key can be reused (no matter whether the eavesdropping
exists or not). Thus, the limitation of perfectly secure encryption (Shannon's
theory) is broken in the quantum setting. Moreover, our scheme can be viewed as
a positive answer to the open problem in quantum cryptography ""how to
unconditionally reuse or recycle the whole key of private-key quantum
encryption"". In order to physically implement the QBE scheme, we only need to
implement two kinds of single-qubit gates (Pauli $X$ gate and Hadamard gate),
so it is within reach of current quantum technology.",291,14,1912,40.28
1923,cryptography,"The hard mathematical problems that assure the security of our current
public-key cryptography (RSA, ECC) are broken if and when a quantum computer
appears rendering them ineffective for use in the quantum era. Lattice based
cryptography is a novel approach to public key cryptography, of which the
mathematical investigation (so far) resists attacks from quantum computers. By
choosing a module learning with errors (MLWE) algorithm as the next standard,
National Institute of Standard & Technology (NIST) follows this approach. The
multiplication of polynomials is the central bottleneck in the computation of
lattice based cryptography. Because public key cryptography is mostly used to
establish common secret keys, focus is on compact area, power and energy budget
and to a lesser extent on throughput or latency. While most other work focuses
on optimizing number theoretic transform (NTT) based multiplications, in this
paper we highly optimize a Toom-Cook based multiplier. We demonstrate that a
memory-efficient striding Toom-Cook with lazy interpolation, results in a
highly compact, low power implementation, which on top enables a very regular
memory access scheme. To demonstrate the efficiency, we integrate this
multiplier into a Saber post-quantum accelerator, one of the four NIST
finalists. Algorithmic innovation to reduce active memory, timely clock gating
and shift-add multiplier has helped to achieve 38% less power than state-of-the
art PQC core, 4x less memory, 36.8% reduction in multiplier energy and 118x
reduction in active power with respect to state-of-the-art Saber accelerator
(not silicon verified). This accelerator consumes 0.158mm2 active area which is
lowest reported till date despite process disadvantages of the state-of-the-art
designs.",260,13,1778,24.17
1924,cryptography,"Two different kinds of synchronization have been applied to cryptography:
Synchronization of chaotic maps by one common external signal and
synchronization of neural networks by mutual learning. By combining these two
mechanisms, where the external signal to the chaotic maps is synchronized by
the nets, we construct a hybrid network which allows a secure generation of
secret encryption keys over a public channel. The security with respect to
attacks, recently proposed by Shamir et al, is increased by chaotic
synchronization.",80,4,530,27.45
1925,cryptography,"A new and successful attack strategy in neural cryptography is presented. The
neural cryptosystem, based on synchronization of neural networks by mutual
learning, has been recently shown to be secure under different attack
strategies. The advanced attacker presented here, named the ``Majority-Flipping
Attacker'', is the first whose success does not decay with the parameters of
the model. This new attacker's outstanding success is due to its using a group
of attackers which cooperate throughout the synchronization process, unlike any
other attack strategy known. An analytical description of this attack is also
presented, and fits the results of simulations.",98,6,664,34.66
1926,cryptography,"Neural cryptography is based on synchronization of tree parity machines by
mutual learning. We extend previous key-exchange protocols by replacing random
inputs with queries depending on the current state of the neural networks. The
probability of a successful attack is calculated for different model parameters
using numerical simulations. The results show that queries restore the security
against cooperating attackers. The success probability can be reduced without
increasing the average synchronization time.",71,6,515,14.76
1927,cryptography,"A principled procedure to infer a hierarchy of statistical distributions
possessing ill-conditioned eigenstructures, from incomplete constraints, is
presented. The inference process of the \textit{pdf}'s employs the Fisher
information as the measure of uncertainty, and, utilizes a semi-supervised
learning paradigm based on a measurement-response model. The principle
underlying the learning paradigm involves providing a quantum mechanical
connotation to statistical processes. The inferred \textit{pdf}'s constitute a
statistical host that facilitates the encryption/decryption of covert
information (code). A systematic strategy to encrypt/decrypt code via unitary
projections into the \textit{null spaces} of the ill-conditioned
eigenstructures, is presented. Numerical simulations exemplify the efficacy of
the model.",101,7,823,-4.81
1928,cryptography,"In this short note we want to introduce {\em anonymous oblivious transfer} a
new cryptographic primitive which can be proven to be strictly more powerful
than oblivious transfer. We show that all functions can be robustly realized by
multi party protocols with {\em anonymous oblivious transfer}. No assumption
about possible collusions of cheaters or disruptors have to be made.
Furthermore we shortly discuss how to realize anonymous oblivious transfer with
oblivious broadcast or by quantum cryptography. The protocol of anonymous
oblivious transfer was inspired by a quantum protocol: the anonymous quantum
channel.",92,6,619,44.34
1929,cryptography,"We develop cryptographically secure techniques to guarantee unconditional
privacy for respondents to polls. Our constructions are efficient and
practical, and are shown not to allow cheating respondents to affect the
``tally'' by more than their own vote -- which will be given the exact same
weight as that of other respondents. We demonstrate solutions to this problem
based on both traditional cryptographic techniques and quantum cryptography.",66,4,447,32.53
1930,cryptography,"In 2004, W. C. Ku and S. M. Chen proposed an efficient remote user
authentication scheme using smart cards to solve the security problems of Chien
et al.'s scheme. Recently, Hsu and Yoon et al. pointed out the security
weaknesses of the Ku and Chen's scheme Furthermore, Yoon et al. also proposed a
new efficient remote user authentication scheme using smart cards. Yoon et al.
also modified the password change phase of Ku and Chen's scheme. This paper
analyzes that password change phase of Yoon et al's modified scheme is still
insecure.",92,13,540,69.58
1931,cryptography,"The Echo protocol tries to do secure location verification using physical
limits imposed by the speeds of light and sound. While the protocol is able to
guarantee that a certain object is within a certain region, it cannot ensure
the authenticity of further messages from the object without using
cryptography. This paper describes an impersonation attack against the protocol
based on this weakness. It also describes a couple of approaches which can be
used to defend against the attack.",79,5,489,42.92
1932,cryptography,"The linear complexity of a periodic sequence over $GF(p^m)$ plays an
important role in cryptography and communication [12]. In this correspondence,
we prove a result which reduces the computation of the linear complexity and
minimal connection polynomial of a period $un$ sequence over $GF(p^m)$ to the
computation of the linear complexities and minimal connection polynomials of
$u$ period $n$ sequences. The conditions $u|p^m-1$ and
  $\gcd(n,p^m-1)=1$ are required for the result to hold. Some applications of
this reduction in fast algorithms to determine the linear complexities and
minimal connection polynomials of sequences over $GF(p^m)$ are presented.",95,5,661,21.94
1933,cryptography,"Conjugacy is not the only possible primitive for designing braid-based
protocols. To illustrate this principle, we describe a Fiat--Shamir-style
authentication protocol that be can be implemented using any binary operation
that satisfies the left self-distributive law. Conjugation is an example of
such an operation, but there are other examples, in particular the shifted
conjugation on Artin's braid group B\_oo, and the finite Laver tables. In both
cases, the underlying structures have a high combinatorial complexity, and they
lead to difficult problems.",81,5,560,25.49
1934,cryptography,"The purpose of the paper is to give new key agreement protocols (a
multi-party extension of the protocol due to Anshel-Anshel-Goldfeld and a
generalization of the Diffie-Hellman protocol from abelian to solvable groups)
and a new homomorphic public-key cryptosystem. They rely on difficulty of the
conjugacy and membership problems for subgroups of a given group. To support
these and other known cryptographic schemes we present a general technique to
produce a family of instances being matrix groups (over finite commutative
rings) which play a role for these schemes similar to the groups $Z\_n^*$ in
the existing cryptographic constructions like RSA or discrete logarithm.",103,4,677,28.2
1935,cryptography,"In this paper, we study cryptography from a geometrical viewpoint. Let N be a
network, we endow N with a natural Grothendieck topology. We use geometric
representations of cohomological classes to define encryptions protocols. Link
to link encryption is related to the notion of torsors. We use the notion of
connective structure defined on a gerbe to define public encryption. We study
statistical properties of data conveyed in a network, and define an entropy
cocycle.",75,7,471,41.87
1936,cryptography,"By combining the one-way coupled chaotic map lattice system with a
bit-reverse operation, we construct a new cryptosystem which is extremely
sensitive to the system parameters even for low-dimensional systems. The
security of this new algorithm is investigated and mechanism of the sensitivity
is analyzed. We further apply this cryptosystem to the public channel
cryptography, based on ""Merkle's puzzles"", by employing it both as
pseudo-random-number (PN) generators and symmetric encryptor. With the
properties of spatiotemporal chaos, the new scheme is rich with new features
and shows some advantages in comparison with the conventional ones.",94,5,646,22.24
1937,cryptography,"We show in details the four quantum key distribution protocols which
initiated the important field of quantum cryptography, using an accessible
language for undergraduate students. We begin presenting the BB84 protocol,
which uses polarization states of photons in order to transmit cryptographic
keys. Thereupon we show the E91 protocol, whose security is based on the use of
singlet states to generate a random sequence of bits. We end the paper with the
BBM92 and the B92 protocol. These last two protocols can be seen as simplified
versions of the first two.",91,6,562,44.54
1938,cryptography,"All existing quantum cryptosystems use non-orthogonal states as the carriers
of information. Non-orthogonal states cannot be cloned (duplicated) by an
eavesdropper. In result, any eavesdropping attempt must introduce errors in the
transmission, and therefore, can be detected by the legal users of the
communication channel. Orthogonal states are not used in quantum cryptography,
since they can be faithfully cloned without altering the transmitted data. In
this Letter we present a cryptographic scheme based on orthogonal states, which
also assures the detection of any eavesdropper.",84,6,586,37.5
1939,cryptography,"Recent progress in quantum cryptography and quantum computers has given hope
to their imminent practical realization. An essential element at the heart of
the application of these quantum systems is a quantum error correction scheme.
We propose a new technique based on the use of coding in order to detect and
correct errors due to imperfect transmission lines in quantum cryptography or
memories in quantum computers. We give a particular example of how to detect a
decohered qubit in order to transmit or preserve with high fidelity the
original qubit.",90,5,555,40.18
1940,cryptography,"We provide a complete proof of the security of quantum cryptography against
any eavesdropping attack including coherent measurements even in the presence
of noise. Polarization-based cryptographic schemes are shown to be equivalent
to EPR-based schemes. We also show that the performance of a noisy channel
approaches that of a noiseless one as the error rate tends to zero. (i.e., the
secrecy capacity $C_s (\epsilon) \to C_s (0)$ as $\epsilon \to 0$.) One
implication of our results is that one can {\it double} the efficiency of a
most well-known quantum cryptographic scheme proposed by Bennett and Brassard
simply by assigning vastly different probabilities to the two conjugate bases.",107,8,690,41.29
1941,cryptography,"Classical and quantum information are very different. Together they can
perform feats that neither could achieve alone, such as quantum computing,
quantum cryptography and quantum teleportation. Some of the applications range
from helping to preventing spies from reading private communications. Among the
tools that will facilitate their implementation, we note quantum purification
and quantum error correction. Although some of these ideas are still beyond the
grasp of current technology, quantum cryptography has been implemented and the
prospects are encouraging for small-scale prototypes of quantum computation
devices before the end of the millennium.",92,6,660,35.88
1942,cryptography,"An elementary derivation of best eavesdropping strategies for the 4 state
BB84 quantum cryptography protocol is presented, for both incoherent and
two--qubit coherent attacks. While coherent attacks do not help Eve to obtain
more information, they are more powerful to reveal the whole message sent by
Alice. Our results are based on symmetric eavesdropping strategies, which we
show to be sufficient to analyze these kind of problems.",67,4,435,40.38
1943,cryptography,"Quantum Cryptography over 23km of installed Telecom fiber using a novel
interferometer with Faraday mirrors is presented. The interferometer needs no
alignment nor polarization control and features 99.8% fringe visibility. A
secret key of 20kbit length with a error rate of 1.35% for 0.1 photon per pulse
was produced.",49,7,318,46.23
1944,cryptography,"The desire to obtain an unconditionally secure bit commitment protocol in
quantum cryptography was expressed for the first time thirteen years ago. Bit
commitment is sufficient in quantum cryptography to realize a variety of
applications with unconditional security. In 1993, a quantum bit commitment
protocol was proposed together with a security proof. However, a basic flaw in
the protocol was discovered by Mayers in 1995 and subsequently by Lo and Chau.
Later the result was generalized by Mayers who showed that unconditionally
secure bit commitment is impossible. A brief review on quantum bit commitment
which focuses on the general impossibility theorem and on recent attempts to
bypass this result is provided.",111,7,720,27.32
1945,cryptography,"The significance of quantum computation for cryptography is discussed.
Following a brief survey of the requirements for quantum computational
hardware, an overview of the ion trap quantum computation project at Los Alamos
is presented. The physical limitations to quantum computation with trapped ions
are analyzed and an assessment of the computational potential of the technology
is made.",57,4,390,26.81
1946,cryptography,"In this article I present a protocol for quantum cryptography which is secure
against attacks on individual signals. It is based on the Bennett-Brassard
protocol of 1984 (BB84). The security proof is complete as far as the use of
single photons as signal states is concerned. Emphasis is given to the
practicability of the resulting protocol. For each run of the quantum key
distribution the security statement gives the probability of a successful key
generation and the probability for an eavesdropper's knowledge, measured as
change in Shannon entropy, to be below a specified maximal value.",95,6,594,35.27
1947,cryptography,"Several mechanisms that affect one and two photon coherence in optical fibers
and their remedies are discussed. The results are illustrated on quantum
cryptography experiments and on long distance Bell inequality tests.",32,3,219,38.32
1948,cryptography,"Correlations of the type discussed by EPR in their original 1935 paradox for
continuous variables exist for the quadrature phase amplitudes of two spatially
separated fields. These correlations were experimentally reported in 1992. We
propose to use such EPR beams in quantum cryptography, to transmit with high
efficiency messages in such a way that the receiver and sender may later
determine whether eavesdropping has occurred. The merit of the new proposal is
in the possibility of transmitting a reasonably secure yet predetermined key.
This would allow relay of a cryptographic key over long distances in the
presence of lossy channels.",100,6,642,42.72
1949,cryptography,"Like all of quantum information theory, quantum cryptography is traditionally
based on two level quantum systems. In this letter, a new protocol for quantum
key distribution based on higher dimensional systems is presented. An
experimental realization using an interferometric setup is also proposed.
Analyzing this protocol from the practical side, one finds an increased key
creation rate while keeping the initial laser pulse rate constant. Analyzing it
for the case of intercept/resend eavesdropping strategy, an increased error
rate is found compared to two dimensional systems, hence an advantage for the
legitimate users to detect an eavesdropper.",96,6,654,26.61
1950,cryptography,"We present a setup for quantum cryptography based on photon pairs in
energy-time Bell states and show its feasability in a laboratory experiment.
Our scheme combines the advantages of using photon pairs instead of faint laser
pulses and the possibility to preserve energy-time entanglement over long
distances. Moreover, using 4-dimensional energy-time states, no fast random
change of bases is required in our setup : Nature itself decides whether to
measure in the energy or in the time base.",78,4,494,36.93
1951,cryptography,"Using polarization-entangled photons from spontaneous parametric
downconversion, we have implemented Ekert's quantum cryptography protocol. The
near-perfect correlations of the photons allow the sharing of a secret key
between two parties. The presence of an eavesdropper is continually checked by
measuring Bell's inequalities. We investigated several possible eavesdropper
strategies, including pseudo-quantum non-demolition measurements. In all cases,
the eavesdropper's presence was readily apparent. We discuss a procedure to
increase her detectability.",69,7,558,9.04
1952,cryptography,"By realizing a quantum cryptography system based on polarization entangled
photon pairs we establish highly secure keys, because a single photon source is
approximated and the inherent randomness of quantum measurements is exploited.
We implement a novel key distribution scheme using Wigner's inequality to test
the security of the quantum channel, and, alternatively, realize a variant of
the BB84 protocol. Our system has two completely independent users separated by
360 m, and generates raw keys at rates of 400 - 800 bits/second with bit error
rates arround 3 percent.",89,4,574,24.82
1953,cryptography,"A new cryptographic tool, anonymous quantum key technique, is introduced that
leads to unconditionally secure key distribution and encryption schemes that
can be readily implemented experimentally in a realistic environment. If
quantum memory is available, the technique would have many features of
public-key cryptography; an identification protocol that does not require a
shared secret key is provided as an illustration. The possibility is also
indicated for obtaining unconditionally secure quantum bit commitment protocols
with this technique.",76,4,549,3.5
1954,cryptography,"The promise of secure cryptographic quantum key distribution schemes is based
on the use of quantum effects in the spin space. We point out that in fact in
many current quantum cryptography protocols the space part of the wave function
is neglected. However exactly the space part of the wave function describes the
behaviour of particles in ordinary real three-dimensional space. As a result
such schemes can be secure against eavesdropping attacks in the abstract spin
space but could be insecure in the real three-dimensional space. We discuss an
approach to the security of quantum key distribution in space by using Bell's
inequality and a special preparation of the space part of the wave function.",115,6,704,48.13
1955,cryptography,"Silicon avalanche photodiodes are the most sensitive photodetectors in the
visible to near infrared region. However, when they are used for single photon
detection in a Geiger mode, they are known to emit light on the controlled
breakdown used to detect a photoelectron. This fluorescence light might have
serious impacts on experimental applications like quantum cryptography or
single-particle spectroscopy. We characterized the fluorescence behaviour of
silicon avalanche photodiodes in the experimentally simple passive quenching
configuration and discuss implications for their use in quantum cryptography
systems.",85,5,619,16.02
1956,cryptography,"A photon source based on postselection from entangled photon pairs produced
by parametric frequency down-conversion is suggested. Its ability to provide
good approximations of single-photon states is examined. Application of this
source in quantum cryptography for quantum key distribution is discussed.
Advantages of the source compared to other currently used sources are
clarified. Future prospects of the photon source are outlined.",61,6,436,33.71
1957,cryptography,"Quantum cryptography with the predetermined key was experimentally realized
using Einstein-Podolsky-Rosen(EPR) correlations of continuously bright optical
beams. Only one of two EPR correlated beams is transmitted with the signals
modulated on quadrature phases and amplitudes, and the other one is retained by
the authorized receiver. The modulated small signals are totally submerged in
the large quantum noise of the signal beam, therefore nobody except the
authorized receiver can decode the signals. Usability of imperfect quantum
correlation, high transmission and detection efficiencies, and security
provided by quantum mechanics are the favorable features of the presented
scheme.",95,5,689,13.48
1958,cryptography,"We report the full implementation of a quantum cryptography protocol using a
stream of single photon pulses generated by a stable and efficient source
operating at room temperature. The single photon pulses are emitted on demand
by a single nitrogen-vacancy (NV) color center in a diamond nanocrystal. The
quantum bit error rate is less that 4.6% and the secure bit rate is 9500
bits/s. The overall performances of our system reaches a domain where single
photons have a measurable advantage over an equivalent system based on
attenuated light pulses.",89,6,551,44.95
1959,cryptography,"A quantum cryptography scheme based on entanglement between a single particle
state and a vacuum state is proposed. The scheme utilizes linear optics devices
to detect the superposition of the vacuum and single particle states. Existence
of an eavesdropper can be detected by using a variant of Bell's inequality.",49,4,313,38.01
1960,cryptography,"We analyze the security of quantum cryptography schemes for $d$-level systems
using 2 or $d+1$ maximally conjugated bases, under individual eavesdropping
attacks based on cloning machines and measurement after the basis
reconciliation. We consider classical advantage distillation protocols, that
allow to extract a key even in situations where the mutual information between
the honest parties is smaller than the eavesdropper's information. In this
scenario, advantage distillation protocols are shown to be as powerful as
quantum distillation: key distillation is possible using classical techniques
if and only if the corresponding state in the entanglement based protocol is
distillable.",97,4,692,4.85
1961,cryptography,"We present a protocol for quantum cryptography in which the data obtained for
mismatched bases are used in full for the purpose of quantum state tomography.
Eavesdropping on the quantum channel is seriously impeded by requiring that the
outcome of the tomography is consistent with unbiased noise in the channel. We
study the incoherent eavesdropping attacks that are still permissible and
establish under which conditions a secure cryptographic key can be generated.
The whole analysis is carried out for channels that transmit quantum systems of
any finite dimension.",88,5,569,40.69
1962,cryptography,"Multiphoton state in quantum cryptography decreases its security. Key
disclosing with universal quantum cloning machine (UQCM) is considered in
explicit manner. Although UQCM cannot make perfect clones, there is some
invariant quantity between the original photon and the imperfect clones. The
invariant quantity, the direction of Stokes parameters, tells us the auxiliary
information leading into key information. The attack, then, corresponds to some
kind of quantum non-demolition measurement. Its application to recent
high-performance quantum cryptography, Y-00 protocol, is also studied.",80,7,593,24.14
1963,cryptography,"We demonstrate single-photon interference over 100 km using a balanced
gated-mode photon detector and a plug & play system for quantum key
distribution. The visibility with 0.1 photon/pulse was more than 80% after 100
km transmission. This corresponds to the fidelity of a quantum cryptography
system of more than 90% and a QBER of less than 10%, satisfying the security
criteria.",61,5,380,39.33
1964,cryptography,"The methods of quantum cryptography enable one to have perfectly secure
communication lines, whereby the laws of quantum physics protect the privacy of
the data exchanged. Each quantum-cryptography scheme has its own security
criteria that need to be met in a practical implementation. We find, however,
that the generally accepted criteria are flawed for a whole class of such
schemes.",60,4,386,34.26
1965,cryptography,"The communication protocol of Home and Whitaker [Phys. Rev. A 67, 022306
(2003)] is examined in some detail, and found to work equally well using a
separable state. The protocol is in fact completely classical, based on simple
post-selection of suitable experimental runs. The quantum cryptography protocol
proposed in the same publication is also examined, and is found to indeed need
quantum properties for the system to be secure. However, the security test
proposed in the mentioned paper is found to be insufficient, and a modification
is proposed here that will ensure security.",93,7,584,35.68
1966,cryptography,"We find that the generally accepted security criteria are flawed for a whole
class of protocols for quantum cryptography. This is so because a standard
assumption of the security analysis, namely that the so-called square-root
measurement is optimal for eavesdropping purposes, is not true in general.
There are rather large parameter regimes in which the optimal measurement
extracts substantially more information than the square-root measurement.",65,4,449,32.53
1967,cryptography,"New quantum cryptography, often called Y-00 protocol, has much higher
performance than the conventional quantum cryptographies. It seems that the
conventional quantum cryptographic attacks are inefficient at Y-00 protocol as
its security is based on the different grounds from that of the conventional
ones. We have, then, tried to cryptoanalyze Y-00 protocol in the view of
cryptographic communication system. As a result, it turns out that the security
of Y-00 protocol is equivalent to that of classical stream cipher.",79,5,521,34.46
1968,cryptography,"We have demonstrated single-photon interference over 150 km using
time-division interferometers for quantum cryptography, which were composed of
two integrated-optic asymmetric Mach-Zehnder interferometers, and balanced
gated-mode photon detectors. The observed fringe visibility was more than 80%
after 150-km transmission.",39,3,324,0.92
1969,cryptography,"In this letter, first, we investigate the security of a continuous-variable
quantum cryptographic scheme with a postselection process against individual
beam splitting attack. It is shown that the scheme can be secure in the
presence of the transmission loss owing to the postselection. Second, we
provide a loss limit for continuous-variable quantum cryptography using
coherent states taking into account excess Gaussian noise on quadrature
distribution. Since the excess noise is reduced by the loss mechanism, a
realistic intercept-resend attack which makes a Gaussian mixture of coherent
states gives a loss limit in the presence of any excess Gaussian noise.",99,5,663,29.38
1970,cryptography,"In this work we review the security vulnerability of Quantum Cryptography
with respect to ""man-in-the-middle attacks"" and the standard authentication
methods applied to counteract these attacks. We further propose a modified
authentication algorithm which features higher efficiency with respect to
consumption of mutual secret bits.",45,3,333,14.8
1971,cryptography,"In this paper we analyze the security of the so-called quantum tomographic
cryptography with the source producing entangled photons via an experimental
scheme proposed in Phys. Rev. Lett. 92, 37903 (2004). We determine the range of
the experimental parameters for which the protocol is secure against the most
general incoherent attacks.",51,6,337,37.3
1972,cryptography,"We present a three-stage quantum cryptographic protocol guaranteeing security
in which each party uses its own secret key. Unlike the BB84 protocol, where
the qubits are transmitted in only one direction and classical information
exchanged thereafter, the communication in the proposed protocol remains
quantum in each stage. A related system of key distribution is also described.",56,4,381,27.11
1973,cryptography,"As an alternative to the usual key generation by two-way communication in
schemes for quantum cryptography, we consider codes for key generation by
one-way communication. We study codes that could be applied to the raw key
sequences that are ideally obtained in recently proposed scenarios for quantum
key distribution, which can be regarded as communication through symmetric
four-letter channels.",59,3,398,24.61
1974,cryptography,"We consider the cloning of sequences of qubits prepared in the states used in
the BB84 or 6-state quantum cryptography protocol, and show that the
single-qubit fidelity is unaffected even if entire sequences of qubits are
prepared in the same basis. This result is of great importance for practical
quantum cryptosystems because it reduces the need for high-speed random number
generation without impairing on the security against finite-size attacks.",69,3,451,28.0
1975,cryptography,"The impossibility of perfectly copying (or cloning) an arbitrary quantum
state is one of the basic rules governing the physics of quantum systems. The
processes that perform the optimal approximate cloning have been found in many
cases. These ""quantum cloning machines"" are important tools for studying a wide
variety of tasks, e.g. state estimation and eavesdropping on quantum
cryptography. This paper provides a comprehensive review of quantum cloning
machines (both for discrete-dimensional and for continuous-variable quantum
systems); in addition, it presents the role of cloning in quantum cryptography,
the link between optimal cloning and light amplification via stimulated
emission, and the experimental demonstrations of optimal quantum cloning.",107,7,756,32.83
1976,cryptography,"Quantum cryptography is the only approach to privacy ever proposed that
allows two parties (who do not share a long secret key ahead of time) to
communicate with provably perfect secrecy under the nose of an eavesdropper
endowed with unlimited computational power and whose technology is limited by
nothing but the fundamental laws of nature. This essay provides a personal
historical perspective on the field. For the sake of liveliness, the style is
purposely that of a spontaneous after-dinner speech.",80,4,504,35.91
1977,cryptography,"This is a study of the security of the Coherent One-Way (COW) protocol for
quantum cryptography, proposed recently as a simple and fast experimental
scheme. In the zero-error regime, the eavesdropper Eve can only take advantage
of the losses in the transmission. We consider new attacks, based on
unambiguous state discrimination, which perform better than the basic
beam-splitting attack, but which can be detected by a careful analysis of the
detection statistics. These results stress the importance of testing several
statistical parameters in order to achieve higher rates of secret bits.",91,5,593,31.41
1978,cryptography,"We consider a variant of the BB84 protocol for quantum cryptography, the
prototype of tomographically incomplete protocols, where the key is generated
by one-way communication rather than the usual two-way communication. Our
analysis, backed by numerical evidence, establishes thresholds for
eavesdropping attacks on the raw data and on the generated key at quantum bit
error rates of 10% and 6.15%, respectively. Both thresholds are lower than the
threshold for unconditional security in the standard BB84 protocol.",76,5,516,20.42
1979,cryptography,"Quantum cryptography can, in principle, provide unconditional security
guaranteed by the law of physics only. Here, we survey the theory and practice
of the subject and highlight some recent developments.",30,3,204,30.87
1980,cryptography,"We use the probability of error as a measure of distinguishability between
two pure and two mixed symmetric coherent states in the context of continuous
variable quantum cryptography. We show that the two mixed symmetric coherent
states (in which the various components have the same real part) never give an
eavesdropper more information than two pure coherent states.",58,3,369,33.58
1981,cryptography,"We introduce a new approach for cryptanalysis of key agreement protocols
based on noncommutative groups. This approach uses functions that estimate the
distance of a group element to a given subgroup. We test it against the
Shpilrain-Ushakov protocol, which is based on Thompson's group F.",45,4,289,56.25
1982,cryptography,"Fuzzy sketches, introduced as a link between biometry and cryptography, are a
way of handling biometric data matching as an error correction issue. We focus
here on iris biometrics and look for the best error-correcting code in that
respect. We show that two-dimensional iterative min-sum decoding leads to
results near the theoretical limits. In particular, we experiment our
techniques on the Iris Challenge Evaluation (ICE) database and validate our
findings.",70,5,462,36.79
1983,cryptography,"Efficient computation of the Tate pairing is an important part of
pairing-based cryptography. Recently with the introduction of the Duursma-Lee
method special attention has been given to the fields of characteristic 3.
Especially multiplication in F_{3^{6m}}, where m is prime, is an important
operation in the above method. In this paper we propose a new method to reduce
the number of F_{3^m} multiplications for multiplication in F_{3^{6m}} from 18
in recent implementations to 15. The method is based on the fast Fourier
tranmsform and explicit formulas are given. The execution times of our software
implementations for F_{3^{6m}} show the efficiency of our results.",103,7,671,45.56
1984,cryptography,"In this work we present a new structure for multiplication in finite fields.
This structure is based on a digit-level LFSR (Linear Feedback Shift Register)
multiplier in which the area of digit-multipliers are reduced using the
Karatsuba method. We compare our results with the other works in the literature
for F_{3^97}. We also propose new formulas for multiplication in F_{3^{6*97}}.
These new formulas reduce the number of F_{3^97}-multiplications from 18 to 15.
The fields F_{3^{97}} and F_{3^{6*97}} are relevant in the context of
pairing-based cryptography.",85,7,564,48.6
1985,cryptography,"We analyse the distribution of secure keys using quantum cryptography based
on the continuous variable degree of freedom of entangled photon pairs. We
derive the information capacity of a scheme based on the spatial entanglement
of photons from a realistic source, and show that the standard measures of
security known for quadrature-based continuous variable quantum cryptography
(CV-QKD) are inadequate. A specific simple eavesdropping attack is analysed to
illuminate how secret information may be distilled well beyond the bounds of
the usual CV-QKD measures.",83,4,563,17.98
1986,cryptography,"Recently the explicit applicability of bound entanglement in quantum
cryptography has been shown. In this paper some of recent results respecting
this topic are reviewed. In particular relevant notions and definitions are
reminded. The new construction of bound entangled states containing secure
correlations is presented. It provides low dimensional 6\otimes6 bound
entangled states with nonzero distillable key.",57,6,414,26.06
1987,cryptography,"Prime reciprocals have applications in coding and cryptography and for
generation of random sequences. This paper investigates the structural
redundancy of prime reciprocals in base 10 in a manner that parallels an
earlier study for binary prime reciprocals. Several different kinds of
structural relationships amongst the digits in reciprocal sequences are
classified with respect to the digit in the least significant place of the
prime. It is also shown that the frequency of digit 0 exceeds that of every
other digit when the entire set of prime reciprocal sequences is considered.",91,5,585,31.41
1988,cryptography,"In this letter we consider a prototype model which is described as an
autonomous continuous time delayed differential equation with just one
variable. The chaos has been investigated with variable delay time and the
synchronization phenomenon is examined both numerically and analytically using
the Krasovskii-Lyapunov functions. We have applied adaptive coupling law for
synchronization,where the coupling equation also contains delay with modulated
time. We also studied the effect of cryptography for this coupled system and
the message extraction procedure is illustrated with the help of simulated
results.",87,5,611,23.97
1989,cryptography,"The goal of this paper is to introduce ideas and methodology of the generic
case complexity to cryptography community. This relatively new approach allows
one to analyze the behavior of an algorithm on ''most'' inputs in a simple and
intuitive fashion which has some practical advantages over classical methods
based on averaging. We present an alternative definition of one-way function
using the concepts of generic case complexity and show its equivalence to the
standard definition. In addition we demonstrate the convenience of the new
approach by giving a short proof that extending adversaries to a larger class
of partial algorithms with errors does not change the strength of the security
assumption.",111,5,709,34.8
1990,cryptography,"We provide a simple description of the most general collective Gaussian
attack in continuous-variable quantum cryptography. In the scenario of such
general attacks, we analyze the asymptotic secret-key rates which are
achievable with coherent states, joint measurements of the quadratures and
one-way classical communication.",44,3,325,23.77
1991,cryptography,"This paper considers interactions between cellular automata and cryptology.
It is known that non-linear elementary rule which is correlation-immune don't
exist. This results limits the use of cellular automata as pseudo-random
generators suitable for cryptographic applications. In addition, for this kind
of pseudo-random generators, a successful cryptanalysis was proposed by Meier
and Staffelbach. However, other ways to design cellular automata capable to
generate good pseudo-random sequences remain and will be discussed in the end
of this article.",77,6,554,13.54
1992,cryptography,"We develop and present a quantum cryptography concept in which phase
determinations are made from the time that a photon is detected, as opposed to
where the photon is detected, and hence is a non-interferometric process. The
phase-encoded quantum information is contained in temporal and polarization
superpositions of single photon states, forming a complex qudit of Hilbert
dimension D equal to or greater than 4. Based on this, we have developed a new
quantum key distribution protocol that allows the generation of secret key in
the presence of higher noise than is possible with other protocols.",96,4,601,30.54
1993,cryptography,"This paper deals with products of moderate-size primes, familiarly known as
smooth numbers. Smooth numbers play a crucial role in information theory,
signal processing and cryptography.
  We present various properties of smooth numbers relating to their
enumeration, distribution and occurrence in various integer sequences. We then
turn our attention to cryptographic applications in which smooth numbers play a
pivotal role.",60,5,426,30.87
1994,cryptography,"In this paper we review and comment on ""A novel protocol-authentication
algorithm ruling out a man-in-the-middle attack in quantum cryptography"", [M.
Peev et al., Int. J. Quant. Inform., 3, 225, (2005)]. In particular, we point
out that the proposed primitive is not secure when used in a generic protocol,
and needs additional authenticating properties of the surrounding
quantum-cryptographic protocol.",59,9,404,39.53
1995,cryptography,"We find a resonance behavior in the disturbance when an eavesdropper chooses
a near-optimal strategy intentionally or unintentionally when the usual
Bennett-Brassard cryptographic scheme is performed between two trusted parties.
This phenomenon tends to disappear when eavesdropping strategy moves far from
the optimal one. Therefore, we conjecture that this resonant effect is a
characteristic for the eavesdropping strategy near to optimal one. We argue
that this effect makes the quantum cryptography more secure against the
eavesdropper's attack.",77,5,550,26.51
1996,cryptography,"The constraints of lightweight distributed computing environments such as
wireless sensor networks lend themselves to the use of symmetric cryptography
to provide security services. The lack of central infrastructure after
deployment of such networks requires the necessary symmetric keys to be
predistributed to participating nodes. The rich mathematical structure of
combinatorial designs has resulted in the proposal of several key
predistribution schemes for wireless sensor networks based on designs. We
review and examine the appropriateness of combinatorial designs as a tool for
building key predistribution schemes suitable for such environments.",90,5,655,14.8
1997,cryptography,"Some quantum cryptographic protocols can be implemented with specially
prepared chocolate balls, others protected by value indefiniteness cannot.
Similarities and differences of cryptography with quanta and chocolate are
discussed. Motivated by these considerations it is proposed to certify quantum
random number generators and quantum cryptographic protocols by value
indefiniteness. This feature, which derives itself from Bell- and
Kochen-Specker type arguments, is only present in systems with three or more
mutually exclusive outcomes.",72,5,541,10.91
1998,cryptography,"Symmetric extendibility of quantum states has recently drawn attention in the
context of quantum cryptography to judge whether quantum states shared between
two distant parties can be purified by means of one-way error correction
protocols. In this letter we study the symmetric extendibility in a specific
class of two-qudit states, i. e. states composed of two d-level systems, in
order to find upper bounds on tolerable error rates for a wide class of
qudit-based quantum cryptographic protocols using two-way error correction. In
important cases these bounds coincide with previously known lower bounds,
thereby proving sharpness of these bounds in arbitrary finite-dimensional
systems.",102,6,690,37.13
1999,cryptography,"This paper is a guide for the pure mathematician who would like to know more
about cryptography based on group theory. The paper gives a brief overview of
the subject, and provides pointers to good textbooks, key research papers and
recent survey papers in the area.",46,3,266,56.59
2000,postmodern literature,"Many believe that Large Language Models (LLMs) open the era of Artificial
Intelligence (AI). Some see opportunities while others see dangers. Yet both
proponents and opponents grasp AI through the imagery popularised by science
fiction. Will the machine become sentient and rebel against its creators? Will
we experience a paperclip apocalypse? Before answering such questions, we
should first ask whether this mental imagery provides a good description of the
phenomenon at hand. Understanding weather patterns through the moods of the
gods only goes so far. The present paper instead advocates understanding LLMs
and their connection to AI through the imagery of Jorge Luis Borges, a master
of 20th century literature, forerunner of magical realism, and precursor to
postmodern literature. This exercise leads to a new perspective that
illuminates the relation between language modelling and artificial
intelligence.",136,8,918,47.69
2001,postmodern literature,"Literary critics often attempt to uncover meaning in a single work of
literature through careful reading and analysis. Applying natural language
processing methods to aid in such literary analyses remains a challenge in
digital humanities. While most previous work focuses on ""distant reading"" by
algorithmically discovering high-level patterns from large collections of
literary works, here we sharpen the focus of our methods to a single literary
theory about Italo Calvino's postmodern novel Invisible Cities, which consists
of 55 short descriptions of imaginary cities. Calvino has provided a
classification of these cities into eleven thematic groups, but literary
scholars disagree as to how trustworthy his categorization is. Due to the
unique structure of this novel, we can computationally weigh in on this debate:
we leverage pretrained contextualized representations to embed each city's
description and use unsupervised methods to cluster these embeddings.
Additionally, we compare results of our computational approach to similarity
judgments generated by human readers. Our work is a first step towards
incorporating natural language processing into literary criticism.",169,8,1183,21.63
2002,postmodern literature,"In this lecture I will review some recent progress in improving the accuracy
of the calculation of density perturbations resulting from inflation.",22,2,146,23.77
2003,postmodern literature,"This is a talk concerning the irrationality of prominent physicists with
regard to the foundations of quantum mechanics, delivered at a conference on
the irrationality of the postmodern attack on science by nonscientists.",33,2,221,12.6
2004,postmodern literature,"The composition as well as the very existence of the interior of a
Schwarzschild black hole (BH) remains at the forefront of open problems in
fundamental physics. To address this issue, we turn to Hawking's ""principle of
ignorance"", which says that, for an observer with limited information, all
descriptions that are consistent with known physics are equally valid. We
compare three different observers who view the BH from the outside and agree on
the external Schwarzschild geometry. First, the modernist, who accepts the
classical BH as the final state of gravitational collapse, the singularity
theorems that underlie this premise and the central singularity that the
theorems predict. The modernist is willing to describe matter in terms of
quantum fields in curved space but insists on (semi)classical gravity. Second
is the skeptic, who wishes to evade any singular behavior by finding a loophole
to the singularity theorems within the realm of classical general relativity
(GR). The third is a postmodernist who similarly wants to circumvent the
singularity theorems but is willing to invoke exotic quantum physics in the
gravitational and/or matter sector to do so. The postmodern view suggests that
the uncertainty principle can stabilize a classically singular BH in a similar
manner to the stabilization of the classically unstable hydrogen atom: Strong
quantum effects in the matter and gravitational sectors resolve the would-be
singularity over horizon-sized length scales. The postmodern picture then
requires a significant departure from (semi)classical gravity, as well as some
exotic matter beyond the standard model of particle physics (SM). We find that
only the postmodern framework is consistent with what is known so far about BH
physics and conclude that a valid description of the BH interior needs matter
beyond the SM and gravitational physics beyond (semi)classical GR.",292,11,1899,33.38
2005,postmodern literature,"Using new insights into strongly coupled gauge theories arising from analytic
calculations and lattice simulations, we explore a framework for technicolor
model building that relies on a non-trivial infrared fixed point, and an
essential role for QCD. Interestingly, the models lead to a simple relation
between the electroweak scale and the QCD confinement scale, and to the
possible existence of exotic leptoquarks with masses of several hundred GeV.",68,3,452,20.05
2006,postmodern literature,"This article discusses what can be proved about the foundations of
mathematics using the notions of algorithm and information. The first part is
retrospective, and presents a beautiful antique, Godel's proof, the first
modern incompleteness theorem, Turing's halting problem, and a piece of
postmodern metamathematics, the halting probability Omega. The second part
looks forward to the new century and discusses the convergence of theoretical
physics and theoretical computer science and hopes for a theoretical biology,
in which the notions of algorithm and information are again crucial.",86,4,590,16.96
2007,postmodern literature,"After a short summary of the Sokal Affair and of the point of view of Steven
Weinberg, we discuss certain aspects of the scientist ideology present in the
last book of Alan Sokal ""Pesudoscience ans Postmodernism: Antagonists or
Fellow-Travellers?"", published in France. The danger of the three extremisms
present in our time - relativist extremism, scientist extremism and its
mirror-image, the religious extremism - is underlined. We point out also the
necessity of a transdisciplinary dialogue between the different disciplines as
a rampart against the fascination caused by these three extremisms.",91,4,600,40.38
2008,postmodern literature,"The science of complexity is based on a new way of thinking that stands in
sharp contrast to the philosophy underlying Newtonian science, which is based
on reductionism, determinism, and objective knowledge. This paper reviews the
historical development of this new world view, focusing on its philosophical
foundations. Determinism was challenged by quantum mechanics and chaos theory.
Systems theory replaced reductionism by a scientifically based holism.
Cybernetics and postmodern social science showed that knowledge is
intrinsically subjective. These developments are being integrated under the
header of ""complexity science"". Its central paradigm is the multi-agent system.
Agents are intrinsically subjective and uncertain about their environment and
future, but out of their local interactions, a global organization emerges.
Although different philosophers, and in particular the postmodernists, have
voiced similar ideas, the paradigm of complexity still needs to be fully
assimilated by philosophy. This will throw a new light on old philosophical
issues such as relativism, ethics and the role of the subject.",160,11,1122,29.86
2009,postmodern literature,"In this paper we study the dynamics of a statistical ensemble of strings,
building on a recently proposed gauge theory of the string geodesic field. We
show that this stochastic approach is equivalent to the Carath\'eodory
formulation of the Nambu-Goto action, supplemented by an averaging procedure
over the family of classical string world-sheets which are solutions of the
equation of motion. In this new framework, the string geodesic field is
reinterpreted as the Gibbs current density associated with the string
statistical ensemble. Next, we show that the classical field equations derived
from the string gauge action, can be obtained as the semi-classical limit of
the string functional wave equation. For closed strings, the wave equation
itself is completely analogous to the Wheeler-DeWitt equation used in quantum
cosmology. Thus, in the string case, the wave function has support on the space
of all possible spatial loop configurations. Finally, we show that the string
distribution induces a multi-phase, or {\it cellular} structure on the
spacetime manifold characterized by domains with a purely Riemannian geometry
separated by domain walls over which there exists a predominantly Weyl
geometry.",184,8,1214,36.32
2010,postmodern literature,"The University of Limoges in the rehabilitation of the premises was
confronted with scientific disposal of property irreplaceable heritage in the
context of ""postmodern"" or ""post industrial"" of our industrial society.
Therefore a ""scientific and cultural heritage Mission"" was created in 2010 to
save as much as possible the memory of the past half-century. For reasons we
discuss plasmas and electric arcs have been an important place at that time in
Western industry and especially by chance in Limoges.",79,4,505,27.86
2011,postmodern literature,"Complex systems and their underlying convoluted networks are ubiquitous, all
we need is an eye for them. They pose problems of organized complexity which
cannot be approached with a reductionist method. Complexity science and its
emergent sister network science both come to grips with the inherent complexity
of complex systems with an holistic strategy. The relevance of complexity,
however, transcends the sciences. Complex systems and networks are the focal
point of a philosophical, cultural and artistic turn of our tightly
interrelated and interdependent postmodern society. Here I take a different,
aesthetic perspective on complexity. I argue that complex systems can be
beautiful and can the object of artification - the neologism refers to
processes in which something that is not regarded as art in the traditional
sense of the word is changed into art. Complex systems and networks are
powerful sources of inspiration for the generative designer, for the artful
data visualizer, as well as for the traditional artist. I finally discuss the
benefits of a cross-fertilization between science and art.",171,10,1111,35.37
2012,postmodern literature,"The results from Planck2015, when combined with earlier observations from
WMAP, ACT, SPT and other experiments, were the first observations to disfavor
the ""classic"" inflationary paradigm. To satisfy the observational constraints,
inflationary theorists have been forced to consider plateau-like inflaton
potentials that introduce more parameters and more fine-tuning, problematic
initial conditions, multiverse-unpredictability issues, and a new 'unlikeliness
problem.' Some propose turning instead to a ""postmodern"" inflationary paradigm
in which the cosmological properties in our observable universe are only
locally valid and set randomly, with completely different properties (and
perhaps even different physical laws) existing in most regions outside our
horizon. By contrast, the new results are consistent with the simplest versions
of ekpyrotic cyclic models in which the universe is smoothed and flattened
during a period of slow contraction followed by a bounce, and another promising
bouncing theory, anamorphic cosmology, has been proposed that can produce
distinctive predictions.",148,5,1095,8.54
2013,postmodern literature,"In the paper, the authors elaborate some recently published research
concerning the originality of artworks in terms of self-organization in the
complex systems physics. It has been demonstrated that the originality issue
such conceived leads to the criterion of a substantial aesthetics whose
applicability is not restricted to the fine arts domain only covering also
physics, biology, cosmology and other fields construed in the complex systems
terms. Moreover, it is about a truth criterion related to the traditional
personality conception revealing the ontological context transcendent to the
gnoseological dualism of subjective and objective reality that is
characteristic of modern science and humanities. Thus, it is considered to be
an aesthetical criterion substantiating art and science as well as the other
developments of the postmodern era. Its impact to psychology, education,
ecology, culture and other humanities is briefly indicated.",138,6,951,9.62
2014,postmodern literature,"The city reading proposed is a modern postmodern urbanism approach which
quantifies but by passing through subjectivism. The isobenefit lines shown
translate cities into benefit landscapes, subjective and continually changeable
according to personal moods needs preferences and urban transformations. They
read attractiveness and how they flow throughout the city. Doing it for each
urban point and for each urban attraction, we obtain the isobenefit orography
of the city, namely a map of its urban attractions and of their flows. This is
a liquid surface rather than solid, as it varies across time and people. It is
in this liquidness where resides the complexity of cities, their bottom up
spirit and the dynamicity of equilibriums and networks. People do not
necessarily go in the most accessible points, but where they need and want to,
and, they flow through paths they need or choose to pass through. It is also
introduced the likeability of places and paths: in addition to the usual
parameters currently used, which weight distances in terms of physical
distance, cost, time or mental easiness representations, psycho-economical
distances used in the isobenefit lines proposed here, also consider how a place
and a path pleases us. According to the Underground Hedonic Theory, this
pleasure to pass through or to stay in agreeable areas has an underground and
an inertia effect too which contributes to delight our lives. The final purpose
of the science of cities and urban design is to understand cities and make them
efficient and attractive to please our lives in them.",254,11,1583,45.69
2015,postmodern literature,"We present, in this dissertation, a pedagogical review of the formalism for
Fermi liquids developed in [Delacretaz et al., arXiv:220305004] that exploits
an underlying algebro-geometric structure described by the group of canonical
transformations of a single particle phase space. This infinite-dimensional
group governs the space of states of zero temperature Fermi liquids and thereby
allows us to write down a nonlinear, bosonized action that reproduces Landau's
kinetic theory in the classical limit. Upon quantizing, we obtain a systematic
effective field theory as an expansion in nonlinear and higher derivative
corrections suppressed by the Fermi momentum $p_F$, without the need to
introduce artificial momentum scales through, e.g., decomposition of the Fermi
surface into patches. We find that Fermi liquid theory can essentially be
thought of as a non-trivial representation of the Lie group of canonical
transformations, bringing it within the fold of effective theories in many-body
physics whose structure is determined by symmetries. We survey the benefits and
limitations of this geometric formalism in the context of scaling, diagrammatic
calculations, scattering and interactions, coupling to background gauge fields,
etc. After setting up a path to extending this formalism to include
superconducting and magnetic phases, as well as applications to the problem of
non-Fermi liquids, we conclude with a discussion on possible future directions
for Fermi surface physics, and more broadly, the usefulness of diffeomorphism
groups in condensed matter physics. Unlike [Delacretaz et al.,
arXiv:220305004], we present a microscopic perspective on this formalism,
motivated by the closure of the algebra of bilocal fermion bilinears and the
consequences of this fact for finite density states of interacting fermions.",265,12,1832,19.2
2016,postmodern literature,"The objects of the great Nonlinear Revolutions - Catastrophes and Chaos in
the 1960s-70s (henceforth, CT); and, small-world and scale-free Network Theory
(NT), emerging quite recently - will be spliced together by a New Kind of
Number Theory, focused on digitizations (i.e., binary strings). NT nodes then
become feature-rich representations (nodules in a ""rhizosphere"") of CT
contents. The ""Box-Kite"" formalism of zero-divisors (ZD's) - first showing in
the 16-D Sedenions, then in all higher 2^N-ions derived from Imaginaries by
Cayley-Dickson Process (CDP) - can model such ""enriched"" nodules. Its
(bit-string XOR-ing vs. matrix-multiplying) operations unfold into
""representations"" of the objects linked in CT with ""partitions of Nullity"":
Singularities. The route from here to fractals and Chaos, via CDP extensions to
2^N-ions for growing N, will involve us in graphics of higher-dimensional
""carry-bit overflow,"" as manifest in the mandala-like patterns of ""emanation
tables"" (the rough equivalent, for ZD's, of group theorists' Cayley Tables).
I'll lead into this with a quote about ""Hjelmslev's Net"" (which I'll claim is
the CDP manque') from a famous postmodern text, Deleuze and Guattari's ""A
Thousand Plateaus"" (where ""rhizosphere"" imagery arose). With strong assists
from the CT-based structuralism of Jean Petitot, Algirdas Greimas's ""Semiotic
Square"" will show us how to explicitly link CT to semiotic foundations via ZD
""representations,"" while the infinite-dimensional ZD meta-fractal or ""Sky""
where Box-Kites fly - first appearing in the 32-D Pathions and incorporating
the higher 2^N-ions - will provide sufficient lebensraum for Levi-Strauss's
""Canonical Formula"" of mythwork to unfurl in. (These results serve to extend my
NKS 2004 paper, available at the Wolfram Science website.)",263,12,1802,33.99
2017,postmodern literature,"The literature review is an indispensable step in the research process. It
provides the benefit of comprehending the research problem and understanding
the current research situation while conducting a comparative analysis of prior
works. However, literature summary is challenging and time consuming. The
previous LLM-based studies on literature review mainly focused on the complete
process, including literature retrieval, screening, and summarization. However,
for the summarization step, simple CoT method often lacks the ability to
provide extensive comparative summary. In this work, we firstly focus on the
independent literature summarization step and introduce ChatCite, an LLM agent
with human workflow guidance for comparative literature summary. This agent, by
mimicking the human workflow, first extracts key elements from relevant
literature and then generates summaries using a Reflective Incremental
Mechanism. In order to better evaluate the quality of the generated summaries,
we devised a LLM-based automatic evaluation metric, G-Score, in refer to the
human evaluation criteria. The ChatCite agent outperformed other models in
various dimensions in the experiments. The literature summaries generated by
ChatCite can also be directly used for drafting literature reviews.",180,11,1292,19.37
2018,postmodern literature,"The goal of this chapter is to support teachers in holistically introducing
graduate students to literature reviews, with a particular focus on secondary
research. It provides an overview of the overall literature review process and
the different types of literature review before diving into guidelines for
selecting and conducting different types of literature review. The chapter also
provides recommendations for evaluating the quality of existing literature
reviews and concludes with a summary of our learning goals and how the chapter
supports teachers in addressing them.",85,4,579,17.37
2019,postmodern literature,"In this study we analyzed a corpus of 8 million words academic literature
from Computational lingustics' academic literature. the lexical bundles from
this corpus are categorized based on structures and functions.",31,3,213,30.36
2020,postmodern literature,"Because most of the scientific literature data is unmarked, it makes semantic
representation learning based on unsupervised graph become crucial. At the same
time, in order to enrich the features of scientific literature, a learning
method of semantic representation of scientific literature based on adaptive
features and graph neural network is proposed. By introducing the adaptive
feature method, the features of scientific literature are considered globally
and locally. The graph attention mechanism is used to sum the features of
scientific literature with citation relationship, and give each scientific
literature different feature weights, so as to better express the correlation
between the features of different scientific literature. In addition, an
unsupervised graph neural network semantic representation learning method is
proposed. By comparing the mutual information between the positive and negative
local semantic representation of scientific literature and the global graph
semantic representation in the potential space, the graph neural network can
capture the local and global information, thus improving the learning ability
of the semantic representation of scientific literature. The experimental
results show that the proposed learning method of semantic representation of
scientific literature based on adaptive feature and graph neural network is
competitive on the basis of scientific literature classification, and has
achieved good results.",205,8,1474,-0.57
2021,postmodern literature,"Research misconduct and frauds pollute the scientific literature. Honest
errors and malevolent data fabrication, image manipulation, journal hijacking,
and plagiarism passed peer review unnoticed. Problematic papers deceive
readers, authors citing them, and AI-powered literature-based discovery.
Flagship publishers accepted hundreds flawed papers despite claiming to enforce
peer review. This application ambitions to decontaminate the scientific
literature using curative and preventive actions.",60,6,498,0.08
2022,postmodern literature,"This paper was originally designed as a literature review for a doctoral
dissertation focusing on Wikipedia. This exposition gives the structure of
Wikipedia and the latest trends in Wikipedia research.",30,3,202,47.79
2023,postmodern literature,"Comment on the literature definition(s) of ""dynamical phase transition""",9,1,71,3.12
2024,postmodern literature,"The process of conducting literature reviews is often time-consuming and
labor-intensive. To streamline this process, I present an AI Literature Review
Suite that integrates several functionalities to provide a comprehensive
literature review. This tool leverages the power of open access science, large
language models (LLMs) and natural language processing to enable the searching,
downloading, and organizing of PDF files, as well as extracting content from
articles. Semantic search queries are used for data retrieval, while text
embeddings and summarization using LLMs present succinct literature reviews.
Interaction with PDFs is enhanced through a user-friendly graphical user
interface (GUI). The suite also features integrated programs for bibliographic
organization, interaction and query, and literature review summaries. This tool
presents a robust solution to automate and optimize the process of literature
review in academic and industrial research.",133,8,965,26.81
2025,postmodern literature,"Context: Requirements engineering in global scaled agile software development
and the planning phase for a multi-vocal literature review. Objective: Develop
a protocol to specify the plan which will be followed to conduct a multi-vocal
literature review study on requirements engineering in global scaled agile
software development. Method: Kitchenham and Charters (2007), and Garousi et
al. (2019) guidelines were followed to develop a protocol for multi-vocal
literature review. Result: A validated protocol to conduct a multi-vocal
literature review. Conclusion: The review protocol consist of five phases
enumerated as follows: research questions, search strategies, validation of
review process, reporting the review, and making changes to the protocol.",105,7,758,19.87
2026,postmodern literature,"A strong link between complexity theory and literature is possible, i.e.
feasible, under one proviso, namely that total novels be considered. However,
neither in literature at large nor in complexity science has been literature
seriously taken into consideration. This paper argues that a total novel is
most conspicuous example of a complex system. The argument is supported by a
clear characterization of what a total novel is and entails. Science and
literature can be thus complemented and developed, hand in hand.",81,8,518,32.39
2027,postmodern literature,"Automatic literature review generation is one of the most challenging tasks
in natural language processing. Although large language models have tackled
literature review generation, the absence of large-scale datasets has been a
stumbling block to the progress. We release SciReviewGen, consisting of over
10,000 literature reviews and 690,000 papers cited in the reviews. Based on the
dataset, we evaluate recent transformer-based summarization models on the
literature review generation task, including Fusion-in-Decoder extended for
literature review generation. Human evaluation results show that some
machine-generated summaries are comparable to human-written reviews, while
revealing the challenges of automatic literature review generation such as
hallucinations and a lack of detailed information. Our dataset and code are
available at https://github.com/tetsu9923/SciReviewGen.",115,8,887,18.15
2028,postmodern literature,"Background: To investigate the correlation between genomic variation and
certain diseases or phenotypes, the fundamental task is to screen out the
concerning publications from massive literature, which is called literature
triage. Some knowledge bases, including UniProtKB/Swiss-Prot and NHGRI-EBI GWAS
Catalog are created for collecting concerning publications. These publications
are manually curated by experts, which is time-consuming. Moreover, the manual
curation of information from literature is not scalable due to the rapidly
increasing amount of publications. In order to cut down the cost of literature
triage, machine-learning models were adopted to automatically identify
biomedical publications. Methods: Comparing to previous studies utilizing
machine-learning models for literature triage, we adopt a multi-channel
convolutional network to utilize rich textual information and meanwhile bridge
the semantic gaps from different corpora. In addition, knowledge embeddings
learned from UMLS is also used to provide extra medical knowledge beyond
textual features in the process of triage. Results: We demonstrate that our
model outperforms the state-of-the-art models over 5 datasets with the help of
knowledge embedding and multiple channels. Our model improves the accuracy of
biomedical literature triage results. Conclusions: Multiple channels and
knowledge embeddings enhance the performance of the CNN model in the task of
biomedical literature triage. Keywords: Literature Triage; Knowledge Embedding;
Multi-channel Convolutional Network",208,11,1558,18.45
2029,postmodern literature,"Literature reviews have long played a fundamental role in synthesizing the
current state of a research field. However, in recent years, certain fields
have evolved at such a rapid rate that literature reviews quickly lose their
relevance as new work is published that renders them outdated. We should
therefore rethink how to structure and publish such literature reviews with
their highly valuable synthesized content. Here, we aim to determine if
existing Linked Data technologies can be harnessed to prolong the relevance of
literature reviews and whether researchers are comfortable with working with
such a solution. We present here our approach of ``living literature reviews''
where the core information is represented as Linked Data which can be amended
with new findings after the publication of the literature review. We present a
prototype implementation, which we use for a case study where we expose
potential users to a concrete literature review modeled with our approach. We
observe that our model is technically feasible and is received well by
researchers, with our ``living'' versions scoring higher than their traditional
counterparts in our user study. In conclusion, we find that there are strong
benefits to using a Linked Data solution to extend the effective lifetime of a
literature review.",205,9,1316,37.03
2030,postmodern literature,"Biomedical research yields a wealth of information, much of which is only
accessible through the literature. Consequently, literature search is an
essential tool for building on prior knowledge in clinical and biomedical
research. Although recent improvements in artificial intelligence have expanded
functionality beyond keyword-based search, these advances may be unfamiliar to
clinicians and researchers. In response, we present a survey of literature
search tools tailored to both general and specific information needs in
biomedicine, with the objective of helping readers efficiently fulfill their
information needs. We first examine the widely used PubMed search engine,
discussing recent improvements and continued challenges. We then describe
literature search tools catering to five specific information needs: 1.
Identifying high-quality clinical research for evidence-based medicine. 2.
Retrieving gene-related information for precision medicine and genomics. 3.
Searching by meaning, including natural language questions. 4. Locating related
articles with literature recommendation. 5. Mining literature to discover
associations between concepts such as diseases and genetic variants.
Additionally, we cover practical considerations and best practices for choosing
and using these tools. Finally, we provide a perspective on the future of
literature search engines, considering recent breakthroughs in large language
models such as ChatGPT. In summary, our survey provides a comprehensive view of
biomedical literature search functionalities with 36 publicly available tools.",212,19,1588,22.31
2031,postmodern literature,"SN 1572, also known as the Tycho's Nova, was a supernova largely reported and
discussed in the literature of the time. Here we talk about this literature. In
the latest texts, we find also mentioned the Kepler's Nova, today known as SN
1604, and other newly observed stars. We discuss them too.",52,5,294,66.74
2032,postmodern literature,"The literature review presented below on Image Compression, Transmission of
3D data over wireless networks and tracking of objects is the in depth study of
Research Papers done in Multimedia lab. Most of the papers presented in this
literature review have tackled the problems present in the conventional system
and offered an optimal and practical solution.",56,3,358,26.14
2033,postmodern literature,"We formally define the literature (reference) snowballing method and present
a refined version of it. We show that the improved algorithm can substantially
reduce curator work, even before application of text classification, by
reducing the number of candidates to classify. We also present a desktop
application named LitBall that implements this and other literature collection
methods, through access to the Semantic Scholar academic graph (S2AG).",65,4,450,24.07
2034,postmodern literature,"We present CitNetExplorer, a new software tool for analyzing and visualizing
citation networks of scientific publications. CitNetExplorer can for instance
be used to study the development of a research field, to delineate the
literature on a research topic, and to support literature reviewing. We first
introduce the main concepts that need to be understood when working with
CitNetExplorer. We then demonstrate CitNetExplorer by using the tool to analyze
the scientometric literature and the literature on community detection in
networks. Finally, we discuss some technical details on the construction,
visualization, and analysis of citation networks in CitNetExplorer.",96,6,672,9.69
2035,postmodern literature,"The scientific community continues to publish an overwhelming amount of new
research related to COVID-19 on a daily basis, leading to much literature
without little to no attention. To aid the community in understanding the
rapidly flowing array of COVID-19 literature, we propose a novel BERT
architecture that provides a brief yet original summarization of lengthy
papers. The model continually learns on new data in online fashion while
minimizing catastrophic forgetting, thus fitting to the need of the community.
Benchmark and manual examination of its performance show that the model provide
a sound summary of new scientific literature.",98,5,644,21.23
2036,postmodern literature,"IEC 60848 GRAFCET is a standardized, graphical specification language for
control functions. Because of the semiformal nature of IEC 60848, the details
of specifications created with GRAFCET can be interpreted in different ways,
possibly leading to faulty implementations. These ambiguities have been
partially addressed in existing literature, but solved in different manners.
Based on a literature review, this work aims at providing an overview of
existing interpretations and, based on that, proposes a comprehensive
interpretation algorithm for IEC 60848, which takes all relevant ambiguities
from the literature review into account.",90,5,638,23.26
2037,postmodern literature,"In the recent physics literature there have appeared contradictory statements
concerning the behaviour of scattering solutions of the 3-dimensional
Schroedinger equation at large times. We clarify the situation and point out
that the issue was rigorously resolved in the mathematics literature.",41,3,294,25.29
2038,postmodern literature,"In this report we define characteristic control design elements and show how
conventional single-agent MPC implements these. We survey recent literature on
multi-agent MPC and discuss how this literature deals with decomposition,
problem assignment, and cooperation.",36,3,266,10.91
2039,postmodern literature,"In this report, we describe the review protocol that will guide the
systematic review of the literature in metrics-based discovery of
vulnerabilities. The protocol have been developed in adherence with the
guidelines for performing Systematic Literature Reviews in Software Engineering
prescribed by Kitchenham and Charters.",45,3,324,14.8
2040,postmodern literature,"This continuously extended technical report collects and compares commonly
used formulae from the literature and provides them in a machine readable way.",22,2,153,15.31
2041,postmodern literature,"This working paper unveils the crafting of a systematic literature review on
open-source platforms. The high-competitive mobile devices market, where
several players such as Apple, Google, Nokia and Microsoft run a platforms- war
with constant shifts in their technological strategies, is gaining increasing
attention from scholars. It matters, then, to review previous literature on
past platforms-wars, such as the ones from the PC and game-console industries,
and assess its implications to the current mobile devices platforms-war. The
paper starts by justifying the purpose and rationale behind this literature
review on open-source platforms. The concepts of open-source software and
computer-based platforms were then discussed both individually and in unison,
in order to clarify the core-concept of 'open-source platform' that guides this
literature review. The detailed design of the employed methodological strategy
is then presented as the central part of this paper. The paper concludes with
preliminary findings organizing previous literature on open-source platforms
for the purpose of guiding future research in this area.",162,8,1138,31.11
2042,postmodern literature,"Literature reviews allow scientists to stand on the shoulders of giants,
showing promising directions, summarizing progress, and pointing out existing
challenges in research. At the same time conducting a systematic literature
review is a laborious and consequently expensive process. In the last decade,
there have a few studies on crowdsourcing in literature reviews. This paper
explores the feasibility of crowdsourcing for facilitating the literature
review process in terms of results, time and effort, as well as to identify
which crowdsourcing strategies provide the best results based on the budget
available. In particular we focus on the screening phase of the literature
review process and we contribute and assess methods for identifying the size of
tests, labels required per paper, and classification functions as well as
methods to split the crowdsourcing process in phases to improve results.
Finally, we present our findings based on experiments run on Crowdflower.",147,7,982,38.15
2043,postmodern literature,"This article's objective is the identification of research opportunities in
the current big data privacy domain, evaluating literature effects on secure
informational assets. Until now, no study has analyzed such relation. Its
results can foster science, technologies and businesses. To achieve these
objectives, a big data privacy Systematic Literature Review (SLR) is performed
on the main scientific peer reviewed journals in Scopus database. Bibliometrics
and text mining analysis complement the SLR. This study provides support to big
data privacy researchers on: most and least researched themes, research
novelty, most cited works and authors, themes evolution through time and many
others. In addition, TOPSIS and VIKOR ranks were developed to evaluate
literature effects versus informational assets indicators. Secure Internet
Servers (SIS) was chosen as decision criteria. Results show that big data
privacy literature is strongly focused on computational aspects. However,
individuals, societies, organizations and governments face a technological
change that has just started to be investigated, with growing concerns on law
and regulation aspects. TOPSIS and VIKOR Ranks differed in several positions
and the only consistent country between literature and SIS adoption is the
United States. Countries in the lowest ranking positions represent future
research opportunities.",195,13,1386,21.09
2044,postmodern literature,"Context: The importance of defining learning outcomes and the planning stage
for a systematic literature review. Objective: A protocol for carrying out a
systematic literature review about the evidence for the tool support for the
learning outcomes and the teaching-learning process using Bloom's taxonomy to
address it. Method: The definition of a protocol to conduct a systematic
literature review according to the guidelines of B. Kitchenham. Results: A
validated protocol to conduct a systematic literature review. Conclusions: A
proposal for the protocol definition of a systematic literature review about
the tool support for the learning outcomes, the teaching-learning process using
Bloom's taxonomy was built. Initials results show that a more detailed review
of the learning outcomes and their alignment with the levels of curricular
progress, training cycles, and Bloom's Taxonomy should be carried out.",134,8,914,23.46
2045,postmodern literature,"The general four-component model-based decomposition with unitary
transformation of coherency matrix (G4U) is a state-of-the-art four-component
decomposition, which has received extensive attentions recently. A literature
survey is carried out to indicate the overall influence, improvement,
development, evaluation, and application of G4U. Totally, 137 literatures are
found mentioning G4U in Google Scholar\c{opyright} until October 7, 2019, which
can be attributed into 4 categories in terms of the degree of concentration and
17 subcategories according to the focus of attention. Among these literatures,
61 of them simply mention G4U mainly because it is a new four-component
model-based decomposition, a typical model-based decomposition, or even a
target decomposition. There are also 9 literatures which improve G4U and
develop G4U-like decompositions with unitary transformation of coherency
matrix. 20 literatures generally use G4U as a typical target decomposition for
comparison or a pseudo-color visualization technique to show the performance of
some developed approaches. There are also 47 literatures dedicated to
critically evaluate and deeply apply G4U in the remote sensing of forestry,
agriculture, wetland, snow, glaciated terrain, earth surface, manmade target,
environment, and damages caused by earthquake, tsunami, and landside, which
indicates the value and significance of G4U in the true sense.",197,8,1422,9.11
2046,postmodern literature,"A dataset of COVID-19-related scientific literature is compiled, combining
the articles from several online libraries and selecting those with open access
and full text available. Then, hierarchical nonnegative matrix factorization is
used to organize literature related to the novel coronavirus into a tree
structure that allows researchers to search for relevant literature based on
detected topics. We discover eight major latent topics and 52 granular
subtopics in the body of literature, related to vaccines, genetic structure and
modeling of the disease and patient studies, as well as related diseases and
virology. In order that our tool may help current researchers, an interactive
website is created that organizes available literature using this hierarchical
structure.",113,5,780,17.37
2047,postmodern literature,"Context: The importance of feature modeling languages for software product
lines and the planning stage for a systematic literature review. Objective: A
protocol for carrying out a systematic literature review about the evidence for
identifying and classifying the errors in feature modeling languages. Method:
The definition of a protocol to conduct a systematic literature review
according to the guidelines of B. Kitchenham. Results: A validated protocol to
conduct a systematic literature review. Conclusions: A proposal for the
protocol definition of a systematic literature review about the identification
and classification of errors in feature modeling was built. Initial results
show that the effects and results for solving these errors should be carried
out.",112,8,769,18.65
2048,postmodern literature,"Since the birth of artificial intelligence 70 years ago, attempts at literary
""creation"" with computers are present in the course of technological
development, creating what one might call ""artificial intelligence literature""
(AI literature). Evolving from ""textual experiments"" conducted by technologists
to ""experimental texts"" that explore the possibilities of conceptions of
literature, AI literature integrates primitive problems including machine
thinking, text generation, and machine creativity, which exhibits the two-way
interaction between social ideas and technology. In the early stage, the mutual
support between technological path and artistic ideas turned out to be a
failure, while AI-driven expressive repetitions are made probable in the
contemporary technological context, paving the way for the transformation of AI
literature from proof for technical possibilities to self-verification of
literary value.",124,4,926,-12.75
2049,postmodern literature,"Increasing number of COVID-19 research literatures cause new challenges in
effective literature screening and COVID-19 domain knowledge aware Information
Retrieval. To tackle the challenges, we demonstrate two tasks along
withsolutions, COVID-19 literature retrieval, and question answering. COVID-19
literature retrieval task screens matching COVID-19 literature documents for
textual user query, and COVID-19 question answering task predicts proper text
fragments from text corpus as the answer of specific COVID-19 related
questions. Based on transformer neural network, we provided solutions to
implement the tasks on CORD-19 dataset, we display some examples to show the
effectiveness of our proposed solutions.",96,5,716,30.2
2050,postmodern literature,"Most activities in hospitals require the presence of the patient. Delays in
patient transport can therefore cause disruptions and costly downtime in many
different areas and departments, which makes patient transport planning a
central operational problem in hospitals. This paper provides the first
literature review of Operations Research approaches for improving non-emergency
patient transport in hospitals. We structure the different patient transport
problems considered in the literature according to several main characteristics
and introduce a four-field notation for patient transport problems that allows
for a concise representation of different problem variants. We then analyze the
relevant literature with respect to different aspects related to the considered
problem variant, the employed modeling and solution techniques, as well as the
data used and the level of practical implementation achieved. Based on our
literature analysis and semi-structured interviews with hospital practitioners,
we provide a comparison of current hospital practice and the existing
literature on patient transport, and we identify research gaps and formulate an
agenda for relevant future research in this area.",169,7,1209,17.47
2051,postmodern literature,"Extraction and synthesis of structured knowledge from extensive scientific
literature are crucial for advancing and disseminating scientific progress.
Although many existing systems facilitate literature review and digest, they
struggle to process multimodal, varied, and inconsistent information within and
across the literature into structured data. We introduce SciDaSynth, a novel
interactive system powered by large language models (LLMs) that enables
researchers to efficiently build structured knowledge bases from scientific
literature at scale. The system automatically creates data tables to organize
and summarize users' interested knowledge in literature via question-answering.
Furthermore, it provides multi-level and multi-faceted exploration of the
generated data tables, facilitating iterative validation, correction, and
refinement. Our within-subjects study with researchers demonstrates the
effectiveness and efficiency of SciDaSynth in constructing quality scientific
knowledge bases. We further discuss the design implications for human-AI
interaction tools for data extraction and structuring.",139,8,1116,0.52
2052,postmodern literature,"""Open access"" has become a central theme of journal reform in academic
publishing. In this article, I examine the relationship between open access
publishing and an important infrastructural element of a modern research
enterprise, scientific literature text mining, or the use of data analytic
techniques to conduct meta-analyses and investigations into the scientific
corpus. I give a brief history of the open access movement, discuss novel
journalistic practices, and an overview of data-driven investigation of the
scientific corpus. I argue that particularly in an era where the veracity of
many research studies has been called into question, scientific literature text
mining should be one of the key motivations for open access publishing, not
only in the basic sciences, but in the engineering and applied sciences as
well. The enormous benefits of unrestricted access to the research literature
should prompt scholars from all disciplines to lend their vocal support to
enabling legal, wholesale access to the scientific literature as part of a data
science pipeline.",164,6,1078,21.26
2053,postmodern literature,"Recently, a review concluded that Google Scholar (GS) is not a suitable
source of information ""for identifying recent conference papers or other gray
literature publications"". The goal of this letter is to demonstrate that GS can
be an effective tool to search and find gray literature, as long as appropriate
search strategies are used. To do this, we took as examples the same two case
studies used by the original review, describing first how GS processes
original's search strategies, then proposing alternative search strategies, and
finally generalizing each case study to compose a general search procedure
aimed at finding gray literature in Google Scholar for two wide selected case
studies: a) all contributions belonging to a congress (the ASCO Annual
Meeting); and b) indexed guidelines as well as gray literature within medical
institutions (National Institutes of Health) and governmental agencies (U.S.
Department of Health & Human Services). The results confirm that original
search strategies were undertrained offering misleading results and erroneous
conclusions. Google Scholar lacks many of the advanced search features
available in other bibliographic databases (such as Pubmed), however, it is one
thing to have a friendly search experience, and quite another to find gray
literature. We finally conclude that Google Scholar is a powerful tool for
searching gray literature, as long as the users are familiar with all the
possibilities it offers as a search engine. Poorly formulated searches will
undoubtedly return misleading results.",236,10,1559,33.17
2054,postmodern literature,"The increase in the number of researchers coupled with the ease of publishing
and distribution of scientific papers (due to technological advancements) has
resulted in a dramatic increase in astronomy literature. This has likely led to
the predicament that the body of the literature is too large for traditional
human consumption and that related and crucial knowledge is not discovered by
researchers. In addition to the increased production of astronomical
literature, recent decades have also brought several advancements in
computational linguistics. Especially, the machine-aided processing of
literature dissemination might make it possible to convert this stream of
papers into a coherent knowledge set. In this paper, we present the application
of computational linguistics techniques to astronomy literature. In particular,
we developed a tool that will find similar articles purely based on text
content from an input paper. We find that our technique performs robustly in
comparison with other tools recommending articles given a reference paper
(known as recommender system). Our novel tool shows the great power in
combining computational linguistics with astronomy literature and suggests that
additional research in this endeavor will likely produce even better tools that
will help researchers cope with the vast amounts of knowledge being produced.",200,9,1366,20.72
2055,postmodern literature,"Clinical Decision Support Systems (CDSS) form an important area of research.
In spite of its importance, it is difficult for researchers to evaluate the
domain primarily because of a considerable spread of relevant literature in
interdisciplinary domains. Previous surveys of CDSS have examined the domain
from the perspective of individual disciplines. However, to the best of our
knowledge, no visual scientometric survey of CDSS has previously been conducted
which provides a broader spectrum of the domain with a horizon covering
multiple disciplines. While traditional systematic literature surveys focus on
analyzing literature using arbitrary results, visual surveys allow for the
analysis of domains by using complex network-based analytical models. In this
paper, we present a detailed visual survey of CDSS literature using important
papers selected from highly cited sources in the Thomson Reuters web of
science. We analyze the entire set of relevant literature indexed in the Web of
Science database. Our key results include the discovery of the articles which
have served as key turning points in literature. Additionally, we have
identified highly cited authors and the key country of origin of top
publications. We also present the Universities with the strongest citation
bursts. Finally, our network analysis has also identified the key journals and
subject categories both in terms of centrality and frequency. It is our belief
that this paper will thus serve as an important role for researchers as well as
clinical practitioners interested in identifying key literature and resources
in the domain of clinical decision support.",249,13,1648,24.98
2056,postmodern literature,"In this study, we investigated the academic literature on quantum
technologies (QT) using bibliometric tools. We used a set of 49,823 articles
obtained from the Web of Science (WoS) database using a search query
constructed through expert opinion. Analysis of this revealed that QT is deeply
rooted in physics, and the majority of the articles are published in physics
journals. Keyword analysis revealed that the literature could be clustered into
three distinct sets, which are (i) quantum communication/cryptography, (ii)
quantum computation, and (iii) physical realizations of quantum systems. We
performed a burst analysis that showed the emergence and fading away of certain
key concepts in the literature. This is followed by co-citation analysis on the
highly cited articles provided by the WoS, using these we devised a set of core
corpus of 34 publications. Comparing the most highly cited articles in this set
with respect to the initial set we found that there is a clear difference in
most cited subjects. Finally, we performed co-citation analyses on country and
organization levels to find the central nodes in the literature. Overall, the
analyses of the datasets allowed us to cluster the literature into three
distinct sets, construct the core corpus of the academic literature in QT, and
to identify the key players on country and organization levels, thus offering
insight into the current state of the field. Search queries and access to
figures are provided in the appendix.",237,11,1496,38.96
2057,postmodern literature,"Temporal evolution of the coronavirus literature over the last thirty years
(N=43,769) is analyzed along with its subdomain of SARS-CoV-2 articles
(N=27,460) and the subdomain of reviews and meta-analytic studies (N=1,027).
(i) The analyses on the subset of SARS-CoV-2 literature identified studies
published prior to 2020 that have now proven highly instrumental in the
development of various clusters of publications linked to SARS-CoV-2. In
particular, the so-called sleeping beauties of the coronavirus literature with
an awakening in 2020 were identified, i.e., previously published studies of
this literature that had remained relatively unnoticed for several years but
gained sudden traction in 2020 in the wake of the SARS-CoV-2 outbreak. (ii) The
subset of 2020 SARS-CoV-2 articles is bibliographically distant from the rest
of this literature published prior to 2020. Individual articles of the
SARS-CoV-2 segment with a bridging role between the two bodies of articles
(i.e., before and after 2020) are identifiable. (iii) Furthermore, the degree
of bibliographic coupling within the 2020 SARS-CoV-2 cluster is much poorer
compared to the cluster of articles published prior to 2020. This could, in
part, be explained by the higher diversity of topics that are studied in
relation to SARS-CoV-2 compared to the literature of coronaviruses published
prior to the SARS-CoV-2 disease. This work demonstrates how scholarly efforts
undertaken during peace time or prior to a disease outbreak could suddenly play
a critical role in prevention and mitigation of health disasters caused by new
diseases.",240,13,1606,38.66
2058,postmodern literature,"There are a few prominent practices for conducting reviews of academic
literature, including searching for specific keywords on Google Scholar or
checking citations from some initial seed paper(s). These approaches serve a
critical purpose for academic literature reviews, yet there remain challenges
in identifying relevant literature when similar work may utilize different
terminology (e.g., mixed-initiative visual analytics papers may not use the
same terminology as papers on model-steering, yet the two topics are relevant
to one another). In this paper, we introduce a system, VitaLITy, intended to
complement existing practices. In particular, VitaLITy promotes serendipitous
discovery of relevant literature using transformer language models, allowing
users to find semantically similar papers in a word embedding space given (1) a
list of input paper(s) or (2) a working abstract. VitaLITy visualizes this
document-level embedding space in an interactive 2-D scatterplot using
dimension reduction. VitaLITy also summarizes meta information about the
document corpus or search query, including keywords and co-authors, and allows
users to save and export papers for use in a literature review. We present
qualitative findings from an evaluation of VitaLITy, suggesting it can be a
promising complementary technique for conducting academic literature reviews.
Furthermore, we contribute data from 38 popular data visualization publication
venues in VitaLITy, and we provide scrapers for the open-source community to
continue to grow the list of supported venues.",223,11,1571,12.46
2059,postmodern literature,"The literature on the relationship between environmental factors such as
climatic changes and natural hazards and human mobility (both internal and
international) is characterized by heterogeneous results: some contributions
highlight the role of climate changes as a driver of migratory flows, while
others underline how this impact is mediated by geographical, economic and the
features of the environmental shock. This paper attempts to map this
literature, focusing on economics and empirical essays.
  The paper improves on the existing literature: (a) providing systematic
research of the literature through main bibliographic databases, followed by a
review and bibliometric analysis of all resulting papers; (b) building a
citation-based network of contributions, that hollows to identify four separate
clusters of paper; (c) applying meta-analysis methods on the sample of 96
papers released between 2003 and 2020, published in an academic journal,
working papers series or unpublished studies, providing 3,904 point estimates
of the effect of slow-onset events and 2,065 point estimates of the effect of
fast-onset events.
  Overall, the meta-analytic average effect estimates a small impact of slow-
and rapid-onset variables on migration, however positive and significant. When
the clustering of the literature is accounted for, however, a significant
heterogeneity emerges among the four clusters of papers, giving rise to new
evidence on the formation of club-like convergence of literature outcomes.",217,6,1514,2.04
2060,postmodern literature,"Gene/protein interactions provide critical information for a thorough
understanding of cellular processes. Recently, considerable interest and effort
has been focused on the construction and analysis of genome-wide gene networks.
The large body of biomedical literature is an important source of gene/protein
interaction information. Recent advances in text mining tools have made it
possible to automatically extract such documented interactions from free-text
literature. In this paper, we propose a comprehensive framework for
constructing and analyzing large-scale gene functional networks based on the
gene/protein interactions extracted from biomedical literature repositories
using text mining tools. Our proposed framework consists of analyses of the
network topology, network topology-gene function relationship, and temporal
network evolution to distill valuable information embedded in the gene
functional interactions in literature. We demonstrate the application of the
proposed framework using a testbed of P53-related PubMed abstracts, which shows
that literature-based P53 networks exhibit small-world and scale-free
properties. We also found that high degree genes in the literature-based
networks have a high probability of appearing in the manually curated database
and genes in the same pathway tend to form local clusters in our
literature-based networks. Temporal analysis showed that genes interacting with
many other genes tend to be involved in a large number of newly discovered
interactions.",207,10,1518,14.29
2061,postmodern literature,"Continuous Integration (CI) is a software engineering practice that aims to
reduce the cost and risk of code integration among teams. Recent empirical
studies have confirmed associations between CI and the software quality (SQ).
However, no existing study investigates causal relationships between CI and SQ.
This paper investigates it by applying the causal Direct Acyclic Graphs (DAGs)
technique. We combine two other strategies to support this technique: a
literature review and a Mining Software Repository (MSR) study. In the first
stage, we review the literature to discover existing associations between CI
and SQ, which help us create a ""literature-based causal DAG"" in the second
stage. This DAG encapsulates the literature assumptions regarding CI and its
influence on SQ. In the third stage, we analyze 12 activity months for 70
opensource projects by mining software repositories -- 35 CI and 35 no-CI
projects. This MSR study is not a typical ""correlation is not causation"" study
because it is used to verify the relationships uncovered in the causal DAG
produced in the first stages. The fourth stage consists of testing the
statistical implications from the ""literature-based causal DAG"" on our dataset.
Finally, in the fifth stage, we build a DAG with observations from the
literature and the dataset, the ""literature-data DAG"". In addition to the
direct causal effect of CI on SQ, we find evidence of indirect effects of CI.
For example, CI affects teams' communication, which positively impacts SQ. We
also highlight the confounding effect of project age.",247,15,1573,45.15
2062,postmodern literature,"Recent breakthroughs in Large Language Models (LLMs) have revolutionized
natural language understanding and generation, igniting a surge of interest in
leveraging these technologies in the field of scientific literature analysis.
Existing benchmarks, however, inadequately evaluate the proficiency of LLMs in
scientific literature analysis, especially in scenarios involving complex
comprehension and multimodal data. In response, we introduced SciAssess, a
benchmark tailored for the in-depth analysis of scientific literature, crafted
to provide a thorough assessment of LLMs' efficacy. SciAssess focuses on
evaluating LLMs' abilities in memorization, comprehension, and analysis within
the context of scientific literature analysis. It includes representative tasks
from diverse scientific fields, such as general chemistry, organic materials,
and alloy materials. And rigorous quality control measures ensure its
reliability in terms of correctness, anonymization, and copyright compliance.
SciAssess evaluates leading LLMs, including GPT-4, GPT-3.5, and Gemini,
identifying their strengths and aspects for improvement and supporting the
ongoing development of LLM applications in scientific literature analysis.
SciAssess and its resources are made available at https://sci-assess.github.io,
offering a valuable tool for advancing LLM capabilities in scientific
literature analysis.",176,12,1387,2.85
2063,postmodern literature,"In scientific research and its application, scientific literature analysis is
crucial as it allows researchers to build on the work of others. However, the
fast growth of scientific knowledge has led to a massive increase in scholarly
articles, making in-depth literature analysis increasingly challenging and
time-consuming. The emergence of Large Language Models (LLMs) has offered a new
way to address this challenge. Known for their strong abilities in summarizing
texts, LLMs are seen as a potential tool to improve the analysis of scientific
literature. However, existing LLMs have their own limits. Scientific literature
often includes a wide range of multimodal elements, such as molecular
structure, tables, and charts, which are hard for text-focused LLMs to
understand and analyze. This issue points to the urgent need for new solutions
that can fully understand and analyze multimodal content in scientific
literature. To answer this demand, we present Uni-SMART (Universal Science
Multimodal Analysis and Research Transformer), an innovative model designed for
in-depth understanding of multimodal scientific literature. Through rigorous
quantitative evaluation across several domains, Uni-SMART demonstrates superior
performance over leading text-focused LLMs. Furthermore, our exploration
extends to practical applications, including patent infringement detection and
nuanced analysis of charts. These applications not only highlight Uni-SMART's
adaptability but also its potential to revolutionize how we interact with
scientific literature.",214,12,1557,17.84
2064,postmodern literature,"It was demonstrated that there is a geometrical order in the structure of
literature. Fractal geometry as a modern mathematical approach and a new
geometrical viewpoint on natural objects including both processes and
structures was employed for analysis of literature. As the first study, the
works of William Shakespeare were chosen as the most important items in western
literature. By counting the number of letters applied in a manuscript, it is
possible to study the whole manuscript statistically. A novel method based on
basic assumption of fractal geometry was proposed for the calculation of
fractal dimensions of the literature. The results were compared with Zipf's
law. Zipf's law was successfully used for letters instead of words. Two new
concepts namely Zipf's dimension and Zipf's order were also introduced. It was
found that changes of both fractal dimension and Zipf's dimension are similar
and dependent on the manuscript length. Interestingly, direct plotting the data
obtained in semi-logarithmic and logarithmic forms also led to a power-law.",164,11,1065,37.91
2065,postmodern literature,"Our results demonstrated that a previously reported protein name
co-occurrence method (5-mention PubGene) which was not based on a hypothesis
testing framework, it is generally statistically more significant than the 99th
percentile of Poisson distribution-based method of calculating co-occurrence.
It agrees with previous methods using natural language processing to extract
protein-protein interaction from text as more than 96% of the interactions
found by natural language processing methods to overlap with the results from
5-mention PubGene method. However, less than 2% of the gene co-expressions
analyzed by microarray were found from direct co-occurrence or interaction
information extraction from the literature. At the same time, combining
microarray and literature analyses, we derive a novel set of 7 potential
functional protein-protein interactions that had not been previously described
in the literature.",128,5,922,13.62
2066,postmodern literature,"In this paper we have a close look at the Sybil attack and advances in
defending against it, with particular emphasis on the recent work. We identify
three major veins of literature work to defend against the attack: using
trusted certification, using resources testing, and using social networks. The
first vein of literature considers defending against the attack using trusted
certification, which is done by either centralized certification or distributed
certification using cryptographic primitives that can replace the centralized
certification entity. The second vein of literature considers defending against
the attack by resources testing, which can by in the form of IP testing,
network coordinates, recurring cost as by requiring clients to solve puzzles.
The third and last vein of literature is by mitigating the attack combining
social networks used as bootstrapping security and tools from random walk
theory that have shown to be effective in defending against the attack under
certain assumptions. Our survey and analyses of the different schemes in the
three veins of literature show several shortcomings which form several
interesting directions and research questions worthy of investigation.",181,7,1214,23.9
2067,postmodern literature,"Literature analysis is a key step in obtaining background information in
biomedical research. However, it is difficult for researchers to obtain
knowledge of their interests in an efficient manner because of the massive
amount of the published biomedical literature. Therefore, efficient and
systematic search strategies are required, which allow ready access to the
substantial amount of literature. In this paper, we propose a novel search
system, named Co-Occurrence based on Co-Operational Formation with Advanced
Method(COCOFAM) which is suitable for the large-scale literature analysis.
COCOFAM is based on integrating both Spark for local clusters and a global job
scheduler to gather crowdsourced co-occurrence data on global clusters. It will
allow users to obtain information of their interests from the substantial
amount of literature.",122,7,847,33.95
2068,postmodern literature,"Among the manifold takes on world literature, it is our goal to contribute to
the discussion from a digital point of view by analyzing the representation of
world literature in Wikipedia with its millions of articles in hundreds of
languages. As a preliminary, we introduce and compare three different
approaches to identify writers on Wikipedia using data from DBpedia, a
community project with the goal of extracting and providing structured
information from Wikipedia. Equipped with our basic set of writers, we analyze
how they are represented throughout the 15 biggest Wikipedia language versions.
We combine intrinsic measures (mostly examining the connectedness of articles)
with extrinsic ones (analyzing how often articles are frequented by readers)
and develop methods to evaluate our results. The better part of our findings
seems to convey a rather conservative, old-fashioned version of world
literature, but a version derived from reproducible facts revealing an implicit
literary canon based on the editing and reading behavior of millions of people.
While still having to solve some known issues, the introduced methods will help
us build an observatory of world literature to further investigate its
representativeness and biases.",188,7,1247,22.79
2069,postmodern literature,"Metrics can be used by businesses to make more objective decisions based on
data. Software startups in particular are characterized by the uncertain or
even chaotic nature of the contexts in which they operate. Using data in the
form of metrics can help software startups to make the right decisions amidst
uncertainty and limited resources. However, whereas conventional business
metrics and software metrics have been studied in the past, metrics in the
spe-cific context of software startup are not widely covered within academic
literature. To promote research in this area and to create a starting point for
it, we have conducted a multi-vocal literature review focusing on practitioner
literature in order to compile a list of metrics used by software startups.
Said list is intended to serve as a basis for further research in the area, as
the metrics in it are based on suggestions made by practitioners and not
empirically verified.",152,7,941,37.34
2070,postmodern literature,"The purpose of the current study is to systematically review the
crowdsourcing literature, extract the activities which have been cited, and
synthesise these activities into a general process model. For this to happen,
we reviewed the related literature on crowdsourcing methods as well as relevant
case studies and extracted the activities which they referred to as part of
crowdsourcing projects. The systematic review of the related literature and an
in-depth analysis of the steps in those papers were followed by a synthesis of
the extracted activities resulting in an eleven-phase process model. This
process model covers all of the activities suggested by the literature. This
paper then briefly discusses activities in each phase and concludes with a
number of implications for both academics and practitioners.",125,6,819,29.18
2071,postmodern literature,"Business process modelling languages typically enable the representation of
business process models by employing (graphical) symbols. These symbols can
vary depending upon the verbosity of the language, the modelling paradigm, the
focus of the language, and so on. To make explicit the different constructs and
rules employed by a specific language, as well as bridge the gap across
different languages, meta-models have been proposed in literature. These
meta-models are a crucial source of knowledge on what state-of-the-art
literature considers relevant to describe business processes. The goal of this
work is to provide an extensive systematic literature review (SLR) of business
process meta-models. This SLR aims at answering research questions concerning:
(i) the kind of meta-models proposed in literature; (ii) the recurring
constructs they contain; (iii) their purposes; and (iv) their evaluations.",131,7,909,32.43
2072,postmodern literature,"The major objective of this work is to study and report the existing
ontology-driven models for narrative information. The paper aims to analyze
these models across various domains. The goal of this work is to bring the
relevant literature, and ontology models under one umbrella, and perform a
parametric comparative study. A systematic literature review methodology was
adopted for an extensive literature selection. A random stratified sampling
technique was used to select the models from the literature. The findings
explicate a comparative view of the narrative models across domains. The
differences and similarities of knowledge representation across domains, in
case of narrative information models based on ontology was identified. There
are significantly fewer studies that reviewed the ontology-based narrative
models. This work goes a step further by evaluating the ontologies using the
parameters from narrative components. This paper will explore the basic
concepts and top-level concepts in the models. Besides, this study provides a
comprehensive study of the narrative theories in the context of ongoing
research. The findings of this work demonstrate the similarities and
differences among the elements of the ontology across domains. It also
identifies the state of the art literature for ontology-based narrative
information.",197,14,1346,30.67
2073,postmodern literature,"The COVID-19 pandemic triggered a wave of novel scientific literature that is
impossible to inspect and study in a reasonable time frame manually. Current
machine learning methods offer to project such body of literature into the
vector space, where similar documents are located close to each other, offering
an insightful exploration of scientific papers and other knowledge sources
associated with COVID-19. However, to start searching, such texts need to be
appropriately annotated, which is seldom the case due to the lack of human
resources. In our system, the current body of COVID-19-related literature is
annotated using unsupervised keyphrase extraction, facilitating the initial
queries to the latent space containing the learned document embeddings
(low-dimensional representations). The solution is accessible through a web
server capable of interactive search, term ranking, and exploration of
potentially interesting literature. We demonstrate the usefulness of the
approach via case studies from the medicinal chemistry domain.",149,7,1043,20.92
2074,postmodern literature,"Discovering and making sense of relevant research literature is fundamental
to becoming knowledgeable in any scientific discipline. Visualization can aid
this process; however, existing tools' adoption and impact have often been
constrained, such as by their reliance on small curated paper datasets that
quickly become outdated or a lack of support for personalized exploration. We
introduce Argo Scholar, an open-source, web-based visualization tool for
interactive exploration of literature and easy sharing of exploration results.
Argo Scholar queries and visualizes Semantic Scholar's live data of almost 200
million papers, enabling users to generate personalized literature exploration
results in real-time through flexible, incremental exploration, a common and
effective method for researchers to discover relevant work. Our tool allows
users to easily share their literature exploration results as a URL or
web-embedded IFrame application. Argo Scholar is open-sourced and available at
https://poloclub.github.io/argo-scholar/.",139,9,1037,14.09
2075,postmodern literature,"Citation impact indicators nowadays play an important role in research
evaluation, and consequently these indicators have received a lot of attention
in the bibliometric and scientometric literature. This paper provides an
in-depth review of the literature on citation impact indicators. First, an
overview is given of the literature on bibliographic databases that can be used
to calculate citation impact indicators (Web of Science, Scopus, and Google
Scholar). Next, selected topics in the literature on citation impact indicators
are reviewed in detail. The first topic is the selection of publications and
citations to be included in the calculation of citation impact indicators. The
second topic is the normalization of citation impact indicators, in particular
normalization for field differences. Counting methods for dealing with
co-authored publications are the third topic, and citation impact indicators
for journals are the last topic. The paper concludes by offering some
recommendations for future research.",148,9,1023,18.86
2076,postmodern literature,"Modeling joint probability distributions over sequences has been studied from
many perspectives. The physics community developed matrix product states, a
tensor-train decomposition for probabilistic modeling, motivated by the need to
tractably model many-body systems. But similar models have also been studied in
the stochastic processes and weighted automata literature, with little work on
how these bodies of work relate to each other. We address this gap by showing
how stationary or uniform versions of popular quantum tensor network models
have equivalent representations in the stochastic processes and weighted
automata literature, in the limit of infinitely long sequences. We demonstrate
several equivalence results between models used in these three communities: (i)
uniform variants of matrix product states, Born machines and locally purified
states from the quantum tensor networks literature, (ii) predictive state
representations, hidden Markov models, norm-observable operator models and
hidden quantum Markov models from the stochastic process literature,and (iii)
stochastic weighted automata, probabilistic automata and quadratic automata
from the formal languages literature. Such connections may open the door for
results and methods developed in one area to be applied in another.",181,7,1304,6.98
2077,postmodern literature,"Scientific literature contain important information related to cutting-edge
innovations in diverse domains. Advances in natural language processing have
been driving the fast development in automated information extraction from
scientific literature. However, scientific literature is often available in
unstructured PDF format. While PDF is great for preserving basic visual
elements, such as characters, lines, shapes, etc., on a canvas for presentation
to humans, automatic processing of the PDF format by machines presents many
challenges. With over 2.5 trillion PDF documents in existence, these issues are
prevalent in many other important application domains as well.
  Our ICDAR 2021 Scientific Literature Parsing Competition (ICDAR2021-SLP) aims
to drive the advances specifically in document understanding. ICDAR2021-SLP
leverages the PubLayNet and PubTabNet datasets, which provide hundreds of
thousands of training and evaluation examples. In Task A, Document Layout
Recognition, submissions with the highest performance combine object detection
and specialised solutions for the different categories. In Task B, Table
Recognition, top submissions rely on methods to identify table components and
post-processing methods to generate the table structure and content. Results
from both tasks show an impressive performance and opens the possibility for
high performance practical applications.",189,13,1403,21.6
2078,postmodern literature,"Heart disease is one of the significant challenges in today's world and one
of the leading causes of many deaths worldwide. Recent advancement of machine
learning (ML) application demonstrates that using electrocardiogram (ECG) and
patient data, detecting heart disease during the early stage is feasible.
However, both ECG and patient data are often imbalanced, which ultimately
raises a challenge for the traditional ML to perform unbiasedly. Over the
years, several data level and algorithm level solutions have been exposed by
many researchers and practitioners. To provide a broader view of the existing
literature, this study takes a systematic literature review (SLR) approach to
uncover the challenges associated with imbalanced data in heart diseases
predictions. Before that, we conducted a meta-analysis using 451 referenced
literature acquired from the reputed journals between 2012 and November 15,
2021. For in-depth analysis, 49 referenced literature has been considered and
studied, taking into account the following factors: heart disease type,
algorithms, applications, and solutions. Our SLR study revealed that the
current approaches encounter various open problems/issues when dealing with
imbalanced data, eventually hindering their practical applicability and
functionality.",183,9,1297,22.85
2079,postmodern literature,"The purpose of this systematic review is to identify and describe the state
of development literature published in Latin America, in Spanish and English,
since 2010. For this, we carried out a topographic review of 44 articles
available in the most important bibliographic indexes of Latin America,
published in journals of diverse disciplines. Our analysis focused on analyzing
the nature and composition of literature, finding a large proportion of
articles coming from Mexico and Colombia, as well as specialized in the
economic discipline. The most relevant articles reviewed show methodological
and thematic diversity, with special attention to the problem of growth in
Latin American development. An important limitation of this review is the
exclusion of articles published in Portuguese, as well as non-indexed
literature (such as theses and dissertations). This leads to various
recommendations for future reviews of the development literature produced in
Latin America.",145,7,979,21.53
2080,postmodern literature,"It is a matter of debate whether a shrinking proportion of scholarly
literature is getting most of the references over time. It is also less well
understood how a narrowing literature usage would affect the circulation of
ideas in the sciences. Here we show, that the utilization of scientific
literature follows dual tendencies over time: while a larger proportion of
literature is cited at least a few times, citations are also concentrating more
on the top of the citation distribution. Parallel to the latter trend, a
paper's future importance increasingly depends on its past citation
performance. A random network model shows that the citation concentration is
directly related to the greater stability of citation performance. The
presented evidence suggests that the growing heterogeneity of citation impact
restricts the mobility of research articles that do not gain attention early
on. While concentration grows from the beginning of the studied period in 1970,
citation dispersion manifest itself significantly only from the mid-1990s when
the popularity of freshly published papers has also risen. Most likely,
advanced information technologies to disseminate papers are behind both of
these latter trends.",185,9,1219,31.11
2081,postmodern literature,"Scientific literature review generation aims to extract and organize
important information from an abundant collection of reference papers and
produces corresponding reviews while lacking a clear and logical hierarchy. We
observe that a high-quality catalogue-guided generation process can effectively
alleviate this problem. Therefore, we present an atomic and challenging task
named Hierarchical Catalogue Generation for Literature Review as the first step
for review generation, which aims to produce a hierarchical catalogue of a
review paper given various references. We construct a novel English
Hierarchical Catalogues of Literature Reviews Dataset with 7.6k literature
review catalogues and 389k reference papers. To accurately assess the model
performance, we design two evaluation metrics for informativeness and
similarity to ground truth from semantics and structure.Our extensive analyses
verify the high quality of our dataset and the effectiveness of our evaluation
metrics. We further benchmark diverse experiments on state-of-the-art
summarization models like BART and large language models like ChatGPT to
evaluate their capabilities. We further discuss potential directions for this
task to motivate future research.",169,10,1235,10.09
2082,postmodern literature,"Efficient planning of scarce resources in hospitals is a challenging task for
which a large variety of Operations Research and Management Science approaches
have been developed since the 1950s. While efficient planning of single
resources such as operating rooms, beds, or specific types of staff can already
lead to enormous efficiency gains, integrated planning of several resources has
been shown to hold even greater potential, and a large number of integrated
planning approaches have been presented in the literature over the past
decades.
  This paper provides the first literature review that focuses specifically on
the Operations Research and Management Science literature related to integrated
planning of different resources in hospitals. We collect the relevant
literature and analyze it regarding different aspects such as uncertainty
modeling and the use of real-life data. Several cross comparisons reveal
interesting insights concerning, e.g., relations between the modeling and
solution methods used and the practical implementation of the approaches
developed. Moreover, we provide a high-level taxonomy for classifying different
resource-focused integration approaches and point out gaps in the literature as
well as promising directions for future research.",182,9,1278,19.71
2083,postmodern literature,"The last twenty-five years have seen the development of a significant
literature within the subfield of econophysics which attempts to model economic
inequality as an emergent property of stochastic interactions among ensembles
of agents. In this article, the literature surrounding this approach to the
study of wealth and income distributions, henceforth the ""random asset
exchange"" literature following the terminology of Sinha (2003), is thoroughly
reviewed for the first time. The foundational papers of Dragulescu and
Yakovenko (2000), Chakraborti and Chakrabarti (2000), and Bouchaud and Mezard
(2000) are discussed in detail, and principal canonical models within the
random asset exchange literature are established. The most common variations
upon these canonical models are enumerated, and significant papers within each
kind of modification are introduced. The successes of such models, as well as
the limitations of their underlying assumptions, are discussed, and it is
argued that the literature should move in the direction of more explicit
representations of economic structure and processes to acquire greater
explanatory power.",164,6,1146,21.26
2084,postmodern literature,"This study presents an overview of the literature on virtual academic
conferences, which have gained prominence due to the COVID-19 pandemic. We
conducted a scoping review analyzing 147 documents covering the literature
available up to October 5th, 2021. We examined the development of the field
focusing on the evolution of virtual academic conferences, main themes in the
literature, and its methodological and theoretical approaches. The results
indicate that the existing literature on virtual academic conferences is mainly
descriptive and lacks a theoretical framework. Future research should focus on
developing a solid theoretical framework to guide empirically and
methodologically robust studies on virtual academic conferences. We emphasize
the importance of recognizing their advantages and disadvantages from the
perspectives of different groups of scholars. This will be a crucial step in
establishing a framework for identifying and addressing dilemmas in online
scholarly communication according to the responsible research and innovation
approach.",149,8,1064,16.02
2085,postmodern literature,"In the rapidly advancing research fields such as AI, managing and staying
abreast of the latest scientific literature has become a significant challenge
for researchers. Although previous efforts have leveraged AI to assist with
literature searches, paper recommendations, and question-answering, a
comprehensive support system that addresses the holistic needs of researchers
has been lacking. This paper introduces SurveyAgent, a novel conversational
system designed to provide personalized and efficient research survey
assistance to researchers. SurveyAgent integrates three key modules: Knowledge
Management for organizing papers, Recommendation for discovering relevant
literature, and Query Answering for engaging with content on a deeper level.
This system stands out by offering a unified platform that supports researchers
through various stages of their literature review process, facilitated by a
conversational interface that prioritizes user interaction and personalization.
Our evaluation demonstrates SurveyAgent's effectiveness in streamlining
research activities, showcasing its capability to facilitate how researchers
interact with scientific literature.",150,7,1174,3.8
2086,postmodern literature,"We give a simple rigourous treatment of the classical results of the abelian
sandpile model. Although we treat results which are well-known in the physics
literature, in many cases we did not find complete proofs in the literature.
The paper tries to fill the gap between the mathematics and the physics
literature on this subject, and also presents some new proofs. It can also
serve as an introduction to the model.",71,5,417,61.87
2087,postmodern literature,"Integrals related to the surface area of arbitrary ellipsoids are derived,
evaluated, and compared with each other and existing integrals found in the
literature. We clarify the literature on the ellipsoid area problem, which
dates back to Legendre's original 1811 work. We derive and evaluate several
additional integrals involving or evaluating to elliptic integrals. These new
integrals are natural extensions of those found in the literature and
constitute useful additions to standard integrals compendia.",74,5,510,18.86
2088,postmodern literature,"A method is described to empower students to efficiently perform general and
literature searches using online resources. The method was tested on
undergraduate and graduate students with varying backgrounds with scientific
literature. Students involved in this study showed marked improvement in their
awareness of how and where to find accurate scientific information.",52,4,369,28.54
2089,postmodern literature,"By systematically applying ten well-known and inequivalent two-part relations
between hypergeometric sums 3F2(...|1) to the published database of all such
sums, 62 new sums are obtained. The existing literature is summarized, and many
purportedly novel results extracted from that literature are shown to be
special cases of these new sums. The general problem of finding elements
contiguous to Watson's, Dixon's and Whipple's theorems is reduced to a simple
algorithm suitable for machine computation. Several errors in the literature
are corrected or noted. The present paper both summarizes and extends a
previous work on this subject.",95,9,638,38.52
2090,postmodern literature,"Literature-based knowledge discovery method was introduced by Dr. Swanson in
1986. He hypothesized a connection between Raynaud's phenomenon and dietary
fish oil, the field of literature-based discovery (LBD) was born from then on.
During the subsequent two decades, LBD's research attracts some scientists
including information science, computer science, and biomedical science, etc..
It has been a part of knowledge discovery and text mining. This paper
summarizes the development of recent years about LBD and presents two parts,
methodology research and applied research. Lastly, some problems are pointed as
future research directions.",91,9,640,41.36
2091,postmodern literature,"Many of the early works in the quality control literature construct control
limits through the use of graphs and tables as described in Wortham and Ringer
(1972). However, the methods used in this literature are restricted to using
only the values that the graphs and tables can provide and to the case where
the parameters of the underlying distribution are known. In this note, we
briefly describe a technique which can be used to calculate exact control
limits without the use of graphs or tables. We also describe what are commonly
referred to in the literature as fiducial limits. Fiducial limits are often
used as the limits in control charting when the parameters of the underlying
distribution are unknown.",119,6,714,47.32
2092,postmodern literature,"This literature review focuses on collective intelligence in humans. A
keyword search was performed on the Web of Knowledge and selected papers were
reviewed in order to reveal themes relevant to collective intelligence. Three
levels of abstraction were identified in discussion about the phenomenon: the
micro-level, the macro-level and the level of emergence. Recurring themes in
the literature were categorized under the above-mentioned framework and
directions for future research were identified.",71,5,501,28.03
2093,postmodern literature,"Bat algorithm (BA) is a bio-inspired algorithm developed by Yang in 2010 and
BA has been found to be very efficient. As a result, the literature has
expanded significantly in the last 3 years. This paper provides a timely review
of the bat algorithm and its new variants. A wide range of diverse applications
and case studies are also reviewed and summarized briefly here. Further
research topics are also discussed.",70,6,416,57.27
2094,postmodern literature,"Cloud Computing Datacenters host millions of virtual machines (VMs) on real
world scenarios. In this context, Virtual Machine Placement (VMP) is one of the
most challenging problems in cloud infrastructure management, considering also
the large number of possible optimization criteria and different formulations
that could be studied. VMP literature include relevant topics such as
energy-efficiency, Service Level Agreements (SLA), cloud service markets,
Quality of Service (QoS) and carbon dioxide emissions, all of them with high
economical and ecological impact. This work presents an extensive up-to-date
review of the most relevant VMP literature in order to identify research
opportunities.",98,5,698,21.23
2095,postmodern literature,"When making choices in software projects, engineers and other stakeholders
engage in decision making that involves uncertain future outcomes. Research in
psychology, behavioral economics and neuroscience has questioned many of the
classical assumptions of how such decisions are made. This literature review
aims to characterize the assumptions that underpin the study of these decisions
in Software Engineering. We identify empirical research on this subject and
analyze how the role of time has been characterized in the study of decision
making in SE. The literature review aims to support the development of
descriptive frameworks for empirical studies of intertemporal decision making
in practice.",102,6,702,25.39
2096,postmodern literature,"A literature survey on ontologies concerning the Security Assessment domain
has been carried out to uncover initiatives that aim at formalizing concepts
from the Security Assessment field of research. A preliminary analysis and a
discussion on the selected works are presented. Our main contribution is an
updated literature review, describing key characteristics, results, research
issues, and application domains of the papers. We have also detected gaps in
the Security Assessment literature that could be the subject of further studies
in the field. This work is meant to be useful for security researchers who wish
to adopt a formal approach in their methods.",102,6,664,33.85
2097,postmodern literature,"This article, produced as a result of the Symposium on Statistical Inference,
is an introduction to the literature on the function of expertise, judgment,
and choice in the practice of statistics and scientific research. In
particular, expert judgment plays a critical role in conducting Frequentist
hypothesis tests and Bayesian models, especially in selection of appropriate
prior distributions for model parameters. The subtlety of interpreting results
is also discussed. Finally, external recommendations are collected for how to
more effectively encourage proper use of judgment in statistics. The paper
synthesizes the literature for the purpose of creating a single reference and
inciting more productive discussions on how to improve the future of statistics
and science.",113,6,779,14.7
2098,postmodern literature,"This article provides a selective review on the recent literature on
econometric models of network formation. The survey starts with a brief
exposition on basic concepts and tools for the statistical description of
networks. I then offer a review of dyadic models, focussing on statistical
models on pairs of nodes and describe several developments of interest to the
econometrics literature. The article also presents a discussion of non-dyadic
models where link formation might be influenced by the presence or absence of
additional links, which themselves are subject to similar influences. This is
related to the statistical literature on conditionally specified models and the
econometrics of game theoretical models. I close with a (non-exhaustive)
discussion of potential areas for further development.",120,7,809,25.8
2099,postmodern literature,"We present in this work a new dataset of coreference annotations for works of
literature in English, covering 29,103 mentions in 210,532 tokens from 100
works of fiction. This dataset differs from previous coreference datasets in
containing documents whose average length (2,105.3 words) is four times longer
than other benchmark datasets (463.7 for OntoNotes), and contains examples of
difficult coreference problems common in literature. This dataset allows for an
evaluation of cross-domain performance for the task of coreference resolution,
and analysis into the characteristics of long-distance within-document
coreference.",88,6,629,45.15
2100,postmodern literature,"The literature for count modeling provides useful tools to conduct causal
inference when outcomes take non-negative integer values. Applied to the
potential outcomes framework, we link the Bayesian causal inference literature
to statistical models for count data. We discuss the general architectural
considerations for constructing the predictive posterior of the missing
potential outcomes. Special considerations for estimating average treatment
effects are discussed, some generalizing certain relationships and some not yet
encountered in the causal inference literature.",76,5,576,9.89
2101,postmodern literature,"Providing personalized recommendations that are also accompanied by
explanations as to why an item is recommended is a research area of growing
importance. At the same time, progress is limited by the availability of open
evaluation resources. In this work, we address the task of scientific
literature recommendation. We present arXivDigest, which is an online service
providing personalized arXiv recommendations to end users and operates as a
living lab for researchers wishing to work on explainable scientific literature
recommendations.",79,5,542,26.0
2102,postmodern literature,"The autonomous vehicle motion prediction literature is reviewed. Motion
prediction is the most challenging task in autonomous vehicles and self-drive
cars. These challenges have been discussed. Later on, the state-of-theart has
reviewed based on the most recent literature and the current challenges are
discussed. The state-of-the-art consists of classical and physical methods,
deep learning networks, and reinforcement learning. prons and cons of the
methods and gap of the research presented in this review. Finally, the
literature surrounding object tracking and motion will be presented. As a
result, deep reinforcement learning is the best candidate to tackle
self-driving cars.",98,9,685,42.07
2103,postmodern literature,"Scientific literature tends to grow as a function of funding and interest in
a given field. Mining such literature can reveal trends that may not be
immediately apparent. The CORD-19 corpus represents a growing corpus of
scientific literature associated with COVID-19. We examined the intersection of
a set of candidate therapeutics identified in a drug-repurposing study with
temporal instances of the CORD-19 corpus to determine if it was possible to
find and measure changes associated with them over time. We propose that the
techniques we used could form the basis of a tool to pre-screen new candidate
therapeutics early in the research process.",103,6,651,42.11
2104,postmodern literature,"The automated assembly and extension of dynamic network models using
information extracted from literature are challenging due to the amount and
inconsistency in published literature. Recently, efforts have been made to
automatically and efficiently assemble the information extracted from
literature into models. In this review, we summarize the basic concept,
performance, advantages, and limitations of five automated extension methods.
Each method was tested for its ability to reconstruct a model of T-cell
differentiation as compared against a number of predefined system properties.",82,5,589,8.37
2105,postmodern literature,"A recent paper by R. Muolo, T. Carletti, J. P. Gleeson, and M. Asllani
[Entropy 23, 36 (2021)] presents a mainly numerical study on the role of
non-normality in the synchronization of coupled periodic oscillators, deriving
apparent contradictions with the existing literature. Here, we show that their
conclusions are artifactual due to a misinterpretation of the master stability
function formalism and confirm that the existing literature is correct. We also
point to a broader existing literature in which research considered in this
paper was correctly addressed numerically, analytically, and experimentally.",90,9,613,19.37
2106,postmodern literature,"Ytterbium (Yb) doped fiber lasers are known to be affected by the creation of
color centers during lasing (socalled photodarkening (PD)). In a previous work,
this defect creation was investigated from a spectroscopic point of view,
showing the presence of traces (ppb) of thulium (Tm) in the Yb doped fiber. It
was shown that Tm has a strong impact on the defect creation process involved
in PD. In this paper, we compare the results from the literature with our Tm
hypothesis, without finding any contradiction. Moreover, this hypothesis can be
an explanation for the discrepancies in the literature.",98,6,601,51.58
2107,postmodern literature,"Monitoring several correlated quality characteristics of a process is common
in modern manufacturing and service industries. Although a lot of attention has
been paid to monitoring the multivariate process mean, not many control charts
are available for monitoring the covariance matrix. This paper presents a
comprehensive overview of the literature on control charts for monitoring the
covariance matrix in a multivariate statistical process monitoring (MSPM)
framework. It classifies the research that has previously appeared in the
literature. We highlight the challenging areas for research and provide some
directions for future research.",91,6,644,27.62
2108,postmodern literature,"In reinforcement learning (RL), the term self-play describes a kind of
multi-agent learning (MAL) that deploys an algorithm against copies of itself
to test compatibility in various stochastic environments. As is typical in MAL,
the literature draws heavily from well-established concepts in classical game
theory and so this survey quickly reviews some fundamental concepts. In what
follows, we present a brief survey of self-play literature, its major themes,
criteria, and techniques, and then conclude with an assessment of current
shortfalls of the literature as well as suggestions for future directions.",90,4,610,24.11
2109,postmodern literature,"We conduct a systematic literature review on the concept of trust in the
worldwide software ecosystem. We acknowledge that trust is something between
two actors in the software ecosystem, and we examine what role trust plays in
the relationships between end-users and (1) software products, (2) package
managers, (3) software producing organizations, and (4) software engineers. Two
major findings emerged from the systematic literature review. To begin, we
provide a definition of trust in the software ecosystem, including a
theoretical framework that decomposes and signifies a theoretical understanding
of trust. Second, we provide a list of trust factors that can be used to
assemble an overview of software trust.",109,6,719,32.43
2110,postmodern literature,"Confusion over different kinds of secondary research, and their divergent
purposes, is undermining the effectiveness and usefulness of secondary studies
in software engineering. This short paper therefore explains the differences
between ad hoc review, case survey, critical review, meta-analysis (aka
systematic literature review), meta-synthesis (aka thematic analysis), rapid
review and scoping review (aka systematic mapping study). These definitions and
associated guidelines help researchers better select and describe their
literature reviews, while helping reviewers select more appropriate evaluation
criteria.",78,4,619,2.79
2111,postmodern literature,"In this paper, we survey literature on prophet inequalities for subadditive
combinatorial auctions. We give an overview of the previous best $O(\log \log
m)$ prophet inequality as well as the preceding $O(\log m)$ prophet inequality.
Then, we provide the constructive posted price mechanisms used in order to
prove the two bounds. We mainly focus on the most recent literature that
resolves a central open problem in this area of discovering a constant factor
prophet inequality for subadditive valuations. We detail the approach of this
new paper, which is $\textit{non-constructive}$ and therefore cannot be
implemented using prices, as done in previous literature.",101,6,667,34.05
2112,postmodern literature,"The advent of ML-driven decision-making and policy formation has led to an
increasing focus on algorithmic fairness. As clustering is one of the most
commonly used unsupervised machine learning approaches, there has naturally
been a proliferation of literature on {\em fair clustering}. A popular notion
of fairness in clustering mandates the clusters to be {\em balanced}, i.e.,
each level of a protected attribute must be approximately equally represented
in each cluster. Building upon the original framework, this literature has
rapidly expanded in various aspects. In this article, we offer a novel
model-based formulation of fair clustering, complementing the existing
literature which is almost exclusively based on optimizing appropriate
objective functions.",110,8,766,19.06
2113,postmodern literature,"This article summarizes the literature on trust of digital technologies from
a human-centric perspective. We summarize literature on trust in face-to-face
interactions from other fields, followed by a discussion of organizational
trust, technology-mediated trust, trust of software products, trust of AI, and
blockchain. This report was created for the Science for Technological
Innovation Veracity Spearhead supported by New Zealand's National Science
Challenges.",62,4,464,16.62
2114,postmodern literature,"In this paper we study the pseudomonotone equilibrium problem. We consider a
new inertial condition for the subgradient extragradient method with
self-adaptive step size for approximating a solution of the equilibrium problem
in a real Hilbert space. Our proposed method contains inertial factor with new
conditions that only depend on the iteration coefficient. We obtain a weak
convergence result of the proposed method under weaker conditions on the
inertial factor than many existing conditions in the literature. Finally, we
present some numerical experiments for our proposed method in comparison with
existing methods in the literature. Our result improves, extends and
generalizes several existing results in the literature.",107,7,732,28.03
2115,postmodern literature,"This survey discusses the recent causal panel data literature. This recent
literature has focused on credibly estimating causal effects of binary
interventions in settings with longitudinal data, with an emphasis on practical
advice for empirical researchers. It pays particular attention to heterogeneity
in the causal effects, often in situations where few units are treated and with
particular structures on the assignment pattern. The literature has extended
earlier work on difference-in-differences or two-way-fixed-effect estimators.
It has more generally incorporated factor models or interactive fixed effects.
It has also developed novel methods using synthetic control approaches.",94,7,691,13.24
2116,postmodern literature,"Identifying the main contributions related to the Automated Test Production
(ATP) of Computer Programs and providing an overview about models,
methodologies and tools used for this purpose is the aim of this Systematic
Literature Review (SLR). The results will enable a comprehensive analysis and
insight to evaluate their applicability. A previously produced Systematic
Literature Mapping (SLM) contributed to the formulation of the ``Research
Questions'' and parameters for the definition of the qualitative analysis
protocol of this review.",77,4,543,11.55
2117,postmodern literature,"Literature in cyber security including cyber security in energy informatics
are tecnocentric focuses that may miss the chances of understanding a bigger
picture of cyber security measures. This research thus aims to conduct a
literature review focusing on non-technical issues in cyber security in the
energy informatics field. The findings show that there are seven non-technical
issues have been discussed in literature, including education, awareness,
policy, standards, human, and risks, challenges, and solutions. These findings
can be valuable for not only researchers, but also managers, policy makers, and
educators.",89,5,624,15.0
2118,postmodern literature,"The mindset literature is a longstanding area of psychological research
focused on beliefs about intelligence, response to challenge, and goals for
learning (Dweck, 2000). However, the mindset literature's applicability to the
context of college physics has not been widely studied. In this paper we narrow
our focus toward students' descriptions of their responses to challenge in
college physics. We ask the research questions, ""can we see responses to
challenge in college physics that resemble that of the mindset literature?"" and
""how do students express evidence of challenge and to what extent is such
evidence reflective of challenges found in the mindset literature?"" To answer
these questions, we developed a novel coding scheme for interview dialogue
around college physics challenge and students' responses to it. In this paper
we present the development process of our coding scheme. We find that it is
possible to see student descriptions of challenge that resemble the mindset
literature's characterizations. However, college physics challenges are
frequently different than those studied in the mindset literature. We show
that, in the landscape of college physics challenges, mindset beliefs cannot
always be considered to be the dominant factor in how students respond to
challenge. Broadly, our coding scheme helps the field move beyond broad
Likert-scale survey measures of students' mindset beliefs.",212,10,1420,43.43
2119,postmodern literature,"Literature-based knowledge discovery process identifies the important but
implicit relations among information embedded in published literature. Existing
techniques from Information Retrieval and Natural Language Processing attempt
to identify the hidden or unpublished connections between information concepts
within published literature, however, these techniques undermine the concept of
predicting the future and emerging relations among scientific knowledge
components encapsulated within the literature. Keyword Co-occurrence Network
(KCN), built upon author selected keywords (i.e., knowledge entities), is
considered as a knowledge graph that focuses both on these knowledge components
and knowledge structure of a scientific domain by examining the relationships
between knowledge entities. Using data from two multidisciplinary research
domains other than the medical domain, capitalizing on bibliometrics, the
dynamicity of temporal KCNs, and a Long Short Term Memory recurrent neural
network, this study proposed a framework to successfully predict the future
literature-based discoveries - the emerging connections among knowledge units.
Framing the problem as a dynamic supervised link prediction task, the proposed
framework integrates some novel node and edge-level features. Temporal
importance of keywords computed from both bipartite and unipartite networks,
communities of keywords, built upon genealogical relations, and relative
importance of temporal citation counts used in the feature construction
process. Both node and edge-level features were input into an LSTM network to
forecast the feature values for positive and negatively labeled non-connected
keyword pairs and classify them accurately. High classification performance
rates suggest that these features are supportive both in predicting the
emerging connections between scientific knowledge units and emerging trend
analysis.",250,11,1911,9.52
2120,postmodern literature,"Context: Maturity of practices and infrastructure in healthcare domain
directly impacts the quality and efficiency of healthcare services. Therefore,
various healthcare administrations (e.g., hospital management to nation-wide
health authority) need to assess and improve their operational maturity.
  Objective: This study aims to review and classify studies that propose/use
maturity assessment or maturity models (MMs) as a vehicle to achieve
operational excellence in healthcare domain.
  Method: To achieve this objective, we performed a Multivocal Literature
Review (MLR) that is a form of Systematic Review and includes data from the
grey literature (e.g., white papers and online documents) in addition to
formal, peer-reviewed literature.
  Results: Based on 101 sources, 80 of which are from the peer-reviewed
literature and 21 are from the grey literature, we identified 68 different MMs
on, e.g., telemedicine, care pathways, and digital imaging. We reviewed them
with respect to various aspects including: types of research and contribution;
list of MMs proposed/used with their subject focuses; elements of
maturity/capability; and application scope or scale. In the synthesis of
empirical benefits of using MMs, two were found significant: (1) Identifying
issues and providing guidance for improvement in healthcare contexts; (2)
Improving efficiency, effectiveness, performance, and productivity.
  Conclusion: This MLR provides an overview of the landscape and serves as an
index to the vast body of knowledge in this area. Our review creates an
opportunity to cope with the challenges in getting an overview of the
state-of-the-art and practice, choosing the most suitable models, or developing
new models with further specialties.",250,16,1749,24.98
2121,postmodern literature,"Deep learning has been widely used for medical image segmentation and a large
number of papers has been presented recording the success of deep learning in
the field. In this paper, we present a comprehensive thematic survey on medical
image segmentation using deep learning techniques. This paper makes two
original contributions. Firstly, compared to traditional surveys that directly
divide literatures of deep learning on medical image segmentation into many
groups and introduce literatures in detail for each group, we classify
currently popular literatures according to a multi-level structure from coarse
to fine. Secondly, this paper focuses on supervised and weakly supervised
learning approaches, without including unsupervised approaches since they have
been introduced in many old surveys and they are not popular currently. For
supervised learning approaches, we analyze literatures in three aspects: the
selection of backbone networks, the design of network blocks, and the
improvement of loss functions. For weakly supervised learning approaches, we
investigate literature according to data augmentation, transfer learning, and
interactive segmentation, separately. Compared to existing surveys, this survey
classifies the literatures very differently from before and is more convenient
for readers to understand the relevant rationale and will guide them to think
of appropriate improvements in medical image segmentation based on deep
learning approaches.",208,9,1473,19.71
2122,postmodern literature,"Systematic literature studies have received much attention in empirical
software engineering in recent years. They have become a powerful tool to
collect and structure reported knowledge in a systematic and reproducible way.
We distinguish systematic literature reviews to systematically analyze reported
evidence in depth, and systematic mapping studies to structure a field of
interest in a broader, usually quantified manner. Due to the rapidly increasing
body of knowledge in software engineering, researchers who want to capture the
published work in a domain often face an extensive amount of publications,
which need to be screened, rated for relevance, classified, and eventually
analyzed. Although there are several guidelines to conduct literature studies,
they do not yet help researchers coping with the specific difficulties
encountered in the practical application of these guidelines. In this article,
we present an experience-based guideline to aid researchers in designing
systematic literature studies with special emphasis on the data collection and
selection procedures. Our guideline aims at providing a blueprint for a
practical and pragmatic path through the plethora of currently available
practices and deliverables capturing the dependencies among the single steps.
The guideline emerges from various mapping studies and literature reviews
conducted by the authors and provides recommendations for the general study
design, data collection, and study selection procedures. Finally, we share our
experiences and lessons learned in applying the different practices of the
proposed guideline.",229,10,1615,20.31
2123,postmodern literature,"Mature test automation is key for achieving software quality at speed. In
this paper, we present a multivocal literature review with the objective to
survey and synthesize the guidelines given in the literature for improving test
automation maturity. We selected and reviewed 81 primary studies, consisting of
26 academic literature and 55 grey literature sources. From primary studies, we
extracted 26 test automation best practices (e.g., Define an effective test
automation strategy, Set up good test environments, Develop high-quality test
scripts) and collected many pieces of advice (e.g., in forms of
implementation/improvement approaches, technical techniques, concepts,
experience-based heuristics) on how to conduct these best practices. We made
main observations: (1) There are only 6 best practices whose positive effect on
maturity improvement have been evaluated by academic studies using formal
empirical methods; (2) Several technical related best practices in this MLR
were not presented in test maturity models; (3) Some best practices can be
linked to success factors and maturity impediments proposed by other scholars;
(4) Most pieces of advice on how to conduct proposed best practices were
identified from experience studies and their effectiveness need to be further
evaluated with cross-site empirical evidence using formal empirical methods;
(5) In the literature, some advice on how to conduct certain best practices are
conflicting, and some advice on how to conduct certain best practices still
need further qualitative analysis.",228,10,1558,13.01
2124,postmodern literature,"The rapid growth of biomedical literature poses a significant challenge for
curation and interpretation. This has become more evident during the COVID-19
pandemic. LitCovid, a literature database of COVID-19 related papers in PubMed,
has accumulated over 180,000 articles with millions of accesses. Approximately
10,000 new articles are added to LitCovid every month. A main curation task in
LitCovid is topic annotation where an article is assigned with up to eight
topics, e.g., Treatment and Diagnosis. The annotated topics have been widely
used both in LitCovid (e.g., accounting for ~18% of total uses) and downstream
studies such as network generation. However, it has been a primary curation
bottleneck due to the nature of the task and the rapid literature growth. This
study proposes LITMC-BERT, a transformer-based multi-label classification
method in biomedical literature. It uses a shared transformer backbone for all
the labels while also captures label-specific features and the correlations
between label pairs. We compare LITMC-BERT with three baseline models on two
datasets. Its micro-F1 and instance-based F1 are 5% and 4% higher than the
current best results, respectively, and only requires ~18% of the inference
time than the Binary BERT baseline. The related datasets and models are
available via https://github.com/ncbi/ml-transformer.",200,18,1360,40.04
2125,postmodern literature,"Data mesh is an emerging domain-driven decentralized data architecture that
aims to minimize or avoid operational bottlenecks associated with centralized,
monolithic data architectures in enterprises. The topic has picked the
practitioners' interest, and there is considerable gray literature on it. At
the same time, we observe a lack of academic attempts at defining and building
upon the concept. Hence, in this article, we aim to start from the foundations
and characterize the data mesh architecture regarding its design principles,
architectural components, capabilities, and organizational roles. We
systematically collected, analyzed, and synthesized 114 industrial gray
literature articles. The review provides insights into practitioners'
perspectives on the four key principles of data mesh: data as a product, domain
ownership of data, self-serve data platform, and federated computational
governance. Moreover, due to the comparability of data mesh and SOA
(service-oriented architecture), we mapped the findings from the gray
literature into the reference architectures from the SOA academic literature to
create the reference architectures for describing three key dimensions of data
mesh: organization of capabilities and roles, development, and runtime.
Finally, we discuss open research issues in data mesh, partially based on the
findings from the gray literature.",194,9,1383,12.97
2126,postmodern literature,"The COVID-19 pandemic led to 1.1 million deaths in the United States, despite
the explosion of coronavirus research. These new findings are slow to translate
to clinical interventions, leading to poorer patient outcomes and unnecessary
deaths. One reason is that clinicians, overwhelmed by patients, struggle to
keep pace with the rate of new coronavirus literature. A potential solution is
developing a tool for evaluating coronavirus literature using large language
models (LLMs) -- neural networks that are deployed for natural language
processing. LLMs can be used to summarize and extract user-specified
information. The greater availability and advancement of LLMs and pre-processed
coronavirus literature databases provide the opportunity to assist clinicians
in evaluating coronavirus literature through a coronavirus literature specific
LLM (covLLM), a tool that directly takes an inputted research article and a
user query to return an answer. Using the COVID-19 Open Research Dataset
(CORD-19), we produced two datasets: (1) synCovid, which uses a combination of
handwritten prompts and synthetic prompts generated using OpenAI, and (2) real
abstracts, which contains abstract and title pairs. covLLM was trained with
LLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca
and synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real
abstract datasets. These models were evaluated by two human evaluators and
ChatGPT. Results demonstrate that training covLLM on the synCovid and abstract
pairs datasets performs competitively with ChatGPT and outperforms covLLM
trained primarily using the Alpaca dataset.",242,12,1658,32.33
2127,postmodern literature,"As Distributed Ledger Technologies (DLTs) rapidly evolve, their impacts
extend beyond technology, influencing environmental and societal aspects. This
evolution has increased publications, making manual literature analysis
increasingly challenging. We address this with a Natural Language Processing
(NLP)-based systematic literature review method to explore the intersection of
Distributed Ledger Technology (DLT) with its Environmental, Social, and
Governance (ESG) aspects. Our approach involves building and refining a
directed citation network from 107 seed papers to a corpus of 24,539
publications and fine-tuning a transformer-based language model for Named
Entity Recognition (NER) on DLT and ESG domains. Applying this model, we
distilled the corpus to 505 key publications, enabling an inaugural literature
review and temporal graph analysis of DLT's evolution in ESG contexts. Our
contributions include an adaptable and scalable NLP-driven systematic
literature review methodology and a unique NER dataset of 54,808 entities,
tailored for DLT and ESG research. Our inaugural literature review demonstrates
their applicability and effectiveness in analyzing DLT's evolution and impacts,
proving invaluable for stakeholders in the DLT domain.",169,8,1252,13.17
2128,postmodern literature,"Motivation: Curation of literature in life sciences is a growing challenge.
The continued increase in the rate of publication, coupled with the relatively
fixed number of curators worldwide presents a major challenge to developers of
biomedical knowledgebases. Very few knowledgebases have resources to scale to
the whole relevant literature and all have to prioritise their efforts.
  Results: In this work, we take a first step to alleviating the lack of
curator time in RNA science by generating summaries of literature for
non-coding RNAs using large language models (LLMs). We demonstrate that
high-quality, factually accurate summaries with accurate references can be
automatically generated from the literature using a commercial LLM and a chain
of prompts and checks. Manual assessment was carried out for a subset of
summaries, with the majority being rated extremely high quality. We also
applied the most commonly used automated evaluation approaches, finding that
they do not correlate with human assessment. Finally, we apply our tool to a
selection of over 4,600 ncRNAs and make the generated summaries available via
the RNAcentral resource. We conclude that automated literature summarization is
feasible with the current generation of LLMs, provided careful prompting and
automated checking are applied.
  Availability: Code used to produce these summaries can be found here:
https://github.com/RNAcentral/litscan-summarization and the dataset of contexts
and summaries can be found here:
https://huggingface.co/datasets/RNAcentral/litsumm-v1. Summaries are also
displayed on the RNA report pages in RNAcentral (https://rnacentral.org/)",233,14,1652,26.4
2129,postmodern literature,"Background: The emergence of generative AI tools, empowered by Large Language
Models (LLMs), has shown powerful capabilities in generating content. To date,
the assessment of the usefulness of such content, generated by what is known as
prompt engineering, has become an interesting research question. Objectives
Using the mean of prompt engineering, we assess the similarity and closeness of
such contents to real literature produced by scientists. Methods In this
exploratory analysis, (1) we prompt-engineer ChatGPT and Google Bard to
generate clinical content to be compared with literature counterparts, (2) we
assess the similarities of the contents generated by comparing them with
counterparts from biomedical literature. Our approach is to use text-mining
approaches to compare documents and associated bigrams and to use network
analysis to assess the terms' centrality. Results The experiments demonstrated
that ChatGPT outperformed Google Bard in cosine document similarity (38% to
34%), Jaccard document similarity (23% to 19%), TF-IDF bigram similarity (47%
to 41%), and term network centrality (degree and closeness). We also found new
links that emerged in ChatGPT bigram networks that did not exist in literature
bigram networks. Conclusions: The obtained similarity results show that ChatGPT
outperformed Google Bard in document similarity, bigrams, and degree and
closeness centrality. We also observed that ChatGPT offers linkage to terms
that are connected in the literature. Such connections could inspire asking
interesting questions and generate new hypotheses.",228,11,1585,22.95
2130,postmodern literature,"By consolidating scattered knowledge, the literature review provides a
comprehensive understanding of the investigated topic. However, reading,
conducting, or peer-reviewing review papers generally demands a significant
investment of time and effort from researchers. To improve efficiency, this
paper aims to provide a thorough review of reviews in the PAMI field from
diverse perspectives. First, this paper proposes several article-level,
field-normalized, and large language model-empowered bibliometric indicators to
evaluate reviews. To facilitate this, a meta-data database dubbed RiPAMI, and a
topic dataset are constructed. Second, based on these indicators, the study
presents comparative analyses of representative reviews, unveiling the
characteristics of publications across various fields, periods, and journals.
The newly emerging AI-generated literature reviews are also appraised, and the
observed differences suggest that most AI-generated reviews still lag behind
human-authored reviews in multiple aspects. Third, we briefly provide a
subjective evaluation of representative PAMI reviews and introduce a paper
structure-based typology of literature reviews. This typology may improve the
clarity and effectiveness for scholars in reading and writing reviews, while
also serving as a guide for AI systems in generating well-organized reviews.
Finally, this work offers insights into the current challenges of literature
reviews and envisions future directions for their development.",200,11,1501,8.88
2131,postmodern literature,"This bibliography attempts to give a comprehensive overview of all the
literature related to the Ashtekar variables. The original version was compiled
by Peter H\""ubner in 1989, and it has been subsequently updated by Gabriela
Gonzalez, Bernd Br\""ugmann, and Troy Schilling. Information about additional
literature, new preprints, and especially corrections are always welcome.",53,4,377,28.13
2132,postmodern literature,"A short historical review is made of some recent literature in the field of
noncommutative geometry, especially the efforts to add a gravitational field to
noncommutative models of space-time and to use it as an ultraviolet regulator.
An extensive bibliography has been added containing reference to recent review
articles as well as to part of the original literature.",58,3,369,16.66
2133,postmodern literature,"Diese kurze Einfuehrung in Theorie und Berechnung linearer Rekurrenzen
versucht, eine Luecke in der Literatur zu fuellen. Zu diesem Zweck sind viele
ausfuehrliche Beispiele angegeben.
  This short introduction to theory and usage of linear recurrences tries to
fill a gap in the literature by giving many extensive examples.",48,4,324,55.24
2134,postmodern literature,"We survey known results about the complexity of surjective homomorphism
problems, studied in the context of related problems in the literature such as
list homomorphism, retraction and compaction. In comparison with these
problems, surjective homomorphism problems seem to be harder to classify and we
examine especially three concrete problems that have arisen from the
literature, two of which remain of open complexity.",62,3,422,23.09
2135,postmodern literature,"Transfer learning techniques are important to handle small training sets and
to allow for quick generalization even from only a few examples. The following
paper is the introduction as well as the literature overview part of my thesis
related to the topic of transfer learning for visual recognition problems.",49,3,309,38.15
2136,postmodern literature,"During the last years, low-rank tensor approximation has been established as
a new tool in scientific computing to address large-scale linear and
multilinear algebra problems, which would be intractable by classical
techniques. This survey attempts to give a literature overview of current
developments in this area, with an emphasis on function-related tensors.",52,3,362,28.17
2137,postmodern literature,"We present a system that constructs and maintains an up-to-date co-occurrence
network of medical concepts based on continuously mining the latest biomedical
literature. Users can explore this network visually via a concise online
interface to quickly discover important and novel relationships between medical
entities. This enables users to rapidly gain contextual understanding of their
medical topics of interest, and we believe this constitutes a significant user
experience improvement over contemporary search engines operating in the
biomedical literature domain.",78,4,570,2.79
2138,postmodern literature,"After revival of the concept of minimal length, many investigations have been
devoted, in literature, to estimate upper-bound on minimal length for systems
like hydrogen atom, deuteron etc. We report here a possible origin of minimal
length for atomic and nuclear systems which is connected with the fundamental
interaction strength and the Compton wavelength. The formula we appear at is
numerically close to the upper-bounds found in literature.",68,4,447,31.51
2139,postmodern literature,"In the sequel, we recall and comment some classical results on the
non-increasing rearrangement and Lorentz spaces. There are papers in the
existing literature that seemed to have been bypassed as regards its
contractive property in~$L^p$ spaces. Also, we provide detailed proofs and some
properties that does not seem to arise in the existing literature.",55,4,355,52.9
2140,postmodern literature,"Fractional difference sequence spaces have been studied in the literature
recently. In this work, some identities or estimates for the operator norms and
the Hausdorff measures of noncompactness of certain operators on some
difference sequence spaces of fractional orders are established. Some classes
of compact operators on those spaces are characterized. The results of this
work are more general and comprehensive then many other studies in literature.",67,5,456,29.04
2141,postmodern literature,"Chondrocytes were described as one cell populations in most cartilage
literature. Two different chondrocyte populations; dark and light, were
described in the articular cartilage and a third population, adipochondrocytes,
was described in the elastic cartilage. The cur-rent literature of cartilage
histology should be updated and highlight that three different populations of
chondrocytes are existed in cartilage.",56,4,415,18.65
2142,postmodern literature,"A principal can restrict an agent's information (the persuasion problem) or
restrict an agent's discretion (the delegation problem). We show that these
problems are generally equivalent - solving one solves the other. We use tools
from the persuasion literature to generalize and extend many results in the
delegation literature, as well as to address novel delegation problems, such as
monopoly regulation with a participation constraint.",65,4,439,24.48
2143,postmodern literature,"Given the large number of publications in software engineering, frequent
literature reviews are required to keep current on work in specific areas. One
tedious work in literature reviews is to find relevant studies amongst
thousands of non-relevant search results. In theory, expert systems can assist
in finding relevant work but those systems have primarily been tested in
simulations rather than in application to actual literature reviews. Hence, few
researchers have faith in such expert systems. Accordingly, using a realistic
case study, this paper assesses how well our state-of-the-art expert system can
help with literature reviews.
  The assessed literature review aimed at identifying test case prioritization
techniques for automated UI testing, specifically from 8,349 papers on IEEE
Xplore. This corpus was studied with an expert system that incorporates an
incrementally updated human-in-the-loop active learning tool. Using that expert
system, in three hours, we found 242 relevant papers from which we identified
12 techniques representing the state-of-the-art in test case prioritization
when source code information is not available. These results were then
validated by six other graduate students manually exploring the same corpus.
Without the expert system, this task would have required 53 hours and would
have found 27 additional papers. That is, our expert system achieved 90% recall
with 6% of the human effort cost when compared to a conventional manual method.
Significantly, the same 12 state-of-the-art test case prioritization techniques
were identified by both the expert system and the manual method. That is, the
27 papers missed by the expert system would not have changed the conclusion of
the literature review.
  Hence, if this result generalizes, it endorses the use of our expert system
to assist in literature reviews.",279,15,1861,34.36
2144,postmodern literature,"The literature review presented below on Action Recognition in the wild is
the in-depth study of Research Papers. Action Recognition problem in the
untrimmed videos is a challenging task and most of the papers have tackled this
problem using hand-crafted features with shallow learning techniques and
sophisticated end-to-end deep learning techniques.",51,3,351,37.13
2145,postmodern literature,"The goal of this paper is to present a centrality measurement for the nodes
of a hypergraph, by using existing literature which extends eigenvector
centrality from a graph to a hypergraph, and literature which give a general
centrality measurement for a graph. We will use this measurement to say more
about the number of communications in a hypergraph, to implement a learning
mechanism, and to construct certain networks.",68,3,423,28.51
2146,postmodern literature,"We compute the $V$-monoid of a weighted Leavitt path algebra of a row-finite
weighted graph, correcting a wrong computation of the $V$-monoid that exists in
the literature. Further we show that the description of $K_0$ of a weighted
Leavitt path algebra that exists in the literature is correct (although the
computation was based on a wrong $V$-monoid description).",58,3,366,42.04
2147,postmodern literature,"Singular limit problems of reaction-diffusion systems have been studied in
cases where the effects of the reaction terms are very large compared with
those of the other terms. Such problems appear in literature in various fields
such as chemistry, ecology, biology, geology and approximation theory. In this
paper, we deal with the singular limit of a general reaction-diffusion system
including many problems in the literature. We formulate the problem, derive the
limit equation and establish a rigorous mathematical theory.",79,5,526,26.0
2148,postmodern literature,"This short report gives a non-asymptotic rate of convergence proof for
solving a two-block coordinate descent problem. This non-asymptotic proof is a
simple result that can be derived easily from available results in the
literature. We give the results in this report because in this general form we
have not seen being stated in the literature.",56,4,345,52.49
2149,postmodern literature,"L\'evy driven term structure models have become an important subject in the
mathematical finance literature. This paper provides a comprehensive analysis
of the L\'evy driven Heath-Jarrow-Morton type term structure equation. This
includes a full proof of existence and uniqueness in particular, which seems to
have been lacking in the finance literature so far.",53,4,361,36.59
2150,postmodern literature,"In this survey paper we give an historical and at the same time thematical
overview of the development of ring geometry from its origin to the current
state of the art. A comprehensive up-to-date list of literature is added with
articles that treat ring geometry within the scope of incidence geometry.",51,3,302,37.13
2151,postmodern literature,"In this paper the preliminary results of a literature review on
characteristics used to define continuous experiments are presented. In total
14 papers were selected. The results were synthesized into a model that gives
an overview of all characteristics.",39,4,255,32.9
2152,postmodern literature,"There are still many potential literature visualizations to be discovered. By
focusing on a single text, the author surveys many existing visualizations
across research domains, in the wild, and creates new visualizations. 58
techniques are indicated, suggesting a wider variety of visualizations beyond
research disciplines.",45,4,325,22.41
2153,postmodern literature,"The concepts of machine homomorphism and machine products developed in the
automata theory literature in the 1960s are more relevant to concurrent systems
than is acknowledged in the process algebra literature and offer a
sophisticated mathematical basis for understanding concurrent systems.",41,2,292,-12.45
2154,postmodern literature,"We survey the treatment of sex and gender in the Computer Graphics research
literature from an algorithmic fairness perspective. The established practices
on the use of gender and sex in our community are scientifically incorrect and
constitute a form of algorithmic bias with potential harmful effects. We
propose ways of addressing these as technical limitations.",55,4,365,27.52
2155,postmodern literature,"In this review we survey the literature on mean-field coupled maps. We start
with the early works from the physics literature, arriving to some recent
results from ergodic theory studying the thermodynamic limit of globally
coupled maps and the associated self-consistent transfer operators. We also
give few pointers to related research fields dealing with mean-field coupled
systems in continuous time, and applications.",62,4,422,25.08
2156,postmodern literature,"Since the term ""Cyber threat hunting"" was introduced in 2016, there have been
a rising trend of proactive defensive measure to create more cyber security.
This research will look into peer reviewed literature on the subject of cyber
threat hunting. Our study shows an increase in the field with methods of
machine learning.\\ Keywords: Cyber threat, Cyber security, threat hunting ,
security system, data driven, Intel, analytic driven, TTPs",69,4,441,45.76
2157,postmodern literature,"We piece together ingredients, which are well known and documented in the
literature, into a new proof of the existence of semistable 3-fold flips",24,1,146,47.12
2158,postmodern literature,"Two different local stability conditions for an asymmetric superfluid has
been discussed in the literature. We here consider the relations between them.",22,3,152,26.47
2159,postmodern literature,"We discuss the use of projects in first-year graduate complexity theory
courses.",12,2,80,42.38
2160,postmodern literature,"We discuss the scientific contributions of Edsger Wybe Dijkstra, his opinions
and his legacy.",14,2,93,40.35
2161,postmodern literature,"This article illustrates the use of a logical specification language to
capture various forms of confidentiality properties used in the security
literature.",22,2,156,-1.63
2162,postmodern literature,"The inclusive distributions of gluons and pions are calculated with absolute
normalization for high-energy nucleon-nucleon collisions. The results for
several unintegrated gluon distributions from the literature are compared. The
gluon distribution proposed recently by Kharzeev and Levin based on the idea of
gluon saturation is tested against DIS data from HERA. We find huge differences
in both rapidity and transverse momentum distributions of gluons and pions in
nucleon-nucleon collisions for different models of unintegrated gluon
distributions. The approximations used recently in the literature are
discussed. The Karzeev-Levin gluon distribution gives extremely good
description of momentum distribution of charged hadrons at midrapidities.
Contrary to a recent claim in the literature, we find that the gluonic
mechanism discussed does not describe the inclusive spectra of charged
particles in the fragmentation region, i.e. in the region of large $|y|$ for
any unintegrated gluon distribution from the literature.",144,10,1026,19.37
2163,postmodern literature,"A procedure to teach Electrodynamics independently of unit systems is
presented and compared with some of those given in physics literature.",21,2,140,24.78
2164,postmodern literature,"This paper gives a critical account of the minority game literature. The
minority game is a simple congestion game: players need to choose between two
options, and those who have selected the option chosen by the minority win. The
learning model proposed in this literature seems to differ markedly from the
learning models commonly used in economics. We relate the learning model from
the minority game literature to standard game-theoretic learning models, and
show that in fact it shares many features with these models. However, the
predictions of the learning model differ considerably from the predictions of
most other learning models. We discuss the main predictions of the learning
model proposed in the minority game literature, and compare these to
experimental findings on congestion games.",125,7,802,41.9
2165,postmodern literature,"This note is withdrawn. The result and its proof are available in the
literature.",14,3,81,81.29
2166,postmodern literature,This note argues about the validity of web-graph data used in the literature.,13,2,77,41.36
2167,postmodern literature,A literature review of neutrino physics and the solar neutrino problem.,11,2,71,34.93
2168,postmodern literature,"The paper investigates the properties of a nonlinear recursive sequence which
includes several ones studied formerly in the literature.",19,2,135,9.89
2169,postmodern literature,"Supersymmetry, shape invariance, exact solubility, and the factorization
method are often studied together in the literature. At the dawn of these
topics confusion was present in regards to their scope of applicability and the
relation among them. Considerable work have been put to study and resolve the
relation among two or more of these topics. These works are scattered over the
literature. While looking at the literature, one can not overlook the number of
places where authors confuse these terms, and concluding implications depending
on wrong assumptions of the relation between two or more of these topics. In
this letter we define supersymmetry, and shape invariance, and show the
relations which connects them to exact solubility and the factorization method,
referring to the literature for the respective detailed work and proofs. At
last we conclude our letter with a Venn diagram which illustrates those
relations.",145,8,931,42.0
2170,postmodern literature,"A review of the empirical literature on access to scholarly information. This
review focuses on surveys of authors, article download and citation analysis.",23,3,155,17.5
2171,postmodern literature,"We give a self-contained exposition of the proof of faithfully flat descent
for projectivity of modules. This fills a gap in the proof given in the
literature.",27,3,159,57.77
2172,postmodern literature,"We review the literature on Information Causality. Since it's for a book, we
don't think an abstract will be needed at all, so we have written this one just
for the sake of the arXiv.",35,3,183,70.63
2173,postmodern literature,"Test functions are important to validate and compare the performance of
optimization algorithms. There have been many test or benchmark functions
reported in the literature; however, there is no standard list or set of
benchmark functions. Ideally, test functions should have diverse properties so
that can be truly useful to test new algorithms in an unbiased way. For this
purpose, we have reviewed and compiled a rich set of 175 benchmark functions
for unconstrained optimization problems with diverse properties in terms of
modality, separability, and valley landscape. This is by far the most complete
set of functions so far in the literature, and tt can be expected this complete
set of functions can be used for validation of new optimization in the future.",123,6,765,46.51
2174,postmodern literature,How to manage knowledge on the Web.,7,2,35,89.75
2175,postmodern literature,"User Experience (UX) has been a buzzword in agile literature in recent years.
However, often UX remains as a vague concept and it may be hard to understand
the very nature of it in the context of agile software development. This paper
explores the multifaceted UX literature, emphasizes the multi-dimensional
nature of the concept and organizes the current state-of-the-art knowledge. As
a starting point to better understand the contemporary meaning of UX assigned
by practitioners, we selected four UX blogs and performed an analysis using a
framework derived from the literature review. The preliminary results show that
the practitioners more often focus on interaction between product and user and
view UX from design perspective predominantly. While the economical perspective
receives little attention in literature, it is evident in practitioners
writings. Our study opens up a promising line of request of the contemporary
meaning of UX in practice.",147,8,958,33.24
2176,postmodern literature,"Employees of early childhood education and care (ECEC) organisations may
experience a wide range of barriers as they attempt to integrate information
technology (IT) into their work practices. However, studies within the ECEC
organisational literature which attempt to identify and understand these
barriers are scant. This literature review is the first to present consolidated
findings from the body of knowledge on barriers to the integration of IT within
ECEC organisations. In addition to highlighting limitations and gaps in the
literature, it proposes a tri-perspective framework to provide for future
research to develop a deeper understanding of not only what barriers exist but
also how they interrelate and shape the IT integration process and the work
practices of ECEC organisational employees.",120,5,807,15.65
2177,postmodern literature,"What is the state of the literature in respect to Crowdsourcing for policy
making? This work attempts to answer this question by collecting, categorizing,
and situating the extant research investigating Crowdsourcing for policy,
within the broader Crowdsourcing literature. To do so, the work first extends
the Crowdsourcing literature by introducing, defining, explaining, and using
seven universal characteristics of all general Crowdsourcing techniques, to
vividly draw-out the relative trade-offs of each mode of Crowdsourcing. From
this beginning, the work systematically and explicitly weds the three types of
Crowdsourcing to the stages of the Policy cycle as a method of situating the
extant literature spanning both domains. Thereafter, we discuss the trends,
highlighting the research gaps, and outline the overlaps in the research on
Crowdsourcing for policy, stemming from our analysis.",129,5,898,28.37
2178,postmodern literature,"This paper is about the general disconnect that we see, both in practice and
in literature, between the disciplines of travel demand modeling and causal
inference. In this paper, we assert that travel demand modeling should be one
of the many fields that focuses on the production of valid causal inferences,
and we hypothesize about reasons for the current disconnect between the two
bodies of research. Furthermore, we explore the potential benefits of uniting
these two disciplines. We consider what travel demand modeling can gain from
greater incorporation of techniques and perspectives from the causal inference
literatures, and we briefly discuss what the causal inference literature might
gain from the work of travel demand modelers. In this paper, we do not attempt
to ""solve"" issues related to the drawing of causal inferences from travel
demand models. Instead, we hope to spark a larger discussion both within and
between the travel demand modeling and causal inference literatures. In
particular, we hope to incite discussion about the necessity of drawing causal
inferences in travel demand applications and the methods by which one might
credibly do so.",184,8,1170,36.32
2179,postmodern literature,"Recent efforts in bioinformatics have achieved tremendous progress in the
machine reading of biomedical literature, and the assembly of the extracted
biochemical interactions into large-scale models such as protein signaling
pathways. However, batch machine reading of literature at today's scale (PubMed
alone indexes over 1 million papers per year) is unfeasible due to both cost
and processing overhead. In this work, we introduce a focused reading approach
to guide the machine reading of biomedical literature towards what literature
should be read to answer a biomedical query as efficiently as possible. We
introduce a family of algorithms for focused reading, including an intuitive,
strong baseline, and a second approach which uses a reinforcement learning (RL)
framework that learns when to explore (widen the search) or exploit (narrow
it). We demonstrate that the RL approach is capable of answering more queries
than the baseline, while being more efficient, i.e., reading fewer documents.",150,8,1003,37.64
2180,postmodern literature,"We describe a deployed scalable system for organizing published scientific
literature into a heterogeneous graph to facilitate algorithmic manipulation
and discovery. The resulting literature graph consists of more than 280M nodes,
representing papers, authors, entities and various interactions between them
(e.g., authorships, citations, entity mentions). We reduce literature graph
construction into familiar NLP tasks (e.g., entity extraction and linking),
point out research challenges due to differences from standard formulations of
these tasks, and report empirical results for each task. The methods described
in this paper are used to enable semantic features in www.semanticscholar.org",93,10,696,21.9
2181,postmodern literature,"An example of a cocomplete abelian category that is not complete is
constructed.",13,2,80,41.36
2182,postmodern literature,"We establish some properties of substochastic matrices that we haven't been
able to find in the literature",17,1,106,54.22
2183,postmodern literature,"As part of the effort to improve quality and to reduce national healthcare
costs, the Centers for Medicare and Medicaid Services (CMS) are responsible for
creating and maintaining an array of clinical quality measures (CQMs) for
assessing healthcare structure, process, outcome, and patient experience across
various conditions, clinical specialties, and settings. The development and
maintenance of CQMs involves substantial and ongoing evaluation of the evidence
on the measure's properties: importance, reliability, validity, feasibility,
and usability. As such, CMS conducts monthly environmental scans of the
published clinical and health service literature. Conducting time consuming,
exhaustive evaluations of the ever-changing healthcare literature presents one
of the largest challenges to an evidence-based approach to healthcare quality
improvement. Thus, it is imperative to leverage automated techniques to aid CMS
in the identification of clinical and health services literature relevant to
CQMs. Additionally, the estimated labor hours and related cost savings of using
CMS Sematrix compared to a traditional literature review are roughly 818 hours
and 122,000 dollars for a single monthly environmental scan.",169,7,1224,9.01
2184,postmodern literature,"Distributed energy resources (DER) provide significant value for renewable
energy integration in modern power grids. However, unlocking this value
requires complex design and coordination. This paper focuses on the emerging
{\em transactive energy systems}, which draw tools and principles from
economics to design the coordination strategies for DERs. The concept of
transactive energy system broadly captures a huge body of literature, and many
of them are closely related but fundamentally different. This gives rise to the
following questions: how to formally compare different transactive energy
systems and their proposed approaches? How to choose the right transactive
energy system to formulate a given problem? What tools are available in the
literature for each class of transactive energy systems? In this paper, we
answer these questions by synthesizing a unifying framework for a large class
of problems studied in the literature. The framework consists of preferences,
control decision, information structure and solution concept. These elements
are important in identifying and distinguishing various transactive energy
systems in the literature. We employ the proposed framework to analyze a few
important class of transactive energy systems. Their connections and
differences are discussed, and available tools for each class of problems are
surveyed.",197,10,1368,29.45
2185,postmodern literature,"Named Entity Recognition and Relation Extraction for Chinese literature text
is regarded as the highly difficult problem, partially because of the lack of
tagging sets. In this paper, we build a discourse-level dataset from hundreds
of Chinese literature articles for improving this task. To build a high quality
dataset, we propose two tagging methods to solve the problem of data
inconsistency, including a heuristic tagging method and a machine auxiliary
tagging method. Based on this corpus, we also introduce several widely used
models to conduct experiments. Experimental results not only show the
usefulness of the proposed dataset, but also provide baselines for further
research. The dataset is available at
https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset",110,7,778,35.98
2186,postmodern literature,"Integration of the scientific literature into a biomedical research
infrastructure requires the processing of the literature, identification of the
contained named entities (NEs) and concepts, and to represent the content in a
standardised way. The CALBC project partners (PPs) have produced a large-scale
annotated biomedical corpus with four different semantic groups through the
harmonisation of annotations from automatic text mining solutions (Silver
Standard Corpus, SSC). The four semantic groups were chemical entities and
drugs (CHED), genes and proteins (PRGE), diseases and disorders (DISO) and
species (SPE). The content of the SSC has been fully integrated into RDF Triple
Store (4,568,678 triples) and has been aligned with content from the GeneAtlas
(182,840 triples), UniProtKb (12,552,239 triples for human) and the lexical
resource LexEBI (BioLexicon). RDF Triple Store enables querying the scientific
literature and bioinformatics resources at the same time for evidence of
genetic causes, such as drug targets and disease involvement.",150,6,1054,24.11
2187,postmodern literature,"We point out that the ideas underlying some test procedures recently proposed
for testing post-model-selection (and for some other test problems) in the
econometrics literature have been around for quite some time in the statistics
literature. We also sharpen some of these results in the statistics literature.
Furthermore, we show that some intuitively appealing testing procedures, that
have found their way into the econometrics literature, lead to tests that do
not have desirable size properties, not even asymptotically.",78,4,527,36.63
2188,postmodern literature,"Context: The Evidence-Based Software Engineering (EBSE) paradigm and the
planning phase of a systematic literature review. Objective: A protocol to do a
systematic literature review with detailed information about the processes
suggested by several guidelines in the field of evidence-based software
engineering. Method: An analisys of recent systematic literature reviews
published in world leading journals, plus the use of two renowned guidelines
and a textbook to sinthetise a formal plan (the protocol). Results: The
validated protocol Conclusions: We found that most of the published systematic
reviews lack on reporting the protocol, or it is weak. There is a lack of tool
support to develop formal protocols. Although a protocol, like a plan, must
have the flexibility to adapt to unforeseen situations, its objective is that
the actual activities should resemble as far as possible of those already
planned. Therefore, it is a difficult balance to achieve and, researchers must
be careful not to introduce alterations that could become threats to the
validity of the entire work.",166,8,1088,30.5
2189,postmodern literature,"We give a counterexample to the proof in the literature [K-Theory 25 (2002),
215-231] of the existence of linear representatives of higher Chow groups of
number fields.",27,2,168,44.07
2190,postmodern literature,"We discuss the relevance of the recent Machine Learning (ML) literature for
economics and econometrics. First we discuss the differences in goals, methods
and settings between the ML literature and the traditional econometrics and
statistics literatures. Then we discuss some specific methods from the machine
learning literature that we view as important for empirical researchers in
economics. These include supervised learning methods for regression and
classification, unsupervised learning methods, as well as matrix completion
methods. Finally, we highlight newly developed methods at the intersection of
ML and econometrics, methods that typically perform better than either
off-the-shelf ML or more traditional econometric methods when applied to
particular classes of problems, problems that include causal inference for
average treatment effects, optimal policy estimation, and estimation of the
counterfactual effect of price changes in consumer choice models.",134,6,971,18.89
2191,postmodern literature,"We derive an identity involving Horadam numbers. Numerous new identities as
well as those found in the existing literature are subsumed in this single
identity.",25,3,160,41.87
2192,postmodern literature,"This survey develops a dual analysis, consisting, first, in a bibliometric
examination and, second, in a close literature review of all the scientific
production around cryptocurrencies conducted in economics so far. The aim of
this paper is twofold. On the one hand, proposes a methodological hybrid
approach to perform comprehensive literature reviews. On the other hand, we
provide an updated state of the art in cryptocurrency economic literature. Our
methodology emerges as relevant when the topic comprises a large number of
papers, that make unrealistic to perform a detailed reading of all the papers.
This dual perspective offers a full landscape of cryptocurrency economic
research. Firstly, by means of the distant reading provided by machine learning
bibliometric techniques, we are able to identify main topics, journals, key
authors, and other macro aggregates. Secondly, based on the information
provided by the previous stage, the traditional literature review provides a
closer look at methodologies, data sources and other details of the papers. In
this way, we offer a classification and analysis of the mounting research
produced in a relative short time span.",180,10,1180,34.26
2193,postmodern literature,"Reviewing scientific literature is a cumbersome, time consuming but crucial
activity in research. Leveraging a scholarly knowledge graph, we present a
methodology and a system for comparing scholarly literature, in particular
research contributions describing the addressed problem, utilized materials,
employed methods and yielded results. The system can be used by researchers to
quickly get familiar with existing work in a specific research domain (e.g., a
concrete research question or hypothesis). Additionally, it can be used to
publish literature surveys following the FAIR Data Principles. The methodology
to create a research contribution comparison consists of multiple tasks,
specifically: (a) finding similar contributions, (b) aligning contribution
descriptions, (c) visualizing and finally (d) publishing the comparison. The
methodology is implemented within the Open Research Knowledge Graph (ORKG), a
scholarly infrastructure that enables researchers to collaboratively describe,
find and compare research contributions. We evaluate the implementation using
data extracted from published review articles. The evaluation also addresses
the FAIRness of comparisons published with the ORKG.",161,11,1204,11.01
2194,postmodern literature,"In this paper, we have studied how the text of an ancient literature on how
their integrity has been preserved for several centuries. Specifically, The
Vedas is an ancient literature, which has its text remained preserved without
any corruption for thousands of years. As we studied the system that protects
the integrity of the text, pronunciation and semantics of the The Vedas, we
discovered a number of similarities it has with the current concept of
blockchain technology. It is surprising that the notion of de-centralized trust
and mathematical encodings have existed since thousands of years in order to
protect this work of literature. We have presented our findings and analysis of
the similarities. There are also certain technical mechanisms that The Vedic
integrity system uses, which can be used to enhance the current digital
blockchain platforms in terms of its security and robustness.",143,7,902,38.86
2195,postmodern literature,"Over its more than thirty-year history, the Advanced Technologies and
Instrumentation (ATI) program has provided grants to support technology
development and instrumentation for ground-based astronomy. Through a
combination of automated literature assessment and in-depth literature review,
we present a survey of ATI-funded research and an assessment of its impact on
astronomy and society. Award acknowledgement and literature citation statistics
for ATI are comparable to a comparison astronomy grant program that does not
support technology development. Citation statistics for both NSF-funded
programs exceed those of the general astronomical literature. Numerous examples
demonstrate the significant, long term impact of ATI-supported research on
astronomy. As part of this impact, ATI grants have provided many early career
researchers the opportunity to gain critical professional experience. However,
technology development unfolds over a time period that is longer than an
individual grant. A longitudinal perspective shows that investments in
technology and instrumentation have lead to extraordinary scientific progress.",152,9,1132,9.89
2196,postmodern literature,"The Open Research Knowledge Graph (ORKG) provides machine-actionable access
to scholarly literature that habitually is written in prose. Following the FAIR
principles, the ORKG makes traditional, human-coded knowledge findable,
accessible, interoperable, and reusable in a structured manner in accordance
with the Linked Open Data paradigm. At the moment, in ORKG papers are described
manually, but in the long run the semantic depth of the literature at scale
needs automation. Operational Research is a suitable test case for this vision
because the mathematical field and, hence, its publication habits are highly
structured: A mundane problem is formulated as a mathematical model, solved or
approximated numerically, and evaluated systematically. We study the existing
literature with respect to the Assembly Line Balancing Problem and derive a
semantic description in accordance with the ORKG. Eventually, selected papers
are ingested to test the semantic description and refine it further.",144,7,996,21.74
2197,postmodern literature,"We introduce some preliminaries about game theory and information security.
Then surveying a subset of the literature, we identify opportunities for future
research.",23,3,165,9.04
2198,postmodern literature,"Human trafficking is a widespread and compound social, economic, and human
rights issue occurring in every region of the world. While there have been an
increasing number of anti-human trafficking works from the Operations Research
and Analytics domains in recent years, no systematic review of this literature
currently exists. We fill this gap by providing a systematic literature review
that identifies and classifies the body of Operations Research and Analytics
research related to the anti-human trafficking domain, thereby illustrating the
collective impact of the field to date. We classify 142 studies to identify
current trends in methodologies, theoretical approaches, data sources,
trafficking contexts, target regions, victim-survivor demographics, and focus
within the well-established 4Ps principles. Using these findings, we discuss
the extent to which the current literature aligns with the global demographics
of human trafficking and identify existing research gaps to propose an agenda
for Operations Research and Analytics researchers.",149,6,1056,15.85
2199,postmodern literature,"Relation classification is an important semantic processing task in the field
of natural language processing. In this paper, we propose the task of relation
classification for Chinese literature text. A new dataset of Chinese literature
text is constructed to facilitate the study in this task. We present a novel
model, named Structure Regularized Bidirectional Recurrent Convolutional Neural
Network (SR-BRCNN), to identify the relation between entities. The proposed
model learns relation representations along the shortest dependency path (SDP)
extracted from the structure regularized dependency tree, which has the
benefits of reducing the complexity of the whole model. Experimental results
show that the proposed method significantly improves the F1 score by 10.3, and
outperforms the state-of-the-art approaches on Chinese literature text.",119,8,848,20.38
2200,postmodern literature,"Function-as-a-Service (FaaS) is one form of the serverless cloud computing
paradigm and is defined through FaaS platforms (e.g., AWS Lambda) executing
event-triggered code snippets (i.e., functions). Many studies that empirically
evaluate the performance of such FaaS platforms have started to appear but we
are currently lacking a comprehensive understanding of the overall domain. To
address this gap, we conducted a multivocal literature review (MLR) covering
112 studies from academic (51) and grey (61) literature. We find that existing
work mainly studies the AWS Lambda platform and focuses on micro-benchmarks
using simple functions to measure CPU speed and FaaS platform overhead (i.e.,
container cold starts). Further, we discover a mismatch between academic and
industrial sources on tested platform configurations, find that function
triggers remain insufficiently studied, and identify HTTP API gateways and
cloud storages as the most used external service integrations. Following
existing guidelines on experimentation in cloud systems, we discover many flaws
threatening the reproducibility of experiments presented in the surveyed
studies. We conclude with a discussion of gaps in literature and highlight
methodological suggestions that may serve to improve future FaaS performance
evaluation studies.",185,14,1318,33.65
2201,postmodern literature,"This review explores the academic and policy literature in the context of
everyday cyber security in organisations. In so doing, it identifies four
behavioural sets that influences how people practice cyber security. These are
compliance with security policy, intergroup coordination and communication,
phishing/email behaviour, and password behaviour. However, it is important to
note that these are not exhaustive and they do not exist in isolation. In
addition, the review explores the notion of security culture as an overarching
theme that overlaps and frames the four behavioural sets. The aim of this
review is therefore to provide a summary of the existing literature in the area
of everyday cyber security within the social sciences, with a particular focus
on organisational contexts. In doing so, it develops a series of suggestions
for future research directions based on existing gaps in the literature. The
review also includes a theoretical lens that will aid the understanding of
existing studies and wider literatures. Where possible, the review makes
recommendations for organisations in relation to everyday cyber security.",172,10,1142,26.71
2202,postmodern literature,"In this note, we discuss circle compactifications of 6d SCFTs for which a
geometric M-theory construction is not known in previous literature.",22,2,142,32.22
2203,postmodern literature,"The flux-weighted gravity-luminosity relation (FWGLR) is investigated for a
sample of 477 classical Cepheids (CCs), including stars that have been
classified in the literature as such but are probably not. The luminosities are
taken from the literature, based on the fitting of the spectral energy
distributions (SEDs) assuming a certain distance and reddening. The
flux-weighted gravity (FWG) is taken from gravity and effective temperature
determinations in the literature based on high-resolution spectroscopy.
  There is a very good agreement between the theoretically predicted and
observed FWG versus pulsation period relation that could serve in estimating
the FWG (and $\log g$) in spectroscopic studies with a precision of 0.1~dex.
  As was known in the literature, the theoretically predicted FWGLR relation
for CCs is very tight and is not very sensitive to metallicity (at least for
LMC and solar values), rotation rate, and crossing of the instability strip.
The observed relation has a slightly different slope and shows more scatter
(0.54~dex). This is due both to uncertainties in the distances and to the
pulsation phase averaged FWG values.
  Data from future Gaia data releases should reduce these errors, and then the
FWGLR could serve as a powerful tool in Cepheid studies.",198,11,1294,37.84
2204,postmodern literature,"Compliance of organizations with internal and external norms is a highly
relevant topic for both practitioners and academics nowadays. However, the
substantive, elementary compliance tactics that organizations can use for
achieving internal compliance have been described in a fragmented manner and in
the literatures of distinct academic disciplines. Using a multidisciplinary
structured literature review of 134 publications, this study offers three
contributions. First, we present a typology of 45 compliance tactics, which
constitutes a comprehensive and rich overview of elementary ways for bringing
the organization into compliance. Secondly, we provide an overview of
fundamental concepts in the theory of compliance, which forms the basis for the
framework we developed for positioning compliance tactics and for analyzing or
developing compliance strategies. Thirdly, we present insights for moving from
compliance tactics to compliance strategies. In the process, and using the
multidisciplinary literature review to take a bird's-eye view, we demonstrate
that compliance strategies need to be regarded as a richer concept than
perceived hitherto. We also show that opportunities for innovation exist.",170,9,1212,24.48
2205,postmodern literature,"The world has faced the devastating outbreak of Severe Acute Respiratory
Syndrome Coronavirus-2 (SARS-CoV-2), or COVID-19, in 2020. Research in the
subject matter was fast-tracked to such a point that scientists were struggling
to keep up with new findings. With this increase in the scientific literature,
there arose a need for organizing those documents. We describe an approach to
organize and visualize the scientific literature on or related to COVID-19
using machine learning techniques so that papers on similar topics are grouped
together. By doing so, the navigation of topics and related papers is
simplified. We implemented this approach using the widely recognized CORD-19
dataset to present a publicly available proof of concept.",113,7,743,43.93
2206,postmodern literature,"As scientists worldwide search for answers to the overwhelmingly unknown
behind the deadly pandemic, the literature concerning COVID-19 has been growing
exponentially. Keeping abreast of the body of literature at such a rapidly
advancing pace poses significant challenges not only to active researchers but
also to the society as a whole. Although numerous data resources have been made
openly available, the analytic and synthetic process that is essential in
effectively navigating through the vast amount of information with heightened
levels of uncertainty remains a significant bottleneck. We introduce a generic
method that facilitates the data collection and sense-making process when
dealing with a rapidly growing landscape of a research domain such as COVID-19
at multiple levels of granularity. The method integrates the analysis of
structural and temporal patterns in scholarly publications with the delineation
of thematic concentrations and the types of uncertainties that may offer
additional insights into the complexity of the unknown. We demonstrate the
application of the method in a study of the COVID-19 literature.",167,7,1136,26.34
2207,postmodern literature,"Visual representation of the law and legal process can aid in recall and
discussion of complicated legal concepts, yet is a skill rarely taught in law
schools. This work investigates the use of flowcharts and similar
process-oriented diagrams in contemporary legal literature through a literature
review and concept-based content analysis. Information visualisations (infovis)
identified in the literature are classified into eleven described archetypal
diagram types, and the results describe their usage quantitatively by type,
year, publication venue and legal domain. We found that the use of infovis in
legal literature is extremely rare, identifying not more than ten articles in
each calendar year. We also identified that the concept flow diagram is most
commonly used, and that Unified Modelling Language (UML) is the most frequently
applied representational approach. This work posits a number of serious
questions for legal educators and practicing lawyers regarding how infovis in
legal education and practice may improve access to justice, legal education and
lay comprehension of complex legal frameworks and processes. It concludes by
asking how we can expect communities to understand and adhere to laws that have
become so complex and verbose as to be incomprehensible even to many of those
who are learned in the law?",203,7,1335,25.12
2208,postmodern literature,"The amount of scientific papers published every day is daunting and
constantly increasing. Keeping up with literature represents a challenge. If
one wants to start exploring new topics it is hard to have a big picture
without reading lots of articles. Furthermore, as one reads through literature,
making mental connections is crucial to ask new questions which might lead to
discoveries. In this work, I present a web tool which uses a Text Mining
strategy to transform large collections of unstructured biomedical articles
into structured data. Generated results give a quick overview on complex topics
which can possibly suggest not explicitly reported information. In particular,
I show two Data Science analyses. First, I present a literature based rare
diseases network build using this tool in the hope that it will help clarify
some aspects of these less popular pathologies. Secondly, I show how a
literature based analysis conducted with PubSqueezer results allows to describe
known facts about SARS-CoV-2. In one sentence, data generated with PubSqueezer
make it easy to use scientific literate in any computational analysis such as
machine learning, natural language processing etc.
  Availability: http://www.pubsqueezer.com",186,13,1237,35.68
2209,postmodern literature,"Among various medical imaging tools, chest radiographs are the most important
and widely used diagnostic tool for detection of thoracic pathologies. Research
is being carried out in order to propose robust automatic diagnostic tool for
detection of pathologies from chest radiographs. Artificial Intelligence
techniques especially deep learning methodologies have found to be giving
promising results in automating the field of medicine. Lot of research has been
done for automatic and fast detection of pneumothorax from chest radiographs
while proposing several frameworks based on artificial intelligence and machine
learning techniques. This study summarizes the existing literature for the
automatic detection of pneumothorax from chest x-rays along with describing the
available chest radiographs datasets. The comparative analysis of the
literature is also provided in terms of goodness. Limitations of the existing
literature along with the research gaps is also given for further
investigation. The paper provides a brief overview of the present work for
pneumothorax detection for helping the researchers in selection of optimal
approach for future research.",166,9,1168,33.44
2210,postmodern literature,"Most of the knowledge in materials science literature is in the form of
unstructured data such as text and images. Here, we present a framework
employing natural language processing, which automates text and image
comprehension and precision knowledge extraction from inorganic glasses'
literature. The abstracts are automatically categorized using latent Dirichlet
allocation (LDA), providing a way to classify and search semantically linked
publications. Similarly, a comprehensive summary of images and plots are
presented using the 'Caption Cluster Plot' (CCP), which provides direct access
to the images buried in the papers. Finally, we combine the LDA and CCP with
the chemical elements occurring in the manuscript to present an 'Elemental
map', a topical and image-wise distribution of chemical elements in the
literature. Overall, the framework presented here can be a generic and powerful
tool to extract and disseminate material-specific information on
composition-structure-processing-property dataspaces, allowing insights into
fundamental problems relevant to the materials science community and
accelerated materials discovery.",157,7,1142,2.58
2211,postmodern literature,"Computational modeling is crucial for understanding and analyzing complex
systems. In biology, model creation is a human dependent task that requires
reading hundreds of papers and conducting wet lab experiments, which would take
days or months. To overcome this hurdle, we propose a novel automated method,
that utilizes the knowledge published in literature to suggest model extensions
by selecting most relevant and useful information in few seconds. In
particular, our novel approach organizes the events extracted from the
literature as a collaboration graph with additional metric that relies on the
event occurrence frequency in literature. Additionally, we show that common
graph centrality metrics vary in the assessment of the extracted events. We
have demonstrated the reliability of the proposed method using three different
selected models, namely, T cell differentiation, T cell large granular
lymphocyte, and pancreatic cancer cell. Our proposed method was able to find
high percent of the desired new events with an average recall of 82%.",158,8,1054,31.62
2212,postmodern literature,"Literature reviews can be time-consuming and tedious to complete. By
cataloging and refactoring three state-of-the-art active learning techniques
from evidence-based medicine and legal electronic discovery, this paper finds
and implements FASTREAD, a faster technique for studying a large corpus of
documents. This paper assesses FASTREAD using datasets generated from existing
SE literature reviews (Hall, Wahono, Radjenovi\'c, Kitchenham et al.). Compared
to manual methods, FASTREAD lets researchers find 95% relevant studies after
reviewing an order of magnitude fewer papers. Compared to other
state-of-the-art automatic methods, FASTREAD reviews 20-50% fewer studies while
finding same number of relevant primary studies in a systematic literature
review.",102,7,761,16.93
2213,postmodern literature,"Structuring related work is a daunting task encompassing literature review,
classification, comparison (primarily in the form of concepts), and gap
analysis. Building taxonomies is a compelling way to structure concepts in the
literature yielding reusable and extensible models. However, constructing
taxonomies as a product of literature reviews could become, to our experiences,
immensely complex and error-prone. Including new literature or addressing
errors may cause substantial changes (ripple effects) in taxonomies coping with
which requires adequate tools. To this end, we propose a
\emph{Taxonomy-as-a-Service (TaaS)} platform. TaaS combines the systematic
paper review process with taxonomy development, visualization, and analysis
capabilities. We evaluate the effectiveness and efficiency of our platform by
employing it in the development of a real-world taxonomy. Our results indicate
that our TaaS can be used to effectively craft and maintain UML-conforming
taxonomies and thereby structure related work. The screencast of our tool
demonstration is available at \url{https://goo.gl/GsTjsP}.",149,11,1107,20.79
2214,postmodern literature,"There is some literature on the application of linear boundary element method
(BEM) for real-time simulation of biological organs. However, literature is
scant when it comes to the application of nonlinear BEM, although there is a
possibility that the use of nonlinear BEM would result in better simulations.
Hence the present paper explores the possibility of using nonlinear BEM for
real-time simulation of biological organs. This paper begins with a general
discussion about using the nonlinear BEM for real-time simulation of biological
organs. Literature on nonlinear BEM is reviewed and the literature that deal
with nonlinear formulations and coding are noted down next. In the later
sections, some results obtained from nonlinear analyses are compared with the
corresponding results from linear analyses. The last section concludes with
remarks that indicate that it might be possible to obtain better simulations in
the future by using nonlinear BEM.",146,8,959,24.88
2215,postmodern literature,"Herein we present one hundred inequalities culled from various corners of the
probability, statistics, and combinatorics literature. We welcome new
suggestions.",21,3,160,18.52
2216,postmodern literature,"The paper explores and analyses the trend of world literature on ""Coronavirus
Disease"" in terms of the output of research publications as indexed in the
Science Citation Index Expanded (SCI-E) of Web of Science during the period
from 2011 to 2020. The study found that 6071 research records have been
published on Coronavirus Disease till March 20, 2020. The various scientometric
components of the research records published in the study period were studied.
The study reveals the various aspects of Coronavirus Disease literature such as
year wise distribution, relative growth rate, doubling time of literature,
geographical wise, organization wise, language wise, form wise , most prolific
authors, and source wise. The highest number of articles was published in the
year 2019, while lowest numbers of research article were reported in the year
2020. Further, the relative growth rate is gradually increases and on the other
hand doubling time decreases. Most of the research publications are published
in English language and most of the publications published in the form of
research articles. USA is the highest contributor to the field of Coronavirus
Disease literature.",183,9,1179,39.87
2217,postmodern literature,"The COVID-19 pandemic has driven ever-greater demand for tools which enable
efficient exploration of biomedical literature. Although semi-structured
information resulting from concept recognition and detection of the defining
elements of clinical trials (e.g. PICO criteria) has been commonly used to
support literature search, the contributions of this abstraction remain poorly
understood, especially in relation to text-based retrieval. In this study, we
compare the results retrieved by a standard search engine with those filtered
using clinically-relevant concepts and their relations. With analysis based on
the annotations from the TREC-COVID shared task, we obtain quantitative as well
as qualitative insights into characteristics of relational and concept-based
literature exploration. Most importantly, we find that the relational concept
selection filters the original retrieved collection in a way that decreases the
proportion of unjudged documents and increases the precision, which means that
the user is likely to be exposed to a larger number of relevant documents.",151,8,1083,20.52
2218,postmodern literature,"In recent years, many studies have applied wearable devices to capture
psychophysiological data from software developers. However, the current
literature lacks investigations that classify the studies and point out gaps to
be explored. This article, therefore, seeks to present a comprehensive overview
of the literature by classifying and creating a systematic map of the works.
Besides, it seeks to pinpoint research gaps, challenges, and trends. Based on
widely known guidelines, a systematic mapping of the literature was designed
and run to answer eight research questions. After applying a careful filtering
process, we selected 27 representative studies from a sample of 2,084
potentially relevant works retrieved from seven digital libraries. The main
results are: a classification scheme of the published studies was produced;
there is no predominance of the devices used to capture psychophysiological
data; over 50% of the studies have explored indicators related to mental states
and neural activity; and 80% have analyzed composite data to understand the
cognitive load and in the context of understanding debugging programs and
strategies. Our findings can benefit researchers and students by creating a
systematic map of the literature, being a starting point for future research.",192,9,1295,30.2
2219,postmodern literature,"Purpose: We seek to explore the realm of literature about digital libraries.
We specifically seek to ascertain how interest in this subject has evolved, its
impact, the most productive journals and countries, the number of occurrences
of digital libraries, the relationships and dynamics of the main concepts
mentioned, and the dynamics of metadata formats.Methods: We extracted corpora
from the Google Scholar and Microsoft Academic Search bibliographic databases.
We analyzed the named entities and concepts contained within these corpora with
the help of text mining technologies, CorTexT in particular.Results: While the
number of publications on the subject of digital libraries is increasing, their
average number of citations is decreasing. China, the United States and India
are the most productive countries on the subject. Literature about conservation
and national libraries has gradually been replaced by literature about open
access, university libraries and the relationship with users. Internet Archive
is the most cited digital library in literature and continues to grow. Dublin
Core is the most talked about metadata format, however the subject of metadata
formats is declining in the corpus today.Conclusion: Digital libraries now seem
to be reaching the age of maturity.",190,11,1290,35.27
2220,postmodern literature,"Powers of Fibonacci polynomials are expressed as single sums, improving on a
double sum recently seen in the literature.",19,2,120,35.27
2221,postmodern literature,"The Covid-19 pandemic has caused a spur in the medical research literature.
With new research advances in understanding the virus, there is a need for
robust text mining tools which can process, extract and present answers from
the literature in a concise and consumable way. With a DialoGPT based
multi-turn conversation generation module, and BM-25 \& neural embeddings based
ensemble information retrieval module, in this paper we present a
conversational system, which can retrieve and answer coronavirus-related
queries from the rich medical literature, and present it in a conversational
setting with the user. We further perform experiments to compare neural
embedding-based document retrieval and the traditional BM25 retrieval algorithm
and report the results.",113,5,769,26.14
2222,postmodern literature,"Debugging is a relevant task for finding bugs during software development,
maintenance, and evolution. During debugging, developers use modern IDE
debuggers to analyze variables, step execution, and set breakpoints. Observing
IDE debuggers, we find several breakpoint types. However, what are the
breakpoint types? The goal of our study is to map the breakpoint types among
IDEs and academic literature. Thus, we mapped the gray literature on the
documentation of the nine main IDEs used by developers according to the three
public rankings. In addition, we performed a systematic mapping of academic
literature over 68 articles describing breakpoint types. Finally, we analyzed
the developers understanding of the main breakpoint types through a
questionnaire. We present three main contributions: (1) the mapping of
breakpoint types (IDEs and literature), (2) compiled definitions of breakpoint
types, (3) a breakpoint type taxonomy. Our contributions provide the first step
to organize breakpoint IDE taxonomy and lexicon, and support further debugging
research.",155,10,1065,38.82
2223,postmodern literature,"Scientific literature is one of the most significant resources for sharing
knowledge. Researchers turn to scientific literature as a first step in
designing an experiment. Given the extensive and growing volume of literature,
the common approach of reading and manually extracting knowledge is too time
consuming, creating a bottleneck in the research cycle. This challenge spans
nearly every scientific domain. For the materials science, experimental data
distributed across millions of publications are extremely helpful for
predicting materials properties and the design of novel materials. However,
only recently researchers have explored computational approaches for knowledge
extraction primarily for inorganic materials. This study aims to explore
knowledge extraction for organic materials. We built a research dataset
composed of 855 annotated and 708,376 unannotated sentences drawn from 92,667
abstracts. We used named-entity-recognition (NER) with BiLSTM-CNN-CRF deep
learning model to automatically extract key knowledge from literature.
Early-phase results show a high potential for automated knowledge extraction.
The paper presents our findings and a framework for supervised knowledge
extraction that can be adapted to other scientific domains.",172,12,1261,21.8
2224,postmodern literature,"This paper provides a review of the job recommender system (JRS) literature
published in the past decade (2011-2021). Compared to previous literature
reviews, we put more emphasis on contributions that incorporate the temporal
and reciprocal nature of job recommendations. Previous studies on JRS suggest
that taking such views into account in the design of the JRS can lead to
improved model performance. Also, it may lead to a more uniform distribution of
candidates over a set of similar jobs. We also consider the literature from the
perspective of algorithm fairness. Here we find that this is rarely discussed
in the literature, and if it is discussed, many authors wrongly assume that
removing the discriminatory feature would be sufficient. With respect to the
type of models used in JRS, authors frequently label their method as `hybrid'.
Unfortunately, they thereby obscure what these methods entail. Using existing
recommender taxonomies, we split this large class of hybrids into subcategories
that are easier to analyse. We further find that data availability, and in
particular the availability of click data, has a large impact on the choice of
method and validation. Last, although the generalizability of JRS across
different datasets is infrequently considered, results suggest that error
scores may vary across these datasets.",208,12,1345,43.83
2225,postmodern literature,"Systematic literature reviews play a vital role in identifying the best
available evidence for health and social care policy. The resources required to
produce systematic reviews can be significant, and a key to the success of any
review is the search strategy used to identify relevant literature. However,
the methods used to construct search strategies can be complex, time consuming,
resource intensive and error prone. In this review, we examine the state of the
art in resolving complex structured information needs, focusing primarily on
the healthcare context. We analyse the literature to identify key challenges
and issues and explore appropriate solutions and workarounds. From this
analysis we propose a way forward to facilitate trust and transparency and to
aid explainability, reproducibility and replicability through a set of key
design principles for tools to support the development of search strategies in
systematic literature reviews.",143,7,956,30.4
2226,postmodern literature,"Scientific writing builds upon already published papers. Manual
identification of publications to read, cite or consider as related papers
relies on a researcher's ability to identify fitting keywords or initial papers
from which a literature search can be started. The rapidly increasing amount of
papers has called for automatic measures to find the desired relevant
publications, so-called paper recommendation systems.
  As the number of publications increases so does the amount of paper
recommendation systems. Former literature reviews focused on discussing the
general landscape of approaches throughout the years and highlight the main
directions. We refrain from this perspective, instead we only consider a
comparatively small time frame but analyse it fully.
  In this literature review we discuss used methods, datasets, evaluations and
open challenges encountered in all works first released between January 2019
and October 2021. The goal of this survey is to provide a comprehensive and
complete overview of current paper recommendation systems.",154,9,1061,26.51
2227,postmodern literature,"Nowadays, the interest in code-mixing has become ubiquitous in Natural
Language Processing (NLP); however, not much attention has been given to
address this phenomenon for Speech Translation (ST) task. This can be solely
attributed to the lack of code-mixed ST task labelled data. Thus, we introduce
Prabhupadavani, which is a multilingual code-mixed ST dataset for 25 languages.
It is multi-domain, covers ten language families, containing 94 hours of speech
by 130+ speakers, manually aligned with corresponding text in the target
language. The Prabhupadavani is about Vedic culture and heritage from Indic
literature, where code-switching in the case of quotation from literature is
important in the context of humanities teaching. To the best of our knowledge,
Prabhupadvani is the first multi-lingual code-mixed ST dataset available in the
ST literature. This data also can be used for a code-mixed machine translation
task. All the dataset can be accessed at https://github.com/frozentoad9/CMST.",148,10,1001,44.24
2228,postmodern literature,"A good amount of research has explored the use of wearables for educational
or learning purposes. We have now reached a point when much literature can be
found on that topic, but few attempts have been made to make sense of that
literature from a holistic perspective. This paper presents a systematic review
of the literature on wearables for learning. Literature was sourced from
conferences and journals pertaining to technology and education, and through an
ad hoc search. Our review focuses on identifying the ways that wearables have
been used to support learning and provides perspectives on that issue from a
historical dimension, and with regards to the types of wearables used, the
populations targeted, and the settings addressed. Seven different ways of how
wearables have been used to support learning were identified. We propose a
framework identifying five main components that have been addressed in existing
research on how wearables can support learning and present our interpretations
of unaddressed research directions based on our review results.",167,8,1067,47.22
2229,postmodern literature,"This paper proposes a novel taxonomy of coordination strategies for
distributed energy resources at the edge of the electricity grid, based on a
systematic analysis of key literature trends. The coordination of distributed
energy resources such as decentralised generation and flexibility sources is
critical for decarbonising electricity and achieving climate goals. The
literature on the topic is growing exponentially; however, there is ambiguity
in the terminology used to date. We seek to resolve this lack of clarity by
synthesising the categories of coordination strategies in a novel exhaustive,
mutually exclusive taxonomy based on agency, information and game type. The
relevance of these concepts in the literature is illustrated through a
systematic literature review of 84,741 publications using a structured topic
search query. Then 93 selected coordination strategies are analysed in more
detail and mapped onto this framework. Clarity on structural assumptions is key
for selecting appropriate coordination strategies for differing contexts within
energy systems. We argue that a plurality of complementary strategies is needed
to coordinate energy systems' different components and achieve deep
decarbonisation.",174,9,1228,7.05
2230,postmodern literature,"Project Management anti-patterns are well-documented in the
software-engineering literature, and studying them allows understanding their
impacts on teams and projects. The video game development industry is known for
its mismanagement practices, and therefore applying this knowledge would help
improving game developers' productivity and well-being. In this paper, we map
project management anti-patterns to anti-patterns reported by game developers
in the gray literature. We read 440 postmortems problems, identified
anti-pattern candidates, and related them with definitions from the
software-engineering literature. We discovered that most anti-pattern
candidates could be mapped to anti-patterns in the software-engineering
literature, except for Feature Creep, Feature Cuts, Working on Multiple
Projects, and Absent or Inadequate Tools. We discussed the impact of the
unmapped candidates on the development process while also drawing a parallel
between video games and traditional software development. Future works include
validating the definitions of the candidates via survey with practitioners and
also considering development anti-patterns.",151,8,1154,15.71
2231,postmodern literature,"Engendering trust in technically acceptable and psychologically embraceable
systems requires domain-specific research to capture unique characteristics of
the field of application. The architecture, engineering, and construction (AEC)
research community has been recently harnessing advanced solutions offered by
artificial intelligence (AI) to improve project workflows. Despite the unique
characteristics of work, workers, and workplaces in the AEC industry, the
concept of trust in AI has received very little attention in the literature.
This paper presents a comprehensive analysis of the academic literature in two
main areas of trust in AI and AI in the AEC, to explore the interplay between
AEC projects unique aspects and the sociotechnical concepts that lead to trust
in AI. A total of 490 peer-reviewed scholarly articles are analyzed in this
study. The main constituents of human trust in AI are identified from the
literature and are characterized within the AEC project types, processes, and
technologies.",149,7,1019,29.38
2232,postmodern literature,"Traditionally, theory and practice of Cognitive Control are linked via
literature reviews by human domain experts. This approach, however, is
inadequate to track the ever-growing literature. It may also be biased, and
yield redundancies and confusion.
  Here we present an alternative approach. We performed automated text analyses
on a large body of scientific texts to create a joint representation of tasks
and constructs. More specifically, 385,705 scientific abstracts were first
mapped into an embedding space using a transformers-based language model.
Document embeddings were then used to identify a task-construct graph embedding
that grounds constructs on tasks and supports nuanced meaning of the constructs
by taking advantage of constrained random walks in the graph.
  This joint task-construct graph embedding, can be queried to generate task
batteries targeting specific constructs, may reveal knowledge gaps in the
literature, and inspire new tasks and novel hypotheses.",142,9,987,36.49
2233,postmodern literature,"We investigate a prototype application for machine-readable literature. The
program is called ""pyDataRecognition"" and serves as an example of a data-driven
literature search, where the literature search query is an experimental
data-set provided by the user. The user uploads a powder pattern together with
the radiation wavelength. The program compares the user data to a database of
existing powder patterns associated with published papers and produces a rank
ordered according to their similarity score. The program returns the digital
object identifier (doi) and full reference of top ranked papers together with a
stack plot of the user data alongside the top five database entries. The paper
describes the approach and explores successes and challenges.",114,7,760,35.27
2234,postmodern literature,"Quality aspects such as ethics, fairness, and transparency have been proven
to be essential for trustworthy software systems. Explainability has been
identified not only as a means to achieve all these three aspects in systems,
but also as a way to foster users' sentiments of trust. Despite this, research
has only marginally focused on the activities and practices to develop
explainable systems. To close this gap, we recommend six core activities and
associated practices for the development of explainable systems based on the
results of a literature review and an interview study. First, we identified and
summarized activities and corresponding practices in the literature. To
complement these findings, we conducted interviews with 19 industry
professionals who provided recommendations for the development process of
explainable systems and reviewed the activities and practices based on their
expertise and knowledge. We compared and combined the findings of the
interviews and the literature review to recommend the activities and assess
their applicability in industry. Our findings demonstrate that the activities
and practices are not only feasible, but can also be integrated in different
development processes.",181,9,1226,31.62
2235,postmodern literature,"Countless traffic accidents often occur because of the inattention of the
drivers. Many factors can contribute to distractions while driving, since
objects or events to physiological conditions, as drowsiness and fatigue, do
not allow the driver to stay attentive. The technological progress allowed the
development and application of many solutions to detect the attention in real
situations, promoting the interest of the scientific community in these last
years. Commonly, these solutions identify the lack of attention and alert the
driver, in order to help her/him to recover the attention, avoiding serious
accidents and preserving lives. Our work presents a Systematic Literature
Review (SLR) of the methods and criteria used to detect attention of drivers at
the wheel, focusing on those methods based on images. As results, 50 studies
were selected from the literature on drivers' attention detection, in which 22
contain solutions in the desired context. The results of SLR can be used as a
resource in the preparation of new research projects in drivers' attention
detection.",167,8,1086,30.3
2236,postmodern literature,"We review the literature on the nature of quality assurance in the context of
comnplex systems developed using iterative and incremental approaches.",22,2,148,6.84
2237,postmodern literature,"We discuss some easy statements dealing with linear inhomogeneous Diophantine
approximation. Surprisingly, we did not find some of them in the literature.",22,3,154,34.93
2238,postmodern literature,"Despite potential benefits in Software Engineering (SE), adoption of software
modelling in industry is low. Technical issues such as tool support have gained
significant research before, but individual guidance and training have received
little attention. As a first step towards providing the necessary guidance in
modelling, we conduct a systematic literature review (SLR) to explore the
current state of the art. We searched academic literature for modelling
guidance, and selected 25 papers for full-text screening through three rounds
of selection. We find research on modelling guidance to be fragmented, with
inconsistent usage of terminology, and a lack of empirical validation or
supporting evidence. We outline the different dimensions commonly used to
provide guidance on software modelling. Additionally, we provide definitions of
the three terms modelling method, style, and guideline as current literature
lacks a well-defined distinction between them. These definitions can help
distinguishing between important concepts and provide precise modelling
guidance.",151,9,1075,26.91
2239,postmodern literature,"The Journal of Economic Literature codes classification system (JEL)
published by the American Economic Association (AEA) is the de facto standard
classification system for research literature in economics. The JEL
classification system is used to classify articles, dissertations, books, book
reviews, and working papers in EconLit, a database maintained by the AEA. Over
time, it has evolved and extended to a system with over 850 subclasses. This
paper reviews the history and development of the JEL classification system,
describes the current version, and provides a selective overview of its uses
and applications in research. The JEL codes classification system has been
adopted by several publishers, and their instructions are reviewed. There are
interesting avenues for future research as the JEL classification system has
been surprisingly little used in existing bibliometric and scientometric
research as well as in library classification systems.",140,7,960,22.45
2240,postmodern literature,"A comprehensive literature review has always been an essential first step of
every meaningful research. In recent years, however, the availability of a vast
amount of information in both open-access and subscription-based literature in
every field has made it difficult, if not impossible, to be certain about the
comprehensiveness of one's survey. This subsequently can lead to reviewers'
questioning of the novelties of the research directions proposed, regardless of
the quality of the actual work presented. In this situation, statistics derived
from the published literature data can provide valuable quantitative and visual
information about research trends, knowledge gaps, and research networks and
hubs in different fields. Our tool provides an automatic and rapid way of
generating insight for systematic reviews in any research area.",124,6,844,29.38
2241,postmodern literature,"Pain is a significant public health problem as the number of individuals with
a history of pain globally keeps growing. In response, many synergistic
research areas have been coming together to address pain-related issues. This
work conducts a review and analysis of a vast body of pain-related literature
using the keyword co-occurrence network (KCN) methodology. In this method, a
set of KCNs is constructed by treating keywords as nodes and the co-occurrence
of keywords as links between the nodes. Since keywords represent the knowledge
components of research articles, analysis of KCNs will reveal the knowledge
structure and research trends in the literature. This study extracted and
analyzed keywords from 264,560 pain-related research articles indexed in IEEE,
PubMed, Engineering Village, and Web of Science published between 2002 and
2021. We observed rapid growth in pain literature in the last two decades: the
number of articles has grown nearly threefold, and the number of keywords has
grown by a factor of 7. We identified emerging and declining research trends in
sensors/methods, biomedical, and treatment tracks. We also extracted the most
frequently co-occurring keyword pairs and clusters to help researchers
recognize the synergies among different pain-related topics.",194,10,1291,41.09
2242,postmodern literature,"It is essential to discuss the role, difficulties, and opportunities
concerning people of different gender in the field of software engineering
research, education, and industry. Although some literature reviews address
software engineering and gender, it is still unclear how research and practices
in Asia exist for handling gender aspects in software development and
engineering. We conducted a systematic literature review to grasp the
comprehensive view of gender research and practices in Asia. We analyzed the 32
identified papers concerning countries and publication years among 463
publications. Researchers and practitioners from various organizations actively
work on gender research and practices in some countries, including China,
India, and Turkey. We identified topics and classified them into seven
categories varying from personal mental health and team building to
organization. Future research directions include investigating the synergy
between (regional) gender aspects and cultural concerns and considering
possible contributions and dependency among different topics to have a solid
foundation for accelerating further research and getting actionable practices.",162,8,1186,14.19
2243,postmodern literature,"Information Extraction from scientific literature can be challenging due to
the highly specialised nature of such text. We describe our entity recognition
methods developed as part of the DEAL (Detecting Entities in the Astrophysics
Literature) shared task. The aim of the task is to build a system that can
identify Named Entities in a dataset composed by scholarly articles from
astrophysics literature. We planned our participation such that it enables us
to conduct an empirical comparison between word-based tagging and span-based
classification methods. When evaluated on two hidden test sets provided by the
organizer, our best-performing submission achieved $F_1$ scores of 0.8307
(validation phase) and 0.7990 (testing phase).",108,8,735,38.92
2244,postmodern literature,"Today, software systems have a significant role in various domains among
which are healthcare, entertainment, transport and logistics, and many more. It
is only natural that with this increasing dependency on software, the number of
software systems increases. Additionally, these systems become more and more
complex. All this leads to a rise in the number of software faults also known
as bugs. As a result, the ability to locate the source of a bug (e.g. a file or
a commit) is vital for the development and maintenance of efficient software
solutions. Bug localization refers to the automated process of discovering
files that contain bugs, based on a bug report. This research project aims to
make a literature review on different techniques for bug localization. This
study distinguishes itself from other surveys and literature reviews [1] in one
significant way. The focus of the work is on identifying, categorizing and
analyzing existing bug localization methods and tools which were evaluated in
an industrial setting. To the best of my knowledge, there are no other works
that prioritise this aspect. Unfortunately, such literature is scarce,
therefore, bug localization techniques evaluated on open source software are
also included.",195,14,1246,46.47
2245,postmodern literature,"The XAI literature is decentralized, both in terminology and in publication
venues, but recent years saw the community converge around keywords that make
it possible to more reliably discover papers automatically. We use keyword
search using the SemanticScholar API and manual curation to collect a
well-formatted and reasonably comprehensive set of 5199 XAI papers, available
at https://github.com/alonjacovi/XAI-Scholar . We use this collection to
clarify and visualize trends about the size and scope of the literature,
citation trends, cross-field trends, and collaboration trends. Overall, XAI is
becoming increasingly multidisciplinary, with relative growth in papers
belonging to increasingly diverse (non-CS) scientific fields, increasing
cross-field collaborative authorship, increasing cross-field citation activity.
The collection can additionally be used as a paper discovery engine, by
retrieving XAI literature which is cited according to specific constraints (for
example, papers that are influential outside of their field, or influential to
non-XAI research).",145,7,1076,8.4
2246,postmodern literature,"Although backdoor learning is an active research topic in the NLP domain, the
literature lacks studies that systematically categorize and summarize backdoor
attacks and defenses. To bridge the gap, we present a comprehensive and
unifying study of backdoor learning for NLP by summarizing the literature in a
systematic manner. We first present and motivate the importance of backdoor
learning for building robust NLP systems. Next, we provide a thorough account
of backdoor attack techniques, their applications, defenses against backdoor
attacks, and various mitigation techniques to remove backdoor attacks. We then
provide a detailed review and analysis of evaluation metrics, benchmark
datasets, threat models, and challenges related to backdoor learning in NLP.
Ultimately, our work aims to crystallize and contextualize the landscape of
existing literature in backdoor learning for the text domain and motivate
further research in the field. To this end, we identify troubling gaps in the
literature and offer insights and ideas into open challenges and future
research directions. Finally, we provide a GitHub repository with a list of
backdoor learning papers that will be continuously updated at
https://github.com/marwanomar1/Backdoor-Learning-for-NLP.",180,10,1262,31.72
2247,postmodern literature,"This article conducts a literature review on the topic of monetary policy in
developing countries and focuses on the effectiveness of monetary policy in
promoting economic growth and the relationship between monetary policy and
economic growth. The literature review finds that the activities of central
banks in developing countries are often overlooked by economic models, but
recent studies have shown that there are many factors that can affect the
effectiveness of monetary policy in these countries. These factors include the
profitability of central banks and monetary unions, the independence of central
banks in their operations, and lags, rigidities, and disequilibrium analysis.
The literature review also finds that studies on the topic have produced mixed
results, with some studies finding that monetary policy has a limited or
non-existent impact on economic growth and others finding that it plays a
crucial role. The article aims to provide a comprehensive understanding of the
current state of research in this field and to identify areas for future study.",164,6,1074,21.26
2248,postmodern literature,"Computer vision applications in transportation logistics and warehousing have
a huge potential for process automation. We present a structured literature
review on research in the field to help leverage this potential. The literature
is categorized w.r.t. the application, i.e. the task it tackles and w.r.t. the
computer vision techniques that are used. Regarding applications, we subdivide
the literature in two areas: Monitoring, i.e. observing and retrieving relevant
information from the environment, and manipulation, where approaches are used
to analyze and interact with the environment. Additionally, we point out
directions for future research and link to recent developments in computer
vision that are suitable for application in logistics. Finally, we present an
overview of existing datasets and industrial solutions. The results of our
analysis are also available online at https://a-nau.github.io/cv-in-logistics.",129,20,929,34.22
2249,postmodern literature,"In this note, we uncover three connections between the metric distortion
problem and voting methods and axioms from the social choice literature.",22,2,145,40.69
2250,postmodern literature,"Edge-to-cloud computing is an emerging paradigm for distributing
computational tasks between edge devices and cloud resources. Different
approaches for orchestration, offloading, and many more purposes have been
introduced in research. However, it is still not clear what has been
implemented in the industry. This work aims to merge this gap by mapping the
existing knowledge on edge-to-cloud tools by providing an overview of the
current state of research in this area and identifying research gaps and
challenges. For this purpose, we conducted a Multivocal Literature Review (MLR)
by analyzing 40 tools from 1073 primary studies (220 PS from the white
literature and 853 PS from the gray literature). We categorized the tools based
on their characteristics and targeted environments. Overall, this systematic
mapping study provides a comprehensive overview of edge-to-cloud tools and
highlights several opportunities for researchers and practitioners for future
research in this area.",145,8,988,33.54
2251,postmodern literature,"This review examines the scientific articles of the last decade, approaching
the subject through the methodology of the scoping literature review. Starting
with the Boolean search global citizens AND education AND (international
business OR international business school) in the ScienceDirect, Emerald, and
Scopus databases, the review resulted in only scientific journal articles,
strictly targeted at tertiary education ONLY of international business schools
and ONLY in those articles that study global citizenship. For reasons of
up-to-date knowledge, the present literature was content with the final decade.
A total of 13 articles are recorded as a result of the aforementioned Boolean
search from a total of 216 articles identified in the first phase of the
search. The results will help the researchers to acquire the required knowledge
base for their research, the academics to incorporate new methods in their
teaching and the approach of their students, and the policymakers to adapt the
schools curricula according to the data from the articles present in the
literature review.",164,6,1090,21.26
2252,postmodern literature,"Economic Complexity (EC) methods have gained increasing popularity across
fields and disciplines. In particular, the EC toolbox has proved particularly
promising in the study of complex and interrelated phenomena, such as the
transition towards a greener economy. Using the EC approach, scholars have been
investigating the relationship between EC and sustainability, proposing to
identify the distinguishing characteristics of green products and to assess the
readiness of productive and technological structures for the sustainability
transition. This article proposes to review and summarize the data, methods,
and empirical literature that are relevant to the study of the sustainability
transition from an EC perspective. We review three distinct but connected
blocks of literature on EC and environmental sustainability. First, we survey
the evidence linking measures of EC to indicators related to environmental
sustainability. Second, we review articles that strive to assess the green
competitiveness of productive systems. Third, we examine evidence on green
technological development and its connection to non-green knowledge bases.
Finally, we summarize the findings for each block and identify avenues for
further research in this recent and growing body of empirical literature.",182,10,1292,17.13
2253,postmodern literature,"Keeping up with research and finding related work is still a time-consuming
task for academics. Researchers sift through thousands of studies to identify a
few relevant ones. Automation techniques can help by increasing the efficiency
and effectiveness of this task. To this end, we developed CRUISE-Screening, a
web-based application for conducting living literature reviews - a type of
literature review that is continuously updated to reflect the latest research
in a particular field. CRUISE-Screening is connected to several search engines
via an API, which allows for updating the search results periodically.
Moreover, it can facilitate the process of screening for relevant publications
by using text classification and question answering models. CRUISE-Screening
can be used both by researchers conducting literature reviews and by those
working on automating the citation screening process to validate their
algorithms. The application is open-source:
https://github.com/ProjectDoSSIER/cruise-screening, and a demo is available
under this URL: https://citation-screening.ec.tuwien.ac.at. We discuss the
limitations of our tool in Appendix A.",158,15,1151,30.16
2254,postmodern literature,"The increasing number of scientific publications in acoustics, in general,
presents difficulties in conducting traditional literature surveys. This work
explores the use of a generative pre-trained transformer (GPT) model to
automate a literature survey of 116 articles on data-driven speech enhancement
methods. The main objective is to evaluate the capabilities and limitations of
the model in providing accurate responses to specific queries about the papers
selected from a reference human-based survey. While we see great potential to
automate literature surveys in acoustics, improvements are needed to address
technical questions more clearly and accurately.",93,5,665,13.99
2255,postmodern literature,"The ACL Anthology is an online repository that serves as a comprehensive
collection of publications in the field of natural language processing (NLP)
and computational linguistics (CL). This paper presents a tool called ``ACL
Anthology Helper''. It automates the process of parsing and downloading papers
along with their meta-information, which are then stored in a local MySQL
database. This allows for efficient management of the local papers using a wide
range of operations, including ""where,"" ""group,"" ""order,"" and more. By
providing over 20 operations, this tool significantly enhances the retrieval of
literature based on specific conditions. Notably, this tool has been
successfully utilised in writing a survey paper (Tang et al.,2022a). By
introducing the ACL Anthology Helper, we aim to enhance researchers' ability to
effectively access and organise literature from the ACL Anthology. This tool
offers a convenient solution for researchers seeking to explore the ACL
Anthology's vast collection of publications while allowing for more targeted
and efficient literature retrieval.",160,10,1092,34.26
2256,postmodern literature,"Purpose: Global adoption of the internet and mobile usage results in a huge
variation in the cultural backgrounds of consumers who generate and consume
electronic word-of-mouth (eWOM). Unsurprisingly, a research trend on
cross-cultural eWOM has emerged. However, there has not been an attempt to
synthesize this research topic. This paper aims to bridge this gap.
  Methodology: This research paper conducts a systematic literature review of
the current research findings on cross-cultural eWOM. Journal articles
published from 2006 to 2021 are included. This study then presents the key
issues in the extant literature and suggests potential future research.
  Findings: The findings show that there has been an upward trend in the number
of publications on cross-cultural eWOM since the early 2010s, with a relatively
steeper increase toward 2020. The findings also synthesize cross-cultural eWOM
research into four elements and suggest potential future research avenues.
  Value: To the best of the authors' knowledge, there is currently no
exhaustive/integrated review of cross-cultural eWOM research. This research
fills the need to summarize the current state of cross-cultural eWOM literature
and identifies research questions to be addressed in the future.",185,12,1264,45.96
2257,postmodern literature,"Academic researchers face challenges keeping up with exponentially growing
published findings in their field. Performing comprehensive literature reviews
to synthesize knowledge is time-consuming and labor-intensive using manual
approaches. Recent advances in artificial intelligence provide promising
solutions, yet many require coding expertise, limiting accessibility.
KNIMEZoBot represents an innovative integration of Zotero, OpenAI, and the
KNIME visual programming platform to automate literature review tasks for users
with no coding experience. By leveraging KNIME's intuitive graphical interface,
researchers can create workflows to search their Zotero libraries and utilize
OpenAI models to extract key information without coding. Users simply provide
API keys and configure settings through a user-friendly interface in a locally
stored copy of the workflow. KNIMEZoBot then allows asking natural language
questions via a chatbot and retrieves relevant passages from papers to generate
synthesized answers. This system has significant potential to expedite
literature reviews for researchers unfamiliar with coding by automating
retrieval and analysis of publications in personal Zotero libraries. KNIMEZoBot
demonstrates how thoughtfully designed AI tools can expand accessibility and
accelerate knowledge building across diverse research domains.",176,10,1360,9.28
2258,postmodern literature,"Systematic literature reviews (SLRs) play an essential role in summarising,
synthesising and validating scientific evidence. In recent years, there has
been a growing interest in using machine learning techniques to automate the
identification of relevant studies for SLRs. However, the lack of standardised
evaluation datasets makes comparing the performance of such automated
literature screening systems difficult. In this paper, we analyse the citation
screening evaluation datasets, revealing that many of the available datasets
are either too small, suffer from data leakage or have limited applicability to
systems treating automated literature screening as a classification task, as
opposed to, for example, a retrieval or question-answering task. To address
these challenges, we introduce CSMeD, a meta-dataset consolidating nine
publicly released collections, providing unified access to 325 SLRs from the
fields of medicine and computer science. CSMeD serves as a comprehensive
resource for training and evaluating the performance of automated citation
screening models. Additionally, we introduce CSMeD-FT, a new dataset designed
explicitly for evaluating the full text publication screening task. To
demonstrate the utility of CSMeD, we conduct experiments and establish
baselines on new datasets.",182,9,1310,22.95
2259,postmodern literature,"The matrix exponential spatial models exhibit similarities to the
conventional spatial autoregressive model in spatial econometrics but offer
analytical, computational, and interpretive advantages. This paper provides a
comprehensive review of the literature on the estimation, inference, and model
selection approaches for the cross-sectional matrix exponential spatial models.
We discuss summary measures for the marginal effects of regressors and detail
the matrix-vector product method for efficient estimation. Our aim is not only
to summarize the main findings from the spatial econometric literature but also
to make them more accessible to applied researchers. Additionally, we
contribute to the literature by introducing some new results. We propose an
M-estimation approach for models with heteroskedastic error terms and
demonstrate that the resulting M-estimator is consistent and has an asymptotic
normal distribution. We also consider some new results for model selection
exercises. In a Monte Carlo study, we examine the finite sample properties of
various estimators from the literature alongside the M-estimator.",157,9,1129,9.28
2260,postmodern literature,"We prove that Ma{\~n}{\'e} generic convex Hamiltonians have only
non-degenerate periodic orbits on a given energy level. This result was stated,
but not proved, in the literature.",27,3,179,32.39
2261,postmodern literature,"Large Language Models (LLMs) generalize well across language tasks, but
suffer from hallucinations and uninterpretability, making it difficult to
assess their accuracy without ground-truth. Retrieval-Augmented Generation
(RAG) models have been proposed to reduce hallucinations and provide provenance
for how an answer was generated. Applying such models to the scientific
literature may enable large-scale, systematic processing of scientific
knowledge. We present PaperQA, a RAG agent for answering questions over the
scientific literature. PaperQA is an agent that performs information retrieval
across full-text scientific articles, assesses the relevance of sources and
passages, and uses RAG to provide answers. Viewing this agent as a question
answering model, we find it exceeds performance of existing LLMs and LLM agents
on current science QA benchmarks. To push the field closer to how humans
perform research on scientific literature, we also introduce LitQA, a more
complex benchmark that requires retrieval and synthesis of information from
full-text scientific papers across the literature. Finally, we demonstrate
PaperQA's matches expert human researchers on LitQA.",165,9,1182,25.19
2262,postmodern literature,"Pilot studies are an essential cornerstone of the design of crowdsourcing
campaigns, yet they are often only mentioned in passing in the scholarly
literature. A lack of details surrounding pilot studies in crowdsourcing
research hinders the replication of studies and the reproduction of findings,
stalling potential scientific advances. We conducted a systematic literature
review on the current state of pilot study reporting at the intersection of
crowdsourcing and HCI research. Our review of ten years of literature included
171 articles published in the proceedings of the Conference on Human
Computation and Crowdsourcing (AAAI HCOMP) and the ACM Digital Library. We
found that pilot studies in crowdsourcing research (i.e., crowd pilot studies)
are often under-reported in the literature. Important details, such as the
number of workers and rewards to workers, are often not reported. On the basis
of our findings, we reflect on the current state of practice and formulate a
set of best practice guidelines for reporting crowd pilot studies in
crowdsourcing research. We also provide implications for the design of
crowdsourcing platforms and make practical suggestions for supporting crowd
pilot study reporting.",183,11,1222,33.95
2263,postmodern literature,"A systematic literature review is a research process that identifies,
evaluates, and interprets all relevant study findings connected to specific
research questions, topics, or phenomena of interest. In this work, a thorough
review of the literature on the issue of the link between module structure and
coding theory was done. A literature search yielded 470 articles from the
Google Scholar, Dimensions, and Science Direct databases. After further article
selection process, 14 articles were chosen to be studied in further depth. The
items retrieved were from the previous ten years, from 2012 to 2022. The PRISMA
analytical approach and bibliometric analysis were employed in this
investigation. A more detailed description of the PRISMA technique and the
significance of the bibliometric analysis is provided. The findings of this
study are presented in the form of brief summaries of the 14 articles and
research recommendations. At the end of the study, recommendations for future
development of the code structure utilized in the articles that are further
investigated are made.",166,10,1086,35.88
2264,postmodern literature,"The intricate relationship between genetic variation and human diseases has
been a focal point of medical research, evidenced by the identification of risk
genes regarding specific diseases. The advent of advanced genome sequencing
techniques has significantly improved the efficiency and cost-effectiveness of
detecting these genetic markers, playing a crucial role in disease diagnosis
and forming the basis for clinical decision-making and early risk assessment.
To overcome the limitations of existing databases that record disease-gene
associations from existing literature, which often lack real-time updates, we
propose a novel framework employing Large Language Models (LLMs) for the
discovery of diseases associated with specific genes. This framework aims to
automate the labor-intensive process of sifting through medical literature for
evidence linking genetic variations to diseases, thereby enhancing the
efficiency of disease identification. Our approach involves using LLMs to
conduct literature searches, summarize relevant findings, and pinpoint diseases
related to specific genes. This paper details the development and application
of our LLM-powered framework, demonstrating its potential in streamlining the
complex process of literature retrieval and summarization to identify diseases
associated with specific genetic variations.",180,7,1352,-1.28
2265,postmodern literature,"These days, software development and security go hand in hand. Numerous
techniques and strategies are discussed in the literature that can be applied
to guarantee the incorporation of security into the software development
process. In this paper the main ideas of secure software development that have
been discussed in the literature are outlined. Next, a dataset on
implementation in practice is gathered through a qualitative interview research
involving 20 companies. Trends and correlations in this dataset are found and
contrasted with theoretical ideas from the literature. The results show that
the organizations that were polled are placing an increasing focus on security.
Although the techniques covered in the literature are being used in the real
world, they are frequently not fully integrated into formal, standardized
processes. The insights gained from our research lay the groundwork for future
research, which can delve deeper into specific elements of these methods to
enhance our understanding of their application in real-world scenarios.",158,9,1060,34.46
2266,postmodern literature,"This manuscript presents a comprehensive review of the use of Artificial
Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous
and organised methodology that assesses and integrates previous research on a
given topic. Numerous tools have been developed to assist and partially
automate the SLR process. The increasing role of AI in this field shows great
potential in providing more effective support for researchers, moving towards
the semi-automatic creation of literature reviews. Our study focuses on how AI
techniques are applied in the semi-automation of SLRs, specifically in the
screening and extraction phases. We examine 21 leading SLR tools using a
framework that combines 23 traditional features with 11 AI features. We also
analyse 11 recent tools that leverage large language models for searching the
literature and assisting academic writing. Finally, the paper discusses current
trends in the field, outlines key research challenges, and suggests directions
for future research.",152,9,1019,35.27
2267,postmodern literature,"The escalating volume of academic literature presents a formidable challenge
in staying updated with the newest research developments. Addressing this, this
study introduces a pioneering AI-based tool, configured specifically to
streamline the efficiency of the article selection phase in Systematic
Literature Reviews (SLRs). Utilizing the robust capabilities of OpenAI's GPT-4
Assistant API, the tool successfully homogenizes the article selection process
across a broad array of academic disciplines. Implemented through a tripartite
approach consisting of data preparation, AI-mediated article assessment, and
structured result presentation, this tool significantly accelerates the
time-consuming task of literature reviews. Importantly, this tool could be
highly beneficial in fields such as management and economics, where the SLR
process involves substantial human judgment. The adoption of a standard GPT
model can substantially reduce potential biases and enhance the speed and
precision of the SLR selection phase. This not only amplifies researcher
productivity and accuracy but also denotes a considerable stride forward in the
way academic research is conducted amidst the surging body of scholarly
publications.",167,8,1225,13.38
2268,postmodern literature,"Decentralized Autonomous Organizations (DAOs) have seen exponential growth
and interest due to their potential to redefine organizational structure and
governance. Despite this, there is a discrepancy between the ideals of autonomy
and decentralization and the actual experiences of DAO stakeholders. The
Information Systems (IS) literature has yet to fully explore whether DAOs are
the optimal organizational choice. Addressing this gap, our research asks, ""Is
a DAO suitable for your organizational needs?"" We derive a gated
decision-making framework through a thematic review of the academic and grey
literature on DAOs. Through five scenarios, the framework critically emphasizes
the gaps between DAOs' theoretical capabilities and practical challenges. Our
findings contribute to the IS discourse on blockchain technologies, with some
ancillary contributions to the IS literature on organizational management and
practitioner literature.",129,7,942,18.96
2269,postmodern literature,"In developing countries, several key sectors, including education, finance,
agriculture, and healthcare, mainly deliver their services via mobile app
technology on handheld devices. As a result, mobile app security has emerged as
a paramount issue in developing countries. In this paper, we investigate the
state of research on mobile app security, focusing on developing countries.
More specifically, we performed a systematic literature review exploring the
research directions taken by existing works, the different security concerns
addressed, and the techniques used by researchers to highlight or address app
security issues. Our main findings are: (1) the literature includes only a few
studies on mobile app security in the context of developing countries ; (2)
among the different security concerns that researchers study, vulnerability
detection appears to be the leading research topic; (3) FinTech apps are
revealed as the main target in the relevant literature. Overall, our work
highlights that there is largely room for developing further specialized
techniques addressing mobile app security in the context of developing
countries.",167,7,1147,17.98
2270,postmodern literature,"What can we learn from the classics of Finnish literature by using
computational emotion analysis? This article tries to answer this question by
examining how computational methods of sentiment analysis can be used in the
study of literary works in conjunction with a qualitative or more 'traditional'
approach to literature and affect. We present and develop a simple but robust
computational approach of affect analysis that uses a carefully curated emotion
lexicon adapted to Finnish turn-of-the-century literary texts combined with
word embeddings to map out the semantic emotional spaces of seminal works of
Finnish literature. We focus our qualitative analysis on selected case studies:
four works by Juhani Aho, Minna Canth, Maria Jotuni, and F. E. Sillanp\""a\""a,
but provide emotion arcs for a total of 975 Finnish novels.
  We argue that a computational analysis of a text's lexicon can be valuable in
evaluating the large distribution of the emotional valence in a text and
provide guidelines to help other researchers replicate our findings. We show
that computational approaches have a place in traditional studies on affect in
literature as a support tool for close-reading-based analyses, but also
allowing for large-scale comparison between, for example, genres or national
canons.",198,8,1296,25.83
2271,postmodern literature,"Previous research demonstrates that the interruption of immersive experiences
may lead to a bias in the results of questionnaires. Thus, the traditional way
of presenting questionnaires, paper-based or web-based, may not be compatible
with evaluating VR experiences. Recent research has shown the positive impact
of embedding questionnaires contextually into the virtual environment. However,
a comprehensive overview of the available VR questionnaire solutions is
currently missing. Furthermore, no clear taxonomy exists for these different
solutions in the literature. To address this, we present a literature review of
VR questionnaire user interfaces (UI) following PRISMA guidelines. Our search
returned 1.109 initial results, which were screened for eligibility, resulting
in a corpus of 25 papers. This paper contributes to HCI and games research with
a literature review of embedded questionnaires in VR, discussing the advantages
and disadvantages and introducing a taxonomy of in-VR questionnaire UIs.",142,10,1011,30.06
2272,postmodern literature,"Context: A Multivocal Literature Review (MLR) is a form of a Systematic
Literature Review (SLR) which includes the grey literature (e.g., blog posts
and white papers) in addition to the published (formal) literature (e.g.,
journal and conference papers). MLRs are useful for both researchers and
practitioners since they provide summaries both the state-of-the art and
-practice in a given area. Objective: There are several guidelines to conduct
SLR studies in SE. However, given the facts that several phases of MLRs differ
from those of traditional SLRs, for instance with respect to the search process
and source quality assessment. Therefore, SLR guidelines are only partially
useful for conducting MLR studies. Our goal in this paper is to present
guidelines on how to conduct MLR studies in SE. Method: To develop the MLR
guidelines, we benefit from three inputs: (1) existing SLR guidelines in SE,
(2), a literature survey of MLR guidelines and experience papers in other
fields, and (3) our own experiences in conducting several MLRs in SE. All
derived guidelines are discussed in the context of three examples MLRs as
running examples (two from SE and one MLR from the medical sciences). Results:
The resulting guidelines cover all phases of conducting and reporting MLRs in
SE from the planning phase, over conducting the review to the final reporting
of the review. In particular, we believe that incorporating and adopting a vast
set of recommendations from MLR guidelines and experience papers in other
fields have enabled us to propose a set of guidelines with solid foundations.
Conclusion: Having been developed on the basis of three types of solid
experience and evidence, the provided MLR guidelines support researchers to
effectively and efficiently conduct new MLRs in any area of SE.",288,16,1805,48.94
2273,postmodern literature,"Timely access to accurate scientific literature in the battle with the
ongoing COVID-19 pandemic is critical. This unprecedented public health risk
has motivated research towards understanding the disease in general,
identifying drugs to treat the disease, developing potential vaccines, etc.
This has given rise to a rapidly growing body of literature that doubles in
number of publications every 20 days as of May 2020. Providing medical
professionals with means to quickly analyze the literature and discover growing
areas of knowledge is necessary for addressing their question and information
needs.
  In this study we analyze the LitCovid collection, 13,369 COVID-19 related
articles found in PubMed as of May 15th, 2020 with the purpose of examining the
landscape of literature and presenting it in a format that facilitates
information navigation and understanding. We do that by applying
state-of-the-art named entity recognition, classification, clustering and other
NLP techniques. By applying NER tools, we capture relevant bioentities (such as
diseases, internal body organs, etc.) and assess the strength of their
relationship with COVID-19 by the extent they are discussed in the corpus. We
also collect a variety of symptoms and co-morbidities discussed in reference to
COVID-19. Our clustering algorithm identifies topics represented by groups of
related terms, and computes clusters corresponding to documents associated with
the topic terms. Among the topics we observe several that persist through the
duration of multiple weeks and have numerous associated documents, as well
several that appear as emerging topics with fewer documents. All the tools and
data are publicly available, and this framework can be applied to any
literature collection. Taken together, these analyses produce a comprehensive,
synthesized view of COVID-19 research to facilitate knowledge discovery from
literature.",280,14,1913,32.73
2274,postmodern literature,"Networks are ubiquitous in science and have become a focal point for
discussion in everyday life. Formal statistical models for the analysis of
network data have emerged as a major topic of interest in diverse areas of
study, and most of these involve a form of graphical representation.
Probability models on graphs date back to 1959. Along with empirical studies in
social psychology and sociology from the 1960s, these early works generated an
active network community and a substantial literature in the 1970s. This effort
moved into the statistical literature in the late 1970s and 1980s, and the past
decade has seen a burgeoning network literature in statistical physics and
computer science. The growth of the World Wide Web and the emergence of online
networking communities such as Facebook, MySpace, and LinkedIn, and a host of
more specialized professional network communities has intensified interest in
the study of networks and network data. Our goal in this review is to provide
the reader with an entry point to this burgeoning literature. We begin with an
overview of the historical development of statistical network modeling and then
we introduce a number of examples that have been studied in the network
literature. Our subsequent discussion focuses on a number of prominent static
and dynamic network models and their interconnections. We emphasize formal
model descriptions, and pay special attention to the interpretation of
parameters and their estimation. We end with a description of some open
problems and challenges for machine learning and statistics.",249,12,1582,31.62
2275,postmodern literature,"As the number of people who use scientific literature databases grows, the
demand for literature retrieval services has been steadily increased. One of
the most popular retrieval services is to find a set of papers similar to the
paper under consideration, which requires a measure that computes similarities
between papers. Scientific literature databases exhibit two interesting
characteristics that are different from general databases. First, the papers
cited by old papers are often not included in the database due to technical and
economic reasons. Second, since a paper references the papers published before
it, few papers cite recently-published papers. These two characteristics cause
all existing similarity measures to fail in at least one of the following
cases: (1) measuring the similarity between old, but similar papers, (2)
measuring the similarity between recent, but similar papers, and (3) measuring
the similarity between two similar papers: one old, the other recent. In this
paper, we propose a new link-based similarity measure called C-Rank, which uses
both in-link and out-link by disregarding the direction of references. In
addition, we discuss the most suitable normalization method for scientific
literature databases and propose an evaluation method for measuring the
accuracy of similarity measures. We have used a database with real-world papers
from DBLP and their reference information crawled from Libra for experiments
and compared the performance of C-Rank with those of existing similarity
measures. Experimental results show that C-Rank achieves a higher accuracy than
existing similarity measures.",241,11,1640,21.63
2276,postmodern literature,"Drug-drug interaction (DDI) is a major cause of morbidity and mortality and a
subject of intense scientific interest. Biomedical literature mining can aid
DDI research by extracting evidence for large numbers of potential interactions
from published literature and clinical databases. Though DDI is investigated in
domains ranging in scale from intracellular biochemistry to human populations,
literature mining has not been used to extract specific types of experimental
evidence, which are reported differently for distinct experimental goals. We
focus on pharmacokinetic evidence for DDI, essential for identifying causal
mechanisms of putative interactions and as input for further pharmacological
and pharmaco-epidemiology investigations. We used manually curated corpora of
PubMed abstracts and annotated sentences to evaluate the efficacy of literature
mining on two tasks: first, identifying PubMed abstracts containing
pharmacokinetic evidence of DDIs; second, extracting sentences containing such
evidence from abstracts. We implemented a text mining pipeline and evaluated it
using several linear classifiers and a variety of feature transforms. The most
important textual features in the abstract and sentence classification tasks
were analyzed. We also investigated the performance benefits of using features
derived from PubMed metadata fields, various publicly available named entity
recognizers, and pharmacokinetic dictionaries. Several classifiers performed
very well in distinguishing relevant and irrelevant abstracts (reaching
F1~=0.93, MCC~=0.74, iAUC~=0.99) and sentences (F1~=0.76, MCC~=0.65,
iAUC~=0.83). We found that word bigram features were important for achieving
optimal classifier performance and that features derived from Medical Subject
Headings (MeSH) terms significantly improved abstract classification. ...",242,20,1845,6.95
2277,postmodern literature,"High Utility Itemset (HUI) mining problem is one of the important problems in
the data mining literature. The problem offers greater flexibility to a
decision maker to incorporate her/his notion of utility into the pattern mining
process. The problem, however, requires the decision maker to choose a minimum
utility threshold value for discovering interesting patterns. This is quite
challenging due to the disparate itemset characteristics and their utility
distributions. In order to address this issue, Top-K High Utility Itemset
(THUI) mining problem was introduced in the literature. THUI mining problem is
primarily a variant of the HUI mining problem that allows a decision maker to
specify the desired number of HUIs rather than the minimum utility threshold
value. Several algorithms have been introduced in the literature to efficiently
mine top-k HUIs. This paper systematically analyses the top-k HUI mining
methods in the literature, describes the methods, and performs a comparative
analysis. The data structures, threshold raising strategies, and pruning
strategies adopted for efficient top-k HUI mining are also presented and
analysed. Furthermore, the paper reviews several extensions of the top-k HUI
mining problem such as data stream mining, sequential pattern mining and
on-shelf utility mining. The paper is likely to be useful for researchers to
examine the key methods in top-k HUI mining, evaluate the gaps in literature,
explore new research opportunities and enhance the state-of-the-art in high
utility pattern mining.",231,12,1548,33.24
2278,postmodern literature,"According to the latest World Economic Forum report, about 70% of the African
population depends on agriculture for their livelihood. This makes agriculture
a critical sector within the African continent. Nonetheless, agricultural
productivity is low and food insecurity is still a challenge. This has in
recent years led to several initiatives in using ICT (Information Communication
Technology) to improve agriculture productivity. This study aims to explore ICT
innovations in the agriculture sector of Africa. To achieve this, we conducted
a SLR (Systematic Literature Review) of the literature published since 2010.
Our search yielded 779 papers, of which 23 papers were selected for a detailed
analysis following a detailed exclusion and quality assessment criteria. The
analysis of the selected papers shows that the main ICT technologies adopted
are text and voice-based services targeting mobile phones. The analysis also
shows that radios are still widely used in disseminating agriculture
information to rural farmers, while computers are mainly used by researchers.
Though the mobile-based services aimed at improving access to accurate and
timely agriculture information, the literature reviews indicate that the
adoption of the services is constrained by poor technological infrastructure,
inappropriate ICT policies and low capacity levels of users, especially
farmers, to using the technologies. The findings further indicate that
literature on an appropriate theoretical framework for guiding ICT innovations
is lacking.",220,12,1537,25.8
2279,postmodern literature,"Business process modelling languages typically enable the representation of
business process models by employing (graphical) symbols. These symbols can
vary depending upon the verbosity of the language, the modeling paradigm, the
focus of the language, and so on. To make explicit the different constructs and
rules employed by a specific language as well as bridge the gap across
different languages, meta-models have been proposed in literature. These
meta-models are a crucial source of knowledge on what state-of-the-art
literature considers relevant to describe business processes. Moreover, the
rapid growth of techniques and tools that aim at supporting all dimensions of
business processes and not only its control flow perspective, as for instance
data and organisational aspects, makes even more important to have a clear
idea, already at the conceptual level, of the key process constructs. The goal
of this work is to provide the first extensive systematic literature review
(SLR) of business process meta-models. This SLR aims at answering research
questions concerning: (i) the kind of meta-models proposed in literature; (ii)
the recurring constructs they contain; (iii) their purposes; and (iv) their
evaluations. Thirty-six papers were selected and evaluated against four
research questions. The results indicate the existence of a reasonable body of
work conducted in this specific area, but not a full maturity. In particular,
while traditional paradigms towards business process modelling, and aspects
related to the business process control flow seem to be well present, novel
paradigms and aspects related to the organisational, data and goal-oriented
aspects of business processes seem to be still under-investigated.",256,11,1740,28.57
2280,postmodern literature,"Social capital creates a synergy that benefits all members of a community.
This review examines how social capital contributes to the food security of
communities. A systematic literature review, based on Prisma, is designed to
provide a state-of-the-art review on capacity social capital in this realm. The
output of this method led to finding 39 related articles. Studying these
articles illustrates that social capital improves food security through two
mechanisms of knowledge sharing and product sharing (i.e., sharing food
products). It reveals that social capital through improving the food security
pillars (i.e., food availability, food accessibility, food utilization, and
food system stability) affects food security. In other words, the interaction
among the community members results in sharing food products and information
among community members, which facilitates food availability and access to
food. There are many shreds of evidence in the literature that sharing food and
food products among the community member decreases household food security and
provides healthy nutrition to vulnerable families and improves the food
utilization pillar of food security. It is also disclosed that belonging to the
social networks increases the community members' resilience and decreases the
community's vulnerability that subsequently strengthens the stability of a food
system. This study contributes to the common literature on food security and
social capital by providing a conceptual model based on the literature. In
addition to researchers, policymakers can use this study's findings to provide
solutions to address food insecurity problems.",240,16,1659,27.32
2281,postmodern literature,"Although blockchain-based digital services promise trust, accountability, and
transparency, multiple paradoxes between blockchains and GDPR have been
highlighted in the recent literature. Some of the recent literature also
proposed possible solutions to these paradoxes. This article aims to conduct a
systematic literature review on GDPR compliant blockchains and synthesize the
findings. In particular, the goal was to identify 1) the GDPR articles that
have been explored in prior literature; 2) the relevant research domains that
have been explored, and 3) the research gaps. Our findings synthesized that the
blockchains relevant GDPR articles can be categorized into six major groups,
namely data deletion and modification (Article 16, 17, and 18), protection by
design by default (Article 25), responsibilities of controllers and processors
(Article 24, 26, and 28), consent management (Article 7), data processing
principles and lawfulness (Article 5,6 and 12), and territorial scope (Article
3). We also found seven research domains where GDPR compliant blockchains have
been discussed, which include IoT, financial data, healthcare, personal
identity, online data, information governance, and smart city. From our
analysis, we have identified a few key research gaps and present a future
research direction.",189,8,1317,27.15
2282,postmodern literature,"Like many scientific fields, new chemistry literature has grown at a
staggering pace, with thousands of papers released every month. A large portion
of chemistry literature focuses on new molecules and reactions between
molecules. Most vital information is conveyed through 2-D images of molecules,
representing the underlying molecules or reactions described. In order to
ensure reproducible and machine-readable molecule representations, text-based
molecule descriptors like SMILES and SELFIES were created. These text-based
molecule representations provide molecule generation but are unfortunately
rarely present in published literature. In the absence of molecule descriptors,
the generation of molecule descriptors from the 2-D images present in the
literature is necessary to understand chemistry literature at scale. Successful
methods such as Optical Structure Recognition Application (OSRA), and
ChemSchematicResolver are able to extract the locations of molecules structures
in chemistry papers and infer molecular descriptions and reactions. While
effective, existing systems expect chemists to correct outputs, making them
unsuitable for unsupervised large-scale data mining. Leveraging the task
formulation of image captioning introduced by DECIMER, we introduce IMG2SMI, a
model which leverages Deep Residual Networks for image feature extraction and
an encoder-decoder Transformer layers for molecule description generation.
Unlike previous Neural Network-based systems, IMG2SMI builds around the task of
molecule description generation, which enables IMG2SMI to outperform OSRA-based
systems by 163% in molecule similarity prediction as measured by the molecular
MACCS Fingerprint Tanimoto Similarity. Additionally, to facilitate further
research on this task, we release a new molecule prediction dataset. including
81 million molecules for molecule description generation",249,12,1890,16.52
2283,postmodern literature,"Literature recommendation systems (LRS) assist readers in the discovery of
relevant content from the overwhelming amount of literature available. Despite
the widespread adoption of LRS, there is a lack of research on the
user-perceived recommendation characteristics for fundamentally different
approaches to content-based literature recommendation. To complement existing
quantitative studies on literature recommendation, we present qualitative study
results that report on users' perceptions for two contrasting recommendation
classes: (1) link-based recommendation represented by the Co-Citation Proximity
(CPA) approach, and (2) text-based recommendation represented by Lucene's
MoreLikeThis (MLT) algorithm. The empirical data analyzed in our study with
twenty users and a diverse set of 40 Wikipedia articles indicate a noticeable
difference between text- and link-based recommendation generation approaches
along several key dimensions. The text-based MLT method receives higher
satisfaction ratings in terms of user-perceived similarity of recommended
articles. In contrast, the CPA approach receives higher satisfaction scores in
terms of diversity and serendipity of recommendations. We conclude that users
of literature recommendation systems can benefit most from hybrid approaches
that combine both link- and text-based approaches, where the user's information
needs and preferences should control the weighting for the approaches used. The
optimal weighting of multiple approaches used in a hybrid recommendation system
is highly dependent on a user's shifting needs.",209,9,1582,11.14
2284,postmodern literature,"The Advancing Data Justice Research and Practice (ADJRP) project aims to
widen the lens of current thinking around data justice and to provide
actionable resources that will help policymakers, practitioners, and impacted
communities gain a broader understanding of what equitable, freedom-promoting,
and rights-sustaining data collection, governance, and use should look like in
increasingly dynamic and global data innovation ecosystems. In this integrated
literature review we hope to lay the conceptual groundwork needed to support
this aspiration. The introduction motivates the broadening of data justice that
is undertaken by the literature review which follows. First, we address how
certain limitations of the current study of data justice drive the need for a
re-location of data justice research and practice. We map out the strengths and
shortcomings of the contemporary state of the art and then elaborate on the
challenges faced by our own effort to broaden the data justice perspective in
the decolonial context. The body of the literature review covers seven thematic
areas. For each theme, the ADJRP team has systematically collected and analysed
key texts in order to tell the critical empirical story of how existing social
structures and power dynamics present challenges to data justice and related
justice fields. In each case, this critical empirical story is also
supplemented by the transformational story of how activists, policymakers, and
academics are challenging longstanding structures of inequity to advance social
justice in data innovation ecosystems and adjacent areas of technological
practice.",241,9,1629,24.0
2285,postmodern literature,"In scientific research, the method is an indispensable means to solve
scientific problems and a critical research object. With the advancement of
sciences, many scientific methods are being proposed, modified, and used in
academic literature. The authors describe details of the method in the abstract
and body text, and key entities in academic literature reflecting names of the
method are called method entities. Exploring diverse method entities in a
tremendous amount of academic literature helps scholars understand existing
methods, select the appropriate method for research tasks, and propose new
methods. Furthermore, the evolution of method entities can reveal the
development of a discipline and facilitate knowledge discovery. Therefore, this
article offers a systematic review of methodological and empirical works
focusing on extracting method entities from full-text academic literature and
efforts to build knowledge services using these extracted method entities.
Definitions of key concepts involved in this review were first proposed. Based
on these definitions, we systematically reviewed the approaches and indicators
to extract and evaluate method entities, with a strong focus on the pros and
cons of each approach. We also surveyed how extracted method entities are used
to build new applications. Finally, limitations in existing works as well as
potential next steps were discussed.",205,11,1409,33.75
2286,postmodern literature,"The connection of home electronic devices to the internet allows remote
control of physical devices and involves the collection of large volumes of
data. With the increase in the uptake of Internet-of-Things home devices, it
becomes critical to understand the digital harms of smart homes. We present a
systematic literature review on the security and privacy harms of smart homes.
PRISMA methodology is used to systematically review 63 studies published
between January 2011 and October 2021; and a review of known cases is
undertaken to illustrate the literature review findings with real-world
scenarios. Published literature identifies that smart homes may pose threats to
confidentiality (unwanted release of information), authentication (sensing
information being falsified) and unauthorised access to system controls. Most
existing studies focus on privacy intrusions as a prevalent form of harm
against smart homes. Other types of harms that are less common in the
literature include hacking, malware and DoS attacks. Digital harms, and data
associated with these harms, may vary extensively across smart devices. Most
studies propose technical measures to mitigate digital harms, while fewer
consider social prevention mechanisms. We also identify salient gaps in
research, and argue that these should be addressed in future cross-disciplinary
research initiatives.",200,11,1374,34.26
2287,postmodern literature,"LitCovid (https://www.ncbi.nlm.nih.gov/research/coronavirus/), first launched
in February 2020, is a first-of-its-kind literature hub for tracking up-to-date
published research on COVID-19. The number of articles in LitCovid has
increased from 55,000 to ~300,000 over the past two and half years, with a
consistent growth rate of ~10,000 articles per month. In addition to the rapid
literature growth, the COVID-19 pandemic has evolved dramatically. For
instance, the Omicron variant has now accounted for over 98% of new infections
in the U.S. In response to the continuing evolution of the COVID-19 pandemic,
this article describes significant updates to LitCovid over the last two years.
First, we introduced the Long Covid collection consisting of the articles on
COVID-19 survivors experiencing ongoing multisystemic symptoms, including
respiratory issues, cardiovascular disease, cognitive impairment, and profound
fatigue. Second, we provided new annotations on the latest COVID-19 strains and
vaccines mentioned in the literature. Third, we improved several existing
features with more accurate machine learning algorithms for annotating topics
and classifying articles relevant to COVID-19. LitCovid has been widely used
with millions of accesses by users worldwide on various information needs and
continues to play a critical role in collecting, curating, and standardizing
the latest knowledge on the COVID-19 literature.",200,15,1433,32.02
2288,postmodern literature,"There is a growing interest in understanding the energy and environmental
footprint of digital currencies, specifically in cryptocurrencies such as
Bitcoin and Ethereum. These cryptocurrencies are operated by a geographically
distributed network of computing nodes, making it hard to accurately estimate
their energy consumption.
  Existing studies, both in academia and industry, attempt to model the
cryptocurrencies energy consumption often based on a number of assumptions for
instance about the hardware in use or geographic distribution of the computing
nodes. A number of these studies has already been widely criticized for their
design choices and subsequent over or under-estimation of the energy use.
  In this study, we evaluate the reliability of prior models and estimates by
leveraging existing scientific literature from fields cognizant of blockchain
such as social energy sciences and information systems. We first design a
quality assessment framework based on existing research, we then conduct a
systematic literature review examining scientific and non-academic literature
demonstrating common issues and potential avenues of addressing these issues.
  Our goal with this article is to to advance the field by promoting scientific
rigor in studies focusing on Blockchain's energy footprint. To that end, we
provide a novel set of codes of conduct for the five most widely used research
methodologies: quantitative energy modeling, literature reviews, data analysis
\& statistics, case studies, and experiments. We envision that these codes of
conduct would assist in standardizing the design and assessment of studies
focusing on blockchain-based systems' energy and environmental footprint.",245,10,1713,18.59
2289,postmodern literature,"Objectives: An SLR is presented focusing on text mining based automation of
SLR creation. The present review identifies the objectives of the automation
studies and the aspects of those steps that were automated. In so doing, the
various ML techniques used, challenges, limitations and scope of further
research are explained.
  Methods: Accessible published literature studies that primarily focus on
automation of study selection, study quality assessment, data extraction and
data synthesis portions of SLR. Twenty-nine studies were analyzed.
  Results: This review identifies the objectives of the automation studies,
steps within the study selection, study quality assessment, data extraction and
data synthesis portions that were automated, the various ML techniques used,
challenges, limitations and scope of further research.
  Discussion: We describe uses of NLP/TM techniques to support increased
automation of systematic literature reviews. This area has attracted increase
attention in the last decade due to significant gaps in the applicability of TM
to automate steps in the SLR process. There are significant gaps in the
application of TM and related automation techniques in the areas of data
extraction, monitoring, quality assessment and data synthesis. There is thus a
need for continued progress in this area, and this is expected to ultimately
significantly facilitate the construction of systematic literature reviews.",208,11,1441,24.98
2290,postmodern literature,"Due to the exponential growth of scientific publications on the Web, there is
a pressing need to tag each paper with fine-grained topics so that researchers
can track their interested fields of study rather than drowning in the whole
literature. Scientific literature tagging is beyond a pure multi-label text
classification task because papers on the Web are prevalently accompanied by
metadata information such as venues, authors, and references, which may serve
as additional signals to infer relevant tags. Although there have been studies
making use of metadata in academic paper classification, their focus is often
restricted to one or two scientific fields (e.g., computer science and
biomedicine) and to one specific model. In this work, we systematically study
the effect of metadata on scientific literature tagging across 19 fields. We
select three representative multi-label classifiers (i.e., a bag-of-words
model, a sequence-based model, and a pre-trained language model) and explore
their performance change in scientific literature tagging when metadata are fed
to the classifiers as additional features. We observe some ubiquitous patterns
of metadata's effects across all fields (e.g., venues are consistently
beneficial to paper tagging in almost all cases), as well as some unique
patterns in fields other than computer science and biomedicine, which are not
explored in previous studies.",210,13,1409,30.91
2291,postmodern literature,"Biomedical knowledge is growing in an astounding pace with a majority of this
knowledge is represented as scientific publications. Text mining tools and
methods represents automatic approaches for extracting hidden patterns and
trends from this semi structured and unstructured data. In Biomedical Text
mining, Literature Based Discovery (LBD) is the process of automatically
discovering novel associations between medical terms otherwise mentioned in
disjoint literature sets. LBD approaches proven to be successfully reducing the
discovery time of potential associations that are hidden in the vast amount of
scientific literature. The process focuses on creating concept profiles for
medical terms such as a disease or symptom and connecting it with a drug and
treatment based on the statistical significance of the shared profiles. This
knowledge discovery approach introduced in 1989 still remains as a core task in
text mining. Currently the ABC principle based two approaches namely open
discovery and closed discovery are mostly explored in LBD process. This review
starts with general introduction about text mining followed by biomedical text
mining and introduces various literature resources such as MEDLINE, UMLS, MESH,
and SemMedDB. This is followed by brief introduction of the core ABC principle
and its associated two approaches open discovery and closed discovery in LBD
process. This review also discusses the deep learning applications in LBD by
reviewing the role of transformer models and neural networks based LBD models
and its future aspects. Finally, reviews the key biomedical discoveries
generated through LBD approaches in biomedicine and conclude with the current
limitations and future directions of LBD.",256,12,1735,30.91
2292,postmodern literature,"Artificial intelligence (AI) has acquired notorious relevance in modern
computing as it effectively solves complex tasks traditionally done by humans.
AI provides methods to represent and infer knowledge, efficiently manipulate
texts and learn from vast amount of data. These characteristics are applicable
in many activities that human find laborious or repetitive, as is the case of
the analysis of scientific literature. Manually preparing and writing a
systematic literature review (SLR) takes considerable time and effort, since it
requires planning a strategy, conducting the literature search and analysis,
and reporting the findings. Depending on the area under study, the number of
papers retrieved can be of hundreds or thousands, meaning that filtering those
relevant ones and extracting the key information becomes a costly and
error-prone process. However, some of the involved tasks are repetitive and,
therefore, subject to automation by means of AI. In this paper, we present a
survey of AI techniques proposed in the last 15 years to help researchers
conduct systematic analyses of scientific literature. We describe the tasks
currently supported, the types of algorithms applied, and available tools
proposed in 34 primary studies. This survey also provides a historical
perspective of the evolution of the field and the role that humans can play in
an increasingly automated SLR process.",212,10,1406,30.6
2293,postmodern literature,"Chemical synthesis, which is crucial for advancing material synthesis and
drug discovery, impacts various sectors including environmental science and
healthcare. The rise of technology in chemistry has generated extensive
chemical data, challenging researchers to discern patterns and refine synthesis
processes. Artificial intelligence (AI) helps by analyzing data to optimize
synthesis and increase yields. However, AI faces challenges in processing
literature data due to the unstructured format and diverse writing style of
chemical literature. To overcome these difficulties, we introduce an end-to-end
AI agent framework capable of high-fidelity extraction from extensive chemical
literature. This AI agent employs large language models (LLMs) for prompt
generation and iterative optimization. It functions as a chemistry assistant,
automating data collection and analysis, thereby saving manpower and enhancing
performance. Our framework's efficacy is evaluated using accuracy, recall, and
F1 score of reaction condition data, and we compared our method with human
experts in terms of content correctness and time efficiency. The proposed
approach marks a significant advancement in automating chemical literature
extraction and demonstrates the potential for AI to revolutionize data
management and utilization in chemistry.",180,10,1332,8.88
2294,postmodern literature,"Networks such as the Internet are essential for our connected world. Quantum
computing poses a threat to this heterogeneous infrastructure since it
threatens fundamental security mechanisms. Therefore, a migration to
post-quantum-cryptography (PQC) is necessary for networks and their components.
At the moment, there is little knowledge on how such migrations should be
structured and implemented in practice. Our systematic literature review
addresses migration approaches for IP networks towards PQC. It surveys papers
about the migration process and exemplary real-world software system
migrations. On the process side, we found that terminology, migration steps,
and roles are not defined precisely or consistently across the literature.
Still, we identified four major phases and appropriate substeps which we
matched with also emerging archetypes of roles. In terms of real-world
migrations, we see that reports used several different PQC implementations and
hybrid solutions for migrations of systems belonging to a wide range of system
types. Across all papers we noticed three major challenges for adopters:
missing experience of PQC and a high realization effort, concerns about the
security of the upcoming system, and finally, high complexity. Our findings
indicate that recent standardization efforts already push quantum-safe
networking forward. However, the literature is still not in consensus about
definitions and best practices. Implementations are mostly experimental and not
necessarily practical, leading to an overall chaotic situation. To better grasp
this fast moving field of (applied) research, our systematic literature review
provides a comprehensive overview of its current state and serves as a starting
point for delving into the matter of PQC migration.",256,15,1787,35.98
2295,postmodern literature,"The hypothesis of conscious machines has been debated since the invention of
the notion of artificial intelligence, powered by the assumption that the
computational intelligence achieved by a system is the cause of the emergence
of phenomenal consciousness in that system as an epiphenomenon or as a
consequence of the behavioral or internal complexity of the system surpassing
some threshold. As a consequence, a huge amount of literature exploring the
possibility of machine consciousness and how to implement it on a computer has
been published. Moreover, common folk psychology and transhumanism literature
has fed this hypothesis with the popularity of science fiction literature,
where intelligent robots are usually antropomorphized and hence given
phenomenal consciousness. However, in this work, we argue how these literature
lacks scientific rigour, being impossible to falsify the opposite hypothesis,
and illustrate a list of arguments that show how every approach that the
machine consciousness literature has published depends on philosophical
assumptions that cannot be proven by the scientific method. Concretely, we also
show how phenomenal consciousness is not computable, independently on the
complexity of the algorithm or model, cannot be objectively measured nor
quantitatively defined and it is basically a phenomenon that is subjective and
internal to the observer. Given all those arguments we end the work arguing why
the idea of conscious machines is nowadays a myth of transhumanism and science
fiction culture.",228,7,1539,7.53
2296,postmodern literature,"In the last two decades, several researchers provided snapshots of the
""current"" state and evolution of empirical research in requirements engineering
(RE) through literature reviews. However, these literature reviews were not
sustainable, as none built on or updated previous works due to the
unavailability of the extracted and analyzed data. KG-EmpiRE is a Knowledge
Graph (KG) of empirical research in RE based on scientific data extracted from
currently 680 papers published in the IEEE International Requirements
Engineering Conference (1994-2022). KG-EmpiRE is maintained in the Open
Research Knowledge Graph (ORKG), making all data openly and long-term available
according to the FAIR data principles. Our long-term goal is to constantly
maintain KG-EmpiRE with the research community to synthesize a comprehensive,
up-to-date, and long-term available overview of the state and evolution of
empirical research in RE. Besides KG-EmpiRE, we provide its analysis with all
supplementary materials in a repository. This repository contains all files
with instructions for replicating and (re-)using the analysis locally or via
executable environments and for repeating the research approach. Since its
first release based on 199 papers (2014-2022), KG-EmpiRE and its analysis have
been updated twice, currently covering over 650 papers. KG-EmpiRE and its
analysis demonstrate how innovative infrastructures, such as the ORKG, can be
leveraged to make data from literature reviews FAIR, openly available, and
maintainable for the research community in the long term. In this way, we can
enable replicable, (re-)usable, and thus sustainable literature reviews to
ensure the quality, reliability, and timeliness of their research results.",250,11,1738,29.18
2297,postmodern literature,"Effective ownership of software artifacts, particularly code, is crucial for
accountability, knowledge sharing, and code quality enhancement. Researchers
have proposed models linking ownership of software artifacts with developer
performance and code quality. Our study aims to systematically examine various
ownership models and provide a structured literature overview. Conducting a
systematic literature review, we identified 79 relevant papers published
between 2005 and 2022. We developed a taxonomy of ownership artifacts based on
type, owners, and degree of ownership, along with compiling modeling variables
and analytics types used in each study. Additionally, we assessed the
replication status of each study. As a result, we identified nine distinct
software artifacts whose ownership has been discussed in the literature, with
""Code"" being the most frequently analyzed artifact. We found that only three
papers (3.79%) provided code and data, whereas nine papers (11.4%) provided
only data. Using our systematic literature review results, we replicated
experiments on nine priority projects at \texttt{Brightsquid}. The company
aimed to compare its code quality against ownership factors in other teams, so
we conducted a replication study using their data. Unlike prior studies, we
found no strong correlation between minor contributors and bug numbers.
Surprisingly, we found no strong link between the total number of developers
modifying a file and bug counts, contrasting previous findings. However, we
observed a significant correlation between major contributors and bug counts,
diverging from earlier research.",230,16,1630,30.57
2298,postmodern literature,"Efficiently extracting data from tables in the scientific literature is
pivotal for building large-scale databases. However, the tables reported in
materials science papers exist in highly diverse forms; thus, rule-based
extractions are an ineffective approach. To overcome this challenge, we present
MaTableGPT, which is a GPT-based table data extractor from the materials
science literature. MaTableGPT features key strategies of table data
representation and table splitting for better GPT comprehension and filtering
hallucinated information through follow-up questions. When applied to a vast
volume of water splitting catalysis literature, MaTableGPT achieved an
extraction accuracy (total F1 score) of up to 96.8%. Through comprehensive
evaluations of the GPT usage cost, labeling cost, and extraction accuracy for
the learning methods of zero-shot, few-shot and fine-tuning, we present a
Pareto-front mapping where the few-shot learning method was found to be the
most balanced solution owing to both its high extraction accuracy (total F1
score>95%) and low cost (GPT usage cost of 5.97 US dollars and labeling cost of
10 I/O paired examples). The statistical analyses conducted on the database
generated by MaTableGPT revealed valuable insights into the distribution of the
overpotential and elemental utilization across the reported catalysts in the
water splitting literature.",198,10,1388,20.92
2299,postmodern literature,"The bulk density of an asteroid informs us about its interior structure and
composition. To constrain the bulk density one needs an estimate for the mass
of the asteroid. The mass is estimated by analyzing an asteroid's gravitational
interaction with another object, such as another asteroid during a close
encounter. An estimate for the mass has typically been obtained with linearized
least-squares methods despite the fact that this family of methods is not able
to properly describe non-Gaussian parameter distributions. In addition, the
uncertainties reported for asteroid masses in the literature are sometimes
inconsistent with each other and suspected to be unrealistically low. We
present a Markov-chain Monte Carlo (MCMC) algorithm for the asteroid mass
estimation problem based on asteroid-asteroid close encounters. We verify that
our algorithm works correctly by applying it to synthetic data sets. We then
use astrometry available through the Minor Planet Center to estimate masses for
a few example cases and compare our results to results reported in the
literature.
  Our mass estimates for the synthetic data sets are fully consistent with the
ground truth. The nominal masses for real example cases typically agree with
the literature but tend to have greater uncertainties than what is reported in
recent literature. Possible reasons for this include different astrometric
datasets and/or weights, different test asteroids, different force models and
different algorithms. For (16) Psyche, the target of NASA's Psyche mission, our
maximum likelihood mass is approximately 55% of what is reported in the
literature. Such a low mass would imply that the bulk density is significantly
lower than previously expected and hence disagrees with the theory of (16)
Psyche being the metallic core of a protoplanet. We however note that masses
reported in recent literature remain within our 3-sigma limits.",292,15,1917,33.34
2300,postmodern literature,"The readability of source code is key for understanding and maintaining
software systems and tests. Several studies investigate the readability of
source code, but there is limited research on the readability of test code and
related influence factors. We investigate the factors that influence the
readability of test code from an academic perspective complemented by practical
views. First, we perform a Systematic Mapping Study (SMS) with a focus on
scientific literature. Second, we extend this study by reviewing grey
literature sources for practical aspects on test code readability and
understandability. Finally, we conduct a controlled experiment on the
readability of a selected set of test cases to collect additional knowledge on
influence factors discussed in practice. The result set of the SMS includes 19
primary studies from the scientific literature. The grey literature search
reveals 62 sources for information on test code readability. Based on an
analysis of these sources, we identified a combined set of 14 factors that
influence the readability of test code. 7 of these factors were found in
scientific and grey literature, while some factors were mainly discussed in
academia (2) or industry (5) with limited overlap. The controlled experiment on
practically relevant influence factors showed that the investigated factors
have a significant impact on readability for half of the selected test cases.
Our review of scientific and grey literature showed that test code readability
is of interest for academia and industry with a consensus on key influence
factors. However, we also found factors only discussed by practitioners. For
some of these factors we were able to confirm an impact on readability in a
first experiment. Therefore, we see the need to bring together academic and
industry viewpoints to achieve a common view on the readability of software
test code.",294,16,1896,34.66
2301,postmodern literature,"The CTIO Prime Focus CCD instrument with an RCA CCD was in operation at the
CTIO 4-m telescope for six years between 1982-1988. A large body of literature
has been published based on CCD images taken with this instrument. We review
the general properties of the now-retired PFCCD system to aid astronomers in
the interpretation of the photometric data in the literature.",62,4,370,50.46
2302,postmodern literature,"Statistical physics is employed to evaluate the performance of
error-correcting codes in the case of finite message length for an ensemble of
Gallager's error correcting codes. We follow Gallager's approach of
upper-bounding the average decoding error rate, but invoke the replica method
to reproduce the tightest general bound to date, and to improve on the most
accurate zero-error noise level threshold reported in the literature. The
relation between the methods used and those presented in the information theory
literature are explored.",81,4,542,27.15
2303,postmodern literature,"The paper presents an analysis performed over the worldwide top 150 firms in
the pharmaceutical industry. It begins with a test of the Gibrat's Law of
Proportionate Effect finding, in line with previous literature, a violation
concerning the variance of the growth. Then it shows, using disaggregated data
on sub-markets (defined according to the ATC code) that this violation can be
completely referred to the existence of a ``diversification'' effect, namely a
scale relation between the number of active sub-markets a firm posses and its
size. The observed scaling property of the firms diversification patterns is in
contrast with the linear assumption typically made in literature. Finally, to
interpret the findings, the work proposes a stochastic model for firms
diversification which fits quite well the data.",126,6,817,28.98
2304,postmodern literature,"Both theoretical and applied economics have a great deal to say about many
aspects of the firm, but the literature on the extinctions, or demises, of
firms is very sparse. We use a publicly available data base covering some 6
million firms in the US and show that the underlying statistical distribution
which characterises the frequency of firm demises - the disappearances of firms
as autonomous entities - is closely approximated by a power law. The exponent
of the power law is, intriguingly, close to that reported in the literature on
the extinction of biological species.",96,4,578,31.25
2305,postmodern literature,"We study a market model in which the volatility of the stock may jump at a
random time from a fixed value to another fixed value. This model was already
described in the literature. We present a new approach to the problem, based on
partial derivative equations, which gives a different perspective to the
problem. Within our framework we can easily consider several prescriptions for
the market price of volatility risk, and interpret their financial meaning.
Thus, we recover solutions previously cited in the literature as well as obtain
new ones.",91,6,550,53.0
2306,postmodern literature,"The literature on self- and tracer- diffusion of polymers in solution, and on
tracer diffusion of probe polymers through solutions of matrix polymers, is
reviewed. I show via systematic reanalysis that the entirety of the published
literature has its concentration c and matrix M and probe P molecular weight
dependences described by a single functional form, namely the stretched
exponential in c, P, and M. Correlations of the scaling prefactor and exponents
with polymer molecular weight, concentration, and size are examined. Scaling
parameters for the diffusion of star polymers do not differ substantially from
scaling parameters for the diffusion of linear chains of equal size.",105,5,685,27.86
2307,postmodern literature,"In this letter, elastic properties of highly anisotropic cellular
poly(propylene) films are reported. The material shows peculiar elastic
properties compared to other foams in the literature. The data is displayed as
the relative Young's modulus $E^*/E_s$ versus relative density $\rho^*/\rho_s$.
Almost all the data from the literature are located on the region
$E^*/E_s=(\rho^*/\rho_s)^n$ with $1\le n\le6$. The introduced material on the
other hand have lower relative Young's modulus at high relative densities,
$n\ge6$.",73,6,524,39.74
2308,postmodern literature,"There are many examples in the literature that suggest that
indistinguishability is intransitive, despite the fact that the
indistinguishability relation is typically taken to be an equivalence relation
(and thus transitive). It is shown that if the uncertainty perception and the
question of when an agent reports that two things are indistinguishable are
both carefully modeled, the problems disappear, and indistinguishability can
indeed be taken to be an equivalence relation. Moreover, this model also
suggests a logic of vagueness that seems to solve many of the problems related
to vagueness discussed in the philosophical literature. In particular, it is
shown here how the logic can handle the sorites paradox.",109,5,719,26.85
2309,postmodern literature,"Transitive text mining - also named Swanson Linking (SL) after its primary
and principal researcher - tries to establish meaningful links between
literature sets which are virtually disjoint in the sense that each does not
mention the main concept of the other. If successful, SL may give rise to the
development of new hypotheses. In this communication we describe our approach
to transitive text mining which employs co-occurrence analysis of the medical
subject headings (MeSH), the descriptors assigned to papers indexed in PubMed.
In addition, we will outline the current state of our web-based information
system which will enable our users to perform literature-driven hypothesis
building on their own.",109,5,709,35.81
2310,postmodern literature,"This bibliography attempts to give a comprehensive overview of all the
literature related to the Ashtekar variables. The original version was compiled
by Peter Huebner in 1989, and it has been subsequently updated by Gabriela
Gonzalez and Bernd Bruegmann. Information about additional literature, new
preprints, and especially corrections are always welcome.",51,4,358,28.84
2311,postmodern literature,"This bibliography attempts to give a comprehensive overview of all the
literature related to the Ashtekar connection and the Rovelli-Smolin loop
variables. The original version was compiled by Peter H\""ubner in 1989, and it
has been subsequently updated by Gabriela Gonzalez, Bernd Br\""ugmann, Monica
Pierri, Troy Schilling, Alejandro Corichi and Christopher Beetle. Information
about additional literature, new preprints, and especially corrections are
always welcome.",64,4,469,24.48
2312,postmodern literature,"The frequencies and damping times of neutron star (and quark star)
oscillations have been computed using the most recent equations of state
available in the literature. We find that some of the empirical relations that
connect the frequencies and damping times of the modes to the mass and radius
of the star, and that were previously derived in the literature need to be
modified.",64,3,381,47.46
2313,postmodern literature,"We present a derivation of the medium dependent wave function renormalization
for a spinor field in presence of a thermal bath. We show that, as already
pointed out in literature, projector operators are not multiplicatively
renormalized and the effect involves a non trivial spinor dependence, which
disappears in the zero temperature covariant limit. The results, which differ
from what already found in literature, are then applied to the decay of a
massive scalar boson into two fermions and to the $\beta$--decay and crossed
related processes relevant for primordial nucleosynthesis.",89,4,588,32.87
2314,postmodern literature,"We present a comprehensive update of the bounds on R-Parity violating
supersymmetric couplings from lepton-flavour- and lepton-number-violating decay
processes. We consider tau and mu decays as well as leptonic and semi-leptonic
decays of mesons. We present several new bounds resulting from tau, eta and
Kaon decays and correct some results in the literature concerning B-meson
decays.",56,4,386,35.57
2315,postmodern literature,"We consider the supersymmetric vector multiplet in a purely quantum
framework. We obtain some discrepancies with respect to the literature in the
expression of the super-propagator and we prove that the model is consistent
only for positive mass. The gauge structure is constructed purely deductive and
leads to the necessity of introducing scalar ghost superfields, in analogy to
the usual gauge theories. The construction of a consistent supersymmetric gauge
theory based on the vector model depends crucially one the definition of gauge
invariance. We find some significant difficulties to impose a supersymmetric
gauge invariance condition for the usual expressions from the literature.",102,6,690,25.39
2316,postmodern literature,"We argue that the giant graviton configurations known from the literature
have a complementary, microscopical description in terms of multiple
gravitational waves undergoing a dielectric (or magnetic moment) effect. We
present a non-Abelian effective action for these gravitational waves with
dielectric couplings and show that stable dielectric solutions exist. These
solutions agree in the large $N$ limit with the giant graviton configurations
in the literature.",65,4,465,15.61
2317,postmodern literature,"We clarify the discussion of N=2 supersymmetric boundary conditions for the
classical d=2, N=(2,2) Non-Linear Sigma Model on an infinite strip. Our
conclusions about the supersymmetric cycles match the results found in the
literature. However, we find a constraint on the boundary action that is not
satisfied by many boundary actions used in the literature.",55,4,358,35.98
2318,postmodern literature,"The apparently trifling unexpected hanging paradox has generated an enormous
philosophical literature. We introduce the mathematician to this literature,
paying special attention to aspects that involve nontrivial mathematics. This
xxx version of the paper contains an exhaustive bibliography that the editors
of the Monthly deemed too lengthy to publish. The bibliography will be
continually updated and readers are encouraged to inform the author of any
omissions that they discover.",69,5,485,20.08
2319,postmodern literature,"The article reviews some of the (fairly scattered) information available in
the mathematical literature on the subject of angles in complex vector spaces.
The following angles and their relations are considered: Euclidean, complex,
and Hermitian angles, (Kasner's) pseudo-angle, the Kaehler angle (synonyms for
the latter used in the literature are: angle of inclination, characteristic
deviation, holomorphic deviation, holomorphy angle, Wirtinger angle, slant
angle).",63,3,469,5.66
2320,postmodern literature,"This paper introduces a new approach for output feedback stabilization of
SISO systems which, unlike most of the techniques found in the literature, does
not use high-gain observers and control input saturation to achieve separation
between the state feedback and observer designs. Rather, we show that by using
nonlinear observers, together with a projection algorithm, the same kind of
separation principle is achieved for a larger class of systems, namely
stabilizable and incompletely observable plants. Furthermore, this new approach
avoids using knowledge of the inverse of the observability mapping, which is
needed by most techniques in the literature when controlling general
stabilizable systems.",103,4,706,19.74
2321,postmodern literature,"This paper is an enhanced version of a more than decade-older paper with a
similar title. Many formulae involving both finite and infinite sums of digamma
and polygamma functions up to quadratic order, few of which appear in standard
reference works or the literature, but which periodically arise in
applications, are collected, reviewed, listed and developed to the point that a
knowledgeable reader could devise a formal proof. Several errors in the
literature are corrected",75,3,477,37.64
2322,postmodern literature,"There are many information and divergence measures exist in the literature on
information theory and statistics. The most famous among them are
Kullback-Leiber relative information and Jeffreys J-divergence. The measures
like, Bhattacharya distance, Hellinger discrimination, Chi-square divergence,
triangular discrimination and harmonic mean divergence are also famous in the
literature on statistics. In this paper we have obtained bounds on triangular
discrimination and symmetric chi-square divergence in terms of relative
information of type s using Csiszar's f-divergence. A relationship among
triangular discrimination and harmonic mean divergence is also given.",88,6,669,19.77
2323,postmodern literature,"By systematically applying ten inequivalent two-part relations between
hypergeometric sums 3F2(1) to the published database of all such sums, 66 new
sums are obtained. Many results extracted from the literature are shown to be
special cases of these new sums. In particular, the general problem of finding
elements contiguous to Watson's, Dixon's and Whipple's theorem is reduced to a
simple algorithm suitable for machine computation. Several errors in the
literature are corrected or noted.",74,5,492,35.78
2324,postmodern literature,"An interesting and satisfactory fluid model has been proposed in literature
for the the description of relativistic electron beams. It was obtained with 14
independent variables by imposing the entropy principle and the relativity
principle. Here the case is considered with an arbitrary number of independent
variables, still satisfying the above mentioned two principles; these lead to
conditions whose general solution is here found. We think that the results
satisfy also a certain ordering with respect to a smallness parameter
$\epsilon$ measuring the dispersion of the velocity about the mean; this
ordering generalizes that appearing in literature for the 14 moments case.",102,5,680,20.21
2325,postmodern literature,"Recently published formulas for the surface and regular solid spherical
harmonics and for the expansion of the product of two normalized associated
Legendre functions with different centers in ellipsoidal coordinates (Telhat
Ozdogan, Metin Orbay, Czech.J.Phys., 52(2002)1297) are critically analyzed. It
is demonstrated that the presented in this work formulas are not original and
they are available in the literature or can easily be obtained from the
published in the literature formulas by changing the summation indices.",76,6,525,20.42
2326,postmodern literature,"An overview of quantum computing and in particular the Hidden Subgroup
Problem are presented from a mathematical viewpoint. Detailed proofs are
supplied for many important results from the literature, and notation is
unified, making it easier to absorb the background necessary to begin research
on the Hidden Subgroup Problem. Proofs are provided which give very concrete
algorithms and bounds for the finite abelian case with little outside
references, and future directions are provided for the nonabelian case. This
summary is current as of October 2004.",85,5,558,41.4
2327,postmodern literature,"This article is intended as a compendium and guide to the variety of Bell
Inequality derivations that have appeared in the literature in recent years,
classifying them into six broad categories, revealing the underlying, often
hidden, assumption common to each - semifactuality. Evaluation of the attendant
conditional brings to light a significant EPR loophole that has not appeared in
the literature. Semantics for the inequality in the ongoing philosophic debate
that led to its discovery is discussed.",77,4,505,20.42
2328,postmodern literature,"The notion of quadratic maps between arbitrary groups appeared at several
places in the literature on quadratic algebra. Here a unified extensive
treatment of their properties is given; the relation with a relative version of
Passi's polynomial maps and groups of degree 2 is established and used to study
the structure of the latter.",54,3,334,35.61
2329,postmodern literature,"The interaction of a point charge and a magnetic moment (and by extension a
point charge and a solenoid) is explored within well-defined point-charge
magnetic-moment models where full calculations are possible. It is shown
explicitly how the ""hidden mechanical momentum"" is introduced by the ""hidden""
external forces of constraint, requiring a prescribed response (through order
1/c^2) of the system to electromagnetic forces. These external forces often go
unmentioned in the textbook and research literature. The dependence of ""hidden
mechanical momentum"" upon detailed external (nonelectromagnetic) forces may
undermine the idea's usefulness in describing nature. Some statements of
dubious validity in the textbook literature are noted.",104,6,740,24.98
2330,postmodern literature,"We study a q-logarithm which was introduced by Euler and give some of its
properties. This q-logarithm did not get much attention in the recent
literature. We derive basic properties, some of which were already given by
Euler in a 1751-paper and 1734-letter to Daniel Bernoulli. The corresponding
q-analogue of the dilogarithm is introduced. The relation to the values at 1
and 2 of a q-analogue of the zeta function is given. We briefly describe some
other q-logarithms that have appeared in the recent literature.",85,7,515,57.06
2331,postmodern literature,"Warm inflation dynamics is fundamentally based on a system-reservoir
configuration in which the dynamics is dictated by a fluctuation-dissipation
relation. Recent work by Cerioni et. al. (arXiv:0804.0163) examined dissipative
dynamics with no associated fluctuation component. Their results, which are
heavily dependent on initial conditions, are at odds with results in the warm
inflation literature, especially the spectral indices. The inconsistency of
their formalism is outlined here and it is shown how this would lead to their
erroneous conclusions. It is then shown how, following the correct dynamical
equations of warm inflation, the results in the literature are correct.",98,9,682,29.55
2332,postmodern literature,"We show that the literature on pion exchange between charm and bottom mesons
is inconsistent. We derive the formalism explicitly, expose differences between
papers in the literature and clarify the implications. We show that the X(3872)
can be a bound state but that results are very sensitive to a poorly
constrained parameter. We confirm that bound states in the B Bbar sector are
possible. The circumstances whereby exotic combinations can bind with cc or bb
quantum numbers are explored.",79,6,491,46.98
2333,postmodern literature,"We make connections between studies in the condensed matter literature on
quantum phase transitions in square lattice antiferromagnets, and results in
the particle theory literature on abelian supersymmetric gauge theories in 2+1
dimensions. In particular, we point out that supersymmetric U(1) gauge theories
(with particle content similar, but not identical, to those of theories of
doped antiferromagnets) provide rigorous examples of quantum phase transitions
which do not obey the Landau-Ginzburg-Wilson paradigm (often referred to as
transitions realizing ""deconfined criticality""). We also make connections
between supersymmetric mirror symmetries and condensed matter particle-vortex
dualities.",92,4,702,-2.0
2334,postmodern literature,"We study Borel systems and continuous systems of measures, with a focus on
mapping properties: compositions, liftings, fibred products and disintegration.
Parts of the theory we develop can be derived from known work in the
literature, and in that sense this paper is of expository nature. However, we
put the above notions in the spotlight and provide a self-contained, purely
measure-theoretic, detailed and thorough investigation of their properties, and
in that aspect our paper enhances and complements the existing literature. Our
work constitutes part of the necessary theoretical framework for categorical
constructions involving measured and topological groupoids with Haar systems, a
line of research we pursue in separate papers.",109,5,740,26.85
2335,postmodern literature,"The Dirac equation, with position-dependent mass, is solved approximately for
the generalized Hulth\'{e}n potential with any spin-orbit quantum number
$\kappa$. Solutions are obtained by using an appropriate coordinate
transformation, reducing the effective mass Dirac equation to a
Schr\""{o}dinger-like differential equation. The Nikiforov-Uvarov method is used
in the calculations to obtain energy eigenvalues and the corresponding wave
functions. Numerical results are compared with those given in the literature.
Analytical results are also obtained for the case of constant mass and the
results are in good agreement with the literature.",88,6,642,28.23
2336,postmodern literature,"We review the literature on the localization transition for the class of
polymers with random potentials that goes under the name of copolymers near
selective interfaces. We outline the results, sketch some of the proofs and
point out the open problems in the field. We also present in detail some
alternative proofs that simplify what one can find in the literature.",61,4,367,59.33
2337,postmodern literature,"Variability in Business Process modeling has already been faced by different
authors from the literature. Depending on the context in which each author
faces the modeling problem, we find different approaches (C-EPC, C-YAWL,
FEATURE-EPC, PESOA, PROVOP, or WORKLETS). In this report we present four of the
most representative approaches (C-EPC, PESOA, PROVOP and WORKLETS) which are
presented by means of the different case studies found in the literature.",68,4,455,48.43
2338,postmodern literature,"This survey paper discusses the history of approximation formulas for n-th
order derivatives by integrals involving orthogonal polynomials. There is a
large but rather disconnected corpus of literature on such formulas. We give
some results in greater generality than in the literature. Notably we unify the
continuous and discrete case. We make many side remarks, for instance on
wavelets, Mantica's Fourier-Bessel functions and Greville's minimum R_alpha
formulas in connection with discrete smoothing.",72,6,504,31.48
2339,postmodern literature,"There are three classical divergence measures exist in the literature on
information theory and statistics. These are namely, Jeffryes-Kullback-Leiber
J-divergence. Sibson-Burbea-Rao Jensen-Shannon divegernce and Taneja
Arithmetic-Geometric divergence. These three measures bear an interesting
relationship among each other. The divergence measures like Hellinger
discrimination, symmetric chi-square divergence, and triangular discrimination
are also known in the literature. In this paper, we have considered generalized
symmetric divergence measures having the measures given above as particular
cases. Bounds on the probability of error are obtained in terms of generalized
symmetric divergence measures. Study of bounds on probability of error is
extended for the difference of divergence measures.",103,9,803,16.08
2340,postmodern literature,"Erbium-Doped Fiber Amplifiers can present holes in spectral gain in
Wavelength Division Multiplexing operation. The origin of this inhomogeneous
saturation behavior is still a subject of controversy. In this paper we present
both an experimental methods and a gain's model. Our experimental method allow
us to measure the first homogeneous linewidth of the 1.5 $\mu$m erbium emission
with gain spectral hole burning consistently with the other measurement in the
literature and the model explains the differences observed in literature
between GSHB and other measurement methods.",85,6,579,37.3
2341,postmodern literature,"Considerable literature has been devoted to developing statistical
inferential results for risk measures, especially for those that are of the
form of L-functionals. However, practical and theoretical considerations have
highlighted quite a number of risk measures that are of the form of ratios, or
even more complex combinations, of two L-functionals. In the present paper we
call such combinations `coupled risk measures' and develop a statistical
inferential theory for them when losses follow heavy-tailed distributions. Our
theory implies -at a stroke- statistical inferential results for absolute and
relative distortion risk measures, weighted premium calculation principles, as
well as for many indices of economic inequality that have appeared in the
econometric literature.",111,5,784,9.42
2342,postmodern literature,"The literature on reconstruction formulas for photoacoustic tomography (PAT)
is vast. The various reconstruction formulas differ by used measurement devices
and geometry on which the data are sampled. In standard photoacoustic imaging
(PAI), the object under investigation is illuminated uniformly. Recently,
sectional photoacoustic imaging techniques, using focusing techniques for
initializing and measuring the pressure along a plane, appeared in the
literature. This paper surveys existing and provides novel exact reconstruction
formulas for sectional photoacoustic imaging.",75,6,579,5.49
2343,postmodern literature,"The ADS All-Sky Survey (ADSASS) is an ongoing effort aimed at turning the
NASA Astrophysics Data System (ADS), widely known for its unrivaled value as a
literature resource for astronomers, into a data resource. The ADS is not a
data repository per se, but it implicitly contains valuable holdings of
astronomical data, in the form of images, tables and object references
contained within articles. The objective of the ADSASS effort is to extract
these data and make them discoverable and available through existing data
viewers. The resulting ADSASS data layer promises to greatly enhance workflows
and enable new research by tying astronomical literature and data assets into
one resource.",109,5,692,26.85
2344,postmodern literature,"This paper addresses the problem of semiparametric efficiency bounds for
conditional moment restriction models with different conditioning variables. We
characterize such an efficiency bound, that in general is not explicit, as a
limit of explicit efficiency bounds for a decreasing sequence of unconditional
(marginal) moment restriction models. An iterative procedure for approximating
the efficient score when this is not explicit is provided. Our theoretical
results complete and extend existing results in the literature, provide new
insight for the theory of semiparametric efficiency bounds literature and open
the door to new applications. In particular, we investigate a class of
regression-like (mean regression, quantile regression,...) models with missing
data.",107,9,773,11.11
2345,postmodern literature,"Tree transducers are formal automata that transform trees into other trees.
Many varieties of tree transducers have been explored in the automata theory
literature, and more recently, in the machine translation literature. In this
paper I review T and xT transducers, situate them among related formalisms, and
show how they can be used to implement rules for machine translation systems
that cover all of the cross-language structural divergences described in Bonnie
Dorr's influential article on the topic. I also present an implementation of xT
transduction, suitable and convenient for experimenting with translation rules.",93,5,627,30.91
2346,postmodern literature,"An analysis in the framework of the radiation dominated era permits to put
bounds on the weak modification of general relativity which arises from the
Lagrangian R^{1+epsilon}. Such a theory has been recently discussed in various
papers in the literature. The new bounds together with previous ones in the
literature rule out this theory in an ultimate way.",58,4,357,34.97
2347,postmodern literature,"The machine-part cell formation problem consists of creating machine cells
and their corresponding part families with the objective of minimizing the
inter-cell and intra-cell movement while maximizing the machine utilization.
This article demonstrates a hybrid clustering approach for the cell formation
problem in cellular manufacturing that conjoins Sorenson s similarity
coefficient based method to form the production cells. Computational results
are shown over the test datasets obtained from the past literature. The hybrid
technique is shown to outperform the other methods proposed in literature and
including powerful soft computing approaches such as genetic algorithms,
genetic programming by exceeding the solution quality on the test problems.",105,5,757,19.4
2348,postmodern literature,"In this paper, we propose a two-sector Markovian infectious model, which is
an extension of Greenwood's model. The central idea of this model is that the
causality of defaults of two sectors is in both direction, which enrich
dependence dynamics. The Bayesian Information Criterion is adopted to compare
the proposed model with the two-sector model in credit literature using the
real data. We find that the newly proposed model is statistically better than
the model in past literature. We also introduce two measures: CRES and CRVaR to
give risk evaluation of our model.",93,6,572,44.14
2349,postmodern literature,"This research presents the development of a critical success factor matrix
for increasing positive user experience of hotel websites based upon user
ratings. Firstly, a number of critical success factors for web usability have
been identified through the initial literature review. Secondly, hotel websites
were surveyed in terms of critical success factors identified through the
literature review. Thirdly, Herzberg's motivation theory has been applied to
the user rating and the critical success factors were categorized into two
areas. Finally, the critical success factor matrix has been developed using the
two main sets of data.",94,6,635,27.01
2350,postmodern literature,"The goal of this paper is to derive the detailed description of the
Enumeration Based Search Algorithm from the high level description provided in
[16], analyze the experimental results from our implementation of the
Enumeration Based Search Algorithm for finding a regular bi-partite graph of
degree 3, and compare it with known results from the available literature. We
show that the values of m for a given girth g for (m, 3) BTUs are within the
known mathematical bounds for regular bi-partitite graphs from the available
literature.",87,3,537,18.86
2351,postmodern literature,"In this note we consider the global convergence properties of the
differential equation $\dot{\Theta}=(\Theta^{T}-\Theta)\Theta$ with
$\Theta\in{SO(n)}$, which is a gradient flow of the function
$f:SO(n)\rightarrow\mathbb{R},\Theta\mapsto{2n-2\tr{\Theta}}$. Many of the
presented results are not new, but scattered throughout literature. The
motivation of this note is to summarize and extend the convergence results
known from literature. Rather than giving an exhaustive list of references, the
results are presented in a self-contained fashion.",69,5,547,37.0
2352,postmodern literature,"This paper proposes entitymetrics to measure the impact of knowledge units.
Entitymetrics highlight the importance of entities embedded in scientific
literature for further knowledge discovery. In this paper, we use Metformin, a
drug for diabetes, as an example to form an entity-entity citation network
based on literature related to Metformin. We then calculate the network
features and compare the centrality ranks of biological entities with results
from Comparative Toxicogenomics Database (CTD). The comparison demonstrates the
usefulness of entitymetrics to detect most of the outstanding interactions
manually curated in CTD.",89,6,633,19.57
2353,postmodern literature,"We prove a quadratic interaction estimate for approximate solutions to scalar
conservation laws obtained by the wavefront tracking approximation or the Glimm
scheme. This quadratic estimate has been used in the literature to prove the
convergence rate of the Glimm scheme. The proof is based on the introduction of
a quadratic functional $\mathfrak Q(t)$, decreasing at every interaction, and
such that its total variation in time is bounded. Differently from other
interaction potentials present in the literature, the form of this functional
is the natural extension of the original Glimm functional, and coincides with
it in the genuinely nonlinear case.",100,5,657,29.18
2354,postmodern literature,"In the following article we consider the time-stability associated to the
sequential Monte Carlo (SMC) estimate of the backward interpretation of
Feynman-Kac Formulae. This is particularly of interest in the context of
performing smoothing for hidden Markov models (HMMs). We prove a central limit
theorem (CLT) under weaker assumptions than adopted in the literature. We then
show that the associated asymptotic variance expression, for additive
functionals grows at most linearly in time, under hypotheses that are weaker
than those currently existing in the literature. The assumptions are verified
for some state-space models.",92,6,630,27.42
2355,postmodern literature,"In this work we consider the nonlocal evolution equation $$ \frac{\partial
u(w,t)}{\partial t}=-u(w,t)+ \int_{S^{1}}J(wz^{-1})f(u(z,t))dz+ h, \,\,\, h > 0
$$ which arises in models of neuronal activity, in $L^{2}(S^{1})$, where
$S^{1}$ denotes the unit sphere. We obtain stronger results on existence of
global attractors and Lypaunov functional than the already existing in the
literature. Furthermore, we prove the result, not yet known in the literature,
of lower semicontinuity of global attractors with respect to connectivity
function $J$.",77,4,545,29.89
2356,postmodern literature,"This paper studies the heavy-traffic asymptotics for the multiclass FIFO
M${}^X$/G/1 queue. We first derive the probability generating function of the
joint queue length distribution. Using the probability generating function, we
then present heavy-traffic asymptotic formulas for the joint queue length
distribution and its joint moments (i.e., the joint queue length moments).
These formulas are proved under weaker conditions on the service time
distributions, compared to the ones reported in the literature. This fact leads
us to conjectures that some of the conditions made in the literature are
relaxed.",89,8,610,47.99
2357,postmodern literature,"Following some strong argumentations of differential geometry in the Landau's
book, some corrections about errors in the old literature on scalar
gravitational waves (SGWs) are given and discussed. In the analysis of the
response ofi nterferometers the computation is first performed in the low
frequencies approximation, then the analysis is applied to all SGWs in the full
frequency and angular dependences. The presented results are in agreement with
the more recent literature on SGWs.",74,4,489,29.48
2358,postmodern literature,"Face detection is one of the most relevant applications of image processing
and biometric systems. Artificial neural networks (ANN) have been used in the
field of image processing and pattern recognition. There is lack of literature
surveys which give overview about the studies and researches related to the
using of ANN in face detection. Therefore, this research includes a general
review of face detection studies and systems which based on different ANN
approaches and algorithms. The strengths and limitations of these literature
studies and systems were included also.",88,6,575,45.15
2359,postmodern literature,"The landmark paper ""Constructing tight fusion frames"" by Casazza, Fickus,
Mixon, Wang and Zhou introduced a fundamental method for constructing unit norm
tight frames, which they called Spectral Tetris. This was a significant
advancement for finite frame theory - especially constructions of finite
frames. This paper then generated a vast amount of literature as Spectral
Tetris was steadily developed, refined, and generalized until today we have a
complete picture of what are the broad applications as well as the limitations
of Spectral Tetris. In this paper, we will put this vast body of literature
into a coherent theory.",98,5,629,46.81
2360,postmodern literature,"Intermittent control has a long history in the physiological literature and
there is strong experimental evidence that some human control systems are
intermittent. Intermittent control has also appeared in various forms in the
engineering literature. This article discusses a particular mathematical model
of Event-driven Intermittent Control which brings together engineering and
physiological insights and builds on and extends previous work in this area.
Illustrative examples of the properties of Intermittent Control in a
physiological context are given together with suggestions for future research
directions in both physiology and engineering.",89,5,651,-1.93
2361,postmodern literature,"This Resource Letter draws on discipline-based education research from
physics, chemistry, and biology to collect literature on the teaching of
thermodynamics and statistical mechanics in the three disciplines. While the
overlap among the disciplinary literatures is limited at present, we hope this
Resource Letter will spark more interdisciplinary interaction.",49,3,362,21.23
2362,postmodern literature,"A Path Relinking algorithm is proposed for the Bandwidth Coloring problem and
the Bandwidth MultiColoring problem. It combines a population based relinking
method and a tabu search based local search procedure. The proposed algorithm
is assessed on two sets of 66 benchmark instances commonly used in the
literature. Computational results demonstrate that the proposed algorithm is
highly competitive in terms of both solution quality and efficiency compared to
the best performing algorithms in the literature. Specifically, it improves the
previous best known results for 15 out of 66 instances, while matching the
previous best known results for 47 cases. Some key elements of the proposed
algorithm are investigated.",108,7,720,36.28
2363,postmodern literature,"This book chapter gives an introduction to, and an overview of, methods for
cooling trapped ions. The main addressees are researchers entering the field.
It is not intended as a comprehensive survey and historical account of the
extensive literature on this topic. We present the physical ideas behind
several cooling schemes, outline their mathematical description, and point to
relevant literature useful for a more in-depth study of this topic.",69,5,447,45.46
2364,postmodern literature,"We contribute to the theory for minimal liftings of cut-generating functions.
In particular, we give three operations that preserve the so-called covering
property of certain structured cut-generating functions. This has the
consequence of vastly expanding the set of undominated cut generating functions
which can be used computationally, compared to known examples from the
literature. The results of this paper are significant generalizations of
previous results from the literature on such operations, and also use
completely different proof techniques which we feel are more suitable for
attacking future research questions in this area.",92,5,642,22.75
2365,postmodern literature,"Despite the rich literature on quantum algorithms, there is a surprisingly
small amount of coverage of their concrete logical design and implementation.
Most resource estimation is done at the level of complexity analysis, but
actual concrete numbers (of quantum gates, qubits, etc.) can differ by orders
of magnitude. The line of work we present here is a formal framework to write,
and reason about, quantum algorithms. Specifically, we designed a language,
Quipper, with scalability in mind, and we are able to report actual resource
counts for seven non-trivial algorithms found in the quantum computer science
literature.",96,6,626,43.53
2366,postmodern literature,"Let G be a p-adic Lie group and Ad be the adjoint representation of G on its
Lie algebra. It was claimed in the literature that the kernel K of Ad always
has an abelian open normal subgroup. We show by means of a counterexample that
this assertion is false; it can even happen that K=G but G has no abelian
subnormal subgroup except for the trivial group. The arguments are based on
auxiliary results on subgroups of free products with central amalgamation.",83,5,457,67.28
2367,postmodern literature,"Swiss cheese sets have been used in the literature as useful examples in the
study of rational approximation and uniform algebras. In this paper, we give a
survey of Swiss cheese constructions and related results. We describe some
notable examples of Swiss cheese sets in the literature. We explain the various
abstract notions of Swiss cheeses, and how they can be manipulated to obtain
desirable properties. In particular, we discuss the Feinstein-Heath
classicalisation theorem and related results. We conclude with the construction
of a new counterexample to a conjecture of S. E. Morris, using a classical
Swiss cheese set.",99,9,628,48.7
2368,postmodern literature,"We investigate modules over ""systematic"" rings. Such rings are ""almost
graded"" and have appeared under various names in the literature; they are
special cases of the G-systems of Grzeszczuk. We analyse their K-theory in the
presence of conditions on the support, and explain how this generalises and
unifies calculations of graded and filtered K-theory scattered in the
literature. Our treatment makes systematic use of the formalism of idempotent
completion and a theory of triangular objects in additive categories, leading
to elementary and transparent proofs throughout.",85,5,574,32.94
2369,postmodern literature,"Following several papers in the prior literature, we study the relationship
between order bounded operators, topologically bounded operators and
topologically continuous operators. Our main contribution is two folded: (i) we
provide a set of counterexamples to illustrate several extant results in the
literature; (ii) we give conditions for the space of order bounded operators to
coincide with the space of topologically bounded operators as well as
conditions for these two spaces to coincide with the space of topologically
continuous operators.",80,3,549,-11.43
2370,postmodern literature,"This paper studies the validity of nonparametric tests used in the regression
discontinuity design. The null hypothesis of interest is that the average
treatment effect at the threshold in the so-called sharp design equals a
pre-specified value. We first show that, under assumptions used in the majority
of the literature, for \emph{any} test the power against any alternative is
bounded above by its size. This result implies that, under these assumptions,
any test with nontrivial power will exhibit size distortions. We next provide a
sufficient strengthening of the standard assumptions under which we show that a
novel test in the literature can control limiting size.",105,6,674,41.7
2371,postmodern literature,"Nonunique factorization in commutative monoids is often studied using
factorization invariants, which assign to each monoid element a quantity
determined by the factorization structure. For numerical monoids (co-finite,
additive submonoids of the natural numbers), several factorization invariants
have received much attention in the recent literature. In this survey article,
we give an overview of the length set, elasticity, delta set,
$\omega$-primality, and catenary degree invariants in the setting of numerical
monoids. For each invariant, we present current major results in the literature
and identify the primary open questions that remain.",90,5,650,23.26
2372,postmodern literature,"For a simple and connected graph, several lower and upper bounds of graph
invariants expressed in terms of the eigenvalues of the normalized Laplacian
matrix have been proposed in literature. In this paper, through a unified
approach based on majorization techniques, we provide some novel inequalities
depending on additional information on the localization of the eigenvalues of
the normalized Laplacian matrix. Some numerical examples show how sharper
results can be obtained with respect to those existing in literature.",78,4,524,28.17
2373,postmodern literature,"Reference management software is a well-known tool for scientific research
work. Since the 1980s, it has been the subject of reviews and evaluations in
library and information science literature. This paper presents a systematic
review of published studies that evaluate reference management software with a
comparative approach. The objective is to identify the types, models, and
evaluation criteria that authors have adopted, in order to determine whether
the methods used provide adequate methodological rigor and useful contributions
to the field of study.",82,5,561,33.75
2374,postmodern literature,"Based on the known non-linear transformation rules of the Weyl multiplet
fields, the action of $N=4$ conformal supergravity is constructed up to terms
quadratic in the fermion fields. The bosonic sector corrects a recent result in
the literature.",38,3,246,43.73
2375,postmodern literature,"This papers deals with connections between quantum anomalies and
transformations of Feynman pseudo-measures. Mathematical objects related to the
notion of the volume element in an infinite-dimensional space considered in the
physics literature are considered and disagreement in the related literature
regarding the origin of quantum anomalies is explained.",48,3,357,13.28
2376,postmodern literature,"The Yule-Simon distribution is usually employed in the analysis of frequency
data. As the Bayesian literature, so far, ignored this distribution, here we
show the derivation of two objective priors for the parameter of the Yule-Simon
distribution. In particular, we discuss the Jeffreys prior and a loss-based
prior, which has recently appeared in the literature. We illustrate the
performance of the derived priors through a simulation study and the analysis
of real datasets.",73,5,477,35.98
2377,postmodern literature,"Research on vandalism in Wikipedia has been of interest for the last decade.
This paper performs a literature review on the subject, with the goal of
identifying the main research topics and approaches, methods and techniques
used. 67 papers have been reviewed. Main topic is the detection of vandalism,
although there is a increasing interest about content quality. The most
commonly used technique is machine learning, based on feature analysis. It
draws attention to the lack of research on information behavior of vandals.",83,7,526,57.47
2378,postmodern literature,"The rapidly expanding corpus of medical research literature presents major
challenges in the understanding of previous work, the extraction of maximum
information from collected data, and the identification of promising research
directions. We present a case for the use of advanced machine learning
techniques as an aide in this task and introduce a novel methodology that is
shown to be capable of extracting meaningful information from large
longitudinal corpora, and of tracking complex temporal changes within it.",77,3,518,15.48
2379,postmodern literature,"Privacy has been frequently identified as a main concern for system
developers while dealing with/managing personal information. Despite this, most
existing work on privacy requirements deals with them as a special case of
security requirements. Therefore, key aspects of privacy are, usually,
overlooked. In this context, wrong design decisions might be made due to
insufficient understanding of privacy concerns. In this paper, we address this
problem with a systematic literature review whose main purpose is to identify
the main concepts/relations for capturing privacy requirements. In addition,
the identified concepts/relations are further analyzed to propose a novel
privacy ontology to be used by software engineers when dealing with privacy
requirements.",109,7,764,27.62
2380,postmodern literature,"We extend Relative Robust Portfolio Optimisation models to allow portfolios
to optimise their distance to a set of benchmarks. Portfolio managers are also
given the option of computing regret in a way which is more in line with market
practices than other approaches suggested in the literature. In addition, they
are given the choice of simply adding an extra constraint to their optimisation
problem instead of outright changing the objective function, as is commonly
suggested in the literature. We illustrate the benefits of this approach by
applying it to equity portfolios in a variety of regions.",96,5,603,30.2
2381,postmodern literature,"In this paper a new system for piecewise primitive surface recovery on point
clouds is presented, which allows a novice user to sketch areas of interest in
order to guide the fitting process. The algorithm is demonstrated against a
benchmark technique for autonomous surface fitting, and, contrasted against
existing literature in user guided surface recovery, with empirical evidence.
It is concluded that the system is an improvement to the current documented
literature for its visual quality when modelling objects which are composed of
piecewise primitive shapes, and, in its ability to fill large holes on occluded
surfaces using free-form input.",100,4,652,29.22
2382,postmodern literature,"We introduce a class of unbiased Monte Carlo estimators for the multivariate
density of max-stable fields generated by Gaussian processes. Our estimators
take advantage of recent results on exact simulation of max-stable fields
combined with identities studied in the Malliavin calculus literature and ideas
developed in the multilevel Monte Carlo literature. Our approach allows
estimating multivariate densities of max-stable fields with precision
$\varepsilon $ at a computational cost of order $O\left( \varepsilon ^{-2}\log
\log \log \left( 1/\varepsilon \right) \right) $.",80,4,578,19.71
2383,postmodern literature,"There is a large literature on semiparametric estimation of average treatment
effects under unconfounded treatment assignment in settings with a fixed number
of covariates. More recently attention has focused on settings with a large
number of covariates. In this paper we extend lessons from the earlier
literature to this new setting. We propose that in addition to reporting point
estimates and standard errors, researchers report results from a number of
supplementary analyses to assist in assessing the credibility of their
estimates.",81,5,540,33.95
2384,postmodern literature,"Keeping track of the ever-increasing body of scientific literature is an
escalating challenge. We present PubTree a hierarchical search tool that
efficiently searches the PubMed/MEDLINE dataset based upon a decision tree
constructed using >26 million abstracts. The tool is implemented as a webpage,
where users are asked a series of eighteen questions to locate pertinent
articles. The implementation of this hierarchical search tool highlights issues
endemic with document retrieval. However, the construction of this tree
indicates that with future developments hierarchical search could become an
effective tool (or adjunct) in the mining of biological literature.",95,6,668,26.81
2385,postmodern literature,"The literature on regression kink designs develops identification results for
average effects of continuous treatments (Card, Lee, Pei, and Weber, 2015),
average effects of binary treatments (Dong, 2018), and quantile-wise effects of
continuous treatments (Chiang and Sasaki, 2019), but there has been no
identification result for quantile-wise effects of binary treatments to date.
In this paper, we fill this void in the literature by providing an
identification of quantile treatment effects in regression kink designs with
binary treatment variables. For completeness, we also develop large sample
theories for statistical inference and a practical guideline on estimation and
inference.",98,4,691,12.9
2386,postmodern literature,"Characterization of classes of switching signals that ensure stability of
switched systems occupies a significant portion of the switched systems
literature. This article collects a multitude of stabilizing switching signals
under an umbrella framework. We achieve this in two steps: Firstly, given a
family of systems, possibly containing unstable dynamics, we propose a new and
general class of stabilizing switching signals. Secondly, we demonstrate that
prior results based on both point-wise and asymptotic characterizations follow
our result. This is the first attempt in the switched systems literature where
these switching signals are unified under one banner.",96,6,669,26.61
2387,postmodern literature,"This paper studies a class of growing systems of random walks on regular
trees, known as \emph{frog models with geometric lifetime} in the literature.
With the help of results from renewal theory, we derive new bounds for their
critical parameters. Our approach also improve the bounds of the literature for
the critical parameter of a percolation model on trees called \emph{cone
percolation}",62,3,393,33.54
2388,postmodern literature,"Researchers have attempted to model information diffusion and topic trends
and lifecycle on online social networks. They have investigated the role of
content, social connections and communities, familiarity and behavioral
similarity in this context. The current article presents a survey of
representative models that perform topic analysis, capture information
diffusion, and explore the properties of social connections in the context of
online social networks. The article concludes with a set of outlines of open
problems and possible directions of future research interest. This article is
intended for researchers to identify the current literature, and explore
possibilities to improve the art.",100,6,702,17.34
2389,postmodern literature,"This Paper represents a literature review of Swarm intelligence algorithm in
the area of semi-supervised classification. There are many research papers for
applying swarm intelligence algorithms in the area of machine learning. Some
algorithms of SI are applied in the area of ML either solely or hybrid with
other ML algorithms. SI algorithms are also used for tuning parameters of ML
algorithm, or as a backbone for ML algorithms. This paper introduces a brief
literature review for applying swarm intelligence algorithms in the field of
semi-supervised learning",87,5,564,36.89
2390,postmodern literature,"In the present case, we propose the correct version of the fractional
Adams-Bashforth methods which take into account the nonlinearity of the kernels
including the power law for the Riemann-Liouville type, the exponential decay
law for the Caputo-Fabrizio case and the Mittag-Leffler law for the
Atangana-Baleanu scenario. The Adams-Bashforth method for fractional
differentiation suggested and are commonly use in the literature nowadays is
not mathematically correct and the method was derived without taking into
account the nonlinearity of the power law kernel. Unlike the proposed version
found in the literature, our approximation, in all the cases, we are able to
recover the standard case whenever the fractional power $\alpha=1$.",109,4,738,17.71
2391,postmodern literature,"In this work, we have identified the need for choosing baseline approaches
for research-paper recommendation systems. Following a literature survey of all
research paper recommendation approaches described over the last four years, we
framed criteria that makes for a well-rounded set of baselines. These are
implemented on Mr. DLib a literature recommendation platform. User click data
was collected as part of an ongoing experiment in collaboration with our
partner Gesis. We reported the results from our evaluation for the experiments.
We will be able to draw clearer conclusions as time passes. We find that a term
based similarity search performs better than keyword based approaches. These
results are a good starting point in finding performance improvements for
related document searches.",120,10,797,41.06
2392,postmodern literature,"In this paper and demo we present a crowd and crowd+AI based system, called
CrowdRev, supporting the screening phase of literature reviews and achieving
the same quality as author classification at a fraction of the cost, and
near-instantly. CrowdRev makes it easy for authors to leverage the crowd, and
ensures that no money is wasted even in the face of difficult papers or
criteria: if the system detects that the task is too hard for the crowd, it
just gives up trying (for that paper, or for that criteria, or altogether),
without wasting money and never compromising on quality.",99,3,584,29.69
2393,postmodern literature,"Inventory decision frameworks proposed in the literature for single-echelon
supply chain systems rely on assumptions to obtain closed form expressions. In
particular, two such frameworks - one conventional and the other with a demand
undershoot - determine optimal reorder point for a desired $\beta$ or Type-II
service level. In this work we assess the accuracy and applicability of these
frameworks with the help of a discrete event simulation framework developed in
SimPy. While in several cases the closed form literature models under-predict
the service level, and thus result in a higher reorder point and safety stock,
we observe some situations where model predicted service levels match the
simulated results with statistical significance.",112,5,748,26.64
2394,postmodern literature,"We develop new algorithms for estimating heterogeneous treatment effects,
combining recent developments in transfer learning for neural networks with
insights from the causal inference literature. By taking advantage of transfer
learning, we are able to efficiently use different data sources that are
related to the same underlying causal mechanisms. We compare our algorithms
with those in the extant literature using extensive simulation studies based on
large-scale voter persuasion experiments and the MNIST database. Our methods
can perform an order of magnitude better than existing benchmarks while using a
fraction of the data.",92,5,636,22.75
2395,postmodern literature,"Grassmannians are of fundamental importance in projective geometry, algebraic
geometry, and representation theory. A vast literature has grown up utilizing
using many different languages of higher mathematics, such as multilinear and
tensor algebra, matroid theory, and Lie groups and Lie algebras. Here we
explore the basic idea of the Plucker relations in Clifford's geometric
algebra. We discover that the Plucker Relations can be fully characterized in
terms of the geometric product, without the need for a confusing hodgepodge of
many different formalisms and mathematical traditions found in the literature.",89,5,614,15.0
2396,postmodern literature,"Ordinary least squares (OLS) linear regression is one of the most basic
statistical techniques for data analysis. In the main stream literature and the
statistical education, the study of linear regression is typically restricted
to the case where the covariates are fixed, errors are mean zero Gaussians with
variance independent of the (fixed) covariates. Even though OLS has been
studied under misspecification from as early as the 1960's, the implications
have not yet caught up with the main stream literature and applied sciences.
The present article is an attempt at a unified viewpoint that makes the various
implications of misspecification stand out.",102,5,660,37.13
2397,postmodern literature,"In this work, an improvement of H\""{o}lder-McCarty inequality is established.
Based on that, several refinements of the generalized mixed Schwarz inequality
are obtained. Consequently, some new numerical radius inequalities are proved.
New inequalities for numerical radius of $n\times n$ matrix of Hilbert space
operators are proved as well. Some refinements of some earlier results were
proved in literature are also given. Some of the presented results are refined
and it shown to be better than earlier results were proved in literature.",81,7,541,40.85
2398,postmodern literature,"I review the philosophical literature on the question of when two physical
theories are equivalent. This includes a discussion of empirical equivalence,
which is often taken to be necessary, and sometimes taken to be sufficient, for
theoretical equivalence; and ""interpretational"" equivalence, which is the idea
that two theories are equivalent just in case they have the same
interpretation. It also includes a discussion of several formal notions of
equivalence that have been considered in the recent philosophical literature,
including (generalized) definitional equivalence and categorical equivalence.
The article concludes with a brief discussion of the relationship between
equivalence and duality.",99,5,706,12.46
2399,postmodern literature,"Building conversational agents have many technical, design and linguistic
challenges. Other more complex elements include using emotionally intelligent
conversational agent to build trust with the individuals. In this chapter, we
introduce the nature of conversational user interfaces (CUIs) for health and
describe UX design principles informed by a systematic literature review of
relevant research works. We analyze scientific literature in conversational
interfaces and chatterbots, providing a survey of major studies and describing
UX design principles and interaction patterns.",78,5,584,9.38
2400,postmodern literature,"An analysis of the literature shows that there are two types of
non-memristive models that have been widely used in the modeling of so-called
""memristive"" neural networks. Here, we demonstrate that such models have
nothing in common with the concept of memristive elements: they describe either
non-linear resistors or certain bi-state systems, which all are devices without
memory. Therefore, the results presented in a significant number of
publications are at least questionable, if not completely irrelevant to the
actual field of memristive neural networks.",84,4,562,26.14
2401,postmodern literature,"In this article we will analyse how to compute the contribution of each input
value to its aggregate output in some nonlinear models. Regression and
classification applications, together with related algorithms for deep neural
networks are presented. The proposed approach merges two methods currently
present in the literature: integrated gradient and deep Taylor decomposition.
Compared to DeepLIFT and Deep SHAP, it provides a natural choice of the
reference point peculiar to the model at use.",75,5,497,35.47
2402,postmodern literature,"There are different constructions of the flux of triad in loop quantum
gravity, namely the fundamental and alternative flux operators. In parallel to
the consistency check on the two versions of operator by the algebraic calculus
in the literature, we check their consistency by the graphical calculus. Our
calculation based on the original Brink graphical method is obviously simpler
than the algebraic calculation. It turns out that our consistency check fixes
the regulating factor $\kappa_{\rm reg}$ of the Ashtekar-Lewandowski volume
operator as $\frac12$, which corrects its previous value in the literature.",91,5,614,22.95
2403,postmodern literature,"This tutorial review provides a guiding reference to researchers who want to
have an overview of the large body of literature about graph spanners. It
reviews the current literature covering various research streams about graph
spanners, such as different formulations, sparsity and lightness results,
computational complexity, dynamic algorithms, and applications. As an
additional contribution, we offer a list of open problems on graph spanners.",64,4,448,24.48
2404,postmodern literature,"Machine education is an emerging research field that focuses on the problem
which is inverse to machine learning. To date, the literature on educating
machines is still in its infancy. A fairly low number of methodology and method
papers are scattered throughout various formal and informal publication
avenues, mainly because the field is not yet well coalesced (with no well
established discussion forums or investigation pathways), but also due to the
breadth of its potential ramifications and research directions. In this study
we bring together the existing literature and organise the discussion into a
small number of research directions (out of many) which are to date
sufficiently explored to form a minimal critical mass that can push the machine
education concept further towards a standalone research field status.",128,5,827,22.08
2405,postmodern literature,"This paper introduces and defends an account of model-based science that I
dub model pluralism. I argue that despite a growing awareness in the philosophy
of science literature of the multiplicity, diversity, and richness of models
and modeling-practices, more radical conclusions follow from this recognition
than have previously been inferred. Going against the tendency within the
literature to generalize from single models, I explicate and defend the
following two core theses: (i) any successful analysis of models must target
sets of models, their multiplicity of functions within science, and their
scientific context and history and (ii) for almost any aspect x of phenomenon
y, scientists require multiple models to achieve scientific goal z.",113,4,752,7.83
2406,postmodern literature,"This paper presents a detailed study of the knowledge of the Kamilaroi and
Euahlayi peoples about the Emu in the Sky. This study was done with
ethnographic data that was not previously reported in detail. We surveyed the
literature to find that there are widespread reports of an Emu in the Sky
across Australian Aboriginal language groups, but little detailed knowledge
available in the literature. This paper reports and describes a comprehensive
Kamilaroi and Euahlayi knowledge of the Emu in the Sky and its cultural
context.",86,5,529,58.11
2407,postmodern literature,"We present a system, TransProse, that automatically generates musical pieces
from text. TransProse uses known relations between elements of music such as
tempo and scale, and the emotions they evoke. Further, it uses a novel
mechanism to determine sequences of notes that capture the emotional activity
in the text. The work has applications in information visualization, in
creating audio-visual e-books, and in developing music apps.",65,5,435,38.01
2408,postmodern literature,"We derive interesting arctangent identities involving the golden ratio,
Fibonacci numbers and Lucas numbers. Binary BBP-type formulas for the
arctangents of certain odd powers of the golden ratio are also derived, for the
first time in the literature. Finally we derive golden-ratio-base BBP-type
formulas for some mathematical constants, including $\pi$, $\log 2$, $\log\phi$
and $\sqrt 2\,\arctan\sqrt 2$. The $\phi-$nary BBP-type formulas derived here
are considerably simpler than similar results contained in earlier literature.",73,5,533,19.06
2409,postmodern literature,"In their ""How proper are Bayesian models in the astronomical literature?""
[arXiv:1712.03549], Hyungsuk Tak, Sujit K. Ghosh and Justin A. Ellis criticised
my work with false statements. This is an infamous case of straw man fallacy.
They give the impression of refuting an opponent's argument, while they refute
an argument that was not presented.",54,7,346,62.34
2410,postmodern literature,"The aim of this paper is to discuss various concentration inequalities for
U-statistics and most recent results. A special focus will be on providing
proofs for bounds on the U-statistics using classical concentration
inequalities, which, although the results well known, the proofs are not found
in the literature.",48,3,315,38.66
2411,postmodern literature,"Cross section data are compiled from the literature for electron collisions
with nitrogen trifluoride (NF$_3$) molecules. Cross sections are collected and
reviewed for total scattering, elastic scattering, momentum transfer,
excitations of rotational and vibrational states, dissociation, ionization, and
dissociative attachment. For each of these processes, the recommended values of
the cross sections are presented. The literature has been surveyed up to the
end of 2016.",65,5,474,29.55
2412,postmodern literature,"In this study, we propose quantum representation of multi wavelength images
(QRMW) which gives preparation and retrieving procedures of quantum images.
Proposed QRMW model represents multi-channel and 2^n x 2^m images. Also, we
present image comparison and some image operations based on QRMW model.
Comparing our model with the models in literature, QRMW model has less time
complexity. Also QRMW model uses fewer qubits than existing models in the
literature.",70,6,461,40.35
2413,postmodern literature,"Due to the recent advances in vehicular ad hoc networks (VANETs), smart
applications have been incorporating the data generated from these networks to
provide quality of life services. In this paper, we have proposed taxonomy of
data mining techniques that have been applied in this domain in addition to a
classification of these techniques. Our contribution is to highlight the
research methodologies in the literature and allow for comparing among them
using different characteristics. The proposed taxonomy covers elementary data
mining techniques such as: preprocessing, outlier detection, clustering, and
classification of data. In addition, it covers centralized, distributed,
offline, and online techniques from the literature.",105,6,735,24.78
2414,postmodern literature,"This paper addresses the log-optimal portfolio for a general semimartingale
model. The most advanced literature on the topic elaborates existence and
characterization of this portfolio under no-free-lunch-with-vanishing-risk
assumption (NFLVR). There are many financial models violating NFLVR, while
admitting the log-optimal portfolio on the one hand. On the other hand, for
financial markets under progressively enlargement of filtration, NFLVR remains
completely an open issue, and hence the literature can be applied to these
models. Herein, we provide a complete characterization of log-optimal portfolio
and its associated optimal deflator, necessary and sufficient conditions for
their existence, and we elaborate their duality as well without NFLVR.",103,6,757,16.73
2415,postmodern literature,"A reinforcement learning agent tries to maximize its cumulative payoff by
interacting in an unknown environment. It is important for the agent to explore
suboptimal actions as well as to pick actions with highest known rewards. Yet,
in sensitive domains, collecting more data with exploration is not always
possible, but it is important to find a policy with a certain performance
guaranty. In this paper, we present a brief survey of methods available in the
literature for balancing exploration-exploitation trade off and computing
robust solutions from fixed samples in reinforcement learning.",91,5,596,31.41
2416,postmodern literature,"We propose algorithms for online principal component analysis (PCA) and
variance minimization for adaptive settings. Previous literature has focused on
upper bounding the static adversarial regret, whose comparator is the optimal
fixed action in hindsight. However, static regret is not an appropriate metric
when the underlying environment is changing. Instead, we adopt the adaptive
regret metric from the previous literature and propose online adaptive
algorithms for PCA and variance minimization, that have sub-linear adaptive
regret guarantees. We demonstrate both theoretically and experimentally that
the proposed algorithms can adapt to the changing environments.",92,6,672,18.96
2417,postmodern literature,"Entropy numbers are an important tool for quantifying the compactness of
operators. Besides establishing new upper bounds on the entropy numbers of
diagonal operators $D_\sigma$ from $\ell_p$ to $\ell_q$, where $p\not=q$, we
investigate the optimality of these bounds. In case of $p<q$ optimality is
proven for fast decaying diagonal sequences, which include exponentially
decreasing sequences. In case of $p>q$ we show optimality under weaker
assumption than previously used in the literature. In addition, we illustrate
the benefit of our results with examples not covered in the literature so far.",89,6,600,28.03
2418,postmodern literature,"Since the introduction and the public availability of the \textsc{ucr} time
series benchmark data sets, numerous Time Series Classification (TSC) methods
has been designed, evaluated and compared to each others. We suggest a critical
view of TSC performance evaluation protocols put in place in recent TSC
literature. The main goal of this `position' paper is to stimulate discussion
and reflexion about performance evaluation in TSC literature.",66,4,445,32.22
2419,postmodern literature,"The literature half-life value of 65Ga is based on only one experiment
carried out more than 60 years ago and it has a relatively large uncertainty.
In the present work this half-life is determined based on the counting of the
gamma-rays following the beta-decay of 65Ga. Our new recommended half-life is
15.133 +- 0.028 min which is in agreement with the literature value but almost
one order of magnitude more precise.",71,6,420,62.17
2420,postmodern literature,"We propose a set of compositional design patterns to describe a large variety
of systems that combine statistical techniques from machine learning with
symbolic techniques from knowledge representation. As in other areas of
computer science (knowledge engineering, software engineering, ontology
engineering, process mining and others), such design patterns help to
systematize the literature, clarify which combinations of techniques serve
which purposes, and encourage re-use of software components. We have validated
our set of compositional design patterns against a large body of recent
literature.",83,4,603,9.52
2421,postmodern literature,"Shared mobility can provide access to transportation on a custom basis
without vehicle ownership. The advent of connected and automated vehicle
technologies can further enhance the potential benefits of shared mobility
systems. Although the implications of a system with shared autonomous vehicles
have been investigated, the research reported in the literature has exhibited
contradictory outcomes. In this paper, we present a summary of the research
efforts in shared autonomous vehicle systems that have been reported in the
literature to date and discuss potential future research directions.",86,5,596,15.81
2422,postmodern literature,"A new clinical literature search engine, called CupQ, is presented. It aims
to help clinicians stay updated with medical knowledge. Although PubMed is
currently one of the most widely used digital libraries for biomedical
information, it frequently does not return clinically relevant results. CupQ
utilizes a ranking algorithm that filters non-medical journals, compares
semantic similarity between queries, and incorporates journal impact factor and
publication date. It organizes search results into useful categories for
medical practitioners: reviews, guidelines, and studies. Qualitative
comparisons suggest that CupQ may return more clinically relevant information
than PubMed. CupQ is available at https://cupq.io/.",97,9,723,23.53
2423,postmodern literature,"Multiple-TSP, also abbreviated in the literature as mTSP, is an extension of
the Traveling Salesman Problem that lies at the core of many variants of the
Vehicle Routing problem of great practical importance. The current paper
develops and experiments with Self Organizing Maps, Evolutionary Algorithms and
Ant Colony Systems to tackle the MinMax formulation of the Single-Depot
Multiple-TSP. Hybridization between the neural network approach and the two
meta-heuristics shows to bring significant improvements, outperforming results
reported in the literature on a set of problem instances taken from TSPLIB.",88,4,609,16.36
2424,postmodern literature,"Most adaptive finite element strategies employ the D\""orfler marking strategy
to single out certain elements $\mathcal{M} \subseteq \mathcal{T}$ of a
triangulation $\mathcal{T}$ for refinement. In the literature, different
algorithms have been proposed to construct $\mathcal{M}$, where usually two
goals compete: On the one hand, $\mathcal{M}$ should contain a minimal number
of elements. On the other hand, one aims for linear costs with respect to the
cardinality of $\mathcal{T}$. Unlike expected in the literature, we formulate
and analyze an algorithm, which constructs a minimal set $\mathcal{M}$ at
linear costs. Throughout, pseudocodes are given.",92,6,655,35.88
2425,postmodern literature,"We report on our experience with strong stabilization using HIFOO, a toolbox
for H-infinity fixed-order controller design. We applied HIFOO to 21
fixed-order stable H-infinity controller design problems in the literature,
comparing the results with those published for other methods. The results show
that HIFOO often achieves good H-infinity performance with low-order stable
controllers, unlike other methods in the literature.",60,4,429,25.8
2426,postmodern literature,"The literature dealing with data-driven analysis and control problems has
significantly grown in the recent years. Most of the recent literature deals
with linear time-invariant systems in which the uncertainty (if any) is assumed
to be deterministic and bounded; relatively little attention has been devoted
to stochastic linear time-invariant systems. As a first step in this direction,
we propose to equip the recently introduced Data-enabled Predictive Control
algorithm with a data-based Extended Kalman Filter to make use of additional
available input-output data for reducing the effect of noise, without
increasing the computational load of the optimization procedure.",97,4,676,13.31
2427,postmodern literature,"This paper presents a critical review of the challenges to the implementation
of learning technologies with particular focus on developing countries. A
comprehensive literature review on learning technologies was undertaken for the
purpose of understanding the challenges in developing countries. The research
question is: what extent does education empower learners to be full
participants in a socially democratic society? The literature review identified
25 papers relevant to this topic. Challenges are interrelated and to bring
about changes in developing countries, this paper proposes two educational
technology frameworks based on: 1. cultural conceptual framework, and 2.
problem-based constructivist psychology simulation model. The framework and
simulation model are both useful to guide practice and research.",113,8,821,23.32
2428,postmodern literature,"In this article, we obtain several new weighted bounds for the numerical
radius of a Hilbert space operator. The significance of the obtained results is
the way they generalize many existing results in the literature; where certain
values of the weights imply some known results, or refinements of these
results. In the end, we present some numerical examples that show how our
results refine the well known results in the literature, related to this topic.",75,4,457,46.1
2429,postmodern literature,"This technical report presents a Systematic Literature Review (SLR) study
that focuses on identifying and classifying the recent research practices
pertaining to CPS development through MDE approaches. The study evaluates 140
research papers published during 2010-2018. Accordingly, a comprehensive
analysis of various MDE approaches used in the development life-cycle of CPS is
presented. Furthermore, the study identifies the research gaps and areas that
need more investigation. The contribution helps researchers and practitioners
to get an overall understanding of the research trends and existing challenges
for further research/development.",87,6,647,19.97
2430,postmodern literature,"Ontologies are a popular way of representing domain knowledge, in particular,
knowledge in domains related to life sciences. (Semi-)automating the process of
building an ontology has attracted researchers from different communities into
a field called ""Ontology Learning"". We provide a formal specification of the
exact and the probably approximately correct learning models from computational
learning theory. Then, we recall from the literature complexity results for
learning lightweight description logic (DL) ontologies in these models.
Finally, we highlight other approaches proposed in the literature for learning
DL ontologies.",87,6,635,19.97
2431,postmodern literature,"Blockchain is an emerging technology with potential to address issues related
to sustainability. Literature reviews on blockchain and sustainability exist,
but there is a need to consolidate existing results, in particular, in terms of
Sustainable Development Goals (SDG). This extended abstract presents an ongoing
tertiary study based on existing literature reviews to investigate the
relationship between blockchain and sustainability in terms of SDGs. Results
from a pilot analysis of 18 reviews using thematic analysis are presented.",76,5,538,26.81
2432,postmodern literature,"The aim of this paper is to provide a definition of groupoid and cogroupoid
internal to a category which makes use of only one object and morphisms, in
contrast with the two object approach commonly found in the literature. We will
give some examples and we will establish a relation with group objects (and
Hopf algebras). The definitions presented here were designed to simplify some
constructions related to internalizations, Lie groupoids and Hopf algebroids.",74,4,463,46.4
2433,postmodern literature,"We present a novel POMDP planning algorithm called heuristic search value
iteration (HSVI).HSVI is an anytime algorithm that returns a policy and a
provable bound on its regret with respect to the optimal policy. HSVI gets its
power by combining two well-known techniques: attention-focusing search
heuristics and piecewise linear convex representations of the value function.
HSVI's soundness and convergence have been proven. On some benchmark problems
from the literature, HSVI displays speedups of greater than 100 with respect to
other state-of-the-art POMDP value iteration algorithms. We also apply HSVI to
a new rover exploration problem 10 times larger than most POMDP problems in the
literature.",105,7,705,45.25
2434,postmodern literature,"The isovector axial vector form factors of $N \rightarrow \Delta$ transition
are calculated by employing Light-cone QCD sum rules. The analytical results
are analysed by both the conventional method, and also by a Monte Carlo based
approach which allows one to scan all of the parameter space. The predictions
are also compared with the results in the literature, where available. Although
the Monte Carlo analysis predicts large uncertainties in the predicted results,
the predictions obtained by the conventional analysis are in good agreement
with other results in the literature.",89,5,583,40.38
2435,postmodern literature,"A sterile neutrino is a well-motivated and widely studied dark matter
candidate. The most straightforward realization of sterile neutrino dark
matter, through the Dodelson-Widrow mechanism, is now ruled out by a
combination of X-ray and Lyman-\alpha measurements. An alternative production
mechanism that is becoming increasingly popular in the literature is the
freeze-in mechanism, involving frameworks where a feeble coupling to a particle
- usually a scalar beyond the Standard Model - in the thermal bath results in a
gradual accumulation of the sterile neutrino dark matter abundance. This
article reviews the various motivations for realizing such frameworks in the
literature, their common characteristic features, and phenomenological
signatures.",107,5,755,10.94
2436,postmodern literature,"Numerical integration and function approximation on compact Riemannian
manifolds based on eigenfunctions of the Laplace-Beltrami operator have been
widely studied in the recent literature. The standard example in numerical
experiments is the Euclidean sphere. Here, we derive numerically feasible
expressions for the approximation schemes on the Grassmannian manifold, and we
present the associated numerical experiments on the Grassmannian. Indeed, our
experiments illustrate and match the corresponding theoretical results in the
literature.",71,5,543,2.65
2437,postmodern literature,"This chapter will appear in the forthcoming Handbook of Approximate Bayesian
Computation (2018).
  Indirect inference (II) is a classical likelihood-free approach that
pre-dates the main developments of ABC and relies on simulation from a
parametric model of interest to determine point estimates of the parameters. It
is not surprising then that some likelihood-free Bayesian approaches have
harnessed the II literature. This chapter provides an introduction to II and
details the connections between ABC and II. A particular focus is placed on the
use of an auxiliary model with a tractable likelihood function, an approach
commonly adopted in the II literature, to facilitate likelihood-free Bayesian
inferences.",105,6,715,33.24
2438,postmodern literature,"Mixed monotone systems form an important class of nonlinear systems that have
recently received attention in the abstraction-based control design area.
Slightly different definitions exist in the literature, and it remains a
challenge to verify mixed monotonicity of a system in general. In this paper,
we first clarify the relation between different existing definitions of mixed
monotone systems, and then give two sufficient conditions for mixed monotone
functions defined on Euclidean space. These sufficient conditions are more
general than the ones from the existing control literature, and they suggest
that mixed monotonicity is a very generic property. Some discussions are
provided on the computational usefulness of the proposed sufficient conditions.",110,6,762,23.77
2439,postmodern literature,"Topic models are a family of statistical-based algorithms to summarize,
explore and index large collections of text documents. After a decade of
research led by computer scientists, topic models have spread to social science
as a new generation of data-driven social scientists have searched for tools to
explore large collections of unstructured text. Recently, social scientists
have contributed to topic model literature with developments in causal
inference and tools for handling the problem of multi-modality. In this paper,
I provide a literature review on the evolution of topic modeling including
extensions for document covariates, methods for evaluation and interpretation,
and advances in interactive visualizations along with each aspect's relevance
and application for social science research.",115,5,807,16.86
2440,postmodern literature,"A data driven computational model that accounts for more than two material
states has been presented in this work. Presented model can account for
multiple state variables, such as stresses, strains, strain rates and failure
stress, as compared to previously reported models with two states. Model is
used to perform deformation and failure simulations of carbon nanotubes and
carbon nanotube/epoxy nanocomposites. The model capability of capturing the
strain rate dependent deformation and failure has been demonstrated through
predictions against uniaxial test data taken from literature. The predicted
results show a good agreement between data set taken from literature and
simulations.",100,6,690,34.26
2441,postmodern literature,"Previous machine learning (ML) system development research suggests that
emerging software quality attributes are a concern due to the probabilistic
behavior of ML systems. Assuming that detailed development processes depend on
individual developers and are not discussed in detail. To help developers to
standardize their ML system development processes, we conduct a preliminary
systematic literature review on ML system development processes. A search query
of 2358 papers identified 7 papers as well as two other papers determined in an
ad-hoc review. Our findings include emphasized phases in ML system
developments, frequently described practices and tailored traditional software
development practices.",99,6,709,17.54
2442,postmodern literature,"The abstract chemical reaction $$ A+A \to \emptyset, $$ understood as a
Markov chain in continuous time, has been studied in the physical literature
for several years. It has been claimed that this reaction can be described by
means of the stochastic differential equation $$ d \phi = - \phi^2 dt + i \,
\phi \, dW_t, $$ where $i$ is the imaginary unit. This affirmation is, at
least, intriguing, and has led to controversy and criticisms in the literature.
The goal of this work is to give partial evidence that such a description may
be possible.",97,5,548,49.15
2443,postmodern literature,"Our research topic is Human segmentation with static camera. This topic can
be divided into three sub-tasks, which are object detection, instance
identification and segmentation. These sub-tasks are three closely related
subjects. The development of each subject has great impact on the other two
fields. In this literature review, we will first introduce the background of
human segmentation and then talk about issues related to the above three fields
as well as how they interact with each other.",78,6,499,47.18
2444,postmodern literature,"Although the blockchain-based applications are considered to be less
vulnerable due to the nature of the distributed ledger, they did not become the
silver bullet with respect to securing the information against different
security risks. In this paper, we present a literature review on the security
risks that can be mitigated by introducing the blockchain technology, and on
the security risks that are identified in the blockchain-based applications. In
addition, we highlight the application and technology domains where these
security risks are observed. The results of this study could be seen as a
preliminary checklist of security risks when implementing blockchain-based
applications.",102,5,693,28.67
2445,postmodern literature,"BMS group (and it's various generalizations) at null infinity have been
studied extensively in the literature as the symmetry group of asymptotically
flat spacetimes. The intricate relationship between soft theorems and the BMS
symmetries have also motivated the definition of such asymptotic symmetries to
time-like infinity. Although the vector fields that generate the (generalized)
BMS algebra at time-like infinity was defined in the literature, the algebra
has not been investigated. In this paper, we fill this gap. We show that the
super-translations and vector fields that generate sphere diffeomorphisms close
under the modified Lie bracket proposed by Barnich et al.",100,6,677,25.8
2446,postmodern literature,"In this paper, we study the Budgeted Influence Maximization with Delay
Problem, for which the number of literature are limited. We propose an
approximate marginal spread computation\mbox{-}based approach for solving this
problem. The proposed methodology has been implemented with three benchmark
social network datasets and the obtained results are compared with the existing
methods from the literature. Experimental results show that the proposed
approach is able to select seed nodes which leads to more number of influential
nodes with reasonable computational time.",82,5,571,33.75
2447,postmodern literature,"Finding answers related to a pandemic of a novel disease raises new
challenges for information seeking and retrieval, as the new information
becomes available gradually. TREC COVID search track aims to assist in creating
search tools to aid scientists, clinicians, policy makers and others with
similar information needs in finding reliable answers from the scientific
literature. We experiment with different ranking algorithms as part of our
participation in this challenge. We propose a novel method for neural
retrieval, and demonstrate its effectiveness on the TREC COVID search.",87,5,584,32.43
2448,postmodern literature,"A distributed denial-of-service (DDoS) attack is an attack wherein multiple
compromised computer systems flood the bandwidth and/or resources of a target,
such as a server, website or other network resource, and cause a denial of
service for users of the targeted resource. The flood of incoming messages,
connection requests or malformed packets to the target system forces it to slow
down or even crash and shut down, thereby denying service to legitimate users
or systems. This paper presents a literature review of DDoS attacks and the
common defense mechanisms available. It also presents a literature review of
the defenses for low-rate DDoS attacks that have not been handled effectively
hitherto.",110,5,704,43.56
2449,postmodern literature,"Given an infinite subset $\mathcal A \subseteq\mathbb N$, let $A$ denote its
smallest $N$ elements. There is a rich and growing literature on the question
of whether for typical $\alpha\in[0,1]$, the pair correlations of the set
$\alpha A \pmod 1\subset [0,1]$ are asymptotically Poissonian as $N$ increases.
We define an inhomogeneous generalization of the concept of pair correlation,
and we consider the corresponding doubly metric question. Many of the results
from the usual setting carry over to this new setting. Moreover, the double
metricity allows us to establish some new results whose singly metric analogues
are missing from the literature.",100,6,653,34.26
2450,postmodern literature,"In recent years the scientific community has devoted much effort in the
development of deep learning models for the generation of new molecules with
desirable properties (i.e. drugs). This has produced many proposals in
literature. However, a systematic comparison among the different VAE methods is
still missing. For this reason, we propose an extensive testbed for the
evaluation of generative models for drug discovery, and we present the results
obtained by many of the models proposed in literature.",78,7,505,34.76
2451,postmodern literature,"In this article, we prove an inner product inequality for Hilbert space
operators. This inequality, then, is utilized to present a general numerical
radius inequality using convex functions. Applications of the new results
include obtaining new forms that generalize and extend some well known results
in the literature, with an application to the newly defined generalized
numerical radius.
  We emphasize that the approach followed in this article is different from the
approaches used in the literature to obtain the refined versions.",81,5,537,25.49
2452,postmodern literature,"Rapid charger is getting more and more important as the electric vehicle (EV)
getting popular. The rapid charging technique plays an important part in the
electric vehicle development. Multiport converter is used in the rapid charging
technique to reduce the required current and also provides some other
advantages. In this paper, the literature review form multiport converter to
the rapid charger of electric vehicle is introduced. Some topologies of
multiport converter are discussed in the literature review. Triple active
bridge topology (TAB) is selected as it is useful and commonly used. The
feasibility of using Sinusoidal Pulse Width Modulation (SPWM) to control the
converter is also discussed in the simulation part. A simple hardware design
and experiment is included at the end.",122,9,793,39.03
2453,postmodern literature,"Models characterized by autoregressive structure and random coefficients are
powerful tools for the analysis of high-frequency, high-dimensional and
volatile time series. The available literature on such models is broad, but
also sectorial, overlapping, and confusing. Most models focus on one property
of the data, while much can be gained by combining the strength of various
models and their sources of heterogeneity. We present a structured overview of
the literature on autoregressive models with random coefficients. We describe
hierarchy and analogies among models, and for each we systematically list
properties, estimation methods, tests, software packages and typical
applications.",97,6,691,26.4
2454,postmodern literature,"The paper focuses on some versions of connected dominating set problems:
basic problems and multicriteria problems. A literature survey on basic problem
formulations and solving approaches is presented. The basic connected
dominating set problems are illustrated by simplifyed numerical examples. New
integer programming formulations of dominating set problems (with multiset
estimates) are suggested.",53,5,401,7.22
2455,postmodern literature,"In this paper, we provide a review on both fundamentals of social networks
and latent space modeling. The former discusses important topics related to
network description, including vertex characteristics and network structure;
whereas the latter articulates relevant advances in network modeling, including
random graph models, generalized random graph models, exponential random graph
models, and social space models. We discuss in detail several latent space
models provided in literature, providing special attention to distance, class,
and eigen models in the context of undirected, binary networks. In addition, we
also examine empirically the behavior of these models in terms of prediction
and goodness-of-fit using more than twenty popular datasets of the network
literature.",111,5,784,9.42
2456,postmodern literature,"The incomplete version of the Macdonald function has various appellations in
literature and earns a well-deserved reputation of being a computational
challenge. This paper ties together the previously disjoint literature and
presents the basic properties of the incomplete Macdonald function, such as
recurrence and differential relations, series and asymptotic expansions. This
paper also shows that the incomplete Macdonald function, as a simple
closed-form expression, is a particular solution to a parabolic partial
differential equation, which arises naturally in a wide variety of transient
and diffusion-related phenomena.",86,4,629,0.04
2457,postmodern literature,"This paper will investigate the literature surrounding cyber security threats
in the 2020 US Elections. It begins with a brief overview of cyber security and
the current state of cyber security regarding elections. In the main body of
the paper, the focus will be on the literature review of three main areas:
voter suppression, voter fraud, and disinformation, considering their impacts
on the outcome of the election and on the voting public. Having evaluated
sources on each this paper concludes by summarising the areas which have had
the greatest impact on the 2020 US elections.",95,5,584,38.86
2458,postmodern literature,"Robotic Process Automation (RPA) is the automation of rule-based routine
processes to increase efficiency and to reduce costs. Due to the utmost
importance of process automation in industry, RPA attracts increasing attention
in the scientific field as well. This paper presents the state-of-the-art in
the RPA field by means of a Systematic Literature Review (SLR). In this SLR, 63
publications are identified, categorised, and analysed along well-defined
research questions. From the SLR findings, moreover, a framework for
systematically analysing, assessing, and comparing existing as well as upcoming
RPA works is derived. The discovered thematic clusters advise further
investigations in order to develop an even more detailed structural research
approach for RPA.",111,7,769,35.78
2459,postmodern literature,"A new and rapidly growing econometric literature is making advances in the
problem of using machine learning methods for causal inference questions. Yet,
the empirical economics literature has not started to fully exploit the
strengths of these modern methods. We revisit influential empirical studies
with causal machine learning methods and identify several advantages of using
these techniques. We show that these advantages and their implications are
empirically relevant and that the use of these methods can improve the
credibility of causal analysis.",82,5,557,33.75
2460,postmodern literature,"This literature review focuses on the use of Natural Language Generation
(NLG) to automatically detect and generate persuasive texts. Extending previous
research on automatic identification of persuasion in text, we concentrate on
generative aspects through conceptualizing determinants of persuasion in five
business-focused categories: benevolence, linguistic appropriacy, logical
argumentation, trustworthiness, tools and datasets. These allow NLG to increase
an existing message's persuasiveness. Previous research illustrates key aspects
in each of the above mentioned five categories. A research agenda to further
study persuasive NLG is developed. The review includes analysis of
seventy-seven articles, outlining the existing body of knowledge and showing
the steady progress in this research field.",106,7,807,11.21
2461,postmodern literature,"In visualization education, both science and humanities, the literature is
often divided into two parts: the design aspect and the analysis of the
visualization. However, we find limited discussion on how to motivate and
engage visualization students in the classroom. In the field of Writing
Studies, researchers develop tools and frameworks for student peer review of
writing. Based on the literature review from the field of Writing Studies, this
paper proposes a new framework to implement visualization peer review in the
classroom to engage today's students. This framework can be customized for
incremental and double-blind review to inspire students and reinforce critical
thinking about visualization.",105,6,710,24.78
2462,postmodern literature,"Modern spin-foam models of four dimensional gravity are based on a discrete
version of the $Spin(4)$ Plebanski formulation. Beyond what is already in the
literature, we clarify the meaning of different Plebanski sectors in this
classical discrete model. We show that the linearized simplicity constraints
used in the EPRL and FK models are not sufficient to impose a restriction to a
single Plebanski sector, but rather, three Plebanski sectors are mixed. We
propose this as the reason for certain extra `undesired' terms in the
asymptotics of the EPRL vertex analyzed by Barrett et al. This explanation for
the extra terms is new and different from that sometimes offered in the
spin-foam literature thus far.",114,6,710,39.87
2463,postmodern literature,"We present an elementary proof based on a direct calculation of the property
of completeness at constant time of the solutions of the Klein-Gordon equation
for a charged particle in a plane wave electromagnetic field. We also review
different forms of the orthogonality and completeness relations previously
presented in the literature and we discuss the possibility to construct the
Feynman propagator for the particle in a plane-wave laser pulse as an expansion
in terms of Volkov solutions. We show that this leads to a rigorous
justification for the expression of the transition amplitude, currently used in
the literature, for a class of laser assisted or laser induced processes.",108,4,685,18.02
2464,postmodern literature,"In this paper we present a mathematical model for collaborative filtering
implementation in stock market predictions. In popular literature collaborative
filtering, also known as Wisdom of Crowds, assumes that group has a greater
knowledge than the individual while each individual can improve group's
performance by its specific information input. There are commercially available
tools for collaborative stock market predictions and patent protected web-based
software solutions. Mathematics that lies behind those algorithms is not
disclosed in the literature, so the presented model and algorithmic
implementation are the main contributions of this work.",91,5,658,14.49
2465,postmodern literature,"In this work, we prove the existence of solutions for a tripled system of
integral equations using some new results of fixed point theory associated with
measure of noncompactness. These results extend some previous works in the
literature, since the condition under which the operator admits fixed points is
more general than the others in literature.",56,3,352,34.6
2466,postmodern literature,"Several objects in the Extremes literature are special instances of
max-stable random sup-measures. This perspective opens connections to the
theory of random sets and the theory of risk measures and makes it possible to
extend corresponding notions and results from the literature with streamlined
proofs. In particular, it clarifies the role of Choquet random sup-measures and
their stochastic dominance property. Key tools are the LePage representation of
a max-stable random sup-measure and the dual representation of its tail
dependence functional. Properties such as complete randomness, continuity,
separability, coupling, continuous choice, invariance and transformations are
also analysed.",96,6,698,26.61
2467,postmodern literature,"Traditional databases have long since reaped the benefits of multidimensional
indexes. Numerous proposals in the literature describe multidimensional index
designs for P2P systems. However, none of these designs have had real world
implementations. Several proposals for P2P multidimensional indexes are
reviewed and analyzed. Znet and VBI-tree are the most promising from a
technical standpoint. All of the proposed designs assume honest nodes and are
thus open to abuse. This is a critical flaw that must be solved before any of
the proposed systems can be used.",86,8,564,42.07
2468,postmodern literature,"We calculate the energy radiated coherently by a system of $N$ charged non
relativistic particles. It disagrees with the energy loss which is obtained if
one employs the Lorentz Abraham Dirac (LAD) equation for each particle, and
sums up the contributions. This fact was already clearly stated in the
classical literature long ago. The reason for the discrepancy is the omission
of the mixing terms in the Poynting vector. For some simple systems we present
a generalized equation for the radiation reaction force which cures this
defect. The counter examples show that the LAD equation cannot be generally
valid and that all ""proofs"" must fail somewhere. We demonstrate this failure
for some popular examples in the literature.",117,8,728,54.52
2469,postmodern literature,"We describe a number of devices for pulling candy, called taffy pullers,that
are related to pseudo-Anosov maps of punctured spheres. Though the mathematical
connection has long been known for the two most common taffy puller models, we
unearth a rich variety of early designs from the patent literature, and
introduce a new one.",53,3,328,53.04
2470,postmodern literature,"In their recent ""Cluster Failure"" paper, Eklund and colleagues cast doubt on
the accuracy of a widely used statistical test in functional neuroimaging.
Here, we leverage nonparametric methods that control the false discovery rate
to offer more nuanced, quantitative guidance about which findings in the
existing literature can be trusted. We show that, in the task studies examined
by Eklund et al., most clusters originally reported to be significant are
indeed trustworthy by the false discovery rate benchmark.",78,5,513,43.22
2471,postmodern literature,"In this letter, we describe a very general procedure to obtain a causal fit
of the permittivity of materials from experimental data with very few
parameters. Unlike other closed forms proposed in the literature, the
particularity of this approach lies in its independence towards the material or
frequency range at stake. Many illustrative numerical examples are given and
the accuracy of the fitting is compared to other expressions in the literature.",71,4,452,22.04
2472,postmodern literature,"Defining various dishonest notions in a formal way is a key step to enable
intelligent agents to act in untrustworthy environments. This review evaluates
the literature for this topic by looking at formal definitions based on modal
logic as well as other formal approaches. Criteria from philosophical
groundwork is used to assess the definitions for correctness and completeness.
The key contribution of this review is to show that only a few definitions
fully comply with this gold standard and to point out the missing steps towards
a successful application of these definitions in an actual agent environment.",97,5,613,29.89
2473,postmodern literature,"Using sequence to sequence algorithms for query expansion has not been
explored yet in Information Retrieval literature nor in Question-Answering's.
We tried to fill this gap in the literature with a custom Query Expansion
engine trained and tested on open datasets. Starting from open datasets, we
built a Query Expansion training set using sentence-embeddings-based Keyword
Extraction. We therefore assessed the ability of the Sequence to Sequence
neural networks to capture expanding relations in the words embeddings' space.",77,5,528,43.43
2474,postmodern literature,"Potential benefits such as agile service delivery have led many companies to
deliver their business capabilities through microservices. Bad smells are
however always around the corner, as witnessed by the considerable body of
literature discussing architectural smells that possibly violate the design
principles of microservices. In this paper, we systematically review the white
and grey literature on the topic, in order to identify the most recognised
architectural smells for microservices and to discuss the architectural
refactorings allowing to resolve them.",80,4,566,18.99
2475,postmodern literature,"To implement dual phase grating x-ray interferometry with x-ray tubes, one
needs to incorporate an absorbing source grating. In order to attain good
fringe visibility, the period of a source grating should be subject to a
stringent condition. In literature some authors claim that the Lau-condition in
Talbot-Lau interferometry can be literally transferred to dual phase grating
interferometry. In this work we show that this statement in literature is
incorrect. Instead, through an intuitive geometrical analysis of fringe
formation, we derived a new generalized Lau-condition that provides a useful
design tool for implementation of dual phase grating interferometry.",98,6,670,26.2
2476,postmodern literature,"As a Bayesian approach to fitting motorway traffic flow models remains rare
in the literature, we explore empirically the sampling challenges this approach
offers which have to do with the strong correlations and multi-modality of the
posterior distribution. In particular, we provide a unified statistical model
to estimate using motorway data both boundary conditions and fundamental
diagram parameters in LWR, a well known motorway traffic flow model. This
allows us to provide a traffic flow density estimation method that is shown to
be superior to two methods found in the traffic flow literature. To sample from
this challenging posterior distribution we use a state-of-the-art gradient-free
function space sampler augmented with parallel tempering.",112,5,756,17.68
2477,postmodern literature,"In this manuscript, we define and study probabilistic values for cooperative
games on simplicial complexes. Inspired by the work of Weber ""Probabilistic
values for games"", we establish the new theory step by step, following the
classical axiomatization, i.e. using the linearity axiom, the dummy axiom, etc.
  Furthermore, we define Shapley values on simplicial complexes generalizing
the classical notion in literature. Remarkably, the traditional axiomatization
of Shapley values can be extended to this general setting for a rather
interesting class of complexes that generalize the notion of vertex-transitive
graphs and vertex-homogeneous simplicial complexes. These combinatorial objects
are very popular in the literature because of the study of Evasiveness
Conjecture in Complexity Theory.",111,8,797,10.4
2478,postmodern literature,"In a polynomial regression model, the divisibility conditions implicit in
polynomial hierarchy give way to a natural construction of constraints for the
model parameters. We use this principle to derive versions of strong and weak
hierarchy and to extend existing work in the literature, which at the moment is
only concerned with models of degree two. We discuss how to estimate parameters
in lasso using standard quadratic programming techniques and apply our proposal
to both simulated data and examples from the literature. The proposed
methodology compares favorably with existing techniques in terms of low
validation error and model size.",99,5,645,20.92
2479,postmodern literature,"We present a formulation of the relative depth estimation from a single image
problem, as a ranking problem. By reformulating the problem this way, we were
able to utilize literature on the ranking problem, and apply the existing
knowledge to achieve better results. To this end, we have introduced a listwise
ranking loss borrowed from ranking literature, weighted ListMLE, to the
relative depth estimation problem. We have also brought a new metric which
considers pixel depth ranking accuracy, on which our method is stronger.",84,5,529,41.7
2480,postmodern literature,"Reinforcement learning is important part of artificial intelligence. In this
paper, we review model-free reinforcement learning that utilizes the average
reward optimality criterion in the infinite horizon setting. Motivated by the
solo survey by Mahadevan (1996a), we provide an updated review of work in this
area and extend it to cover policy-iteration and function approximation methods
(in addition to the value-iteration and tabular counterparts). We present a
comprehensive literature mapping. We also identify and discuss opportunities
for future work.",79,6,560,13.14
2481,postmodern literature,"In this paper, finite element method is applied to Leland's model for
numerical simulation of option pricing with transaction costs. Spatial finite
element models based on P1 and/or P2 elements are formulated in combination
with a Crank-Nicolson-type temporal scheme. The temporal scheme is implemented
using the Rannacher approach. Examples with several sets of parameter values
are presented and compared with finite difference results in the literature.
Spatial-temporal mesh-size ratios are observed for controlling the stability of
our method. Our results compare favorably with the finite difference results in
the literature for the model.",93,7,646,30.36
2482,postmodern literature,"Over the last decade or so, Approximate Message Passing (AMP) algorithms have
become extremely popular in various structured high-dimensional statistical
problems. The fact that the origins of these techniques can be traced back to
notions of belief propagation in the statistical physics literature lends a
certain mystique to the area for many statisticians. Our goal in this work is
to present the main ideas of AMP from a statistical perspective, to illustrate
the power and flexibility of the AMP framework. Along the way, we strengthen
and unify many of the results in the existing literature.",95,5,599,47.32
2483,postmodern literature,"In recent years, the axiomatic approach to centrality measures has attracted
attention in the literature. However, most papers propose a collection of
axioms dedicated to one or two considered centrality measures. In result, it is
hard to capture the differences and similarities between various measures. In
this paper, we propose an axiom system for four classic feedback centralities:
Eigenvector centrality, Katz centrality, Katz prestige and PageRank. We prove
that each of these four centrality measures can be uniquely characterized with
a subset of our axioms. Our system is the first one in the literature that
considers all four feedback centralities.",100,7,661,37.6
2484,postmodern literature,"The authors of the article have reviewed the scientific literature on the
development of the Russian-Chinese cooperation in the field of combining
economic and logistics projects of the Eurasian Economic Union and the Silk
Road Economic Belt. The opinions of not only Russian, but also Chinese experts
on these projects are indicated, which provides the expansion of the vision of
the concept of the New Silk Road in both countries.",70,3,432,35.95
2485,postmodern literature,"Although there are several proposals of relativistic spin in the literature,
the recognition of intrinsicality as a key characteristic for the definition of
this concept is responsible for selecting a single tensor operator that
adequately describes such a quantity. This intrinsic definition does not
correspond to Wigner's spin operator, which is the definition that is widely
adopted in the relativistic quantum information theory literature. Here, the
differences between the predictions obtained considering the intrinsic spin and
Wigner's spin are investigated. The measurements involving the intrinsic spin
are modeled by means of the interaction with an electromagnetic field in a
relativistic Stern-Gerlach setup.",102,5,722,11.75
2486,postmodern literature,"For delivering products or services to their clients, organizations execute
manifold business processes. During such execution, upcoming process tasks need
to be allocated to internal resources. Resource allocation is a complex
decision-making problem with high impact on the effectiveness and efficiency of
processes. A wide range of approaches was developed to support research
allocation automatically. This systematic literature survey provides an
overview of approaches and categorizes them regarding their resource allocation
goals and capabilities, their use of models and data, their algorithmic
solutions, and their maturity. Rule-based approaches were identified as
dominant, but heuristics and learning approaches also play a relevant role.",102,7,751,11.92
2487,postmodern literature,"There is a large amount of literature on the topic of covarieties,
coequations and coequational specifications, dating back to the early
seventies. Nevertheless, coequations have not (yet) emerged as an everyday
practical specification formalism for computer scientists. In this review
paper, we argue that this is partly due to the multitude of syntaxes for
writing down coequations, which seems to have led to some confusion about what
coequations are and what they are for. By surveying the literature, we identify
four types of syntaxes: coequations-as-corelations, coequations-as-predicates,
coequations-as-equations, and coequations-as-modal-formulas. We present each of
these in a tutorial fashion, relate them to each other, and discuss their
respective uses.",108,6,767,24.17
2488,postmodern literature,"The paper is concerned with common shock models of claim triangles. These are
usually constructed as a linear combinations of shock components and
idiosyncratic components. Previous literature has discussed the unbalanced
property of such models, whereby the shocks may over- or under-contribute to
some observations. The literature has also introduced corrections for this. The
present paper discusses 'auto-balanced' models, in which all shock and
idiosyncratic components contribute to observations such that their
proportionate contributions are constant from one observation to another. The
conditions for auto-balance are found to be simple and applicable to a wide
range of model structures. Numerical illustrations are given.",103,8,733,31.17
2489,postmodern literature,"In this short note, we reify the connection between work on the storage
capacity problem in wide two-layer treelike neural networks and the
rapidly-growing body of literature on kernel limits of wide neural networks.
Concretely, we observe that the ""effective order parameter"" studied in the
statistical mechanics literature is exactly equivalent to the infinite-width
Neural Network Gaussian Process Kernel. This correspondence connects the
expressivity and trainability of wide two-layer neural networks.",71,4,506,22.04
2490,postmodern literature,"We establish general upper bounds on the Kolmogorov distance between two
probability distributions in terms of the distance between these distributions
as measured with respect to the Wasserstein or smooth Wasserstein metrics.
These bounds generalise existing results from the literature. To illustrate the
broad applicability of our general bounds, we apply them to extract Kolmogorov
distance bounds from multivariate normal, beta and variance-gamma
approximations that have been established in the Stein's method literature.",73,4,527,29.89
2491,postmodern literature,"Explainable reinforcement learning (XRL) is an emerging subfield of
explainable machine learning that has attracted considerable attention in
recent years. The goal of XRL is to elucidate the decision-making process of
learning agents in sequential decision-making settings. In this survey, we
propose a novel taxonomy for organizing the XRL literature that prioritizes the
RL setting. We overview techniques according to this taxonomy. We point out
gaps in the literature, which we use to motivate and outline a roadmap for
future work.",81,6,537,38.11
2492,postmodern literature,"In recent years, the interest in developing adaptive solutions for online
testing has grown significantly in the industry. While the advances related to
this relative new technology have been developed in multiple domains, it lacks
in the literature a systematic and complete treatment of the procedure that
involves exploration, inference, and analysis. This short paper aims to develop
a comprehensive understanding of adaptive online testing, including various
building blocks and analytical results. We also address the latest
developments, research directions, and challenges that have been less mentioned
in the literature.",90,5,629,23.26
2493,postmodern literature,"This article provides a review of the literature on rigorous definitions and
constructions in Quantum Field Theory, spanning the period of seven decades.
Comparing with the ideas and constructions found in the modern physics
literature, we conclude that none of the existing systems of QFT axioms can
cover all the physical situations. Therefore, it is still an outstanding open
problem to formulate a complete definition of QFT. We argue that the question
is of relevance for both physicists and mathematicians.",80,5,512,42.72
2494,postmodern literature,"We aim to contribute to the literature on product space and diversification
by proposing a number of extensions of the current literature: (1) we propose
that the alternative but related idea of a country space also has empirical and
theoretical appeal; (2) we argue that the loss of comparative advantage should
be an integral part of (testing the empirical relevance of) the product space
idea; (3) we propose several new indicators for measuring relatedness in
product space; and (4) we propose a non-parametric statistical test based on
bootstrapping to test the empirical relevance of the product space idea.",98,2,613,-44.92
2495,postmodern literature,"We introduce ReservoirComputing.jl, an open source Julia library for
reservoir computing models. The software offers a great number of algorithms
presented in the literature, and allows to expand on them with both internal
and external tools in a simple way. The implementation is highly modular, fast
and comes with a comprehensive documentation, which includes reproduced
experiments from literature. The code and documentation are hosted on Github
under an MIT license https://github.com/SciML/ReservoirComputing.jl.",71,8,519,31.68
2496,postmodern literature,"Rickrolling is an Internet cultural phenomenon born in the mid 2000s.
Originally confined to Internet fora, it has spread to other channels and
media. In this paper, we hypothesize that rickrolling has reached the formal
academic world. We design and conduct a systematic experiment to survey
rickrolling in the academic literature. As of March 2022, there are 23 academic
documents intentionally rickrolling the reader. Rickrolling happens in
footnotes, code listings, references. We believe that rickrolling in academia
proves inspiration and facetiousness, which is healthy for good science. This
original research suggests areas of improvement for academic search engines and
calls for more investigations about academic pranks and humor.",108,9,742,40.85
2497,postmodern literature,"We show that identities involving trigonometric sums recently proved by
Harshitha, Vasuki and Yathirajsharma, using Ramanujan's theory of theta
functions, were either already in the literature or can be proved easily by
adapting results that can be found in the literature. Also we prove two
conjectures given in that paper. After mentioning many other works dealing with
identities for various trigonometric sums, we end this paper by describing an
automated approach for proving such trigonometric identities.",76,4,511,28.88
2498,postmodern literature,"The importance of context in data quality (DQ) was shown many years ago and
nowadays is widely accepted. Early approaches and surveys defined DQ as
\textit{fitness for use} and showed the influence of context on DQ. This paper
presents a Systematic Literature Review (SLR) for investigating how context is
taken into account in recent proposals for DQ management. We specifically
present the planning and execution of the SLR, the analysis criteria and our
results reflecting the relationship between context and DQ in the state of the
art and, particularly, how that context is defined and used for DQ management.",99,5,614,37.84
2499,postmodern literature,"Fog computing, as a distributed paradigm, offers cloud-like services at the
edge of the network with low latency and high-access bandwidth to support a
diverse range of IoT application scenarios. To fully utilize the potential of
this computing paradigm, scalable, adaptive, and accurate scheduling mechanisms
and algorithms are required to efficiently capture the dynamics and
requirements of users, IoT applications, environmental properties, and
optimization targets. This paper presents a taxonomy of recent literature on
scheduling IoT applications in Fog computing. Based on our new classification
schemes, current works in the literature are analyzed, research gaps of each
category are identified, and respective future directions are described.",106,5,753,19.2
2500,sociolinguistics,"Language is a social phenomenon and variation is inherent to its social
nature. Recently, there has been a surge of interest within the computational
linguistics (CL) community in the social dimension of language. In this article
we present a survey of the emerging field of ""Computational Sociolinguistics""
that reflects this increased interest. We aim to provide a comprehensive
overview of CL research on sociolinguistic themes, featuring topics such as the
relation between language and social identity, language use in social
interaction and multilingual communication. Moreover, we demonstrate the
potential for synergy between the research communities involved, by showing how
the large-scale data-driven methods that are widely used in CL can complement
existing sociolinguistic studies, and how sociolinguistics can inform and
challenge the methods and assumptions employed in CL studies. We hope to convey
the possible benefits of a closer collaboration between the two communities and
conclude with a discussion of open challenges.",152,7,1042,20.42
2501,sociolinguistics,"Emotion classification is a challenging task in NLP due to the inherent
idiosyncratic and subjective nature of linguistic expression, especially with
code-mixed data. Pre-trained language models (PLMs) have achieved high
performance for many tasks and languages, but it remains to be seen whether
these models learn and are robust to the differences in emotional expression
across languages. Sociolinguistic studies have shown that Hinglish speakers
switch to Hindi when expressing negative emotions and to English when
expressing positive emotions. To understand if language models can learn these
associations, we study the effect of language on emotion prediction across 3
PLMs on a Hinglish emotion classification dataset. Using LIME and token level
language ID, we find that models do learn these associations between language
choice and emotional expression. Moreover, having code-mixed data present in
the pre-training can augment that learning when task-specific data is scarce.
We also conclude from the misclassifications that the models may overgeneralise
this heuristic to other infrequent examples where this sociolinguistic
phenomenon does not apply.",167,8,1164,38.76
2502,sociolinguistics,"While language competition models of diachronic language shift are
increasingly sophisticated, drawing on sociolinguistic components like variable
language prestige, distance from language centers and intermediate bilingual
transitionary populations, in one significant way they fall short. They fail to
consider contact-based outcomes resulting in mixed language practices, e.g.
outcome scenarios such as creoles or unmarked code switching as an emergent
communicative norm. On these lines something very interesting is uncovered in
India, where traditionally there have been monolingual Hindi speakers and
Hindi/English bilinguals, but virtually no monolingual English speakers. While
the Indian census data reports a sharp increase in the proportion of
Hindi/English bilinguals, we argue that the number of Hindi/English bilinguals
in India is inaccurate, given a new class of urban individuals speaking a mixed
lect of Hindi and English, popularly known as ""Hinglish"". Based on
predator-prey, sociolinguistic theories, salient local ecological factors and
the rural-urban divide in India, we propose a new mathematical model of
interacting monolingual Hindi speakers, Hindi/English bilinguals and Hinglish
speakers. The model yields globally asymptotic stable states of coexistence, as
well as bilingual extinction. To validate our model, sociolinguistic data from
different Indian classes are contrasted with census reports: We see that
purported urban Hindi/English bilinguals are unable to maintain fluent Hindi
speech and instead produce Hinglish, whereas rural speakers evidence
monolingual Hindi. Thus we present evidence for the first time where an
unrecognized mixed lect involving English but not ""English"", has possibly taken
over a sizeable faction of a large global population.",248,11,1793,18.08
2503,sociolinguistics,"Public health practitioners and policy makers grapple with the challenge of
devising effective message-based interventions for debunking public health
misinformation in cyber communities. ""Framing"" and ""personalization"" of the
message is one of the key features for devising a persuasive messaging
strategy. For an effective health communication, it is imperative to focus on
""preference-based framing"" where the preferences of the target sub-community
are taken into consideration. To achieve that, it is important to understand
and hence characterize the target sub-communities in terms of their social
interactions. In the context of health-related misinformation, vaccination
remains to be the most prevalent topic of discord. Hence, in this paper, we
conduct a sociolinguistic analysis of the two competing vaccination communities
on Twitter: ""pro-vaxxers"" or individuals who believe in the effectiveness of
vaccinations, and ""anti-vaxxers"" or individuals who are opposed to
vaccinations. Our data analysis show significant linguistic variation between
the two communities in terms of their usage of linguistic intensifiers,
pronouns, and uncertainty words. Our network-level analysis show significant
differences between the two communities in terms of their network density,
echo-chamberness, and the EI index. We hypothesize that these sociolinguistic
differences can be used as proxies to characterize and understand these
communities to devise better message interventions.",203,10,1483,14.7
2504,sociolinguistics,"People tend to align their use of language to the linguistic behaviour of
their own ingroup and to simultaneously diverge from the language use of
outgroups. This paper proposes to model this phenomenon of sociolinguistic
identity maintenance as an evolutionary game in which individuals play the
field and the dynamics are supplied by a multi-population extension of the
replicator-mutator equation. Using linearization, the stabilities of all
dynamic equilibria of the game in its fully symmetric two-population special
case are found. The model is then applied to an empirical test case from
adolescent sociolinguistic behaviour. It is found that the empirically attested
population state corresponds to one of a number of stable equilibria of the
game under an independently plausible value of a parameter controlling the rate
of linguistic mutations. An asymmetric three-population extension of the game,
explored with numerical solution methods, furthermore predicts to which
specific equilibrium the system converges.",150,7,1024,20.72
2505,sociolinguistics,"The aim of this study is to determine the effect of language varieties on the
spectral distribution of stressed and unstressed sonorants (nasals /m, n/,
lateral approximants /l/, and rhotics /r/) and on their coarticulatory effects
on adjacent sounds. To quantify the shape of the spectral distribution, we
calculated the spectral moments from the sonorant spectra of nasals /m, n/,
lateral approximants /l/, and rhotics /r/ produced by Athenian Greek and
Cypriot Greek speakers. To estimate the co-articulatory effects of sonorants on
the adjacent vowels' F1 - F4 formant frequencies, we developed polynomial
models of the adjacent vowel's formant contours. We found significant effects
of language variety (sociolinguistic information) on the spectral moments of
each sonorant /m/, /n/, /l/, /r/ (except between /m/ and /n/) and on the
formant contours of the adjacent vowel. All sonorants (including /m/ and /n/)
had distinct effects on adjacent vowel's formant contours, especially for F3
and F4. The study highlights that the combination of spectral moments and
coarticulatory effects of sonorants determines linguistic (stress and phonemic
category) and sociolinguistic (language variety) characteristics of sonorants.
It also provides the first comparative acoustic analysis of Athenian Greek and
Cypriot Greek sonorants.",195,8,1328,26.44
2506,sociolinguistics,"Individuals signal aspects of their identity and beliefs through linguistic
choices. Studying these choices in aggregate allows us to examine large-scale
attitude shifts within a population. Here, we develop computational methods to
study word choice within a sociolinguistic lexical variable -- alternate words
used to express the same concept -- in order to test for change in the United
States towards sexuality and gender. We examine two variables: i) referents to
significant others, such as the word ""partner"" and ii) referents to an
indefinite person, both of which could optionally be marked with gender. The
linguistic choices in each variable allow us to study increased rates of
acceptances of gay marriage and gender equality, respectively. In longitudinal
analyses across Twitter and Reddit over 87M messages, we demonstrate that
attitudes are changing but that these changes are driven by specific
demographics within the United States. Further, in a quasi-causal analysis, we
show that passages of Marriage Equality Acts in different states are drivers of
linguistic change.",165,8,1089,39.37
2507,sociolinguistics,"We study the stability of the cohabitation of French and Dutch in the
Brussels-capital region (Belgium). To this aim, we use available time series of
fractions of speakers of monolinguals of both tongues as well as the fractions
of bilinguals. The time series span a period from the mid-XIX century until
1947, year of the last accepted linguistic census. During this period, French
penetrated the Dutch-vernacular region of Brussels and started a language shift
that lasts to this day. The available time series are analyzed with a
mathematical model of sociolinguistic dynamics that accounts for cohabitation
of languages along bilingualism. Our equations are compatible with long-term
coexistence of both languages, or with one tongue taking over and extinguishing
the other. A series of model parameters (which we constrain by fitting our
equations to the data) determine which long-term trajectory (cohabitation or
extinction) would be followed. This allows us to estimate whether the empirical
data are compatible with a coexistence of Dutch and French -- in physics terms,
whether both tongues are {\em miscible}. Our results tilt towards
non-coexistence, or coexistence with a starkly-dominated, minority language.
The costs of attempting to sustain such sociolinguistic system are discussed.",196,11,1300,43.22
2508,sociolinguistics,"This abstract proposes an approach towards goal-oriented modeling of the
detection and modeling complex social phenomena in multiparty discourse in an
online political strategy game. We developed a two-tier approach that first
encodes sociolinguistic behavior as linguistic features then use reinforcement
learning to estimate the advantage afforded to any player. In the first tier,
sociolinguistic behavior, such as Friendship and Reasoning, that speakers use
to influence others are encoded as linguistic features to identify the
persuasive strategies applied by each player in simultaneous two-party
dialogues. In the second tier, a reinforcement learning approach is used to
estimate a graph-aware reward function to quantify the advantage afforded to
each player based on their standing in this multiparty setup. We apply this
technique to the game Diplomacy, using a dataset comprising of over 15,000
messages exchanged between 78 users. Our graph-aware approach shows robust
performance compared to a context-agnostic setup.",148,7,1032,21.02
2509,sociolinguistics,"Politeness plays an important role in regulating communication and enhancing
social interactions.Research suggests that people treat interactive systems as
social agents and may expect those systems to exhibit polite behavior. We
augment early research in this area by proposing a framework that is grounded
in sociolinguistics and pragmatics. The framework focuses on two complementary
concepts - clarity and politeness. We suggest that these concepts are pertinent
to various domains of interactive technologies and provide examples for the
applicability of clarity and politeness rules to human-computer interaction
(HCI). We conducted a laboratory experiment, in which politeness and clarity
served as independent factors in the context of a cooperative computer game,
based on the Peekaboom game. The manipulation of clarity failed, yet politeness
was manipulated successfully based on the framework's rules of politeness. The
results provide empirical support for the basic propositions of the framework
and may facilitate more systematic research on politeness in various domains of
social computing and other areas related to HCI.",163,9,1138,17.03
2510,sociolinguistics,"We investigate the birth and diffusion of lexical innovations in a large
dataset of online social communities. We build on sociolinguistic theories and
focus on the relation between the spread of a novel term and the social role of
the individuals who use it, uncovering characteristics of innovators and
adopters. Finally, we perform a prediction task that allows us to anticipate
whether an innovation will successfully spread within a community.",70,4,448,22.45
2511,sociolinguistics,"We introduce a framework for quantifying semantic variation of common words
in Communities of Practice and in sets of topic-related communities. We show
that while some meaning shifts are shared across related communities, others
are community-specific, and therefore independent from the discussed topic. We
propose such findings as evidence in favour of sociolinguistic theories of
socially-driven semantic variation. Results are evaluated using an independent
language modelling task. Furthermore, we investigate extralinguistic features
and show that factors such as prominence and dissemination of words are related
to semantic variation.",88,6,643,19.77
2512,sociolinguistics,"We study how emojis are used to express solidarity in social media in the
context of two major crisis events - a natural disaster, Hurricane Irma in 2017
and terrorist attacks that occurred on November 2015 in Paris. Using annotated
corpora, we first train a recurrent neural network model to classify
expressions of solidarity in text. Next, we use these expressions of solidarity
to characterize human behavior in online social networks, through the temporal
and geospatial diffusion of emojis. Our analysis reveals that emojis are a
powerful indicator of sociolinguistic behaviors (solidarity) that are exhibited
on social media as the crisis events unfold.",103,5,660,20.21
2513,sociolinguistics,"We conduct a quantitative analysis contrasting human-written English news
text with comparable large language model (LLM) output from 4 LLMs from the
LLaMa family. Our analysis spans several measurable linguistic dimensions,
including morphological, syntactic, psychometric and sociolinguistic aspects.
The results reveal various measurable differences between human and
AI-generated texts. Among others, human texts exhibit more scattered sentence
length distributions, a distinct use of dependency and constituent types,
shorter constituents, and more aggressive emotions (fear, disgust) than
LLM-generated texts. LLM outputs use more numbers, symbols and auxiliaries
(suggesting objective language) than human texts, as well as more pronouns. The
sexist bias prevalent in human text is also expressed by LLMs.",109,7,812,27.62
2514,sociolinguistics,"There have been recent advances in computer-based recognition of isolated,
citation-form signs from video. There are many challenges for such a task, not
least the naturally occurring inter- and intra- signer synchronic variation in
sign production, including sociolinguistic variation in the realization of
certain signs. However, there are several significant factors that make
recognition of signs from continuous signing an even more difficult problem.
This article presents an overview of such challenges, based in part on findings
from a large corpus of linguistically annotated video data for American Sign
Language (ASL). Some linguistic regularities in the structure of signs that can
boost handshape and sign recognition are also discussed.",109,6,750,32.43
2515,sociolinguistics,"Twitter is one of the most popular social media. Due to the ease of
availability of data, Twitter is used significantly for research purposes.
Twitter is known to evolve in many aspects from what it was at its birth;
nevertheless, how it evolved its own linguistic style is still relatively
unknown. In this paper, we study the evolution of various sociolinguistic
aspects of Twitter over large time scales. To the best of our knowledge, this
is the first comprehensive study on the evolution of such aspects of this OSN.
We performed quantitative analysis both on the word level as well as on the
hashtags since it is perhaps one of the most important linguistic units of this
social media. We studied the (in)formality aspects of the linguistic styles in
Twitter and find that it is neither fully formal nor completely informal; while
on one hand, we observe that Out-Of-Vocabulary words are decreasing over time
(pointing to a formal style), on the other hand it is quite evident that
whitespace usage is getting reduced with a huge prevalence of running texts
(pointing to an informal style). We also analyze and propose quantitative
reasons for repetition and coalescing of hashtags in Twitter. We believe that
such phenomena may be strongly tied to different evolutionary aspects of human
languages.",216,10,1305,47.12
2516,sociolinguistics,"Our usage of language is not solely reliant on cognition but is arguably
determined by myriad external factors leading to a global variability of
linguistic patterns. This issue, which lies at the core of sociolinguistics and
is backed by many small-scale studies on face-to-face communication, is
addressed here by constructing a dataset combining the largest French Twitter
corpus to date with detailed socioeconomic maps obtained from national census
in France. We show how key linguistic variables measured in individual Twitter
streams depend on factors like socioeconomic status, location, time, and the
social network of individuals. We found that (i) people of higher socioeconomic
status, active to a greater degree during the daytime, use a more standard
language; (ii) the southern part of the country is more prone to use more
standard language than the northern one, while locally the used variety or
dialect is determined by the spatial distribution of socioeconomic status; and
(iii) individuals connected in the social network are closer linguistically
than disconnected ones, even after the effects of status homophily have been
removed. Our results inform sociolinguistic theory and may inspire novel
learning methods for the inference of socioeconomic status of people from the
way they tweet.",200,6,1312,22.42
2517,sociolinguistics,"This research offers a new interdisciplinary approach to the field of
Linguistics by using Computational Linguistics, NLP, Bayesian Statistics and
Sociolinguistics methods. This thesis investigates word order change in
infinitival clauses from Object-Verb (OV) to Verb-Object (VO) in the history of
Latin and Old French. By applying a variationist approach, I examine a
synchronic word order variation in each stage of language change, from which I
infer the character, periodization and constraints of diachronic variation. I
also show that in discourse-configurational languages, such as Latin and Early
Old French, it is possible to identify pragmatically neutral contexts by using
information structure annotation. I further argue that by mapping pragmatic
categories into a syntactic structure, we can detect how word order change
unfolds. For this investigation, the data are extracted from annotated corpora
spanning several centuries of Latin and Old French and from additional
resources created by using computational linguistic methods. The data are then
further codified for various pragmatic, semantic, syntactic and sociolinguistic
factors. This study also evaluates previous factors proposed to account for
word order alternation and change. I show how information structure and
syntactic constraints change over time and propose a method that allows
researchers to differentiate a stable word order alternation from alternation
indicating a change. Finally, I present a three-stage probabilistic model of
word order change, which also conforms to traditional language change patterns.",228,11,1599,22.95
2518,sociolinguistics,"This paper examines 3,517 Facebook ads created by Russia's Internet Research
Agency (IRA) between June 2015 and August 2017 in its active measures
disinformation campaign targeting the 2016 U.S. general election. We aimed to
unearth the relationship between ad engagement (as measured by ad clicks) and
41 features related to ads' metadata, sociolinguistic structures, and
sentiment. Our analysis was three-fold: (i) understand the relationship between
engagement and features via correlation analysis; (ii) find the most relevant
feature subsets to predict engagement via feature selection; and (iii) find the
semantic topics that best characterize the dataset via topic modeling. We found
that ad expenditure, text size, ad lifetime, and sentiment were the top
features predicting users' engagement to the ads. Additionally, positive
sentiment ads were more engaging than negative ads, and sociolinguistic
features (e.g., use of religion-relevant words) were identified as highly
important in the makeup of an engaging ad. Linear SVM and Logistic Regression
classifiers achieved the highest mean F-scores (93.6% for both models),
determining that the optimal feature subset contains 12 and 6 features,
respectively. Finally, we corroborate the findings of related works that the
IRA specifically targeted Americans on divisive ad topics (e.g., LGBT rights,
African American reparations).",200,15,1389,34.26
2519,sociolinguistics,"Privacy preservation is a crucial component of any real-world application.
But, in applications relying on machine learning backends, privacy is
challenging because models often capture more than what the model was initially
trained for, resulting in the potential leakage of sensitive information. In
this paper, we propose an automatic and quantifiable metric that allows us to
evaluate humans' perception of a model's ability to preserve privacy with
respect to sensitive variables. In this paper, we focus on saliency-based
explanations, explanations that highlight regions of the input text, to infer
internal workings of a black box model. We use the degree with which
differences in interpretation of general vs privacy preserving models correlate
with sociolinguistic biases to inform metric design. We show how certain
commonly-used methods that seek to preserve privacy do not align with human
perception of privacy preservation leading to distrust about model's claims. We
demonstrate the versatility of our proposed metric by validating its utility
for measuring cross corpus generalization for both privacy and emotion.
Finally, we conduct crowdsourcing experiments to evaluate the inclination of
the evaluators to choose a particular model for a given purpose when model
explanations are provided, and show a positive relationship with the proposed
metric. To the best of our knowledge, we take the first step in proposing
automatic and quantifiable metrics that best align with human perception of
model's ability for privacy preservation, allowing for cost-effective model
development.",236,10,1601,19.5
2520,sociolinguistics,"Education is a goal-oriented field. But if we want to treat education
scientifically so we can accumulate, evaluate, and refine what we learn, then
we must develop a theoretical framework that is strongly rooted in objective
observations and through which different theoretical models of student thinking
can be compared. Much that is known in the behavioral sciences is robust and
observationally based. In this paper, I draw from a variety of fields ranging
from neuroscience to sociolinguistics to propose an over-arching theoretical
framework that allows us to both make sense of what we see in the classroom and
to compare a variety of specific theoretical approaches. My synthesis is
organized around an analysis of the individual's cognition and how it interacts
with the environment. This leads to a two level system, a knowledge-structure
level where associational patterns dominate, and a control-structure level
where one can describe expectations and epistemology. For each level, I sketch
some plausible starting models for student thinking and learning in physics and
give examples of how a theoretical orientation can affect instruction and
research.",178,8,1165,28.77
2521,sociolinguistics,"Questions of participant understanding of the nature of an activity have been
addressed in anthropology and sociolinguistics with the concepts of frames and
framing. For example, a student may frame a learning activity as an opportunity
for sensemaking or as an assignment to fill out a worksheet. The student's
understanding of the nature of the activity affects what she notices, what
knowledge she accesses, and how she thinks to act. Previous analyses have found
evidence of framing primarily in linguistic markers associated with speech
acts. In this paper, we show that there is useful evidence of framing in easily
observed features of students' behavior. We apply this observational
methodology to explore dynamics among behavior, framing, and the conceptual
substance of student reasoning in the context of collaborative active-learning
activities in an introductory university physics course.",135,7,902,23.26
2522,sociolinguistics,"Thanks to the Eslo1 (""Enqu\^ete sociolinguistique d'Orl\'eans"", i.e.
""Sociolinguistic Inquiery of Orl\'eans"") campain, a large oral corpus has been
gathered and transcribed in a textual format. The purpose of the work presented
here is to associate a morpho-syntactic label to each unit of this corpus. To
this aim, we have first studied the specificities of the necessary labels, and
their various possible levels of description. This study has led to a new
original hierarchical structuration of labels. Then, considering that our new
set of labels was different from the one used in every available software, and
that these softwares usually do not fit for oral data, we have built a new
labeling tool by a Machine Learning approach, from data labeled by Cordial and
corrected by hand. We have applied linear CRF (Conditional Random Fields)
trying to take the best possible advantage of the linguistic knowledge that was
used to define the set of labels. We obtain an accuracy between 85 and 90%,
depending of the parameters used.",168,10,1033,50.16
2523,sociolinguistics,"During the last decade, much attention has been paid to language competition
in the complex systems community, that is, how the fractions of speakers of
several competing languages evolve in time. In this paper we review recent
advances in this direction and focus on three aspects. First we consider the
shift from two-state models to three state models that include the possibility
of bilingual individuals. The understanding of the role played by bilingualism
is essential in sociolinguistics. In particular, the question addressed is
whether bilingualism facilitates the coexistence of languages. Second, we will
analyze the effect of social interaction networks and physical barriers.
Finally, we will show how to analyze the issue of bilingualism from a game
theoretical perspective.",119,8,789,37.3
2524,sociolinguistics,"Mixed language data is one of the difficult yet less explored domains of
natural language processing. Most research in fields like machine translation
or sentiment analysis assume monolingual input. However, people who are capable
of using more than one language often communicate using multiple languages at
the same time. Sociolinguists believe this ""code-switching"" phenomenon to be
socially motivated. For example, to express solidarity or to establish
authority. Most past work depend on external tools or resources, such as
part-of-speech tagging, dictionary look-up, or named-entity recognizers to
extract rich features for training machine learning models. In this paper, we
train recurrent neural networks with only raw features, and use word embedding
to automatically learn meaningful representations. Using the same
mixed-language Twitter corpus, our system is able to outperform the best
SVM-based systems reported in the EMNLP'14 Code-Switching Workshop by 1% in
accuracy, or by 17% in error rate reduction.",148,9,1021,35.78
2525,sociolinguistics,"Language in social media is mostly driven by new words and spellings that are
constantly entering the lexicon thereby polluting it and resulting in high
deviation from the formal written version. The primary entities of such
language are the out-of-vocabulary (OOV) words. In this paper, we study various
sociolinguistic properties of the OOV words and propose a classification model
to categorize them into at least six categories. We achieve 81.26% accuracy
with high precision and recall. We observe that the content features are the
most discriminative ones followed by lexical and context features.",93,7,603,38.82
2526,sociolinguistics,"Instead of studying the properties of social relationship from an objective
view, in this paper, we focus on individuals' subjective and asymmetric
opinions on their interrelationships. Inspired by the theories from
sociolinguistics, we investigate two individuals' opinions on their
interrelationship with their interactive language features. Eliminating the
difference of personal language style, we clarify that the asymmetry of
interactive language feature values can indicate individuals' asymmetric
opinions on their interrelationship. We also discuss how the degree of
opinions' asymmetry is related to the individuals' personality traits.
Furthermore, to measure the individuals' asymmetric opinions on
interrelationship concretely, we develop a novel model synthetizing interactive
language and social network features. The experimental results with Enron email
dataset provide multiple evidences of the asymmetric opinions on
interrelationship, and also verify the effectiveness of the proposed model in
measuring the degree of opinions' asymmetry.",140,7,1058,-2.94
2527,sociolinguistics,"Though current researches often study the properties of online social
relationship from an objective view, we also need to understand individuals'
subjective opinions on their interrelationships in social computing studies.
Inspired by the theories from sociolinguistics, the latest work indicates that
interactive language can reveal individuals' asymmetric opinions on their
interrelationship. In this work, in order to explain the opinions' asymmetry on
interrelationship with more latent factors, we extend the investigation from
single relationship to the structural context in online social network. We
analyze the correlation between interactive language features and the
structural context of interrelationships. The structural context of vertex,
edges and triangles in social network are considered. With statistical analysis
on Enron email dataset, we find that individuals' opinions (measured by
interactive language features) on their interrelationship are related to some
of their important structural context in social network. This result can help
us to understand and measure the individuals' opinions on their
interrelationship with more intrinsic information.",160,8,1177,14.39
2528,sociolinguistics,"In contrast to many decades of research on oral code-switching, the study of
written multilingual productions has only recently enjoyed a surge of interest.
Many open questions remain regarding the sociolinguistic underpinnings of
written code-switching, and progress has been limited by a lack of suitable
resources. We introduce a novel, large, and diverse dataset of written
code-switched productions, curated from topical threads of multiple bilingual
communities on the Reddit discussion platform, and explore questions that were
mainly addressed in the context of spoken language thus far. We investigate
whether findings in oral code-switching concerning content and style, as well
as speaker proficiency, are carried over into written code-switching in
discussion forums. The released dataset can further facilitate a range of
research and practical activities.",124,6,869,37.84
2529,sociolinguistics,"Information about individuals can help to better understand what they say,
particularly in social media where texts are short. Current approaches to
modelling social media users pay attention to their social connections, but
exploit this information in a static way, treating all connections uniformly.
This ignores the fact, well known in sociolinguistics, that an individual may
be part of several communities which are not equally relevant in all
communicative situations. We present a model based on Graph Attention Networks
that captures this observation. It dynamically explores the social graph of a
user, computes a user representation given the most relevant connections for a
target task, and combines it with linguistic information to make a prediction.
We apply our model to three different tasks, evaluate it against alternative
models, and analyse the results extensively, showing that it significantly
outperforms other current methods.",141,7,951,22.24
2530,sociolinguistics,"The current study yielded a number of important findings. We managed to build
a neural network that achieved an accuracy score of 91 per cent in classifying
troll and genuine tweets. By means of regression analysis, we identified a
number of features that make a tweet more susceptible to correct labelling and
found that they are inherently present in troll tweets as a special type of
discourse. We hypothesised that those features are grounded in the
sociolinguistic limitations of troll writing, which can be best described as a
combination of two factors: speaking with a purpose and trying to mask the
purpose of speaking. Next, we contended that the orthogonal nature of these
factors must necessarily result in the skewed distribution of many different
language parameters of troll messages. Having chosen as an example distribution
of the topics and vocabulary associated with those topics, we showed some very
pronounced distributional anomalies, thus confirming our prediction.",155,7,988,36.83
2531,sociolinguistics,"Much work in cross-lingual transfer learning explored how to select better
transfer languages for multilingual tasks, primarily focusing on typological
and genealogical similarities between languages. We hypothesize that these
measures of linguistic proximity are not enough when working with
pragmatically-motivated tasks, such as sentiment analysis. As an alternative,
we introduce three linguistic features that capture cross-cultural similarities
that manifest in linguistic patterns and quantify distinct aspects of language
pragmatics: language context-level, figurative language, and the lexification
of emotion concepts. Our analyses show that the proposed pragmatic features do
capture cross-cultural similarities and align well with existing work in
sociolinguistics and linguistic anthropology. We further corroborate the
effectiveness of pragmatically-driven transfer in the downstream task of
choosing transfer languages for cross-lingual sentiment analysis.",122,6,971,4.41
2532,sociolinguistics,"Analyzing the readability of articles has been an important sociolinguistic
task. Addressing this task is necessary to the automatic recommendation of
appropriate articles to readers with different comprehension abilities, and it
further benefits education systems, web information systems, and digital
libraries. Current methods for assessing readability employ empirical measures
or statistical learning techniques that are limited by their ability to
characterize complex patterns such as article structures and semantic meanings
of sentences. In this paper, we propose a new and comprehensive framework which
uses a hierarchical self-attention model to analyze document readability. In
this model, measurements of sentence-level difficulty are captured along with
the semantic meanings of each sentence. Additionally, the sentence-level
features are incorporated to characterize the overall readability of an article
with consideration of article structures. We evaluate our proposed approach on
three widely-used benchmark datasets against several strong baseline
approaches. Experimental results show that our proposed method achieves the
state-of-the-art performance on estimating the readability for various web
articles and literature.",164,9,1244,8.37
2533,sociolinguistics,"Correctly resolving textual mentions of people fundamentally entails making
inferences about those people. Such inferences raise the risk of systemic
biases in coreference resolution systems, including biases that can harm binary
and non-binary trans and cis stakeholders. To better understand such biases, we
foreground nuanced conceptualizations of gender from sociology and
sociolinguistics, and develop two new datasets for interrogating bias in crowd
annotations and in existing coreference resolution systems. Through these
studies, conducted on English text, we confirm that without acknowledging and
building systems that recognize the complexity of gender, we build systems that
lead to many potential harms.",99,5,717,12.46
2534,sociolinguistics,"Artificial Intelligence has the capacity to amplify and perpetuate societal
biases and presents profound ethical implications for society. Gender bias has
been identified in the context of employment advertising and recruitment tools,
due to their reliance on underlying language processing and recommendation
algorithms. Attempts to address such issues have involved testing learned
associations, integrating concepts of fairness to machine learning and
performing more rigorous analysis of training data. Mitigating bias when
algorithms are trained on textual data is particularly challenging given the
complex way gender ideology is embedded in language. This paper proposes a
framework for the identification of gender bias in training data for machine
learning.The work draws upon gender theory and sociolinguistics to
systematically indicate levels of bias in textual training data and associated
neural word embedding models, thus highlighting pathways for both removing bias
from training data and critically assessing its impact.",145,7,1038,13.07
2535,sociolinguistics,"Speakers of non-English languages often adopt loanwords from English to
express new or unusual concepts. While these loanwords may be borrowed
unchanged, speakers may also integrate the words to fit the constraints of
their native language, e.g. creating Spanish ""tuitear"" from English ""tweet.""
Linguists have often considered the process of loanword integration to be more
dependent on language-internal constraints, but sociolinguistic constraints
such as speaker background remain only qualitatively understood. We investigate
the role of social context and speaker background in Spanish speakers' use of
integrated loanwords on social media. We find first that newspaper authors use
the integrated forms of loanwords and native words more often than social media
authors, showing that integration is associated with formal domains. In social
media, we find that speaker background and expectations of formality explain
loanword and native word integration, such that authors who use more Spanish
and who write to a wider audience tend to use integrated verb forms more often.
This study shows that loanword integration reflects not only language-internal
constraints but also social expectations that vary by conversation and speaker.",180,10,1238,40.18
2536,sociolinguistics,"Chatbots are often designed to mimic social roles attributed to humans.
However, little is known about the impact on user's perceptions of using
language that fails to conform to the associated social role. Our research
draws on sociolinguistic theory to investigate how a chatbot's language choices
can adhere to the expected social role the agent performs within a given
context. In doing so, we seek to understand whether chatbots design should
account for linguistic register. This research analyzes how register
differences play a role in shaping the user's perception of the human-chatbot
interaction. Ultimately, we want to determine whether register-specific
language influences users' perceptions and experiences with chatbots. We
produced parallel corpora of conversations in the tourism domain with similar
content and varying register characteristics and evaluated users' preferences
of chatbot's linguistic choices in terms of appropriateness, credibility, and
user experience. Our results show that register characteristics are strong
predictors of user's preferences, which points to the needs of designing
chatbots with register-appropriate language to improve acceptance and users'
perceptions of chatbot interactions.",173,9,1235,24.17
2537,sociolinguistics,"Studying the ways in which language is gendered has long been an area of
interest in sociolinguistics. Studies have explored, for example, the speech of
male and female characters in film and the language used to describe male and
female politicians. In this paper, we aim not to merely study this phenomenon
qualitatively, but instead to quantify the degree to which the language used to
describe men and women is different and, moreover, different in a positive or
negative way. To that end, we introduce a generative latent-variable model that
jointly represents adjective (or verb) choice, with its sentiment, given the
natural gender of a head (or dependent) noun. We find that there are
significant differences between descriptions of male and female nouns and that
these differences align with common gender stereotypes: Positive adjectives
used to describe women are more often related to their bodies than adjectives
used to describe men.",151,6,947,40.82
2538,sociolinguistics,"Social engineers attempt to manipulate users into undertaking actions such as
downloading malware by clicking links or providing access to money or sensitive
information. Natural language processing, computational sociolinguistics, and
media-specific structural clues provide a means for detecting both the ask
(e.g., buy gift card) and the risk/reward implied by the ask, which we call
framing (e.g., lose your job, get a raise). We apply linguistic resources such
as Lexical Conceptual Structure to tackle ask detection and also leverage
structural clues such as links and their proximity to identified asks to
improve confidence in our results. Our experiments indicate that the
performance of ask detection, framing detection, and identification of the top
ask is improved by linguistically motivated classes coupled with structural
clues such as links. Our approach is implemented in a system that informs users
about social engineering risk situations.",141,10,958,34.15
2539,sociolinguistics,"Much previous work characterizing language variation across Internet social
groups has focused on the types of words used by these groups. We extend this
type of study by employing BERT to characterize variation in the senses of
words as well, analyzing two months of English comments in 474 Reddit
communities. The specificity of different sense clusters to a community,
combined with the specificity of a community's unique word types, is used to
identify cases where a social group's language deviates from the norm. We
validate our metrics using user-created glossaries and draw on sociolinguistic
theories to connect language variation with trends in community behavior. We
find that communities with highly distinctive language are medium-sized, and
their loyal and highly engaged users interact in dense networks.",125,6,820,37.64
2540,sociolinguistics,"Development of language proficiency models for non-native learners has been
an active area of interest in NLP research for the past few years. Although
language proficiency is multidimensional in nature, existing research typically
considers a single ""overall proficiency"" while building models. Further,
existing approaches also considers only one language at a time. This paper
describes our experiments and observations about the role of pre-trained and
fine-tuned multilingual embeddings in performing multi-dimensional,
multilingual language proficiency classification. We report experiments with
three languages -- German, Italian, and Czech -- and model seven dimensions of
proficiency ranging from vocabulary control to sociolinguistic appropriateness.
Our results indicate that while fine-tuned embeddings are useful for
multilingual proficiency modeling, none of the features achieve consistently
best performance for all dimensions of language proficiency. All code, data and
related supplementary material can be found at:
https://github.com/nishkalavallabhi/MultidimCEFRScoring.",139,9,1091,0.82
2541,sociolinguistics,"The goal of this paper is to provide a complete representation of regional
linguistic variation on a global scale. To this end, the paper focuses on
removing three constraints that have previously limited work within
dialectology/dialectometry. First, rather than assuming a fixed and incomplete
set of variants, we use Computational Construction Grammar to provide a
replicable and falsifiable set of syntactic features. Second, rather than
assuming a specific area of interest, we use global language mapping based on
web-crawled and social media datasets to determine the selection of national
varieties. Third, rather than looking at a single language in isolation, we
model seven major languages together using the same methods: Arabic, English,
French, German, Portuguese, Russian, and Spanish. Results show that models for
each language are able to robustly predict the region-of-origin of held-out
samples better using Construction Grammars than using simpler syntactic
features. These global-scale experiments are used to argue that new methods in
computational sociolinguistics are able to provide more generalized models of
regional variation that are essential for understanding language variation and
change at scale.",178,8,1230,28.77
2542,sociolinguistics,"New words are regularly introduced to communities, yet not all of these words
persist in a community's lexicon. Among the many factors contributing to
lexical change, we focus on the understudied effect of social networks. We
conduct a large-scale analysis of over 80k neologisms in 4420 online
communities across a decade. Using Poisson regression and survival analysis,
our study demonstrates that the community's network structure plays a
significant role in lexical change. Apart from overall size, properties
including dense connections, the lack of local clusters and more external
contacts promote lexical innovation and retention. Unlike offline communities,
these topic-based communities do not experience strong lexical levelling
despite increased contact but accommodate more niche words. Our work provides
support for the sociolinguistic hypothesis that lexical change is partially
shaped by the structure of the underlying network but also uncovers findings
specific to online communities.",143,8,1002,25.39
2543,sociolinguistics,"The success of an open source software (OSS) project requires effective
communication among its members. Given that OSS projects often have established
social status systems, much communication may happen between individuals of
different statuses, particularly, elite developers who have project management
privileges and ordinary project contributors. Since sociolinguistics literature
and our prior work have found that groups in different status would be likely
develop different language styles, which may hinder critical cross status
communication, and hereby influence the outcomes of the project. We seek to
develop an understanding of cross status communication, as well as its impacts
on the outcomes of an OSS project in terms of productivity and quality. The
anticipated results describe the linguistic similarities and differences of
cross status communication and reveal the relationships between these
linguistic similarities and differences and project outcomes.",136,6,977,18.49
2544,sociolinguistics,"We present evidence that the word entropy of American English has been rising
steadily since around 1900, contrary to predictions from existing
sociolinguistic theories. We also find differences in word entropy between
media categories, with short-form media such as news and magazines having
higher entropy than long-form media, and social media feeds having higher
entropy still. To explain these results we develop an ecological model of the
attention economy that combines ideas from Zipf's law and information foraging.
In this model, media consumers maximize information utility rate taking into
account the costs of information search, while media producers adapt to
technologies that reduce search costs, driving them to generate higher entropy
content in increasingly shorter formats.",116,5,793,25.12
2545,sociolinguistics,"Point-of-interest (POI) type prediction is the task of inferring the type of
a place from where a social media post was shared. Inferring a POI's type is
useful for studies in computational social science including sociolinguistics,
geosemiotics, and cultural geography, and has applications in geosocial
networking technologies such as recommendation and visualization systems. Prior
efforts in POI type prediction focus solely on text, without taking visual
information into account. However in reality, the variety of modalities, as
well as their semiotic relationships with one another, shape communication and
interactions in social media. This paper presents a study on POI type
prediction using multimodal information from text and images available at
posting time. For that purpose, we enrich a currently available data set for
POI type prediction with the images that accompany the text messages. Our
proposed method extracts relevant information from each modality to effectively
capture interactions between text and image achieving a macro F1 of 47.21
across eight categories significantly outperforming the state-of-the-art method
for POI type prediction based on text-only methods. Finally, we provide a
detailed analysis to shed light on cross-modal interactions and the limitations
of our best performing model.",193,10,1327,32.83
2546,sociolinguistics,"Natural language processing (NLP) models trained on people-generated data can
be unreliable because, without any constraints, they can learn from spurious
correlations that are not relevant to the task. We hypothesize that enriching
models with speaker information in a controlled, educated way can guide them to
pick up on relevant inductive biases. For the speaker-driven task of predicting
code-switching points in English--Spanish bilingual dialogues, we show that
adding sociolinguistically-grounded speaker features as prepended prompts
significantly improves accuracy. We find that by adding influential phrases to
the input, speaker-informed models learn useful and explainable linguistic
information. To our knowledge, we are the first to incorporate speaker
characteristics in a neural model for code-switching, and more generally, take
a step towards developing transparent, personalized models that use speaker
information in a controlled way.",131,6,955,19.5
2547,sociolinguistics,"Text analysis of social media for sentiment, topic analysis, and other
analysis depends initially on the selection of keywords and phrases that will
be used to create the research corpora. However, keywords that researchers
choose may occur infrequently, leading to errors that arise from using small
samples. In this paper, we use the capacity for memorization, interpolation,
and extrapolation of Transformer Language Models such as the GPT series to
learn the linguistic behaviors of a subgroup within larger corpora of Yelp
reviews. We then use prompt-based queries to generate synthetic text that can
be analyzed to produce insights into specific opinions held by the populations
that the models were trained on. Once learned, more specific sentiment queries
can be made of the model with high levels of accuracy when compared to
traditional keyword searches. We show that even in cases where a specific
keyphrase is limited or not present at all in the training corpora, the GPT is
able to accurately generate large volumes of text that have the correct
sentiment.",171,7,1070,34.09
2548,sociolinguistics,"Populations have often been perceived as a structuring component for language
to emerge and evolve: the larger the population, the more structured the
language. While this observation is widespread in the sociolinguistic
literature, it has not been consistently reproduced in computer simulations
with neural agents. In this paper, we thus aim to clarify this apparent
contradiction. We explore emergent language properties by varying agent
population size in the speaker-listener Lewis Game. After reproducing the
experimental difference, we challenge the simulation assumption that the agent
community is homogeneous. We first investigate how speaker-listener asymmetry
alters language structure to examine two potential diversity factors: training
speed and network capacity. We find out that emergent language properties are
only altered by the relative difference of learning speeds between speaker and
listener, and not by their absolute values. From then, we leverage this
observation to control population heterogeneity without introducing confounding
factors. We finally show that introducing such training speed heterogeneities
naturally sort out the initial contradiction: larger simulated communities
start developing more stable and structured languages.",173,10,1267,18.15
2549,sociolinguistics,"Chatbots are more and more prevalent in commercial and science contexts. They
help customers complain about a product or service or support them to find the
best travel deals. Other bots provide mental health support or help book
medical appointments. This paper argues that insights into users' language
ideologies and their rapport expectations can be used to inform the audience
design of the bot's language and interaction patterns and ensure equitable
access to the services provided by bots. The argument is underpinned by three
kinds of data: simulated user interactions with a chatbot facilitating health
appointment bookings, users' introspective comments on their interactions and
users' qualitative survey comments post engagement with the booking bot. In
closing, I will define audience design for conversational AI and discuss how
user-centred analyses of chatbot interactions and sociolinguistically informed
theoretical approaches, such as rapport management, can be used to support
audience design.",148,7,1014,29.48
2550,sociolinguistics,"We present a new dataset for studying conversation disentanglement in movies
and TV series. While previous work has focused on conversation disentanglement
in IRC chatroom dialogues, movies and TV shows provide a space for studying
complex pragmatic patterns of floor and topic change in face-to-face
multi-party interactions. In this work, we draw on theoretical research in
sociolinguistics, sociology, and film studies to operationalize a
conversational thread (including the notion of a floor change) in dramatic
texts, and use that definition to annotate a dataset of 10,033 dialogue turns
(comprising 2,209 threads) from 831 movies. We compare the performance of
several disentanglement models on this dramatic dataset, and apply the
best-performing model to disentangle 808 movies. We see that, contrary to
expectation, average thread lengths do not decrease significantly over the past
40 years, and characters portrayed by actors who are women, while
underrepresented, initiate more new conversational threads relative to their
speaking time.",153,6,1051,23.5
2551,sociolinguistics,"To recognize and mitigate harms from large language models (LLMs), we need to
understand the prevalence and nuances of stereotypes in LLM outputs. Toward
this end, we present Marked Personas, a prompt-based method to measure
stereotypes in LLMs for intersectional demographic groups without any lexicon
or data labeling. Grounded in the sociolinguistic concept of markedness (which
characterizes explicitly linguistically marked categories versus unmarked
defaults), our proposed method is twofold: 1) prompting an LLM to generate
personas, i.e., natural language descriptions, of the target demographic group
alongside personas of unmarked, default groups; 2) identifying the words that
significantly distinguish personas of the target group from corresponding
unmarked ones. We find that the portrayals generated by GPT-3.5 and GPT-4
contain higher rates of racial stereotypes than human-written portrayals using
the same prompts. The words distinguishing personas of marked (non-white,
non-male) groups reflect patterns of othering and exoticizing these
demographics. An intersectional lens further reveals tropes that dominate
portrayals of marginalized groups, such as tropicalism and the
hypersexualization of minoritized women. These representational harms have
concerning implications for downstream applications like story generation.",180,11,1343,25.8
2552,sociolinguistics,"The socioeconomic background of people and how they use standard forms of
language are not independent, as demonstrated in various sociolinguistic
studies. However, the extent to which these correlations may be influenced by
the mixing of people from different socioeconomic classes remains relatively
unexplored from a quantitative perspective. In this work we leverage geotagged
tweets and transferable computational methods to map deviations from standard
English on a large scale, in seven thousand administrative areas of England and
Wales. We combine these data with high-resolution income maps to assign a proxy
socioeconomic indicator to home-located users. Strikingly, across eight
metropolitan areas we find a consistent pattern suggesting that the more
different socioeconomic classes mix, the less interdependent the frequency of
their departures from standard grammar and their income become. Further, we
propose an agent-based model of linguistic variety adoption that sheds light on
the mechanisms that produce the observations seen in the data.",152,7,1060,20.42
2553,sociolinguistics,"Automatic speech recognition (ASR) systems are known to be sensitive to the
sociolinguistic variability of speech data, in which gender plays a crucial
role. This can result in disparities in recognition accuracy between male and
female speakers, primarily due to the under-representation of the latter group
in the training data. While in the context of hybrid ASR models several
solutions have been proposed, the gender bias issue has not been explicitly
addressed in end-to-end neural architectures. To fill this gap, we propose a
data augmentation technique that manipulates the fundamental frequency (f0) and
formants. This technique reduces the data unbalance among genders by simulating
voices of the under-represented female speakers and increases the variability
within each gender group. Experiments on spontaneous English speech show that
our technique yields a relative WER improvement up to 9.87% for utterances by
female speakers, with larger gains for the least-represented f0 ranges.",148,8,999,33.14
2554,sociolinguistics,"Transcribed speech and user-generated text in Arabic typically contain a
mixture of Modern Standard Arabic (MSA), the standardized language taught in
schools, and Dialectal Arabic (DA), used in daily communications. To handle
this variation, previous work in Arabic NLP has focused on Dialect
Identification (DI) on the sentence or the token level. However, DI treats the
task as binary, whereas we argue that Arabic speakers perceive a spectrum of
dialectness, which we operationalize at the sentence level as the Arabic Level
of Dialectness (ALDi), a continuous linguistic variable. We introduce the
AOC-ALDi dataset (derived from the AOC dataset), containing 127,835 sentences
(17% from news articles and 83% from user comments on those articles) which are
manually labeled with their level of dialectness. We provide a detailed
analysis of AOC-ALDi and show that a model trained on it can effectively
identify levels of dialectness on a range of other corpora (including dialects
and genres not included in AOC-ALDi), providing a more nuanced picture than
traditional DI systems. Through case studies, we illustrate how ALDi can reveal
Arabic speakers' stylistic choices in different situations, a useful property
for sociolinguistic analyses.",188,7,1247,22.79
2555,sociolinguistics,"Much work in the space of NLP has used computational methods to explore
sociolinguistic variation in text. In this paper, we argue that memes, as
multimodal forms of language comprised of visual templates and text, also
exhibit meaningful social variation. We construct a computational pipeline to
cluster individual instances of memes into templates and semantic variables,
taking advantage of their multimodal structure in doing so. We apply this
method to a large collection of meme images from Reddit and make available the
resulting \textsc{SemanticMemes} dataset of 3.8M images clustered by their
semantic function. We use these clusters to analyze linguistic variation in
memes, discovering not only that socially meaningful variation in meme usage
exists between subreddits, but that patterns of meme innovation and
acculturation within these communities align with previous findings on written
language.",134,7,912,31.92
2556,sociolinguistics,"Linguistic landscape is an important field in sociolinguistic research. Eye
tracking technology is a common technology in psychological research. There are
few cases of using eye movement to study linguistic landscape. This paper uses
eye tracking technology to study the actual fixation of the linguistic
landscape and finds that in the two dimensions of fixation time and fixation
times, the fixation of native Chinese speakers to the linguistic landscape is
higher than that of the general landscape. This paper argues that this
phenomenon is due to the higher information density of linguistic landscapes.
At the same time, the article also discusses other possible reasons for this
phenomenon.",107,7,698,36.49
2557,sociolinguistics,"This paper measures the skew in how well two families of LLMs represent
diverse geographic populations. A spatial probing task is used with
geo-referenced corpora to measure the degree to which pre-trained language
models from the OPT and BLOOM series represent diverse populations around the
world. Results show that these models perform much better for some populations
than others. In particular, populations across the US and the UK are
represented quite well while those in South and Southeast Asia are poorly
represented. Analysis shows that both families of models largely share the same
skew across populations. At the same time, this skew cannot be fully explained
by sociolinguistic factors, economic factors, or geographic factors. The basic
conclusion from this analysis is that pre-trained models do not equally
represent the world's population: there is a strong skew towards specific
geographic populations. This finding challenges the idea that a single model
can be used for all populations.",155,9,1008,43.32
2558,sociolinguistics,"Language models and humans are two types of learning systems. Finding or
facilitating commonalities could enable major breakthroughs in our
understanding of the acquisition and evolution of language. Many theories of
language evolution rely heavily on learning biases and learning pressures. Yet
due to substantial differences in learning pressures, it is questionable
whether the similarity between humans and machines is sufficient for insights
to carry over and to be worth testing with human participants. Here, we review
the emergent communication literature, a subfield of multi-agent reinforcement
learning, from a language evolution perspective. We find that the emergent
communication literature excels at designing and adapting models to recover
initially absent linguistic phenomena of natural languages. Based on a short
literature review, we identify key pressures that have recovered initially
absent human patterns in emergent communication models: communicative success,
efficiency, learnability, and other psycho-/sociolinguistic factors. We argue
that this may serve as inspiration for how to design language models for
language acquisition and language evolution research.",164,9,1191,16.83
2559,sociolinguistics,"Bragging is the act of uttering statements that are likely to be positively
viewed by others and it is extensively employed in human communication with the
aim to build a positive self-image of oneself. Social media is a natural
platform for users to employ bragging in order to gain admiration, respect,
attention and followers from their audiences. Yet, little is known about the
scale of bragging online and its characteristics. This paper employs
computational sociolinguistics methods to conduct the first large scale study
of bragging behavior on Twitter (U.S.) by focusing on its overall prevalence,
temporal dynamics and impact of demographic factors. Our study shows that the
prevalence of bragging decreases over time within the same population of users.
In addition, younger, more educated and popular users in the U.S. are more
likely to brag. Finally, we conduct an extensive linguistics analysis to unveil
specific bragging themes associated with different user traits.",152,12,983,45.86
2560,sociolinguistics,"A defining characteristic of conspiracy texts is that they negotiate power
and identity by recontextualizing prior knowledge. This dynamic has been shown
to intensify on social media, where knowledge sources can readily be integrated
into antagonistic narratives through hyperlinks. The objective of the present
chapter is to further our understanding of this dynamic by surfacing and
examining 1) how online conspiracy narratives recontextualize prior knowledge
by coupling it with heterogeneous antagonistic elements, and 2) how such
recontextualizing narratives operate as connectors around which diverse actors
might form narrative coalitions. To this end, the chapter offers an empirical
analysis of links to prior knowledge in public messaging channels from the
Pushshift Telegram dataset. Using transferable methods from the field of
bibliometrics, we find that politically extreme Telegram channels engage with a
variety of established knowledge sources, including scientific journals,
scientific repositories and other sources associated with the system of
scholarly communication. Channels engaging with shared knowledge sources
thereby form narrative coalitions ranging from scientific and technological
imaginaries to far-right extremist and antisemitic conspiracy theories. Our
analysis of these coalitions reveals (i) linguistic, political, and thematic
forces that shape conspiracy narratives, (ii) emerging ideological,
epistemological and ontological positions associated with online conspiracism,
and (iii) how references to shared knowledge contribute to the communicability
of conspiracy narratives.",214,8,1619,-1.89
2561,sociolinguistics,"We present a study of the relationship between gender, linguistic style, and
social networks, using a novel corpus of 14,000 Twitter users. Prior
quantitative work on gender often treats this social variable as a female/male
binary; we argue for a more nuanced approach. By clustering Twitter users, we
find a natural decomposition of the dataset into various styles and topical
interests. Many clusters have strong gender orientations, but their use of
linguistic resources sometimes directly conflicts with the population-level
language statistics. We view these clusters as a more accurate reflection of
the multifaceted nature of gendered language styles. Previous corpus-based work
has also had little to say about individuals whose linguistic styles defy
population-level gender patterns. To identify such individuals, we train a
statistical classifier, and measure the classifier confidence for each
individual in the dataset. Examining individuals whose language does not match
the classifier's model for their gender, we find that they have social networks
that include significantly fewer same-gender social connections and that, in
general, social network homophily is correlated with the use of same-gender
language markers. Pairing computational methods and social theory thus offers a
new perspective on how gender emerges as individuals position themselves
relative to audiences, topics, and mainstream gender norms.",206,10,1431,22.85
2562,sociolinguistics,"Authorship analysis (AA) is the study of unveiling the hidden properties of
authors from a body of exponentially exploding textual data. It extracts an
author's identity and sociolinguistic characteristics based on the reflected
writing styles in the text. It is an essential process for various areas, such
as cybercrime investigation, psycholinguistics, political socialization, etc.
However, most of the previous techniques critically depend on the manual
feature engineering process. Consequently, the choice of feature set has been
shown to be scenario- or dataset-dependent. In this paper, to mimic the human
sentence composition process using a neural network approach, we propose to
incorporate different categories of linguistic features into distributed
representation of words in order to learn simultaneously the writing style
representations based on unlabeled texts for authorship analysis. In
particular, the proposed models allow topical, lexical, syntactical, and
character-level feature vectors of each document to be extracted as
stylometrics. We evaluate the performance of our approach on the problems of
authorship characterization and authorship verification with the Twitter,
novel, and essay datasets. The experiments suggest that our proposed text
representation outperforms the bag-of-lexical-n-grams, Latent Dirichlet
Allocation, Latent Semantic Analysis, PVDM, PVDBOW, and word2vec
representations.",193,10,1427,15.91
2563,sociolinguistics,"Language change is a complex social phenomenon, revealing pathways of
communication and sociocultural influence. But, while language change has long
been a topic of study in sociolinguistics, traditional linguistic research
methods rely on circumstantial evidence, estimating the direction of change
from differences between older and younger speakers. In this paper, we use a
data set of several million Twitter users to track language changes in
progress. First, we show that language change can be viewed as a form of social
influence: we observe complex contagion for phonetic spellings and ""netspeak""
abbreviations (e.g., lol), but not for older dialect markers from spoken
language. Next, we test whether specific types of social network connections
are more influential than others, using a parametric Hawkes process model. We
find that tie strength plays an important role: densely embedded social ties
are significantly better conduits of linguistic influence. Geographic locality
appears to play a more limited role: we find relatively little evidence to
support the hypothesis that individuals are more influenced by geographically
local social ties, even in their usage of geographical dialect markers.",179,10,1214,31.82
2564,sociolinguistics,"Distinctive linguistic practices help communities build solidarity and
differentiate themselves from outsiders. In an online community, one such
practice is variation in orthography, which includes spelling, punctuation, and
capitalization. Using a dataset of over two million Instagram posts, we
investigate orthographic variation in a community that shares pro-eating
disorder (pro-ED) content. We find that not only does orthographic variation
grow more frequent over time, it also becomes more profound or deep, with
variants becoming increasingly distant from the original: as, for example,
#anarexyia is more distant than #anarexia from the original spelling #anorexia.
These changes are driven by newcomers, who adopt the most extreme linguistic
practices as they enter the community. Moreover, this behavior correlates with
engagement: the newcomers who adopt deeper orthographic variants tend to remain
active for longer in the community, and the posts that contain deeper variation
receive more positive feedback in the form of ""likes."" Previous work has linked
community membership change with language change, and our work casts this
connection in a new light, with newcomers driving an evolving practice, rather
than adapting to it. We also demonstrate the utility of orthographic variation
as a new lens to study sociolinguistic change in online communities,
particularly when the change results from an exogenous force such as a content
ban.",213,9,1456,27.56
2565,sociolinguistics,"Endowing a dialogue system with particular personality traits is essential to
deliver more human-like conversations. However, due to the challenge of
embodying personality via language expression and the lack of large-scale
persona-labeled dialogue data, this research problem is still far from
well-studied. In this paper, we investigate the problem of incorporating
explicit personality traits in dialogue generation to deliver personalized
dialogues.
  To this end, firstly, we construct PersonalDialog, a large-scale multi-turn
dialogue dataset containing various traits from a large number of speakers. The
dataset consists of 20.83M sessions and 56.25M utterances from 8.47M speakers.
Each utterance is associated with a speaker who is marked with traits like Age,
Gender, Location, Interest Tags, etc. Several anonymization schemes are
designed to protect the privacy of each speaker. This large-scale dataset will
facilitate not only the study of personalized dialogue generation, but also
other researches on sociolinguistics or social science.
  Secondly, to study how personality traits can be captured and addressed in
dialogue generation, we propose persona-aware dialogue generation models within
the sequence to sequence learning framework. Explicit personality traits
(structured by key-value pairs) are embedded using a trait fusion module.
During the decoding process, two techniques, namely persona-aware attention and
persona-aware bias, are devised to capture and address trait-related
information. Experiments demonstrate that our model is able to address proper
traits in different contexts. Case studies also show interesting results for
this challenging research problem.",233,17,1696,30.36
2566,sociolinguistics,"Sharing personal narratives is a fundamental aspect of human social behavior
as it helps share our life experiences. We can tell stories and rely on our
background to understand their context, similarities, and differences. A
substantial effort has been made towards developing storytelling machines or
inferring characters' features. However, we don't usually find models that
compare narratives. This task is remarkably challenging for machines since
they, as sometimes we do, lack an understanding of what similarity means. To
address this challenge, we first introduce a corpus of real-world spoken
personal narratives comprising 10,296 narrative clauses from 594 video
transcripts. Second, we ask non-narrative experts to annotate those clauses
under Labov's sociolinguistic model of personal narratives (i.e., action,
orientation, and evaluation clause types) and train a classifier that reaches
84.7% F-score for the highest-agreed clauses. Finally, we match stories and
explore whether people implicitly rely on Labov's framework to compare
narratives. We show that actions followed by the narrator's evaluation of these
are the aspects non-experts consider the most. Our approach is intended to help
inform machine learning methods aimed at studying or representing personal
narratives.",185,14,1295,38.92
2567,sociolinguistics,"From conspiracy theories to fake cures and fake treatments, COVID-19 has
become a hot-bed for the spread of misinformation online. It is more important
than ever to identify methods to debunk and correct false information online.
In this paper, we present a methodology and analyses to characterize the two
competing COVID-19 misinformation communities online: (i) misinformed users or
users who are actively posting misinformation, and (ii) informed users or users
who are actively spreading true information, or calling out misinformation. The
goals of this study are two-fold: (i) collecting a diverse set of annotated
COVID-19 Twitter dataset that can be used by the research community to conduct
meaningful analysis; and (ii) characterizing the two target communities in
terms of their network structure, linguistic patterns, and their membership in
other communities. Our analyses show that COVID-19 misinformed communities are
denser, and more organized than informed communities, with a possibility of a
high volume of the misinformation being part of disinformation campaigns. Our
analyses also suggest that a large majority of misinformed users may be
anti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19
informed users tend to use more narratives than misinformed users.",191,8,1302,26.85
2568,sociolinguistics,"This paper develops a construction-based dialectometry capable of identifying
previously unknown constructions and measuring the degree to which a given
construction is subject to regional variation. The central idea is to learn a
grammar of constructions (a CxG) using construction grammar induction and then
to use these constructions as features for dialectometry. This offers a method
for measuring the aggregate similarity between regional CxGs without limiting
in advance the set of constructions subject to variation. The learned CxG is
evaluated on how well it describes held-out test corpora while dialectometry is
evaluated on how well it can model regional varieties of English. Themethod is
tested using two distinct datasets: First, the International Corpus of English
representing eight outer circle varieties; Second, a web-crawled corpus
representing five inner circle varieties. Results show that themethod (1)
produces a grammar with stable quality across sub-sets of a single corpus that
is (2) capable of distinguishing between regional varieties of Englishwith a
high degree of accuracy, thus (3) supporting dialectometricmethods formeasuring
the similarity between varieties of English and (4) measuring the degree to
which each construction is subject to regional variation. This is important for
cognitive sociolinguistics because it operationalizes the idea that competition
between constructions is organized at the functional level so that
dialectometry needs to represent as much of the available functional space as
possible.",223,8,1554,13.72
2569,sociolinguistics,"In this work, we investigate pronunciation differences in English spoken by
Singaporean children in relation to their American and British counterparts by
conducting Kmeans clustering and Archetypal analysis on selected vowel pairs
and approximants. Given that Singapore adopts British English as the
institutional standard due to historical reasons, one might expect Singaporean
children to follow British pronunciation patterns. Indeed, Singaporean and
British children are more similar in their production of syllable-final /r/ --
they do not lower their third formant nearly as much as American children do,
suggesting a lack of rhoticity. Interestingly, Singaporean children also
present similar patterns to American children when it comes to their fronting
of vowels as demonstrated across various vowels including TRAP-BATH split
vowels. Singaporean children's English also demonstrated characteristics that
do not resemble any of the other two populations. We observe that Singaporean
children's vowel height characteristics are distinct from both that of American
and British children. In tense and lax vowel pairs, we also consistently
observe that the distinction is less conspicuous for Singaporean children
compared to the other speaker groups. Further, while American and British
children demonstrate lowering of F1 and F2 formants in transitions into
syllable-final /l/s, a wide gap between F2 and F3 formants, and small
difference between F1 and F2 formants, all of these are not exhibited in
Singaporean children's pronunciation. These findings point towards potential
sociolinguistic implications of how Singapore English might be evolving to
embody more than British pronunciation characteristics. Furthermore, these
findings also suggest that Singapore English could be have been influenced by
languages beyond American and British English, potentially due to Singapore's
multilingual environment.",269,11,1917,18.89
2570,sociolinguistics,"Vocal fry or creaky voice refers to a voice quality characterized by
irregular glottal opening and low pitch. It occurs in diverse languages and is
prevalent in American English, where it is used not only to mark phrase
finality, but also sociolinguistic factors and affect. Due to its irregular
periodicity, creaky voice challenges automatic speech processing and
recognition systems, particularly for languages where creak is frequently used.
  This paper proposes a deep learning model to detect creaky voice in fluent
speech. The model is composed of an encoder and a classifier trained together.
The encoder takes the raw waveform and learns a representation using a
convolutional neural network. The classifier is implemented as a multi-headed
fully-connected network trained to detect creaky voice, voicing, and pitch,
where the last two are used to refine creak prediction. The model is trained
and tested on speech of American English speakers, annotated for creak by
trained phoneticians.
  We evaluated the performance of our system using two encoders: one is
tailored for the task, and the other is based on a state-of-the-art
unsupervised representation. Results suggest our best-performing system has
improved recall and F1 scores compared to previous methods on unseen data.",197,11,1289,43.02
2571,sociolinguistics,"Using style-transfer models to reduce offensiveness of social media comments
can help foster a more inclusive environment. However, there are no sizable
datasets that contain offensive texts and their inoffensive counterparts, and
fine-tuning pretrained models with limited labeled data can lead to the loss of
original meaning in the style-transferred text. To address this issue, we
provide two major contributions. First, we release the first
publicly-available, parallel corpus of offensive Reddit comments and their
style-transferred counterparts annotated by expert sociolinguists. Then, we
introduce the first discourse-aware style-transfer models that can effectively
reduce offensiveness in Reddit text while preserving the meaning of the
original text. These models are the first to examine inferential links between
the comment and the text it is replying to when transferring the style of
offensive Reddit text. We propose two different methods of integrating
discourse relations with pretrained transformer models and evaluate them on our
dataset of offensive comments from Reddit and their inoffensive counterparts.
Improvements over the baseline with respect to both automatic metrics and human
evaluation indicate that our discourse-aware models are better at preserving
meaning in style-transferred text when compared to the state-of-the-art
discourse-agnostic models.",192,9,1385,30.2
2572,sociolinguistics,"Social dynamics are shaped by each person's actions, as well as by collective
trends that emerge when individuals are brought together. These latter kind of
influences escape anyone's control. They are, instead, dominated by aggregate
societal properties such as size, polarization, cohesion, or hierarchy. Such
features add nuance and complexity to social structure, and might be present,
or not, for societies of different sizes. How do societies become more complex?
Are there specific scales at which they are reorganized into emergent entities?
In this paper we introduce the {\em social complexity spectrum}, a
methodological tool, inspired by theoretical considerations about dynamics on
complex networks, that addresses these questions empirically. We use as a probe
a sociolinguistic process that has unfolded over decades within the
north-western Spanish region of Galicia, across populations of varied sizes. We
estimate how societal complexity increases monotonously with population size;
and how specific scales stand out, at which complexity would build up faster.
These scales are noted as dips in our spectra, similarly to missing wavelengths
in light spectroscopy. Also, `red-' and `blue-shifts' take place as the general
population shifted from more rural to more urban settings. These shifts help us
sharpen our observations. Besides specific results around social complexity
build-up, our work introduces a powerful tool to be applied in further study
cases.",218,12,1478,45.96
2573,sociolinguistics,"Scholarly text is often laden with jargon, or specialized language that can
facilitate efficient in-group communication within fields but hinder
understanding for out-groups. In this work, we develop and validate an
interpretable approach for measuring scholarly jargon from text. Expanding the
scope of prior work which focuses on word types, we use word sense induction to
also identify words that are widespread but overloaded with different meanings
across fields. We then estimate the prevalence of these discipline-specific
words and senses across hundreds of subfields, and show that word senses
provide a complementary, yet unique view of jargon alongside word types. We
demonstrate the utility of our metrics for science of science and computational
sociolinguistics by highlighting two key social implications. First, though
most fields reduce their use of jargon when writing for general-purpose venues,
and some fields (e.g., biological sciences) do so less than others. Second, the
direction of correlation between jargon and citation rates varies among fields,
but jargon is nearly always negatively correlated with interdisciplinary
impact. Broadly, our findings suggest that though multidisciplinary venues
intend to cater to more general audiences, some fields' writing norms may act
as barriers rather than bridges, and thus impede the dispersion of scholarly
ideas.",202,11,1384,40.28
2574,sociolinguistics,"The analysis of data in which multiple languages are represented has gained
popularity among computational linguists in recent years. So far, much of this
research focuses mainly on the improvement of computational methods and largely
ignores linguistic and social aspects of C-S discussed across a wide range of
languages within the long-established literature in linguistics. To fill this
gap, we offer a survey of code-switching (C-S) covering the literature in
linguistics with a reflection on the key issues in language technologies. From
the linguistic perspective, we provide an overview of structural and functional
patterns of C-S focusing on the literature from European and Indian contexts as
highly multilingual areas. From the language technologies perspective, we
discuss how massive language models fail to represent diverse C-S types due to
lack of appropriate training data, lack of robust evaluation benchmarks for C-S
(across multilingual situations and types of C-S) and lack of end-to-end
systems that cover sociolinguistic aspects of C-S as well. Our survey will be a
step towards an outcome of mutual benefit for computational scientists and
linguists with a shared interest in multilingualism and C-S.",185,7,1225,23.29
2575,sociolinguistics,"Social media users on sites like Twitter, Instagram, and Tiktok use the
profile description, or bio, field of user profiles to present themselves to
the world. In contrast to the ``offline'' world, where social context often
encourages us to adopt a single identity, the profile description is a
free-text field in which users are encouraged to present the self using
multiple, sometimes conflicting, social identities. While sociologists, social
psychologists, sociolinguists, and increasingly computational social
scientists, have developed a large and growing array of methods to estimate the
meaning of individual social identities, little work has attended to the ways
in which social meanings emerge from the collections of social identities
present in social media bios. The present work proposes and evaluate three
novel, identity-based methods to measure the social dimensions of meaning
expressed in Twitter bios. We show that these models outperform reasonable
baselines with respect to 1) predicting which sets of identities are more
likely to co-occur within a single biography and 2) quantifying perceptions of
entire social media biographies along salient dimensions of social meaning on
Twitter, in particular partisanship. We demonstrate the utility of our method
in a computational social science setting by using model outputs to better
understand how self presentation along dimensions of partisanship, religion,
age, and gender are related to the sharing of URLs on Twitter from low versus
high quality news sites.",229,7,1535,15.78
2576,sociolinguistics,"In multilingual societies, it is common to encounter different language
varieties. Various approaches have been proposed to discuss different
mechanisms of language shift. However, current models exploring language shift
in languages in contact often overlook the influence of language ideologies.
Language ideologies play a crucial role in understanding language usage within
a cultural community, encompassing shared beliefs, assumptions, and feelings
towards specific language forms. These ideologies shed light on the social
perceptions of different language varieties expressed as language attitudes. In
this study, we introduce an approach that incorporates language ideologies into
a model for contact varieties by considering speaker preferences as a
parameter. Our findings highlight the significance of preference in language
shift, which can even outweigh the influence of language prestige associated,
for example, with a standard variety. Furthermore, we investigate the impact of
the degree of interaction between individuals holding opposing preferences on
the language shift process. Quite expectedly, our results indicate that when
communities with different preferences mix, the coexistence of language
varieties becomes less likely. However, variations in the degree of interaction
between individuals with contrary preferences notably lead to non-trivial
transitions from states of coexistence of varieties to the extinction of a
given variety, followed by a return to coexistence, ultimately culminating in
the dominance of the previously extinct variety. By studying finite-size
effects, we observe that the duration of coexistence states increases
exponentially with network size. Ultimately, our work constitutes a
quantitative approach to the study of language ideologies in sociolinguistics.",248,13,1817,16.62
2577,sociolinguistics,"For a large portion of real-life utterances, the intention cannot be solely
decided by either their semantic or syntactic characteristics. Although not all
the sociolinguistic and pragmatic information can be digitized, at least
phonetic features are indispensable in understanding the spoken language.
Especially in head-final languages such as Korean, sentence-final prosody has
great importance in identifying the speaker's intention. This paper suggests a
system which identifies the inherent intention of a spoken utterance given its
transcript, in some cases using auxiliary acoustic features. The main point
here is a separate distinction for cases where discrimination of intention
requires an acoustic cue. Thus, the proposed classification system decides
whether the given utterance is a fragment, statement, question, command, or a
rhetorical question/command, utilizing the intonation-dependency coming from
the head-finality. Based on an intuitive understanding of the Korean language
that is engaged in the data annotation, we construct a network which identifies
the intention of a speech, and validate its utility with the test sentences.
The system, if combined with up-to-date speech recognizers, is expected to be
flexibly inserted into various language understanding modules.",182,9,1295,14.49
2578,sociolinguistics,"In real-time, social media data strongly imprints world events, popular
culture, and day-to-day conversations by millions of ordinary people at a scale
that is scarcely conventionalized and recorded. Vitally, and absent from many
standard corpora such as books and news archives, sharing and commenting
mechanisms are native to social media platforms, enabling us to quantify social
amplification (i.e., popularity) of trending storylines and contemporary
cultural phenomena. Here, we describe Storywrangler, a natural language
processing instrument designed to carry out an ongoing, day-scale curation of
over 100 billion tweets containing roughly 1 trillion 1-grams from 2008 to
2021. For each day, we break tweets into unigrams, bigrams, and trigrams
spanning over 100 languages. We track n-gram usage frequencies, and generate
Zipf distributions, for words, hashtags, handles, numerals, symbols, and
emojis. We make the data set available through an interactive time series
viewer, and as downloadable time series and daily distributions. Although
Storywrangler leverages Twitter data, our method of extracting and tracking
dynamic changes of n-grams can be extended to any similar social media
platform. We showcase a few examples of the many possible avenues of study we
aim to enable including how social amplification can be visualized through
'contagiograms'. We also present some example case studies that bridge n-gram
time series with disparate data sources to explore sociotechnical dynamics of
famous individuals, box office success, and social unrest.",227,12,1566,31.51
2579,cultural anthropology,"The intricate relationship between language and culture has long been a
subject of exploration within the realm of linguistic anthropology. Large
Language Models (LLMs), promoted as repositories of collective human knowledge,
raise a pivotal question: do these models genuinely encapsulate the diverse
knowledge adopted by different cultures? Our study reveals that these models
demonstrate greater cultural alignment along two dimensions -- firstly, when
prompted with the dominant language of a specific culture, and secondly, when
pretrained with a refined mixture of languages employed by that culture. We
quantify cultural alignment by simulating sociological surveys, comparing model
responses to those of actual survey participants as references. Specifically,
we replicate a survey conducted in various regions of Egypt and the United
States through prompting LLMs with different pretraining data mixtures in both
Arabic and English with the personas of the real respondents and the survey
questions. Further analysis reveals that misalignment becomes more pronounced
for underrepresented personas and for culturally sensitive topics, such as
those probing social values. Finally, we introduce Anthropological Prompting, a
novel method leveraging anthropological reasoning to enhance cultural
alignment. Our study emphasizes the necessity for a more balanced multilingual
pretraining dataset to better represent the diversity of human experience and
the plurality of different cultures with many implications on the topic of
cross-lingual transfer.",216,8,1556,18.79
2580,cultural anthropology,"The small community of the Tomaraho, an ethnic group culturally derived from
the Zamucos, became known in the South American and world anthropological
scenario in recent times. This group, far from the banks of the Paraguay river,
remained concealed from organized modern societies for many years. Like any
other groups of people in close contact with nature, the Tomaraho developed a
profound and rich world view which parallels other more widely researched
aboriginal cultures as well as showing distinctive features of their own. This
is also apparent in their imagery of the sky and of the characters that are
closely connected with the celestial sphere. This paper is based on the lengthy
anthropological studies of G. Sequera. We have recently undertaken a project to
carry out a detailed analysis of the different astronomical elements present in
the imagined sky of the Tomaraho and other Chamacoco ethnic groups. We will
briefly review some aspects of this aboriginal culture: places where they live,
regions of influence in the past, their linguistic family, their living habits
and how the advancement of civilization affected their culture and survival. We
will later mention the fieldwork carried out for decades and some of the
existing studies and publications. We will also make a brief description of the
methodology of this work and special anthropological practices. Last but not
least, we will focus on the Tomaraho conception of the sky as well as describe
the research work we have been doing in recent times.",247,12,1531,46.4
2581,cultural anthropology,"A brief review is given of some recent positive developments regarding the
reception of archaeoastronomy by the archaeological institutions in Italy.
Discussions and problems that are currently going on in this field are also
mentioned, such as the separation of the scientific and humanistic disciplines
(i.e. the two cultures problem). Suggestions based on contemporary philosophy
are also reported. Finally, sky-gazing is proposed as the place where the two
cultures could meet, since, taking Plato into account, sky-gazing could be
considered the mom of the human knowledge, and of the scientific and humanistic
disciplines.",93,7,628,35.68
2582,cultural anthropology,"The article introduces the concept of ""diversity-aware"" robotics and
discusses the need to develop computational models to embed robots with
diversity-awareness: that is, robots capable of adapting and re-configuring
their behavior to recognize, respect, and value the uniqueness of the person
they interact with to promote inclusion regardless of their age, race, gender,
cognitive or physical capabilities, etc. Finally, the article discusses
possible technical solutions based on Ontologies and Bayesian Networks,
starting from previous experience with culturally competent robots.",79,3,584,-2.47
2583,cultural anthropology,"The paper defends the thesis that analysis of time meaning in a context of
philosophy of physical and mathematical natural sciences and philosophical
anthropology allows to clear basis of human being and to construct special
model of general understanding of time as a creation of nature or creation of
human. Regulations on discretization and virtual nature of cultural
interaction, mutual tension of limits of cultural and historical process allow
connecting philosophy of the nature and philosophical anthropology with system
of categories (energy, weight, distance, etc.). It finds application both in
the physical and mathematical sphere and in the field of humanitarian studies.
We can make a conclusion that neither nature nor human create the time. Time is
an imaginary phenomenon connecting human activity and natural processes in the
limits of human consciousness.",132,7,874,19.3
2584,cultural anthropology,"In this paper we study the differences in historical worldview between
Western and Eastern cultures, represented through the English, Chinese,
Japanese, and German Wikipedia. In particular, we analyze the historical
networks of the World's leaders since the beginning of written history,
comparing them in the four different Wikipedias.",48,3,336,30.2
2585,cultural anthropology,"Machine learning (ML), being now widely accessible to the research community
at large, has fostered a proliferation of new and striking applications of
these emergent mathematical techniques across a wide range of disciplines. In
this paper, we will focus on a particular case study: the field of
paleoanthropology, which seeks to understand the evolution of the human species
based on biological and cultural evidence. As we will show, the easy
availability of ML algorithms and lack of expertise on their proper use among
the anthropological research community has led to foundational misapplications
that have appeared throughout the literature. The resulting unreliable results
not only undermine efforts to legitimately incorporate ML into anthropological
research, but produce potentially faulty understandings about our human
evolutionary and behavioral past.
  The aim of this paper is to provide a brief introduction to some of the ways
in which ML has been applied within paleoanthropology; we also include a survey
of some basic ML algorithms for those who are not fully conversant with the
field, which remains under active development. We discuss a series of missteps,
errors, and violations of correct protocols of ML methods that appear
disconcertingly often within the accumulating body of anthropological
literature. These mistakes include use of outdated algorithms and practices;
inappropriate train/test splits, sample composition, and textual explanations;
as well as an absence of transparency due to the lack of data/code sharing, and
the subsequent limitations imposed on independent replication. We assert that
expanding samples, sharing data and code, re-evaluating approaches to peer
review, and, most importantly, developing interdisciplinary teams that include
experts in ML are all necessary for progress in future research incorporating
ML within anthropology.",276,9,1891,11.08
2586,cultural anthropology,"Different people and cultures associate different emotional states to
different parts and spaces of cities. These vary according to individuals,
their cultures and also to the time of day, day of week, season, special
occasions and more. Recurring patterns may occur in correspondence of the
places in which people work, study, entertain themselves, consume, relate, wait
or just take a break. What can we learn from these patterns? Trying to find
possible answers to this question passes through the possibility to visualize
and represent the configurations of emotional expressions in urban spaces,
across time, geography, theme, cultures and other dimensions. We have developed
ways in which it is possible to harvest people's geo-located (or geo-locatable)
emotional expressions from major social networks and to visualize them
according to a variety of different modalities. In this paper we will present a
series of these types of visualizations, and the ways in which they can be used
to gain better understandings of these emotional patterns as they arise, from
points of view which derive from anthropology, urbanism, sociology, politics
and also arts and poetics. The paper will focus on the ways in which the data
is harvested from different social networks, then categorized and annotated
with meta-data describing the emotional states, the languages in which people
express themselves, the geographic locations, the themes expressed. A
methodology for representing this information across a variety of domains
(time, space, emotion, theme) will then be presented in detail. A reflection on
possible usage cases for anthropology, urbanism, policy-making, arts and design
will end the contribution, as well as the description of series of open issues
and the indication of possible next-steps for research.",277,10,1817,34.9
2587,cultural anthropology,"Humans have always constructed spaces, through Mythos and Logos, as part of
an aspiration to capture the essence of the changing world. This has been a
permanent endeavour since the invention of language. By doing this, in fact,
Humankind started constructing itself: we are beings in constant evolutionary
process in real and imaginary spaces. Our concepts of Space and our
anthropological ideas, specially the fundamental concepts of subject and
subjectivity, are intertwined and intimately connected. We believe that the
great narratives about Humanity, which ultimately define our view of ourselves,
are entangled with those concepts that Cassirer identified as the cornerstones
of culture: space, time, and number. To explore these ideas, the authors wrote
an essay, in 2017, in a book format, in which the fundamental role of real and
imaginary spaces (and especially of their dimensionalities) in the History of
Culture was discussed. This book, titled ""O Livro, o Espa\c{c}o e a Natureza:
Ensaio Sobre a Leitura do Mundo, as Muta\c{c}\~oes da Cultura e do Sujeito"",
has a preface written by Francisco Antonio Doria. As many of the issues treated
there are among his multiple interests, it was decided to revisit here the
problems of subjectivity and subject's relationship with the dimensionality of
space including the question of the architecture of books and other writing
supports.",217,9,1393,35.51
2588,cultural anthropology,"In this paper we study the differences in historical World View between
Western and Eastern cultures, represented through the English, the Chinese,
Japanese, and German Wikipedia. In particular, we analyze the historical
networks of the World's leaders since the beginning of written history,
comparing them in the different Wikipedias and assessing cultural chauvinism.
We also identify the most influential female leaders of all times in the
English, German, Spanish, and Portuguese Wikipedia. As an additional lens into
the soul of a culture we compare top terms, sentiment, emotionality, and
complexity of the English, Portuguese, Spanish, and German Wikinews.",98,5,664,29.69
2589,cultural anthropology,"Education is a right of all, however, every individual is different than
others. Teachers in post-communism era discover inherent individualism to
equally train all towards job market of fourth industrial revolution. We can
consider scenario of ethnic minority education in academic practices. Ethnic
minority group has grown in their own culture and would prefer to be taught in
their native way. We have formulated such linguistic anthropology(how people
learn)based engagement as semi-supervised problem. Then, we have developed an
conditional deep generative adversarial network algorithm namely LA-GAN to
classify linguistic ethnographic features in student engagement. Theoretical
justification proves the objective, regularization and loss function of our
semi-supervised adversarial model. Survey questions are prepared to reach some
form of assumptions about z-generation and ethnic minority group, whose
learning style, learning approach and preference are our main area of interest.",137,9,993,20.28
2590,cultural anthropology,"Extensive cooperation among biologically unrelated individuals is uniquely
human and much current research attempts to explain this fact. We draw upon
social, cultural, and psychological aspects of human uniqueness to present an
integrated theory of human cooperation that explains aspects of human
cooperation that are problematic for other theories (e.g., defector invasion
avoidance, preferential assortment to exclude free riders, and the second order
free rider problem). We propose that the evolution of human cooperative
behavior required (1) a capacity for self-sustained, self-referential thought
manifested as an integrated worldview, including a sense of identity and point
of view, and (2) the cultural formation of kinship-based social organizational
systems within which social identities can be established and transmitted
through enculturation. Human cooperative behavior arose, we argue, through the
acquisition of a culturally grounded social identity that included the
expectation of cooperation among kin. This identity is linked to basic survival
instincts by emotions that are mentally experienced as culture laden feelings.
As a consequence, individuals are motivated to cooperate with those perceived
culturally as kin, while deviations from expected social behavior are
experienced as threatening to one's social identity, leading to punishment of
those seen as violating cultural expectations regarding socially proper
behavior.",201,9,1454,0.04
2591,cultural anthropology,"Unbiased models are foundational in the archaeological study of cultural
transmission. Applications have as- sumed that archaeological data represent
synchronic samples, despite the accretional nature of the archaeological
record. I document the circumstances under which time-averaging alters the
distribution of model predictions. Richness is inflated in long-duration
assemblages, and evenness is ""flattened"" compared to unaveraged samples. Tests
of neutrality, employed to differentiate biased and unbiased models, suffer
serious problems with Type I error under time-averaging. Finally, the
time-scale over which time-averaging alters predictions is determined by the
mean trait lifetime, providing a way to evaluate the impact of these effects
upon archaeological samples.",103,7,778,11.72
2592,cultural anthropology,"The commentators have brought a wealth of new perspectives to the question of
how culture evolves. Each of their diverse disciplines--ranging from psychology
to biology to anthropology to economics to engineering--has a valuable
contribution to make to our understanding of this complex, multifaceted topic.
Though the vast majority of their comments were supportive of my approach, it
is natural that a reply such as this focus on points where my views differ from
that of the commentators. ... I conclude by saying that I am grateful to the
commentators for their diverse perspectives and insights, their overall support
for the project, and provocative ideas for where to go from here. Clearly there
are many fascinating avenues to explore as we move forward on our quest to
understand how culture evolves.",130,9,809,45.29
2593,cultural anthropology,"Much work in cross-lingual transfer learning explored how to select better
transfer languages for multilingual tasks, primarily focusing on typological
and genealogical similarities between languages. We hypothesize that these
measures of linguistic proximity are not enough when working with
pragmatically-motivated tasks, such as sentiment analysis. As an alternative,
we introduce three linguistic features that capture cross-cultural similarities
that manifest in linguistic patterns and quantify distinct aspects of language
pragmatics: language context-level, figurative language, and the lexification
of emotion concepts. Our analyses show that the proposed pragmatic features do
capture cross-cultural similarities and align well with existing work in
sociolinguistics and linguistic anthropology. We further corroborate the
effectiveness of pragmatically-driven transfer in the downstream task of
choosing transfer languages for cross-lingual sentiment analysis.",122,6,971,4.41
2594,cultural anthropology,"Autocatalytic networks have been used to model the emergence of
self-organizing structure capable of sustaining life and undergoing biological
evolution. Here, we model the emergence of cognitive structure capable of
undergoing cultural evolution. Mental representations of knowledge and
experiences play the role of catalytic molecules, and interactions amongst them
(e.g., the forging of new associations) play the role of reactions, and result
in representational redescription. The approach tags mental representations
with their source, i.e., whether they were acquired through social learning,
individual learning (of pre-existing information), or creative thought
(resulting in the generation of new information). This makes it possible to
model how cognitive structure emerges, and to trace lineages of cumulative
culture step by step. We develop a formal representation of the cultural
transition from Oldowan to Acheulean tool technology using Reflexively
Autocatalytifc and Food set generated (RAF) networks. Unlike more primitive
Oldowan stone tools, the Acheulean hand axe required not only the capacity to
envision and bring into being something that did not yet exist, but
hierarchically structured thought and action, and the generation of new mental
representations: the concepts EDGING, THINNING, SHAPING, and a meta-concept,
HAND AXE. We show how this constituted a key transition towards the emergence
of semantic networks that were self-organizing, self-sustaining, and
autocatalytic, and discuss how such networks replicated through social
interaction. The model provides a promising approach to unraveling one of the
greatest anthropological mysteries: that of why development of the Acheulean
hand axe was followed by over a million years of cultural stasis.",252,14,1782,22.85
2595,cultural anthropology,"On one hand, kinship is a universal human phenomenon that tends to align with
biological relatedness, which might suggest evolutionary foundations. On the
other hand, kinship has exceptional variation across the human populations,
which points to cultural foundations. Furthermore, even if its foundation was
biological, kinship is often too imprecise to track genetic relatedness
efficiently, while inclusive fitness theory would suggest focusing only on the
closest relatives, which is not the case in most human cultures. It was the
parallel validity of these contradicting arguments that led to decades of
fierce debate about the definition and measurement of the phenomenon. This
paper offers a new approach to kinship. First, the model demonstrates that it
is possible to generate kinship networks (a) derived from the kind of basic kin
connections that our species shares with other apes, but (b) driven by network
rather than biological logic beyond the immediate family. Second the model
demonstrates that kinship as a network heuristic works efficiently only in high
fertility societies, and gives way to similarity-based friendship with
demographic transition. The results explain (i) why kinship labelling is unique
to our species, (ii) why kinship is universal among human cultures, (iii) why
kinship terminology systems are varied across cultures, (iv) why linguistic kin
assignment is imprecise, and (v) why kinship is replaced by homophily when
relatives are scarce. The model offers a unifying framework to the debate
between social and evolutionary anthropology concerning the concept of human
kinship.",243,10,1620,27.15
2596,cultural anthropology,"How does our society appreciate the uniqueness of cultural products? This
fundamental puzzle has intrigued scholars in many fields, including psychology,
sociology, anthropology, and marketing. It has been theorized that cultural
products that balance familiarity and novelty are more likely to become
popular. However, a cultural product's novelty is typically multifaceted. This
paper uses songs as a case study to study the multiple facets of uniqueness and
their relationship with success. We first unpack the multiple facets of a
song's novelty or uniqueness and, next, measure its impact on a song's
popularity. We employ a series of statistical models to study the relationship
between a song's popularity and novelty associated with its lyrics, chord
progressions, or audio properties. Our analyses performed on a dataset of over
fifty thousand songs find a consistently negative association between all types
of song novelty and popularity. Overall we found a song's lyrics uniqueness to
have the most significant association with its popularity. However, audio
uniqueness was the strongest predictor of a song's popularity, conditional on
the song's genre. We further found the theme and repetitiveness of a song's
lyrics to mediate the relationship between the song's popularity and novelty.
Broadly, our results contradict the ""optimal distinctiveness theory"" (balance
between novelty and familiarity) and call for an investigation into the
multiple dimensions along which a cultural product's uniqueness could manifest.",225,12,1532,27.01
2597,cultural anthropology,"In lieu of an abstract here is the first paragraph: No other species remotely
approaches the human capacity for the cultural evolution of novelty that is
accumulative, adaptive, and open-ended (i.e., with no a priori limit on the
size or scope of possibilities). By culture we mean extrasomatic
adaptations--including behavior and technology--that are socially rather than
sexually transmitted. This chapter synthesizes research from anthropology,
psychology, archaeology, and agent-based modeling into a speculative yet
coherent account of two fundamental cognitive transitions underlying human
cultural evolution that is consistent with contemporary psychology. While the
chapter overlaps with a more technical paper on this topic (Gabora & Smith
2018), it incorporates new research and elaborates a genetic component to our
overall argument. The ideas in this chapter grew out of a non-Darwinian
framework for cultural evolution, referred to as the Self-other Reorganization
(SOR) theory of cultural evolution (Gabora, 2013, in press; Smith, 2013), which
was inspired by research on the origin and earliest stage in the evolution of
life (Cornish-Bowden & C\'ardenas 2017; Goldenfeld, Biancalani, & Jafarpour,
2017, Vetsigian, Woese, & Goldenfeld 2006; Woese, 2002). SOR bridges
psychological research on fundamental aspects of our human nature such as
creativity and our proclivity to reflect on ideas from different perspectives,
with the literature on evolutionary approaches to cultural evolution that
aspire to synthesize the behavioral sciences much as has been done for the
biological scientists. The current chapter is complementary to this effort, but
less abstract; it attempts to ground the theory of cultural evolution in terms
of cognitive transitions as suggested by archaeological evidence.",261,10,1808,13.51
2598,cultural anthropology,"The Genographic Project is an international effort using genetic data to
chart human migratory history. The project is non-profit and non-medical, and
through its Legacy Fund supports locally led efforts to preserve indigenous and
traditional cultures. In its second phase, the project is focusing on markers
from across the entire genome to obtain a more complete understanding of human
genetic variation. Although many commercial arrays exist for genome-wide SNP
genotyping, they were designed for medical genetic studies and contain
medically related markers that are not appropriate for global population
genetic studies. GenoChip, the Genographic Project's new genotyping array, was
designed to resolve these issues and enable higher-resolution research into
outstanding questions in genetic anthropology. We developed novel methods to
identify AIMs and genomic regions that may be enriched with alleles shared with
ancestral hominins. Overall, we collected and ascertained AIMs from over 450
populations. Containing an unprecedented number of Y-chromosomal and mtDNA SNPs
and over 130,000 SNPs from the autosomes and X-chromosome, the chip was
carefully vetted to avoid inclusion of medically relevant markers. The GenoChip
results were successfully validated. To demonstrate its capabilities, we
compared the FST distributions of GenoChip SNPs to those of two commercial
arrays for three continental populations. While all arrays yielded similarly
shaped (inverse J) FST distributions, the GenoChip autosomal and X-chromosomal
distributions had the highest mean FST, attesting to its ability to discern
subpopulations. The GenoChip is a dedicated genotyping platform for genetic
anthropology and promises to be the most powerful tool available for assessing
population structure and migration history.",256,13,1808,24.48
2599,cultural anthropology,"From an anthropological point of view, the whole concept of a ""path of
progress"" in astronomical discovery is anathema, since it implicitly downgrades
other cultural perspectives, such as the many ""indigenous cosmologies"" that
still exist in the modern world. By doing so, one risks provoking those who
hold them and-as is most obvious in places such as Hawaii where the two
""world-views"" come into direct contact-reating avoidable resistance to that
very progress. The problem is complicated by the existence of ""fringe"" and
""new-age"" views that are increasingly confused with, and even passed off as,
indigenous perceptions. In a modern world where widespread public perceptions
include many that are unscientific in the broadest sense of the term, I shall
argue that there are actually a range of positive benefits for progress in
scientific astronomy to be derived from the mutual awareness and comprehension
of ""genuine"" cultural world-views whose goals-in common with those of modern
science-are to make sense of the cosmos within which people live. While two-way
education is clearly a prerequisite, I shall argue that the necessary level of
reconciliation can only be achieved through more fundamental attempts by modern
astronomers to understand, and ultimately to respect, both the non-Western
frameworks of thought that give rise to other cultural perspectives and the
heritage associated with them. One of the most obvious potential benefits could
derive from common attitudes towards the natural heritage of astronomy, namely
dark skies.",237,7,1550,22.92
2600,cultural anthropology,"In many indigenous societies, people are categorised into several cultural
groups, or clans, within which they believe to share ancestors. Clan
attributions provide certain rules for marriage and descent. Such rules between
clans constitute kinship structures. Anthropologists have revealed several
kinship structures. Here, we propose an agent-based model of indigenous
societies to reveal the evolution of kinship structures. In the model, several
societies compete. Societies themselves comprise multiple families with
parameters for cultural traits and mate preferences. These values determine
with whom each family cooperates and competes and are transmitted to a new
generation with mutation. The growth rate of each family is determined by the
number of cooperators and competitors. Through this multi-level evolution,
family traits and preferences diverge to form clusters that can be regarded as
clans. Subsequently, kinship structures emerge, including dual organisation and
generalised or restricted exchange, as well as patrilineal, matrilineal, and
double descent systems. These structures emerge depending on the necessity of
cooperation and the strength of mating competition. Their dependence is also
estimated analytically. Finally, statistical analysis using the Standard
Cross-Cultural Sample, a global ethnographic database, empirically verified
theoretical results. Such collaboration between theoretical and empirical
approaches will unveil universal features in anthropology.",200,16,1498,15.68
2601,cultural anthropology,"The popularity of media sharing platforms in recent decades has provided an
abundance of open source data that remains underutilized by heritage scholars.
By pairing geotagged internet photographs with machine learning and computer
vision algorithms, we build upon the current theoretical discourse of
anthropology associated with visuality and heritage tourism to identify travel
patterns across a known archaeological heritage circuit, and quantify visual
culture and experiences in Cuzco, Peru. Leveraging large-scale in-the-wild
tourist photos, our goals are to (1) understand how the intensification of
tourism intersects with heritage regulations and social media, aiding in the
articulation of travel patterns across Cuzco's heritage landscape; and to (2)
assess how aesthetic preferences and visuality become entangled with the
rapidly evolving expectations of tourists, whose travel narratives are curated
on social media and grounded in historic site representations.",135,4,977,-8.05
2602,cultural anthropology,"We present a resource for computational experiments on Mapudungun, a
polysynthetic indigenous language spoken in Chile with upwards of 200 thousand
speakers. We provide 142 hours of culturally significant conversations in the
domain of medical treatment. The conversations are fully transcribed and
translated into Spanish. The transcriptions also include annotations for
code-switching and non-standard pronunciations. We also provide baseline
results on three core NLP tasks: speech recognition, speech synthesis, and
machine translation between Spanish and Mapudungun. We further explore other
applications for which the corpus will be suitable, including the study of
code-switching, historical orthography change, linguistic structure, and
sociological and anthropological studies.",103,7,786,20.18
2603,cultural anthropology,"The Human-Machine Interaction (HMI) research field is an important topic in
machine learning that has been deeply investigated thanks to the rise of
computing power in the last years. The first time, it is possible to use
machine learning to classify images and/or videos instead of the traditional
computer vision algorithms. The aim of this paper is to build a symbiosis
between a convolutional neural network (CNN) and a recurrent neural network
(RNN) to recognize cultural/anthropological Italian sign language gestures from
videos. The CNN extracts important features that later are used by the RNN.
With RNNs we are able to store temporal information inside the model to provide
contextual information from previous frames to enhance the prediction accuracy.
Our novel approach uses different data augmentation techniques and
regularization methods from only RGB frames to avoid overfitting and provide a
small generalization error.",142,7,938,30.5
2604,cultural anthropology,"We propose a decision-making model for joint intentionality by interpreting
it as group-mindedness at the microlevel. We apply this model to give a formal
justification of the first part of the Interdependence Hypothesis due to
Tomasello et al. [Current Anthropology, 2012] which asserts that the emergence
of joint intentionality evolved due to the challenges of difficult
collaborative foraging practices among early humans, and that its evolution led
to robust collaboration and some form of altruism.
  In another application of the microlevel group-mindedness we consider the
problem of establishing cooperation in high-risk-of-defection strategic
conflicts and we show that the emergence of cooperation in such situations can
be explained in the context of cultural group selection as the result of
adaptive learning.",120,5,823,15.65
2605,cultural anthropology,"Wikipedia has evolved beyond its original function as an online encyclopedia
in an increasingly complex data-driven society. The social platform is met with
a balancing act between collective intelligence and mass surveillance;
processes need to be developed to protect individuals and the community from
government mass surveillance without sacrificing the important contributions
made through prohibited anonymous communication software. Case studies are
provided from NSA government surveillance practices, the anti-SOPA legislation
movement, and research that covers Wikipedia's involvement with participatory
journalism, disinformation, self-censorship, and the use of Tor. This paper
proposes that a common ground can be developed between individuals, public and
private institutions through future research in socio-cultural anthropology and
policy frameworks around data retention and government accountability.
Wikipedia is used as an example within the US intelligence community as a
complex organisation that can adapt to changes through its iterative nature,
which draws insight into how policy frameworks can be future-proofed. Finally,
this paper is a wake-up call to individuals, private institutions, and
governments to remain vigilant about the storage and use of personal
information as a result of contributing to online communities.",184,7,1352,6.47
2606,cultural anthropology,"The metaverse and digital, virtual environments have been part of recent
history as places in which people can socialize, work and spend time playing
games. However, the infancy of the development of these digital, virtual
environments brings some challenges that are still not fully depicted. With
this article, we seek to identify and map the currently available knowledge and
scientific effort to discover what principles, guidelines, laws, policies, and
practices are currently in place to allow for the design of digital, virtual
environments, and the metaverse. Through a scoping review, we aimed to
systematically survey the existing literature and discern gaps in knowledge
within the domain of metaverse research from sociological, anthropological,
cultural, and experiential perspectives. The objective of this review was
twofold: (1) to examine the focus of the literature studying the metaverse from
various angles and (2) to formulate a research agenda for the design and
development of ethical digital, virtual environments. With this paper, we
identified several works and articles detailing experiments and research on the
design of digital, virtual environments and metaverses. We found an increased
number of publications in the year 2022. This finding, together with the fact
that only a few articles were focused on the domain of ethics, culture and
society shows that there is still a vast amount of work to be done to create
awareness, principles and policies that could help to design safe, secure and
inclusive digital, virtual environments and metaverses.",241,9,1580,24.0
2607,cultural anthropology,"Two mechanisms that have been used to study the evolution of cooperative
behavior are altruistic punishment, in which cooperative individuals pay
additional costs to punish defection, and multilevel selection, in which
competition between groups can help to counteract individual-level incentives
to cheat. Boyd, Gintis, Bowles, and Richerson have used simulation models of
cultural evolution to suggest that altruistic punishment and pairwise
group-level competition can work in concert to promote cooperation, even when
neither mechanism can do so on its own. In this paper, we formulate a PDE model
for multilevel selection motivated by the approach of Boyd and coauthors,
modeling individual-level birth-death competition with a replicator equation
based on individual payoffs and describing group-level competition with
pairwise conflicts based on differences in the average payoffs of the competing
groups. Building off of existing PDE models for multilevel selection with
frequency-independent group-level competition, we use analytical and numerical
techniques to understand how the forms of individual and average payoffs can
impact the long-time ability to sustain altruistic punishment in
group-structured populations. We find several interesting differences between
the behavior of our new PDE model with pairwise group-level competition and
existing multilevel PDE models, including the observation that our new model
can feature a non-monotonic dependence of the long-time collective payoff on
the strength of altruistic punishment. Going forward, our PDE framework can
serve as a way to connect and compare disparate approaches for understanding
multilevel selection across the literature in evolutionary biology and
anthropology.",243,7,1745,-3.48
2608,cultural anthropology,"This paper proposes that the distinctively human capacity for cumulative,
adaptive, open-ended cultural evolution came about through two
temporally-distinct cognitive transitions. First, the origin of Homo-specific
culture over two MYA was made possible by the onset of a finer-grained
associative memory that allowed episodes to be encoded in greater detail. This
in turn meant more overlap amongst the distributed representations of these
episodes, such that they could more readily evoke one another through
self-triggered recall (STR). STR enabled representational redescription, the
chaining of thoughts and actions, and the capacity for a stream of thought.
Second, fully cognitive modernity following the appearance of anatomical
modernity after 200,000 BP, was made possible by the onset of contextual focus
(CF): the ability to shift between an explicit convergent mode conducive to
logic and refinement of ideas, and an implicit divergent mode conducive to
free-association, viewing situations from radically new perspectives, concept
combination, analogical thinking, and insight. This paved the way for an
integrated, creative internal network of understandings, and behavioral
modernity. We discuss feasible neural mechanisms for this two-stage proposal,
and outline how STR and CF differ from other proposals. We provide
computational evidence for the proposal obtained with an agent-based model of
cultural evolution in which agents invent ideas for actions and imitate the
fittest of their neighbors' actions. Mean fitness and diversity of actions
across the artificial society increased with STR, and even more so with CF, but
CF was only effective if STR was already in place. CF was most effective
following a change in task, which supports its hypothesized role in escaping
mental fixation. The proposal is discussed in the context of transition theory
in the life sciences.",279,12,1894,28.77
2609,cultural anthropology,An attempt of a new kind of complexity anthropology is considered.,11,2,66,34.93
2610,cultural anthropology,"The introduction and emergence of agriculture into Eastern North America
(ENA) and Europe proceeded very differently in both subcontinents: it varied in
timing, speed, and mechanism. Common to both regions, agricultural subsistence
profited from the introduction of major staple crops which had been
domesticated elsewhere; in both regions, the temperate climate and originally
predominant forest vegetation provided an environmental context conducive to
agriculture. To understand the different paths to agricultural subsistence, an
integrated view of technological innovation, domestication and exchange of
domesticates, migration and trade is required within the constraints imposed by
the environmental context and geography. This study makes use of a numerical
model of regional socio-technological evolution which builds on adaptation of
important characteristics of prehistoric societies such as technology and
subsistence diversity. With this Global Land Use and Technological Evolution
Simulator (GLUES), regional transitions from foraging to agropastoralism, and
associated land use and demographic changes are realistically hindcasted. I
show that the model is capable of explaining the different timing, speed, and
transition mechanisms: Europe received a large package of foreign domesticates
and converted rapidly to agriculture, this fast transition can be best
explained with demic and cultural diffusion followed by fast adoption by
resident foragers. In contrast, ENA trajectories show a more gradual
transition. Hunting-gathering and agropastoral life style coexisted for a long
time and agriculture was adopted slowly into the existing subsistence scheme.",228,9,1675,8.71
2611,cultural anthropology,"Digital Archaeoludology (DAL) is a new field of study involving the analysis
and reconstruction of ancient games from incomplete descriptions and
archaeological evidence using modern computational techniques. The aim is to
provide digital tools and methods to help game historians and other researchers
better understand traditional games, their development throughout recorded
human history, and their relationship to the development of human culture and
mathematical knowledge. This work is being explored in the ERC-funded Digital
Ludeme Project.
  The aim of this inaugural international research meeting on DAL is to gather
together leading experts in relevant disciplines - computer science, artificial
intelligence, machine learning, computational phylogenetics, mathematics,
history, archaeology, anthropology, etc. - to discuss the key themes and
establish the foundations for this new field of research, so that it may
continue beyond the lifetime of its initiating project.",137,6,984,10.23
2612,cultural anthropology,"We advance binational link-tracing sampling design, an innovative data
collection methodology for sampling from transnational social fields, i.e.,
transnational networks embedding migrants and non-migrants. This paper shows
the practical challenges of such a design, the representativeness of the
samples and the qualities of the resulted networks. We performed 303
face-to-face structured interviews on sociodemographic variables, migration
trajectories and personal networks of people living in a Romanian migration
sending community (D\^ambovi\c{t}a) and in a migration receiving Spanish town
(Castell\'on), simultaneously in both sites. Inter-connecting the personal
networks, we built a multi-layered complex network structure embedding 4,855
nominated people, 5,477 directed ties (nominations) and 2,540 edges. Results
indicate that the participants' unique identification is a particularly
difficult challenge, the representativeness of the data is not optimal
(homophily on observed attributes was detected in the nomination patterns), and
the relational and attribute data allow to explore the social organization of
the Romanian migrant enclave in Castell\'on, as well as its connectivity to
other places. Furthermore, we provide methodological suggestions for improving
link-tracing sampling from transnational networks of migration. Our research
contributes to the emerging efforts of applying social network analysis to the
study of international migration.",193,10,1470,4.71
2613,cultural anthropology,"Families form the basis of society, and anthropologists have characterised
various family systems. This study developed a multi-level evolutionary model
of pre-industrial agricultural societies to simulate the evolution of family
systems and determine how each of them adapts to environmental conditions and
forms a characteristic socio-economic structure. In the model, competing
societies evolve, which themselves comprise multiple evolving families that
grow through family labour. Each family has two strategy parameters: the time
children leave the parental home and the distribution of inheritance among
siblings. The evolution of these parameters demonstrates that four basic family
systems emerge; families can become either nuclear or extended, and have either
an equal or unequal inheritance distribution. Nuclear families emerge where
land resources are sufficient, whereas extended families emerge where land
resources are limited. Equal inheritance emerges where the amount of wealth
required for a family to survive is large, whereas unequal inheritance emerges
where the required wealth is small. Analyses on the wealth distribution of
families demonstrate a higher level of poverty in extended families, and that
the accumulation of wealth is accelerated for unequal inheritance. By comparing
wealth distributions in the model with historical data, family systems are
associated with characteristic economic structures and modern social
ideologies. Empirical data analyses using the cross-cultural ethnographic
database verify the theoretical relationship between the environmental
conditions, family systems, and socio-economic structures. Theoretical studies
by this simple constructive model, as presented here, will integrate the
understandings of family systems in evolutionary anthropology, demography, and
socioeconomic histories.",249,12,1853,6.24
2614,cultural anthropology,"Within anthropology, the use of three-dimensional (3D) imaging has become
increasingly standard and widespread since it broadens the available avenues
for addressing a wide range of key issues. The ease with which 3D models can be
shared has had major impacts for research, cultural heritage, education,
science communication, and public engagement, as well as contributing to the
preservation of the physical specimens and archiving collections in widely
accessible data bases. Current scanning protocols have the ability to create
the required research quality 3D models; however, they tend to be time and
labor intensive and not practical when working with large collections. Here we
describe a streamlined, Batch Artifact Scanning Protocol we have developed to
rapidly create 3D models using a medical CT scanner. Though this method can be
used on a variety of material types, we use a large collection of
experimentally broken ungulate limb bones. Using the Batch Artifact Scanning
Protocol, we were able to efficiently create 3D models of 2,474 bone fragments
at a rate of less than $3$ minutes per specimen, as opposed to an average of 50
minutes per specimen using structured light scanning.",188,7,1199,31.25
2615,cultural anthropology,"Many species engage in acts that could be called creative. However, human
creativity is unique in that it has transformed our planet. Given that the
anatomy of the human brain is not so different from that of the great apes,
what enables us to be so creative? Recent collaborations at the frontier of
anthropology, archaeology, psychology, and cognitive science are culminating in
speculative but increasingly sophisticated efforts to answer to this question.
Examining the skeletons of our ancestors gives cues as to anatomical
constraints that hindered or made possible various kinds of creative
expression. Relics of the past have much to tell us about the thoughts,
beliefs, and creative abilities of the people who invented and used them. How
the spectacular creativity of humans came about is the first topic addressed in
this chapter. Studies at the intersection of creativity and evolution are not
limited to investigations into the biological evolution of a highly creative
species. Creative ideas themselves might be said to evolve through culture.
Human creativity is distinctive because of the adaptive and open-ended manner
in which change accumulates. Inventions build on previous ones in ways that
enhance their utility or aesthetic appeal, or make them applicable in different
situations. There is no a priori limit to how a creative idea might unfold. It
is this proclivity to take an idea and make it our own, or 'put our own spin on
it', that makes creative ideas evolve. The next section of this chapter
investigates in what sense creative ideas evolve through culture. Finally, we
address what forces supported the evolution of creativity. Does being creative
help us live longer, or attract mates? Perhaps creative projects can sometimes
interfere with survival and reproductive fitness; are there non-biological
factors that compel us to create? This is a third topic addressed in this
chapter.",304,16,1917,54.32
2616,cultural anthropology,"Social media are being increasingly used for health promotion, yet the
landscape of users, messages and interactions in such fora is poorly
understood. Studies of social media and diabetes have focused mostly on
patients, or public agencies addressing it, but have not looked broadly at all
the participants or the diversity of content they contribute. We study Twitter
conversations about diabetes through the systematic analysis of 2.5 million
tweets collected over 8 months and the interactions between their authors. We
address three questions: (1) what themes arise in these tweets?, (2) who are
the most influential users?, (3) which type of users contribute to which
themes? We answer these questions using a mixed-methods approach, integrating
techniques from anthropology, network science and information retrieval such as
thematic coding, temporal network analysis, and community and topic detection.
Diabetes-related tweets fall within broad thematic groups: health information,
news, social interaction, and commercial. At the same time, humorous messages
and references to popular culture appear consistently, more than any other type
of tweet. We classify authors according to their temporal 'hub' and 'authority'
scores. Whereas the hub landscape is diffuse and fluid over time, top
authorities are highly persistent across time and comprise bloggers, advocacy
groups and NGOs related to diabetes, as well as for-profit entities without
specific diabetes expertise. Top authorities fall into seven interest
communities as derived from their Twitter follower network. Our findings have
implications for public health professionals and policy makers who seek to use
social media as an engagement tool and to inform policy design.",256,12,1742,35.98
2617,cultural anthropology,"We find that the set of local quantum operations and classical communication
for multiparty quantum states can be considered as analogous to online meetings
between members of a population. Moreover, monotonicity properties of quantum
and classical correlations of quantum states of shared systems also carry over
to relations between members of the population, giving rise to what may be
termed as a second law of anthropology.",66,3,428,21.06
2618,cultural anthropology,"What kind of questions about human mobility can computational analysis help
answer? How to translate the findings into anthropology? We analyzed a publicly
available data set of road traffic counters in Slovenia to answer these
questions. The data reveals interesting information on how a nation drives, how
it travels for tourism, which locations it prefers, what it does during the
week and the weekend, and how its habits change during the year. We conducted
the empirical analysis in two parts. First, we defined interesting traffic
spots and designed computational methods to find them in a large data set. As
shown in the paper, traffic counters hint at potential causes and effects in
driving practices that we can interpret anthropologically. Second, we used
clustering to find groups of similar traffic counters as described by their
daily profiles. Clustering revealed the main features of road traffic in
Slovenia. Using the two quantitative approaches, we outline the general
properties of road traffic in the country and identify and explain interesting
outliers. We show that quantitative data analysis only partially answers
anthropological questions, but it can be a valuable tool for preliminary
research. We conclude that open data are a useful component in an
anthropological analysis and that quantitative discovery of small local events
can help us pinpoint future fieldwork sites.",217,11,1402,44.64
2619,cultural anthropology,"This article examines the importance of graphic representations in the social
sciences, and particularly in (medieval) history, taking as its starting point
a reflection by {\'E}tienne-Jules Marey, a physiologist and pioneer of
19th-century photography and cinema. Marey believed that the visual should
replace language in many fields. Indeed, the twentieth and early twenty-first
centuries saw an exponential multiplication of visual media, particularly with
the advent of digital technology. However, this ''graphics revolution'' has not
affected all disciplines equally. Significant differences remain between
scientific fields such as astrophysics, anthropology, chemistry and medieval
history, despite their shared commitment to describing dynamic processes and
changes of state. Yet, while historians have already digitized a large part of
the cultural heritage from Antiquity to the 10th-13th centuries, exploration of
this corpus using visualizations remains limited. There is therefore untapped
potential in this field.This article begins by outlining a typology and
quantification of the past and potential roles of visual representations in
medieval history. It examines two distinct intellectual approaches: 1. the use
of visuals to support a scientific discourse (majority) and 2. the construction
of a historical discourse based on observations made from visual figures with
the aim of modeling phenomena invisible to the naked eye. The author thus
examines the use of ''images'' in medievalism, focusing on the annual volumes
of the Soci{\'e}t{\'e} des historiens m{\'e}di{\'e}vistes de l'enseignement
sup{\'e}rieur (SHMESP), up to 2006. Two other parts of the text look at the
still-rare forms of visual representation in medieval history, particularly
those with a ''heuristic vocation'', using iconographic objects, parchments,
buildings and digitized texts. The article suggests various visualization
techniques, such as network analysis, the creation of ''stemmas 2.0'' and
interactive chronologies, which could benefit the discipline. These methods
could potentially profoundly change our understanding of ancient societies, by
showing the dynamic relationships between different aspects of these societies.
One of the most important advances expected from these visual methods is a
better understanding of the patterns of development in medieval Europe, which
varied from region to region. The hypothesis is that the scarcity of heuristic
graphics in medieval history stems from the relationship with ancient documents
and the historical method based on narration and exemplarity. The article thus
questions the value of ''visual modelling'' in medieval history, and highlights
the challenges associated with the widespread adoption of this approach in the
humanities and social sciences. Finally, the text invites us to reflect on the
nature and functioning of heuristic visual devices, by comparing medieval
''images'' and contemporary scientific visuals. In both cases, the point is to
materialize the invisible in order to show something that exists beyond the
visual. The author suggests that this way of approaching visuals could play a
growing role in the decades to come, particularly in the field of data science.",463,23,3244,24.78
2620,cultural anthropology,"Computerization has created a digital ecological niche where humans live in a
state of interconnection that modifies their Epigenetics. Within this
hyper-datafied virtual space, the logged-in agent enhances their intellectual
and rational abilities, giving rise to a new cognitive entity. Humans are
evolving towards a new anthropological status that shifts the terms of the
Digital History debate from History to the historian, compelling the latter to
reflect on the positions of Fichte and Schelling regarding the mind-body-world
relationship (ecological niche). This reflection leads to the possibility of
overcoming the crisis of History imposed by presentism and the necessity of
redefining the research methodology based on the new vision of the
interconnection between the mind and the digital niche as an investigative
tool.",122,5,833,15.14
2621,cultural anthropology,"Over the next few years, society as a whole will need to address what core
values it wishes to protect when dealing with technology. Anthropology, a field
dedicated to the very notion of what it means to be human, can provide some
interesting insights into how to cope and tackle these changes in our Western
society and other areas of the world. It can be challenging for social science
practitioners to grasp and keep up with the pace of technological innovation,
with many being unfamiliar with the jargon of AI. This short guide serves as
both an introduction to AI ethics and social science and anthropological
perspectives on the development of AI. It intends to provide those unfamiliar
with the field with an insight into the societal impact of AI systems and how,
in turn, these systems can lead us to rethink how our world operates.",146,6,842,50.3
2622,cultural anthropology,"The increasing ubiquity of language technology necessitates a shift towards
considering cultural diversity in the machine learning realm, particularly for
subjective tasks that rely heavily on cultural nuances, such as Offensive
Language Detection (OLD). Current understanding underscores that these tasks
are substantially influenced by cultural values, however, a notable gap exists
in determining if cultural features can accurately predict the success of
cross-cultural transfer learning for such subjective tasks. Addressing this,
our study delves into the intersection of cultural features and transfer
learning effectiveness. The findings reveal that cultural value surveys indeed
possess a predictive power for cross-cultural transfer learning success in OLD
tasks and that it can be further improved using offensive word distance. Based
on these results, we advocate for the integration of cultural information into
datasets. Additionally, we recommend leveraging data sources rich in cultural
information, such as surveys, to enhance cultural adaptability. Our research
signifies a step forward in the quest for more inclusive, culturally sensitive
language technologies.",162,8,1181,14.19
2623,cultural anthropology,"As the utilization of large language models (LLMs) has proliferated
worldwide, it is crucial for them to have adequate knowledge and fair
representation for diverse global cultures. In this work, we uncover culture
perceptions of three SOTA models on 110 countries and regions on 8
culture-related topics through culture-conditioned generations, and extract
symbols from these generations that are associated to each culture by the LLM.
We discover that culture-conditioned generation consist of linguistic ""markers""
that distinguish marginalized cultures apart from default cultures. We also
discover that LLMs have an uneven degree of diversity in the culture symbols,
and that cultures from different geographic regions have different presence in
LLMs' culture-agnostic generation. Our findings promote further research in
studying the knowledge and fairness of global culture perception in LLMs. Code
and Data can be found in: https://github.com/huihanlhh/Culture-Gen/",136,7,972,23.05
2624,cultural anthropology,"Making use of the information from the World Value Survey (WVS), and
operationalizing a definition of national culture that encompasses both the
relevance of specific cultural traits and the interdependence among them, this
paper proposes a methodology to reveal the latent structure of national culture
and to measure cultural distance between countries that takes into account both
the difference in cultural traits and the difference in the network structure
of national cultures. Exploiting the possibilities offered by copula graphical
models for discrete data, this paper infers the cultural networks of all the
countries included in the WVS (Wave 6) and proposes a novel unifying framework
to measure national culture and international cultural distances. The Jeffreys'
divergence between copula graphical models, taken as the measure of cultural
distance between countries, captures the orthogonality of the two components of
cultural distance: the one based on cultural traits and the one based on the
network structure among them. Moreover, the two components are shown to
correlate with different national and structural characteristics of cultural
networks, thus encompassing the different informational sets related to
national cultures.",182,5,1250,-0.1
2625,cultural anthropology,"The deployment of large language models (LLMs) raises concerns regarding
their cultural misalignment and potential ramifications on individuals and
societies with diverse cultural backgrounds. While the discourse has focused
mainly on political and social biases, our research proposes a Cultural
Alignment Test (Hoftede's CAT) to quantify cultural alignment using Hofstede's
cultural dimension framework, which offers an explanatory cross-cultural
comparison through the latent variable analysis. We apply our approach to
quantitatively evaluate LLMs, namely Llama 2, GPT-3.5, and GPT-4, against the
cultural dimensions of regions like the United States, China, and Arab
countries, using different prompting styles and exploring the effects of
language-specific fine-tuning on the models' behavioural tendencies and
cultural values. Our results quantify the cultural alignment of LLMs and reveal
the difference between LLMs in explanatory cultural dimensions. Our study
demonstrates that while all LLMs struggle to grasp cultural values, GPT-4 shows
a unique capability to adapt to cultural nuances, particularly in Chinese
settings. However, it faces challenges with American and Arab cultures. The
research also highlights that fine-tuning LLama 2 models with different
languages changes their responses to cultural questions, emphasizing the need
for culturally diverse development in AI for worldwide acceptance and ethical
use. For more details or to contribute to this research, visit our GitHub page
https://github.com/reemim/Hofstedes_CAT/",211,10,1548,22.34
2626,cultural anthropology,"Cross cultural research projects are becoming a norm in our global world.
More and more projects are being executed using teams from eastern and western
cultures. Cultural competence might help project managers to achieve project
goals and avoid potential risks in cross cultural project environments and
would also support them to promote creativity and motivation through flexible
leadership. In our paper we introduce an idea for constructing an information
system, a cross cultural knowledge space, which could support cross cultural
communication, collaborative learning experiences and time based project
management functions. The case cultures in our project are Finnish and
Japanese. The system can be used both in virtual and in physical spaces for
example to clarify cultural business etiquette. The core of our system design
will be based on cross cultural ontology, and the system implementation on XML
technologies. Our approach is a practical, step by step example of constructive
research. In our paper we shortly describe Hofstede's dimensions for assessing
cultures as one example of a larger framework for our study. We also discuss
the concept of time in cultural context.",182,11,1191,44.54
2627,cultural anthropology,"There is a bidirectional relationship between culture and AI; AI models are
increasingly used to analyse culture, thereby shaping our understanding of
culture. On the other hand, the models are trained on collections of cultural
artifacts thereby implicitly, and not always correctly, encoding expressions of
culture. This creates a tension that both limits the use of AI for analysing
culture and leads to problems in AI with respect to cultural complex issues
such as bias.
  One approach to overcome this tension is to more extensively take into
account the intricacies and complexities of culture. We structure our
discussion using four concepts that guide humanistic inquiry into culture:
subjectivity, scalability, contextuality, and temporality. We focus on these
concepts because they have not yet been sufficiently represented in AI
research. We believe that possible implementations of these aspects into AI
research leads to AI that better captures the complexities of culture. In what
follows, we briefly describe these four concepts and their absence in AI
research. For each concept, we define possible research challenges.",172,10,1137,35.17
2628,cultural anthropology,"Text-To-Image (TTI) models, such as DALL-E and StableDiffusion, have
demonstrated remarkable prompt-based image generation capabilities.
Multilingual encoders may have a substantial impact on the cultural agency of
these models, as language is a conduit of culture. In this study, we explore
the cultural perception embedded in TTI models by characterizing culture across
three hierarchical tiers: cultural dimensions, cultural domains, and cultural
concepts. Based on this ontology, we derive prompt templates to unlock the
cultural knowledge in TTI models, and propose a comprehensive suite of
evaluation techniques, including intrinsic evaluations using the CLIP space,
extrinsic evaluations with a Visual-Question-Answer (VQA) model and human
assessments, to evaluate the cultural content of TTI-generated images. To
bolster our research, we introduce the CulText2I dataset, derived from four
diverse TTI models and spanning ten languages. Our experiments provide insights
regarding Do, What, Which and How research questions about the nature of
cultural encoding in TTI models, paving the way for cross-cultural applications
of these models.",160,7,1146,18.99
2629,cultural anthropology,"Culture evolves following a process that is akin to biological evolution,
although with some significant differences. At the same time culture has often
a collective good value for human groups. This paper studies culture in an
evolutionary perspective, with a focus on the implications of group definition
for the coexistence of different cultures. A model of cultural evolution is
presented where agents interacts in an artificial environment. The belonging to
a specific memetic group is a major factor allowing agents to exploit different
environmental niches with, as a result, the coexistence of different cultures
in the same environment.",98,6,645,26.2
2630,cultural anthropology,"The current article traces back the scientific interest to cultural levels
across the organization at the University of National and World Economy, and
especially in the series of Economic Alternatives - an official scientific
magazine, issued by this Institution. Further, a wider and critical review of
international achievements in this field is performed, revealing diverse
analysis perspectives with respect to cultural levels. Also, a useful model of
exploring and teaching the cultural levels beyond the organization is proposed.
  Keywords: globalization, national culture, organization culture, cultural
levels, cultural economics. JEL: M14, Z10.",91,6,655,10.91
2631,cultural anthropology,"The paper discusses the potential of large vision-language models as objects
of interest for empirical cultural studies. Focusing on the comparative
analysis of outputs from two popular text-to-image synthesis models, DALL-E 2
and Stable Diffusion, the paper tries to tackle the pros and cons of striving
towards culturally agnostic vs. culturally specific AI models. The paper
discusses several examples of memorization and bias in generated outputs which
showcase the trade-off between risk mitigation and cultural specificity, as
well as the overall impossibility of developing culturally agnostic models.",87,5,608,15.51
2632,cultural anthropology,"Cultural values vary significantly around the world. Despite a large
heterogeneity, similarities across national cultures are present. This paper
studies cross-country culture heterogeneity via the joint inference of
country-specific copula graphical models from world-wide survey data. To this
end, a random graph generative model of the cultural networks is introduced,
with a latent space and proximity measures that embed cultural relatedness
across countries. Within-country heterogeneity is also accounted for, via
parametric modelling of the marginal distributions of each cultural trait. All
together, the different components of the model are able to identify several
dimensions of culture.",96,7,699,21.4
2633,cultural anthropology,"Cultural bias is pervasive in many large language models (LLMs), largely due
to the deficiency of data representative of different cultures. Typically,
cultural datasets and benchmarks are constructed either by extracting subsets
of existing datasets or by aggregating from platforms such as Wikipedia and
social media. However, these approaches are highly dependent on real-world data
and human annotations, making them costly and difficult to scale. Inspired by
cognitive theories on social communication, this paper introduces CulturePark,
an LLM-powered multi-agent communication framework for cultural data
collection. CulturePark simulates cross-cultural human communication with
LLM-based agents playing roles in different cultures. It generates high-quality
cross-cultural dialogues encapsulating human beliefs, norms, and customs. Using
CulturePark, we generated 41,000 cultural samples to fine-tune eight
culture-specific LLMs. We evaluated these models across three downstream tasks:
content moderation, cultural alignment, and cultural education. Results show
that for content moderation, our GPT-3.5-based models either match or
outperform GPT-4 on datasets. Regarding cultural alignment, our models surpass
GPT-4 on Hofstede's VSM 13 framework. Furthermore, for cultural education of
human participants, our models demonstrate superior outcomes in both learning
efficacy and user experience compared to GPT-4. CulturePark proves an important
step in addressing cultural bias and advancing the democratization of AI,
highlighting the critical role of culturally inclusive data in model training.",212,14,1608,12.63
2634,cultural anthropology,"Image Captioning generates descriptive sentences from images using
Vision-Language Pre-trained models (VLPs) such as BLIP, which has improved
greatly. However, current methods lack the generation of detailed descriptive
captions for the cultural elements depicted in the images, such as the
traditional clothing worn by people from Asian cultural groups. In this paper,
we propose a new framework, \textbf{Culturally-aware Image Captioning (CIC)},
that generates captions and describes cultural elements extracted from cultural
visual elements in images representing cultures. Inspired by methods combining
visual modality and Large Language Models (LLMs) through appropriate prompts,
our framework (1) generates questions based on cultural categories from images,
(2) extracts cultural visual elements from Visual Question Answering (VQA)
using generated questions, and (3) generates culturally-aware captions using
LLMs with the prompts. Our human evaluation conducted on 45 participants from 4
different cultural groups with a high understanding of the corresponding
culture shows that our proposed framework generates more culturally descriptive
captions when compared to the image captioning baseline based on VLPs. Our code
and dataset will be made publicly available upon acceptance.",176,7,1290,16.36
2635,cultural anthropology,"Recent studies have highlighted the presence of cultural biases in Large
Language Models (LLMs), yet often lack a robust methodology to dissect these
phenomena comprehensively. Our work aims to bridge this gap by delving into the
Food domain, a universally relevant yet culturally diverse aspect of human
life. We introduce FmLAMA, a multilingual dataset centered on food-related
cultural facts and variations in food practices. We analyze LLMs across various
architectures and configurations, evaluating their performance in both
monolingual and multilingual settings. By leveraging templates in six different
languages, we investigate how LLMs interact with language-specific and cultural
knowledge. Our findings reveal that (1) LLMs demonstrate a pronounced bias
towards food knowledge prevalent in the United States; (2) Incorporating
relevant cultural context significantly improves LLMs' ability to access
cultural knowledge; (3) The efficacy of LLMs in capturing cultural nuances is
highly dependent on the interplay between the probing language, the specific
model architecture, and the cultural context in question. This research
underscores the complexity of integrating cultural understanding into LLMs and
emphasizes the importance of culturally diverse datasets to mitigate biases and
enhance model performance across different cultural domains.",188,8,1358,10.33
2636,cultural anthropology,"The integration of new technology with cultural studies enhances our
understanding of cultural heritage but often struggles to connect with diverse
audiences. It is challenging to align personal interpretations with the
intended meanings across different cultures. Our study investigates the
important factors in appreciating art from a cross-cultural perspective. We
explore the application of Large Language Models (LLMs) to bridge the cultural
and language barriers in understanding Traditional Chinese Paintings (TCPs). We
present CultiVerse, a visual analytics system that utilizes LLMs within a
mixed-initiative framework, enhancing interpretative appreciation of TCP in a
cross-cultural dialogue. CultiVerse addresses the challenge of translating the
nuanced symbolism in art, which involves interpreting complex cultural
contexts, aligning cross-cultural symbols, and validating cultural acceptance.
CultiVerse integrates an interactive interface with the analytical capability
of LLMs to explore a curated TCP dataset, facilitating the analysis of
multifaceted symbolic meanings and the exploration of cross-cultural
serendipitous discoveries. Empirical evaluations affirm that CultiVerse
significantly improves cross-cultural understanding, offering deeper insights
and engaging art appreciation.",165,9,1306,-0.2
2637,cultural anthropology,"In studies of cultural differentiation, the joint mechanisms of homophily and
influence have been able to explain how distinct cultural groups can form.
While these mechanisms normally lead to cultural convergence, increased levels
of heterogeneity can allow them to produce global diversity. However, this
emergent cultural diversity has proven to be unstable in the face of ""cultural
drift""- small errors or innovations that allow cultures to change from within.
We develop a model of cultural differentiation that combines the traditional
mechanisms of homophily and influence with a third mechanism of 2network
homophily"", in which network structure co-evolves with cultural interaction. We
show that if social ties are allowed to change with cultural influence, a
complex relationship between heterogeneity and cultural diversity is revealed,
in which increased heterogeneity can reduce cultural group formation while
simultaneously increasing social connectedness. Our results show that in
certain regions of the parameter space these co-evolutionary dynamics can lead
to patterns of cultural diversity that are stable in the presence of cultural
drift.",167,7,1159,17.88
2638,cultural anthropology,"Video-sharing social media like YouTube provide access to diverse cultural
products from all over the world, making it possible to test theories that the
Web facilitates global cultural convergence. Drawing on a daily listing of
YouTube's most popular videos across 58 countries, we investigate the
consumption of popular videos in countries that differ in cultural values,
language, gross domestic product, and Internet penetration rate. Although
online social media facilitate global access to cultural products, we find this
technological capability does not result in universal cultural convergence.
Instead, consumption of popular videos in culturally different countries
appears to be constrained by cultural values. Cross-cultural convergence is
more advanced in cosmopolitan countries with cultural values that favor
individualism and power inequality.",119,6,860,13.48
2639,cultural anthropology,"The recent release of ChatGPT has garnered widespread recognition for its
exceptional ability to generate human-like responses in dialogue. Given its
usage by users from various nations and its training on a vast multilingual
corpus that incorporates diverse cultural and societal norms, it is crucial to
evaluate its effectiveness in cultural adaptation. In this paper, we
investigate the underlying cultural background of ChatGPT by analyzing its
responses to questions designed to quantify human cultural differences. Our
findings suggest that, when prompted with American context, ChatGPT exhibits a
strong alignment with American culture, but it adapts less effectively to other
cultural contexts. Furthermore, by using different prompts to probe the model,
we show that English prompts reduce the variance in model responses, flattening
out cultural differences and biasing them towards American culture. This study
provides valuable insights into the cultural implications of ChatGPT and
highlights the necessity of greater diversity and cultural awareness in
language technologies.",155,7,1089,19.91
2640,cultural anthropology,"Pretrained large language models have revolutionized many applications but
still face challenges related to cultural bias and a lack of cultural
commonsense knowledge crucial for guiding cross-culture communication and
interactions. Recognizing the shortcomings of existing methods in capturing the
diverse and rich cultures across the world, this paper introduces a novel
approach for massively multicultural knowledge acquisition. Specifically, our
method strategically navigates from densely informative Wikipedia documents on
cultural topics to an extensive network of linked pages. Leveraging this
valuable source of data collection, we construct the CultureAtlas dataset,
which covers a wide range of sub-country level geographical regions and
ethnolinguistic groups, with data cleaning and preprocessing to ensure textual
assertion sentence self-containment, as well as fine-grained cultural profile
information extraction. Our dataset not only facilitates the evaluation of
language model performance in culturally diverse contexts but also serves as a
foundational tool for the development of culturally sensitive and aware
language models. Our work marks an important step towards deeper understanding
and bridging the gaps of cultural disparities in AI, to promote a more
inclusive and balanced representation of global cultures in the digital domain.",186,7,1362,6.17
2641,cultural anthropology,"To enhance language models' cultural awareness, we design a generalizable
pipeline to construct cultural knowledge bases from different online
communities on a massive scale. With the pipeline, we construct CultureBank, a
knowledge base built upon users' self-narratives with 12K cultural descriptors
sourced from TikTok and 11K from Reddit. Unlike previous cultural knowledge
resources, CultureBank contains diverse views on cultural descriptors to allow
flexible interpretation of cultural knowledge, and contextualized cultural
scenarios to help grounded evaluation. With CultureBank, we evaluate different
LLMs' cultural awareness, and identify areas for improvement. We also fine-tune
a language model on CultureBank: experiments show that it achieves better
performances on two downstream cultural tasks in a zero-shot setting. Finally,
we offer recommendations based on our findings for future culturally aware
language technologies. The project page is https://culturebank.github.io . The
code and model is at https://github.com/SALT-NLP/CultureBank . The released
CultureBank dataset is at https://huggingface.co/datasets/SALT-NLP/CultureBank .",148,14,1153,21.29
2642,cultural anthropology,"Divergent cumulative cultural evolution occurs when the cultural evolutionary
trajectory diverges from the biological evolutionary trajectory. We consider
the conditions under which divergent cumulative cultural evolution can occur.
We hypothesize that two conditions are necessary. First that genetic and
cultural information are stored separately in the agent. Second cultural
information must be transferred horizontally between agents of different
generations. We implement a model with these properties and show evidence of
divergent cultural evolution under both cooperative and competitive selection
pressures.",80,7,617,-1.25
2643,cultural anthropology,"When learning technologies are introduced in educational environments, it is
assumed that the educational environment is culture neutral i.e, all
educational environments have the same challenges, problems and cultural norms.
However, it can be observed that cultural factors can influence the successful
implementation and use of learning technologies. In this study the aims were to
explore contextual challenges to implementing different educational
technologies and to explore the effects of culture. The results of this survey
suggest that Hofstede's cultural measures of uncertainty avoidance, power
distance and Individualist/collectivist measures, and Duckworth's Grit measure
of passion and perseverance have a strong impact on the culture of technology
use in India.",108,6,776,15.71
2644,cultural anthropology,"Human culture research has witnessed an opportunity of revolution thanks to
the big data and social network revolution. Websites such as Douban.com,
Goodreads.com, Pandora and IMDB become the new gold mine for cultural
researchers. In 2021 and 2022, the author of this paper invented 2 data-free
recommender systems for AI cold-start problem. The algorithms can recommend
cultural and commercial products to users without reference to users' past
preferences. The social implications of the new inventions are human cultural
tastes can be predicted very precisely without any information related to human
individuals. In this paper, we analyze the AI technologies and its cultural
implications together with other AI algorithms. We show that human culture is
(mostly) a history irrelevant and predictable experience.",121,10,816,39.23
2645,cultural anthropology,"The hostility between the two cultures, scientific and literary, was framed
by C.P. Snow in 1959 and later by others. The scientific culture is nowadays
often identified with STEM (Science, Technology, Engineering and Mathematics)
whereas the literary culture generally refers to humanities and social
sciences. Wilson expressed the wish for the unity of knowledge. We put forward
the notions of knowledge distance and knowledge consilience threshold to
quantitatively measure distance and coupling process between different branches
of knowledge. Our findings suggest that the gulf between the two cultures is
widening.",90,8,620,39.33
2646,cultural anthropology,"We study a model describing the spread of a globalized culture in a
population of individuals localized at the nodes of a social network. The
influence of this globalized culture, assumed to be foreign to the local
culture, is measured by a probability to convince each individual to adopt its
cultural traits. This probability depends upon the degree s--a real between 0
and 1--of ``wise'' skepticism characterizing the personality of each individual
and a parameter a representing the resistance of the society as a whole to the
spread of the foreign cultural traits. A greater a indicates a stronger
resistance of the local culture to globalization. On the other hand, each
individual interacts with a random number of other individuals--her cultural
neighborhood--uniformly distributed between 1 and a maximum value. The
probability distribution of an individual to belong to the cultural
neighborhood of another individual has a power-law behavior. A small fraction r
of the total population belonging to the tail of this probability distribution
have an s-value equal to 1. They represent the most conservative individuals
firmly attached to their local culture.",182,9,1168,22.95
2647,cultural anthropology,"In the Axelrod's model of cultural dissemination, we consider mobility of
cultural agents through the introduction of a density of empty sites and the
possibility that agents in a dissimilar neighborhood can move to them if their
mean cultural similarity with the neighborhood is below some threshold. While
for low values of the density of empty sites the mobility enhances the
convergence to a global culture, for high enough values of it the dynamics can
lead to the coexistence of disconnected domains of different cultures. In this
regime, the increase of initial cultural diversity paradoxically increases the
convergence to a dominant culture. Further increase of diversity leads to
fragmentation of the dominant culture into domains, forever changing in shape
and number, as an effect of the never ending eroding activity of cultural
minorities.",133,5,853,20.76
2648,cultural anthropology,"Cultures around the world organise stars into constellations, or asterisms,
and these groupings are often considered to be arbitrary and culture-specific.
Yet there are striking similarities in asterisms across cultures, and groupings
such as Orion, the Big Dipper, the Pleiades and the Southern Cross are widely
recognized across many different cultures. Psychologists have informally
suggested that these shared patterns are explained by Gestalt laws of grouping,
but there have been no systematic attempts to catalog asterisms that recur
across cultures or to explain the perceptual basis of these groupings. Here we
compile data from 27 cultures around the world and show that a simple
computational model of perceptual grouping accounts for many of the recurring
cross-cultural asterisms. Our results suggest that basic perceptual principles
account for more of the structure of asterisms across cultures than previously
acknowledged and highlight ways in which specific cultures depart from this
shared baseline.",149,6,1018,32.77
2649,cultural anthropology,"This paper identifies a cultural dominance issue within large language models
(LLMs) due to the predominant use of English data in model training (e.g.,
ChatGPT). LLMs often provide inappropriate English-culture-related answers that
are not relevant to the expected culture when users ask in non-English
languages. To systematically evaluate the cultural dominance issue, we build a
benchmark of concrete (e.g., holidays and songs) and abstract (e.g., values and
opinions) cultural objects. Empirical results show that the representative GPT
models suffer from the culture dominance problem, where GPT-4 is the most
affected while text-davinci-003 suffers the least from this problem. Our study
emphasizes the need to critically examine cultural dominance and ethical
consideration in their development and deployment. We show that two
straightforward methods in model development (i.e., pretraining on more diverse
data) and deployment (e.g., culture-aware prompting) can significantly mitigate
the cultural dominance issue in LLMs.",145,17,1033,31.38
2650,cultural anthropology,"The ability of humans to create and disseminate culture is often credited as
the single most important factor of our success as a species. In this
Perspective, we explore the notion of machine culture, culture mediated or
generated by machines. We argue that intelligent machines simultaneously
transform the cultural evolutionary processes of variation, transmission, and
selection. Recommender algorithms are altering social learning dynamics.
Chatbots are forming a new mode of cultural transmission, serving as cultural
models. Furthermore, intelligent machines are evolving as contributors in
generating cultural traits--from game strategies and visual art to scientific
results. We provide a conceptual framework for studying the present and
anticipated future impact of machines on cultural evolution, and present a
research agenda for the study of machine culture.",124,8,872,28.13
2651,cultural anthropology,"Culture fundamentally shapes people's reasoning, behavior, and communication.
Generative artificial intelligence (AI) technologies may cause a shift towards
a dominant culture. As people increasingly use AI to expedite and even automate
various professional and personal tasks, cultural values embedded in AI models
may bias authentic expression. We audit large language models for cultural
bias, comparing their responses to nationally representative survey data, and
evaluate country-specific prompting as a mitigation strategy. We find that
GPT-4, 3.5 and 3 exhibit cultural values resembling English-speaking and
Protestant European countries. Our mitigation strategy reduces cultural bias in
recent models but not for all countries/territories. To avoid cultural bias in
generative AI, especially in high-stakes contexts, we suggest using culture
matching and ongoing cultural audits.",120,9,889,13.95
2652,cultural anthropology,"The recovery and resilience of the cultural and creative sectors after the
COVID-19 pandemic is a current topic with priority for the European Commission.
Cultural gems is a crowdsourced web platform managed by the Joint Research
Centre of the European Commission aimed at creating community-led maps as well
as a common repository for cultural and creative places across European cities
and towns. More than 130,000 physical locations and online cultural activities
in more than 300 European cities and towns are currently tracked by the
application. The main objective of Cultural gems consists in raising a holistic
vision of European culture, reinforcing a sense of belonging to a common
European cultural space. This data article describes the ontology developed for
Cultural gems, adopted to represent the domain of knowledge of the application
by means of FAIR (Findable, Accessible, Interoperable, Reusable) principles and
following the paradigms of Linked Open Data (LOD). We provide an overview of
this dataset, and describe the ontology model, along with the services used to
access and consume the data.",172,7,1115,25.42
2653,cultural anthropology,"Cultural gems is a web application conceived by the European Commission's
Joint Research Centre (DG JRC), which aims at engaging people and organisations
across Europe to create a unique repository of cultural and creative places.
The main goal is to provide a vision of European culture in order to strengthen
a sense of identity within a single European cultural realm. Cultural gems maps
more than 130,000 physical places in over 300 European cities and towns, and
since 2020 it also lists online cultural initiatives. The new release aims,
among other, to increase the interoperability of the application. At this
purpose, we provide an overview on the current development of an ontology for
Cultural gems used to map cultural heritage in European cities by using Linked
Open Data (LOD) standards, and making the data FAIR, that is Findable,
Accessible, Interoperable, and Reusable. We provide an overview of the
methodology, presenting the structure of the ontology, and the services and
tools we are currently building on top.",165,7,1032,35.1
2654,cultural anthropology,"Large language models (LLMs) have demonstrated substantial commonsense
understanding through numerous benchmark evaluations. However, their
understanding of cultural commonsense remains largely unexamined. In this
paper, we conduct a comprehensive examination of the capabilities and
limitations of several state-of-the-art LLMs in the context of cultural
commonsense tasks. Using several general and cultural commonsense benchmarks,
we find that (1) LLMs have a significant discrepancy in performance when tested
on culture-specific commonsense knowledge for different cultures; (2) LLMs'
general commonsense capability is affected by cultural context; and (3) The
language used to query the LLMs can impact their performance on
cultural-related tasks. Our study points to the inherent bias in the cultural
understanding of LLMs and provides insights that can help develop culturally
aware language models.",123,6,907,12.67
2655,cultural anthropology,"We aim to study through an agent-based model the cultural conditions leading
to a decrease or an increase of discrimination between groups after a major
cultural threat such as a terrorist attack. We propose an agent-based model of
cultural dynamics inspired from the social psychological theories. An agent has
a cultural identity comprised of the most acceptable positions about each of
the different cultural worldviews corresponding to the main cultural groups of
the considered society and a margin of acceptance around each of these most
acceptable positions. An agent forms an attitude about another agent depending
on the similarity between their cultural identities. When a terrorist attack is
perpetrated in the name of an extreme cultural identity, the negatively
perceived agents from this extreme cultural identity modify their margins of
acceptance in order to differentiate themselves more from the threatening
cultural identity. We generated a set of populations with cultural identities
compatible with data given by a survey on groups' attitudes among a large
sample representative of the population of France; we then simulated the
reaction of these agents facing a threat. For most populations, the average
attitude toward agents with the same preferred worldview as the terrorists
becomes more negative; however, when the population shows some cultural
properties, we noticed the opposite effect as the average attitude of the
population becomes less negative. This particular context requires that the
agents sharing the same preferred worldview with the terrorists strongly
differentiate themselves from the terrorists' extreme cultural identity and
that the other agents be aware of these changes.",258,9,1721,21.77
2656,cultural anthropology,"Drivers for globalization are significant where today's organizations look
for cheaper and faster ways to develop software as well as ways to satisfy
quality and investment requirements imposed by customers, shareholders, and
governments. Given these needs, Global Software Development (GSD) has become a
""normal"" way of doing business. Working in GSD often require teams of different
cultures to work together. A poor understanding of cultural differences can
create barriers to trust or missed opportunities. The literature on culture in
GSD is either outdated or disparate, requiring practitioners to read many
papers to get an overview of how to manage multi-cultural teams. In this study,
we aim to highlight how to increase cultural awareness within teams, avoid
potential conflict and harness differences for improved team spirit. To answer
our research question, ""How should cultural differences be managed, identified
and communicated to a GSD team?"", we conducted a systematic literature review
of the GSD literature. A synthesis of solutions found in nineteen studies
provided 12 distinct practices that organizations can implement, to include,
""provide a cultural knowledge base"", ""understand and make team members aware of
cultural differences"" and ""plan responses to mitigate occurrences of cultural
misunderstandings"". These implementable cultural practices go some way to
providing solutions to managing multi-cultural development teams, and thus to
support one of the problem dimensions in GSD and embrace cultural differences.",224,10,1544,31.82
2657,cultural anthropology,"The integration of Large Language Models (LLMs) into various global cultures
fundamentally presents a cultural challenge: LLMs must navigate interactions,
respect social norms, and avoid transgressing cultural boundaries. However, it
is still unclear if LLMs can adapt their outputs to diverse cultural norms. Our
study focuses on this aspect. We introduce NormAd, a novel dataset, which
includes 2.6k stories that represent social and cultural norms from 75
countries, to assess the ability of LLMs to adapt to different granular levels
of socio-cultural contexts such as the country of origin, its associated
cultural values, and prevalent social norms. Our study reveals that LLMs
struggle with cultural reasoning across all contextual granularities, showing
stronger adaptability to English-centric cultures over those from the Global
South. Even with explicit social norms, the top-performing model,
Mistral-7b-Instruct, achieves only 81.8\% accuracy, lagging behind the 95.6\%
achieved by humans. Evaluation on NormAd further reveals that LLMs struggle to
adapt to stories involving gift-giving across cultures. Due to inherent
agreement or sycophancy biases, LLMs find it considerably easier to assess the
social acceptability of stories that adhere to cultural norms than those that
deviate from them. Our benchmark measures the cultural adaptability (or lack
thereof) of LLMs, emphasizing the potential to make these technologies more
equitable and useful for global audiences. We release the NormAd dataset and
its associated code on GitHub.",224,14,1551,37.1
2658,cultural anthropology,"Context: Cultural aspects are of high importance as they guide people's
behaviour and thus, influence how people apply methods and act in projects. In
recent years, software engineering research emphasized the need to analyze the
challenges of specific cultural characteristics. Investigating the influence of
cultural characteristics is challenging due to the multi-faceted concept of
culture. People's behaviour, their beliefs and underlying values are shaped by
different layers of culture, e.g., regions, organizations, or groups. In this
study, we focus on agile methods, which are agile approaches that focus on
underlying values, collaboration and communication. Thus, cultural and social
aspects are of high importance for their successful use in practice. Objective:
In this paper, we address challenges that arise when using the model of
cultural dimensions by Hofstede to characterize specific cultural values. This
model is often used when discussing cultural influences in software
engineering. Method: As a basis, we conducted an exploratory, multiple case
study, consisting of two cases in Japan and two in Germany. Contributions: In
this study, we observed that cultural characteristics of the participants
differed significantly from cultural characteristics that would typically be
expected for people from the respective country. This drives our conclusion
that for studies in empirical software engineering that address cultural
factors, a case-specific analysis of the characteristics is needed.",216,14,1516,27.83
2659,cultural anthropology,"An image is often said to be worth a thousand words, and certain images can
tell rich and insightful stories. Can these stories be told via image
captioning? Images from folklore genres, such as mythology, folk dance,
cultural signs, and symbols, are vital to every culture. Our research compares
the performance of four popular vision-language models (GPT-4V, Gemini Pro
Vision, LLaVA, and OpenFlamingo) in identifying culturally specific information
in such images and creating accurate and culturally sensitive image captions.
We also propose a new evaluation metric, Cultural Awareness Score (CAS),
dedicated to measuring the degree of cultural awareness in image captions. We
provide a dataset MOSAIC-1.5k, labeled with ground truth for images containing
cultural background and context, as well as a labeled dataset with assigned
Cultural Awareness Scores that can be used with unseen data. Creating
culturally appropriate image captions is valuable for scientific research and
can be beneficial for many practical applications. We envision that our work
will promote a deeper integration of cultural sensitivity in AI applications
worldwide. By making the dataset and Cultural Awareness Score available to the
public, we aim to facilitate further research in this area, encouraging the
development of more culturally aware AI systems that respect and celebrate
global diversity.",206,10,1385,33.65
2660,cultural anthropology,"For more than $50$ years the {\it Mean Measure of Divergence} (MMD) has been
one of the most prominent tools used in anthropology for the study of
non-metric traits. However, one of the problems, in anthropology including
palaeoanthropology (more often there), is the lack of big enough samples or the
existence of samples without sufficiently measured traits. Since 1969, with the
advent of bootstrapping techniques, this issue has been tackled successfully in
many different ways. Here, we present a parametric bootstrap technique based on
the fact that the transformed $ \theta $, obtained from the Anscombe
transformation to stabilize the variance, nearly follows a normal distribution
with zero mean and variance $ \sigma^2 = 1 / (N + 1/2) $, where $ N $ is the
size of the measured trait. When the probabilistic distribution is known,
parametric procedures offer more powerful results than non-parametric ones. We
profit from knowing the probabilistic distribution of $ \theta $ to develop a
parametric bootstrapping method. We explain it carefully with mathematical
support. We give examples, both with artificial data and with real ones. Our
results show that this parametric bootstrap procedure is a powerful tool to
study samples with scarcity of data.",200,10,1262,41.7
2661,cultural anthropology,"I discuss some general aspects of the creation, interpretation, and reception
of mathematics as a part of civilization and culture.",20,2,131,25.8
2662,cultural anthropology,"Axelrod's model for culture dissemination offers a nontrivial answer to the
question of why there is cultural diversity given that people's beliefs have a
tendency to become more similar to each other's as people interact repeatedly.
The answer depends on the two control parameters of the model, namely, the
number $F$ of cultural features that characterize each agent, and the number
$q$ of traits that each feature can take on, as well as on the size $A$ of the
territory or, equivalently, on the number of interacting agents. Here we
investigate the dependence of the number $C$ of distinct coexisting cultures on
the area $A$ in Axelrod's model -- the culture-area relationship -- through
extensive Monte Carlo simulations. We find a non-monotonous culture-area
relation, for which the number of cultures decreases when the area grows beyond
a certain size, provided that $q$ is smaller than a threshold value $q_c = q_c
(F)$ and $F \geq 3$. In the limit of infinite area, this threshold value
signals the onset of a discontinuous transition between a globalized regime
marked by a uniform culture (C=1), and a completely polarized regime where all
$C = q^F$ possible cultures coexist. Otherwise the culture-area relation
exhibits the typical behavior of the species-area relation, i.e., a
monotonically increasing curve the slope of which is steep at first and
steadily levels off at some maximum diversity value.",229,9,1419,30.43
2663,cultural anthropology,"An emotional version of Sapir-Whorf hypothesis suggests that differences in
language emotionalities influence differences among cultures no less than
conceptual differences. Conceptual contents of languages and cultures to
significant extent are determined by words and their semantic differences;
these could be borrowed among languages and exchanged among cultures. Emotional
differences, as suggested in the paper, are related to grammar and mostly
cannot be borrowed. Conceptual and emotional mechanisms of languages are
considered here along with their functions in the mind and cultural evolution.
A fundamental contradiction in human mind is considered: language evolution
requires reduced emotionality, but ""too low"" emotionality makes language
""irrelevant to life,"" disconnected from sensory-motor experience. Neural
mechanisms of these processes are suggested as well as their mathematical
models: the knowledge instinct, the language instinct, the dual model
connecting language and cognition, dynamic logic, neural modeling fields.
Mathematical results are related to cognitive science, linguistics, and
psychology. Experimental evidence and theoretical arguments are discussed.
Approximate equations for evolution of human minds and cultures are obtained.
Their solutions identify three types of cultures: ""conceptual""-pragmatic
cultures, in which emotionality of language is reduced and differentiation
overtakes synthesis resulting in fast evolution at the price of uncertainty of
values, self doubts, and internal crises; ""traditional-emotional"" cultures
where differentiation lags behind synthesis, resulting in cultural stability at
the price of stagnation; and ""multi-cultural"" societies combining fast cultural
evolution and stability. Unsolved problems and future theoretical and
experimental directions are discussed.",239,12,1839,7.15
2664,cultural anthropology,"Cultural activity is an inherent aspect of urban life and the success of a
modern city is largely determined by its capacity to offer generous cultural
entertainment to its citizens. To this end, the optimal allocation of cultural
establishments and related resources across urban regions becomes of vital
importance, as it can reduce financial costs in terms of planning and improve
quality of life in the city, more generally. In this paper, we make use of a
large longitudinal dataset of user location check-ins from the online social
network WeChat to develop a data-driven framework for cultural planning in the
city of Beijing. We exploit rich spatio-temporal representations on user
activity at cultural venues and use a novel extended version of the traditional
latent Dirichlet allocation model that incorporates temporal information to
identify latent patterns of urban cultural interactions. Using the
characteristic typologies of mobile user cultural activities emitted by the
model, we determine the levels of demand for different types of cultural
resources across urban areas. We then compare those with the corresponding
levels of supply as driven by the presence and spatial reach of cultural venues
in local areas to obtain high resolution maps that indicate urban regions with
lack of cultural resources, and thus give suggestions for further urban
cultural planning and investment optimisation.",217,7,1414,9.35
2665,cultural anthropology,"Recommender systems have become the dominant means of curating cultural
content, significantly influencing the nature of individual cultural
experience. While the majority of research on recommender systems optimizes for
personalized user experience, this paradigm does not capture the ways that
recommender systems impact cultural experience in the aggregate, across
populations of users. Although existing novelty, diversity, and fairness
studies probe how systems relate to the broader social role of cultural
content, they do not adequately center culture as a core concept and challenge.
In this work, we introduce commonality as a new measure that reflects the
degree to which recommendations familiarize a given user population with
specified categories of cultural content. Our proposed commonality metric
responds to a set of arguments developed through an interdisciplinary dialogue
between researchers in computer science and the social sciences and humanities.
With reference to principles underpinning non-profit, public service media
systems in democratic societies, we identify universality of address and
content diversity in the service of strengthening cultural citizenship as
particularly relevant goals for recommender systems delivering cultural
content. Taking diversity in movie recommendation as a case study in enhancing
pluralistic cultural experience, we empirically compare systems' performance
using commonality and existing utility, diversity, and fairness metrics. Our
results demonstrate that commonality captures a property of system behavior
complementary to existing metrics and suggest the need for alternative,
non-personalized interventions in recommender systems oriented to strengthening
cultural citizenship across populations of users. In this way, commonality
contributes to a growing body of scholarship developing 'public good'
rationales for digital media and ML systems.",259,10,1917,-0.07
2666,cultural anthropology,"The global audience for software products includes members of different
countries, religions, and cultures: people who speak different languages, have
different life styles, and have different perceptions and expectations of any
given product. A major impediment in interface development is that there is
inadequate empirical evidence for the effects of culture in the usability
engineering methods used for developing user interfaces. This paper presents a
controlled study investigating the effects of culture on the effectiveness of
structured interviews in usability testing. The experiment consisted of
usability testing of a website with two independent groups of Indian
participants by two interviewers; one belonging to the Indian culture and the
other to the Anglo-American culture. Participants found more usability problems
and made more suggestions to an interviewer who was a member of the same
(Indian) culture than to the foreign (Anglo-American) interviewer. The results
of the study empirically establish that culture significantly affects the
efficacy of structured interviews during international user testing. The
implications of this work for usability engineering are discussed.",170,8,1200,12.97
2667,cultural anthropology,"This paper reviews and clarifies five misunderstandings about cultural
evolution identified by Henrich, Boyd, and Richerson (2008). First, cultural
representations are neither discrete nor continuous; they are distributed
across neurons that respond to microfeatures. This enables associations to be
made, and cultural change to be generated. Second, 'replicator dynamics' do not
ensure natural selection. The replicator notion does not capture the
distinction between actively interpreted self-assembly code and passively
copied self-description, which leads to a fundamental principle of natural
selection: inherited information is transmitted, whereas acquired information
is not. Third, this principle is violated in culture by the ubiquity of
acquired change. Moreover, biased transmission is less important to culture
than the creative processes by which novelty is generated. Fourth, there is no
objective basis for determining cultural fitness. Fifth, the necessity of
randomness is discussed. It is concluded that natural selection is
inappropriate as an explanatory framework for culture.",150,11,1098,22.41
2668,cultural anthropology,"The application of conventional phylogenetic techniques for inferring
cultural history is problematic due to differences in the nature of information
transmission in biological and cultural realms. In culture, units of
transmission are not just measurable attributes, but communicable concepts.
Therefore, relatedness amongst cultural elements often resides at the
conceptual level not captured by traditional phylogenetic methods. This paper
takes a cognitively inspired approach to analyzing material cultural history.
We show that combining data for physical attributes of cultural artifacts with
conceptual information can uncover cultural influences among different
ethnolinguistic groups, and reveal new patterns of cultural ancestry. Using the
Baltic psaltery, a musical instrument with a well-documented ethnographic and
archaeological record, we recovered a previously unacknowledged pattern of
historical relationship that is more congruent with geographical distribution
and temporal data than is obtained with other approaches.",136,7,1039,-2.34
2669,cultural anthropology,"For many people, Wikipedia represents one of the primary sources of knowledge
about foreign cultures. Yet, different Wikipedia language editions offer
different descriptions of cultural practices. Unveiling diverging
representations of cultures provides an important insight, since they may
foster the formation of cross-cultural stereotypes, misunderstandings and
potentially even conflict. In this work, we explore to what extent the
descriptions of cultural practices in various European language editions of
Wikipedia differ on the example of culinary practices and propose an approach
to mine cultural relations between different language communities trough their
description of and interest in their own and other communities' food culture.
We assess the validity of the extracted relations using 1) various external
reference data sources (i.e., the European Social Survey, migration
statistics), 2) crowdsourcing methods and 3) simulations.",130,8,948,24.07
2670,cultural anthropology,"Culture is core to human civilization, and is essential for human
intellectual achievements in social context. Culture also influences how humans
work together, perform particular task and overall lifestyle and dealing with
other groups of civilization. Thus, culture is concerned with establishing
shared ideas, particularly those playing a key role in success. Does it impact
on how two individuals can work together in achieving certain goals? In this
paper, we establish a means to derive cultural association and map it to
culturally mediated success. Human interactions with the environment are
typically in the form of expressions. Association between culture and behavior
produce similar beliefs which lead to common principles and actions, while
cultural similarity as a set of common expressions and responses. To measure
cultural association among different candidates, we propose the use of a
Graphical Association Method (GAM). The behaviors of candidates are captured
through series of expressions and represented in the graphical form. The
association among corresponding node and core nodes is used for the same. Our
approach provides a number of interesting results and promising avenues for
future applications.",182,11,1229,29.35
2671,cultural anthropology,"As we navigate our cultural environment, we learn cultural biases, like those
around gender, social class, health, and body weight. It is unclear, however,
exactly how public culture becomes private culture. In this paper, we provide a
theoretical account of such cultural learning. We propose that neural word
embeddings provide a parsimonious and cognitively plausible model of the
representations learned from natural language. Using neural word embeddings, we
extract cultural schemata about body weight from New York Times articles. We
identify several cultural schemata that link obesity to gender, immorality,
poor health, and low socioeconomic class. Such schemata may be subtly but
pervasively activated in public culture; thus, language can chronically
reproduce biases. Our findings reinforce ongoing concerns that machine learning
can also encode, and reproduce, harmful human biases.",129,9,896,29.75
2672,cultural anthropology,"Cultural adaptation, i.e., the matching of a robot's behaviours to the
cultural norms and preferences of its user, is a well known key requirement for
the success of any assistive application. However, culture-dependent robot
behaviours are often implicitly set by designers, thus not allowing for an easy
and automatic adaptation to different cultures. This paper presents a method
for the design of culture-aware robots, that can automatically adapt their
behaviour to conform to a given culture. We propose a mapping from cultural
factors to related parameters of robot behaviours which relies on linguistic
variables to encode heterogeneous cultural factors in a uniform formalism, and
on fuzzy rules to encode qualitative relations among multiple variables. We
illustrate the approach in two practical case studies.",123,8,820,33.75
2673,cultural anthropology,"Understanding online communities requires an appreciation of both structure
and culture. But basic questions remain difficult to pose. How do these facets
interact and drive each other? Using data on the membership and governance
styles of 5,000 small-scale online communities, we construct empirical measures
for cross-server similarities in institutional structure and culture to explore
the influence of institutional environment on their culture, and the influence
of culture on their institutional environment. To establish the influence of
culture and institutions on each other, we construct networks of communities,
linking those that are more similar either in their members or governance. We
then use network analysis to assess the causal relationships between shared
culture and institutions. Our result shows that while effects in both
directions are evident, there is a much stronger role for institutions on
culture than culture on institutions. These processes are evident within
administrative and informational type rules.",149,8,1039,27.22
2674,cultural anthropology,"The article introduces the concept of image ""culturization,"" which we define
as the process of altering the ``brushstroke of cultural features"" that make
objects perceived as belonging to a given culture while preserving their
functionalities. First, we defined a pipeline for translating objects' images
from a source to a target cultural domain based on state-of-the-art Generative
Adversarial Networks. Then, we gathered data through an online questionnaire to
test four hypotheses concerning the impact of images belonging to different
cultural domains on Italian participants. As expected, results depend on
individual tastes and preferences: however, they align with our conjecture that
some people, during the interaction with an intelligent system, will prefer to
be shown images modified to match their cultural background. The study has two
main limitations. First, we focussed on the culturization of individual objects
instead of complete scenes. However, objects play a crucial role in conveying
cultural meanings and can strongly influence how an image is perceived within a
specific cultural context. Understanding and addressing object-level
translation is a vital step toward achieving more comprehensive scene-level
translation in future research. Second, we performed experiments with Italian
participants only. We think that there are unique aspects of Italian culture
that make it an interesting and relevant case study for exploring the impact of
image culturization. Italy is a very culturally conservative society, and
Italians have specific sensitivities and expectations regarding the accurate
representation of their cultural identity and traditions, which can shape
individuals' preferences and inclinations toward certain visual styles,
aesthetics, and design choices. As a consequence, we think they are an ideal
candidate for a preliminary investigation of image culturization.",271,13,1908,23.16
2675,cultural anthropology,"While cultural backgrounds have been shown to affect linguistic expressions,
existing natural language processing (NLP) research on culture modeling is
overly coarse-grained and does not examine cultural differences among speakers
of the same language. To address this problem and augment NLP models with
cultural background features, we collect, annotate, manually validate, and
benchmark EnCBP, a finer-grained news-based cultural background prediction
dataset in English. Through language modeling (LM) evaluations and manual
analyses, we confirm that there are noticeable differences in linguistic
expressions among five English-speaking countries and across four states in the
US. Additionally, our evaluations on nine syntactic (CoNLL-2003), semantic
(PAWS-Wiki, QNLI, STS-B, and RTE), and psycholinguistic tasks (SST-5, SST-2,
Emotion, and Go-Emotions) show that, while introducing cultural background
information does not benefit the Go-Emotions task due to text domain conflicts,
it noticeably improves deep learning (DL) model performance on other tasks. Our
findings strongly support the importance of cultural background modeling to a
wide variety of NLP tasks and demonstrate the applicability of EnCBP in
culture-related research.",168,6,1244,11.99
2676,cultural anthropology,"Translating cultural-specific content is crucial for effective cross-cultural
communication. However, many MT systems still struggle to translate sentences
containing cultural-specific entities accurately and understandably. Recent
advancements in in-context learning utilize lightweight prompts to guide large
language models (LLMs) in machine translation tasks. Nevertheless, the
effectiveness of this approach in enhancing machine translation with cultural
awareness remains uncertain. To address this gap, we introduce a new data
curation pipeline to construct a culturally relevant parallel corpus, enriched
with annotations of cultural-specific items. Furthermore, we devise a novel
evaluation metric to assess the understandability of translations in a
reference-free manner by GPT-4. We evaluate a variety of neural machine
translation (NMT) and LLM-based MT systems using our dataset. Additionally, we
propose several prompting strategies for LLMs to incorporate external and
internal cultural knowledge into the translation process. Our results
demonstrate that eliciting explanations can significantly enhance the
understandability of cultural-specific entities, especially those without
well-known translations.",154,10,1223,3.36
2677,cultural anthropology,"The cultural landscape of interactions with dialogue agents is a compelling
yet relatively unexplored territory. It's clear that various sociocultural
aspects -- from communication styles and beliefs to shared metaphors and
knowledge -- profoundly impact these interactions. To delve deeper into this
dynamic, we introduce cuDialog, a first-of-its-kind benchmark for dialogue
generation with a cultural lens. We also develop baseline models capable of
extracting cultural attributes from dialogue exchanges, with the goal of
enhancing the predictive accuracy and quality of dialogue agents. To
effectively co-learn cultural understanding and multi-turn dialogue
predictions, we propose to incorporate cultural dimensions with dialogue
encoding features. Our experimental findings highlight that incorporating
cultural value surveys boosts alignment with references and cultural markers,
demonstrating its considerable influence on personalization and dialogue
quality. To facilitate further exploration in this exciting domain, we publish
our benchmark publicly accessible at https://github.com/yongcaoplus/cuDialog.",142,9,1116,0.42
2678,cultural anthropology,"Large language models (LLMs) are reported to be partial to certain cultures
owing to the training data dominance from the English corpora. Since
multilingual cultural data are often expensive to collect, existing efforts
handle this by prompt engineering or culture-specific pre-training. However,
they might overlook the knowledge deficiency of low-resource culture and
require extensive computing resources. In this paper, we propose CultureLLM, a
cost-effective solution to incorporate cultural differences into LLMs.
CultureLLM adopts World Value Survey (WVS) as seed data and generates
semantically equivalent training data via the proposed semantic data
augmentation. Using only 50 seed samples from WVS with augmented data, we
fine-tune culture-specific LLMs and one unified model (CultureLLM-One) for 9
cultures covering rich and low-resource languages. Extensive experiments on 60
culture-related datasets demonstrate that CultureLLM significantly outperforms
various counterparts such as GPT-3.5 (by 8.1%) and Gemini Pro (by 9.5%) with
comparable performance to GPT-4 or even better. Our human study shows that the
generated samples are semantically equivalent to the original samples,
providing an effective solution for LLMs augmentation.",172,12,1250,21.8
2679,cultural anthropology,"While the creation of a strong security culture has been researched and
discussed for decades, it continues to elude many businesses. Part of the
challenge faced is distilling pertinent, recent academic findings and research
into useful guidance. In this article, we aim to tackle this issue by
conducting a state-of-the-art study into organisational cyber security culture
research. This work investigates four questions, including how cyber security
culture is defined, what factors are essential to building and maintaining such
a culture, the frameworks proposed to cultivate a security culture and the
metrics suggested to assess it. Through the application of the PRISMA
systematic literature review technique, we identify and analyse 58 research
articles from the last 10 years (2010-2020). Our findings demonstrate that
while there have been notable changes in the use of terms (e.g., information
security culture and cyber security culture), many of the most influential
factors across papers are similar. Top management support, policy and
procedures, and awareness for instance, are critical in engendering cyber
security culture. Many of the frameworks reviewed revealed common foundations,
with organisational culture playing a substantial role in crafting appropriate
cyber security culture models. Questionnaires and surveys are the most used
tool to measure cyber security culture, but there are also concerns as to
whether more dynamic measures are needed. For practitioners, this article
highlights factors and models essential to the creation and management of a
robust security culture. For research, we produce an up-to-date
characterisation of the field and also define open issues deserving of further
attention such as the role of change management processes and national culture
in an enterprise's cyber security culture.",271,14,1846,31.62
2680,cultural anthropology,"Every now and then the cultural paradigm of a society changes. Human history
can be regarded as a sequence of long periods of cultural stasis punctuated by
paradigm shifts that transform culture upside-down over the turn of a few
generations. We propose here a population dynamics model devised to analyse
paradigm shifts. In this model individuals are defined by a vector of cultural
traits that can change mainly through imitation of other individuals' traits.
The novelty of the model is that cultural traits may interact reinforcing or
hindering each other. Imitation is then biased by the 'cultural fitness'
landscape thus defined. Our main result is that abrupt paradigm shifts occur,
as a response to weak changes in the landscape, only when cultural traits do
interact---whereas adaptation is smooth if there is no interaction. Borrowing
the genetic term, this interaction is called 'cultural epistasis'. The result
is robust to the way that epistasis is implemented, to whether imitation is
biased by homophily, or to changes in other model parameters. Finally, a
relevant consequence of this dynamics is the irreversible nature of paradigm
shifts: the old paradigm cannot be restored even if the external changes are
undone. Our model puts the phenomenon of paradigm shifts in cultural evolution
in the same category as catastrophic shifts in ecology or phase transitions in
physics.",220,12,1393,34.26
2681,cultural anthropology,"A quantitative understanding of societies requires useful combinations of
empirical data and mathematical models. Models of cultural dynamics aim at
explaining the emergence of culturally homogeneous groups through social
influence. Traditionally, the initial cultural traits of individuals are chosen
uniformly at random, the emphasis being on characterizing the model outcomes
that are independent of these (`annealed') initial conditions. Here, motivated
by an increasing interest in forecasting social behavior in the real world, we
reverse the point of view and focus on the effect of specific (`quenched')
initial conditions, including those obtained from real data, on the final
cultural state. We study the predictability, rigorously defined in an
information-theoretic sense, of the \emph{social content} of the final cultural
groups (i.e. who ends up in which group) from the knowledge of the initial
cultural traits. We find that, as compared to random and shuffled initial
conditions, the hierarchical ultrametric-like organization of empirical
cultural states significantly increases the predictability of the final social
content by largely confining cultural convergence within the lower levels of
the hierarchy. Moreover, predictability correlates with the compatibility of
short-term social coordination and long-term cultural diversity, a property
that has been recently found to be strong and robust in empirical data. We also
introduce a null model generating initial conditions that retain the
ultrametric representation of real data. Using this ultrametric model,
predictability is highly enhanced with respect to the random and shuffled
cases, confirming the usefulness of the empirical hierarchical organization of
culture for forecasting the outcome of social influence models.",253,12,1802,11.96
2682,cultural anthropology,"Recommender systems have become the dominant means of curating cultural
content, significantly influencing individual cultural experience. Since
recommender systems tend to optimize for personalized user experience, they can
overlook impacts on cultural experience in the aggregate. After demonstrating
that existing metrics do not center culture, we introduce a new metric,
commonality, that measures the degree to which recommendations familiarize a
given user population with specified categories of cultural content. We
developed commonality through an interdisciplinary dialogue between researchers
in computer science and the social sciences and humanities. With reference to
principles underpinning public service media systems in democratic societies,
we identify universality of address and content diversity in the service of
strengthening cultural citizenship as particularly relevant goals for
recommender systems delivering cultural content. We develop commonality as a
measure of recommender system alignment with the promotion of content toward a
shared cultural experience across a population of users. We empirically compare
the performance of recommendation algorithms using commonality with existing
metrics, demonstrating that commonality captures a novel property of system
behavior complementary to existing metrics. Alongside existing fairness and
diversity metrics, commonality contributes to a growing body of scholarship
developing `public good' rationales for machine learning systems.",198,9,1512,-4.47
2683,cultural anthropology,"Culture is a collection of connected and potentially interactive patterns
that characterize a social group or a passed-on idea that people acquire as
members of society. While offline activities can provide a better picture of
the geographical association of cultural traits than online activities,
gathering such data on a large scale has been challenging. Here, we use
multi-decade longitudinal records of cultural events from Meetup.com, the
largest event-based social networking service, to examine the landscape of
offline cultural events. We analyze the temporal and categorical event dynamics
driven by cultural diversity using over 2 million event logs collected over 17
years in 90 countries. Our results show that the national economic status
explains 44.6 percent of the variance in total event count, while cultural
characteristics such as individualism and long-term orientation explain 32.8
percent of the variance in topic categories. Furthermore, our analysis using
hierarchical clustering reveals cultural proximity between the topics of
socio-cultural activities (e.g., politics, leisure, health, technology). We
expect that this work provides a landscape of social and cultural activities
across the world, which allows us to better understand their dynamical patterns
as well as their associations with cultural characteristics.",193,13,1348,28.33
2684,cultural anthropology,"A transformative approach to mental health therapy lies at the crossroads of
cultural heritage and advanced technology. This paper introduces an innovative
method that fuses machine learning techniques with traditional Emirati motifs,
focusing on the United Arab Emirates (UAE). We utilize the Stable Diffusion XL
(SDXL) model, enhanced with Low-Rank Adaptation (LoRA), to create culturally
significant coloring templates featuring Al-Sadu weaving patterns. This novel
approach leverages coloring therapy for its recognized stress-relieving
benefits and embeds deep cultural resonance, making it a potent tool for
therapeutic intervention and cultural preservation. Specifically targeting
Generalized Anxiety Disorder (GAD), our method demonstrates significant
potential in reducing associated symptoms. Additionally, the paper delves into
the broader implications of color and music therapy, emphasizing the importance
of culturally tailored content. The technical aspects of the SDXL model and its
LoRA fine-tuning showcase its capability to generate high-quality, culturally
specific images. This research stands at the forefront of integrating mental
wellness practices with cultural heritage, providing a groundbreaking
perspective on the synergy between technology, culture, and healthcare. In
future work, we aim to employ biosignals to assess the level of engagement and
effectiveness of color therapy. A key focus will be to examine the impact of
the Emirati heritage Al Sadu art on Emirati individuals and compare their
responses with those of other nationalities. This will provide deeper insights
into the cultural specificity of therapeutic interventions and further the
understanding of the unique interplay between cultural identity and mental
health therapy.",244,12,1774,15.1
2685,cultural anthropology,"We discuss how to generate singled peaked votes uniformly from the Impartial
Culture model.",14,2,91,48.81
2686,cultural anthropology,"We contribute to the understanding of social relationships within cultural
contexts by proposing a connection between a social theory, relational models
theory (RMT: Fiske 1991, 1992) and a social and political one, cultural or
plural rationality theory (PRT: Douglas, 1982, Thompson et al., 1990). Drawing
examples from the literature of both theories, we argue that each relational
model of RMT may be implemented in ways compatible with each cultural bias of
PRT. A cultural bias restrains the range of congruent implementations of
relational models, but does not preclude any relational model altogether. This
stands in contrast to earlier reconciliation attempts between PRT and RMT.
Based on hypothetical one-to-one mappings, these attempts expect each cultural
setting to be significantly associated with some, but not all, relational
models. The framework we develop helps explain the findings of these previous
attempts and provides insights into empirical research by clarifying which
associations to expect between relationships and cultural contexts. We discuss
the theoretical basis of our framework, including the idea that RMT and PRT
apply to different levels of analysis: RMT's relational models are tied to
relationships between two actors and PRT's cultural biases to structures of
social networks.",195,9,1317,17.78
2687,cultural anthropology,"We consider an open-ended set of cultural features in the Axelrod's model of
cultural dissemination. By replacing the features in which a high degree of
consensus is achieved by new ones, we address here an essential ingredient of
societies: the evolution of topics as a result of social dynamics and debate.
Our results show that, once cultural clusters have been formed, the
introduction of new topics into the social debate has little effect on them,
but it does have a significant influence on the cultural overlap. Along with
the Monte-Carlo simulations, we derive and numerically solve an equation for
the stationary cultural overlap based on a mean-field approach. Although the
mean-field analysis reproduces qualitatively the characteristic phase
transition of the Axelrod's model, it underestimates the cultural overlap,
highlighting the role of the local interactions in the Axelrod's dynamics, as
well as the correlations between the different cultural features.",148,6,973,24.51
2688,cultural anthropology,"Global acceptance of Emojis suggests a cross-cultural, normative use of
Emojis. Meanwhile, nuances in Emoji use across cultures may also exist due to
linguistic differences in expressing emotions and diversity in conceptualizing
topics. Indeed, literature in cross-cultural psychology has found both
normative and culture-specific ways in which emotions are expressed. In this
paper, using social media, we compare the Emoji usage based on frequency,
context, and topic associations across countries in the East (China and Japan)
and the West (United States, United Kingdom, and Canada). Across the East and
the West, our study examines a) similarities and differences on the usage of
different categories of Emojis such as People, Food \& Drink, Travel \& Places
etc., b) potential mapping of Emoji use differences with previously identified
cultural differences in users' expression about diverse concepts such as death,
money emotions and family, and c) relative correspondence of validated
psycho-linguistic categories with Ekman's emotions. The analysis of Emoji use
in the East and the West reveals recognizable normative and culture specific
patterns. This research reveals the ways in which Emojis can be used for
cross-cultural communication.",184,9,1251,31.41
2689,cultural anthropology,"Daily life activities, such as eating and sleeping, are deeply influenced by
a person's culture, hence generating differences in the way a same activity is
performed by individuals belonging to different cultures. We argue that taking
cultural information into account can improve the performance of systems for
the automated recognition of human activities. We propose four different
solutions to the problem and present a system which uses a Naive Bayes model to
associate cultural information with semantic information extracted from still
images. Preliminary experiments with a dataset of images of individuals lying
on the floor, sleeping on a futon and sleeping on a bed suggest that: i)
solutions explicitly taking cultural information into account are more accurate
than culture-unaware solutions; and ii) the proposed system is a promising
starting point for the development of culture-aware Human Activity Recognition
methods.",139,5,936,10.77
2690,cultural anthropology,"Cultural competence is a well known requirement for an effective healthcare,
widely investigated in the nursing literature. We claim that personal assistive
robots should likewise be culturally competent, aware of general cultural
characteristics and of the different forms they take in different individuals,
and sensitive to cultural differences while perceiving, reasoning, and acting.
Drawing inspiration from existing guidelines for culturally competent
healthcare and the state-of-the-art in culturally competent robotics, we
identify the key robot capabilities which enable culturally competent
behaviours and discuss methodologies for their development and evaluation.",88,4,676,-9.03
2691,cultural anthropology,"Previous work has shown that it is possible to train neuronal cultures on
Multi-Electrode Arrays (MEAs), to recognize very simple patterns. However, this
work was mainly focused to demonstrate that it is possible to induce plasticity
in cultures, rather than performing a rigorous assessment of their pattern
recognition performance. In this paper, we address this gap by developing a
methodology that allows us to assess the performance of neuronal cultures on a
learning task. Specifically, we propose a digital model of the real cultured
neuronal networks; we identify biologically plausible simulation parameters
that allow us to reliably reproduce the behavior of real cultures; we use the
simulated culture to perform handwritten digit recognition and rigorously
evaluate its performance; we also show that it is possible to find improved
simulation parameters for the specific task, which can guide the creation of
real cultures.",142,5,936,18.52
2692,cultural anthropology,"How different cultures evaluate a person? Is an important person in one
culture is also important in the other culture? We address these questions via
ranking of multilingual Wikipedia articles. With three ranking algorithms based
on network structure of Wikipedia, we assign ranking to all articles in 9
multilingual editions of Wikipedia and investigate general ranking structure of
PageRank, CheiRank and 2DRank. In particular, we focus on articles related to
persons, identify top 30 persons for each rank among different editions and
analyze distinctions of their distributions over activity fields such as
politics, art, science, religion, sport for each edition. We find that local
heroes are dominant but also global heroes exist and create an effective
network representing entanglement of cultures. The Google matrix analysis of
network of cultures shows signs of the Zipf law distribution. This approach
allows to examine diversity and shared characteristics of knowledge
organization between cultures. The developed computational, data driven
approach highlights cultural interconnections in a new perspective.",163,8,1122,36.18
2693,cultural anthropology,"What role does culture play in determining institutions in a country? This
paper argues that the establishment of institutions is a process originating
predominantly in a nation's culture and tries to discern the role of a cultural
background in the governance of countries. We use the six Hofstede's Cultural
Dimensions and the six Worldwide Governance Indicators to test the strength of
the relationship on 94 countries between 1996 and 2019. We find that the
strongest cultural characteristics are Power Distance with negative effect on
governance and Long-Term Orientation with positive effect. We also determine
how well countries transform their cultural characteristics into institutions
using stochastic frontier analysis.",107,5,730,32.83
2694,cultural anthropology,"Throughout history, maps have been used as a tool to explore cities. They
visualize a city's urban fabric through its streets, buildings, and points of
interest. Besides purely navigation purposes, street names also reflect a
city's culture through its commemorative practices. Therefore, cultural maps
that unveil socio-cultural characteristics encoded in street names could
potentially raise citizens' historical awareness. But designing effective
cultural maps is challenging, not only due to data scarcity but also due to the
lack of effective approaches to engage citizens with data exploration. To
address these challenges, we collected a dataset of 5,000 streets across the
cities of Paris, Vienna, London, and New York, and built their cultural maps
grounded on cartographic storytelling techniques. Through data exploration
scenarios, we demonstrated how cultural maps engage users and allow them to
discover distinct patterns in the ways these cities are gender-biased,
celebrate various professions, and embrace foreign cultures.",149,8,1040,32.94
2695,cultural anthropology,"The present study examines to what extent cultural background determines
sensorimotor synchronization in humans",14,1,111,14.97
2696,cultural anthropology,"Diabetes is a global health problem with a high mortality rate. The research
indicates low levels of technology use amongst diabetic patients in low
socioeconomic environments and minority groups. We posit that the culture of
patients is a potential reason for the low adoption and use of technology.
However, research on the proliferation of culture at an individual level is
limited. Therefore, this paper assessed the influence of culture on mobile
application adoption and use amongst diabetic patients in the Cape Flats, South
Africa. This study used key constructs from the Theory of Planned Behaviour
(TPB) and Hofstede's cultural dimensions. It was analysed using survey data
from 439 respondents using purposive sampling. It was found that the dimensions
of Hofstede and the Theory of Planned Behaviour can identify how culture
influences mobile application adoption of diabetic patients in the geographical
Cape Flats area. However, this research indicates a stronger relationship
between culture and diabetes self-management activities than culture and the
adoption of mobile applications.",164,10,1100,36.08
2697,cultural anthropology,"Hofstede's six cultural dimensions make it possible to measure the culture of
countries but are criticized for assuming the homogeneity of each country. In
this paper, we propose two measures based on Hofstede's cultural dimensions
which take into account the heterogeneous structure of citizens with respect to
their countries of origin. Using these improved measures, we study the
influence of heterogeneous culture and cultural diversity on the quality of
institutions measured by the six worldwide governance indicators. We use a
linear regression model allowing for dependence in spatial and temporal
dimensions as well as high correlation between the governance indicators. Our
results show that the effect of cultural diversity improves some of the
governance indicators while worsening others depending on the individual
Hofstede cultural dimension.",125,6,857,20.72
2698,cultural anthropology,"Cultural transmission is the domain-general social skill that allows agents
to acquire and use information from each other in real-time with high fidelity
and recall. In humans, it is the inheritance process that powers cumulative
cultural evolution, expanding our skills, tools and knowledge across
generations. We provide a method for generating zero-shot, high recall cultural
transmission in artificially intelligent agents. Our agents succeed at
real-time cultural transmission from humans in novel contexts without using any
pre-collected human data. We identify a surprisingly simple set of ingredients
sufficient for generating cultural transmission and develop an evaluation
methodology for rigorously assessing it. This paves the way for cultural
evolution as an algorithm for developing artificial general intelligence.",115,7,830,18.15
2699,cultural anthropology,"Artificial intelligence (AI) systems attempt to imitate human behavior. How
well they do this imitation is often used to assess their utility and to
attribute human-like (or artificial) intelligence to them. However, most work
on AI refers to and relies on human intelligence without accounting for the
fact that human behavior is inherently shaped by the cultural contexts they are
embedded in, the values and beliefs they hold, and the social practices they
follow. Additionally, since AI technologies are mostly conceived and developed
in just a handful of countries, they embed the cultural values and practices of
these countries. Similarly, the data that is used to train the models also
fails to equitably represent global cultural diversity. Problems therefore
arise when these technologies interact with globally diverse societies and
cultures, with different values and interpretive practices. In this position
paper, we describe a set of cultural dependencies and incongruencies in the
context of AI-based language and vision technologies, and reflect on the
possibilities of and potential strategies towards addressing these
incongruencies.",171,8,1152,29.79
2700,cultural anthropology,"This chapter aims to stress the importance of addressing culture when
designing and implementing learning analytics services. Learning analytics have
been implemented in different countries with the purpose of improving learning
and supporting teaching; yet, largely at a limited scale and so far with
limited evidence of achieving their purpose. Even though some solutions seem
promising, their transfer from one country to another might prove challenging
and sometimes impossible due to various technical, social, contextual and
cultural factors. In this chapter, we argue for a need to carefully consider
one of these factors, namely cultural values when designing and implementing
learning analytics systems. Viewing culture from a value-sensitive perspective,
in this chapter, we: 1)exemplify two selected values (i.e. privacy and
autonomy) that might play a significant role in the design of learning
analytics systems, and 2)discuss opportunities for applying culture-and
value-sensitive design methods that can guide the design of culturally aware
learning analytics systems. Finally, a set of design implications for
culturally aware and value-sensitive learning analytics services is offered.",170,9,1202,21.43
2701,cultural anthropology,"The need for a more sustainable lifestyle is a key focus for several
countries. Using a questionnaire survey conducted in Hungary, this paper
examines how culture influences environmentally conscious behaviour. Having
investigated the direct impact of Hofstedes cultural dimensions on
pro-environmental behaviour, we found that the culture of a country hardly
affects actual environmentally conscious behaviour. The findings indicate that
only individualism and power distance have a significant but weak negative
impact on pro-environmental behaviour. Based on the findings, we can state that
a positive change in culture is a necessary but not sufficient condition for
making a country greener.",100,6,696,17.34
2702,cultural anthropology,"Culture shapes people's behavior, both online and offline. Surprisingly,
there is sparse research on how cultural context affects network formation and
content consumption on social media. We analyzed the friendship networks and
dyadic relations between content producers and consumers across 73 countries
through a cultural lens in a closed-network setting. Closed networks allow for
intimate bonds and self-expression, providing a natural setting to study
cultural differences in behavior. We studied three theoretical frameworks of
culture - individualism, relational mobility, and tightness. We found that
friendship networks formed across different cultures differ in egocentricity,
meaning the connectedness between a user's friends. Individualism, mobility,
and looseness also significantly negatively impact how tie strength affects
content consumption. Our findings show how culture affects social media
behavior, and we outline how researchers can incorporate this in their work.
Our work has implications for content recommendations and can improve content
engagement.",146,10,1079,29.75
2703,cultural anthropology,"We introduce a stochastic cellular automaton as a model for culture and
border formation. The model can be conceptualized as a game where the expansion
rate of cultures is quantified in terms of their area and perimeter in such a
way that approximately geometrically round cultures get a competitive
advantage. We first analyse the model with periodic boundary conditions, where
we study how the model can end up in a fixed state, i.e. freezes. Then we
implement the model on the European geography with mountains and rivers. We see
how the model reproduces some qualitative features of European culture
formation, namely that rivers and mountains are more frequently borders between
cultures, mountainous regions tend to have higher cultural diversity and the
central European plain has less clear cultural borders.",129,8,816,36.83
2704,cultural anthropology,"Purpose: Global adoption of the internet and mobile usage results in a huge
variation in the cultural backgrounds of consumers who generate and consume
electronic word-of-mouth (eWOM). Unsurprisingly, a research trend on
cross-cultural eWOM has emerged. However, there has not been an attempt to
synthesize this research topic. This paper aims to bridge this gap.
  Methodology: This research paper conducts a systematic literature review of
the current research findings on cross-cultural eWOM. Journal articles
published from 2006 to 2021 are included. This study then presents the key
issues in the extant literature and suggests potential future research.
  Findings: The findings show that there has been an upward trend in the number
of publications on cross-cultural eWOM since the early 2010s, with a relatively
steeper increase toward 2020. The findings also synthesize cross-cultural eWOM
research into four elements and suggest potential future research avenues.
  Value: To the best of the authors' knowledge, there is currently no
exhaustive/integrated review of cross-cultural eWOM research. This research
fills the need to summarize the current state of cross-cultural eWOM literature
and identifies research questions to be addressed in the future.",185,12,1264,45.96
2705,cultural anthropology,"Pretrained large Vision-Language models have drawn considerable interest in
recent years due to their remarkable performance. Despite considerable efforts
to assess these models from diverse perspectives, the extent of visual cultural
awareness in the state-of-the-art GPT-4V model remains unexplored. To tackle
this gap, we extensively probed GPT-4V using the MaRVL benchmark dataset,
aiming to investigate its capabilities and limitations in visual understanding
with a focus on cultural aspects. Specifically, we introduced three visual
related tasks, i.e. caption classification, pairwise captioning, and culture
tag selection, to systematically delve into fine-grained visual cultural
evaluation. Experimental results indicate that GPT-4V excels at identifying
cultural concepts but still exhibits weaker performance in low-resource
languages, such as Tamil and Swahili. Notably, through human evaluation, GPT-4V
proves to be more culturally relevant in image captioning tasks than the
original MaRVL human annotations, suggesting a promising solution for future
visual cultural benchmark construction.",146,9,1107,16.42
2706,cultural anthropology,"Understanding how social norms vary across cultures can help us build
culturally aligned NLP systems. We propose a culture agnostic approach to norm
discovery, using moral emotions, shame and pride, to identify examples of
normative expectations and extract corresponding social norms. We present the
first cross cultural self-conscious emotions dataset, obtained from 5.4K
Bollywood and Hollywood movies, along with over 10K extracted social norms. We
validate our dataset using native speakers and demonstrate how our dataset
reveals variations in social norms that align with the cultural dichotomy
observed in these nations e.g., Bollywood movies emphasize shame due to
deviation from social roles, and express pride in family honor, while Hollywood
shames poverty and incompetence, and takes pride in ethical behavior. Notably,
females are shamed more across both cultures and both cultures shame women for
violating similar normative expectations.",138,9,953,43.02
2707,cultural anthropology,"For synergistic interactions between humans and artificial intelligence (AI)
systems, AI outputs often need to be explainable to people. Explainable AI
(XAI) systems are commonly tested in human user studies. However, whether XAI
researchers consider potential cultural differences in human explanatory needs
remains unexplored. We highlight psychological research that found significant
differences in human explanations between many people from Western, commonly
individualist countries and people from non-Western, often collectivist
countries. We argue that XAI research currently overlooks these variations and
that many popular XAI designs implicitly and problematically assume that
Western explanatory needs are shared cross-culturally. Additionally, we
systematically reviewed over 200 XAI user studies and found that most studies
did not consider relevant cultural variations, sampled only Western
populations, but drew conclusions about human-XAI interactions more generally.
We also analyzed over 30 literature reviews of XAI studies. Most reviews did
not mention cultural differences in explanatory needs or flag overly broad
cross-cultural extrapolations of XAI user study results. Combined, our analyses
provide evidence of a cultural bias toward Western populations in XAI research,
highlighting an important knowledge gap regarding how culturally diverse users
may respond to widely used XAI systems that future work can and should address.",198,10,1456,15.31
2708,cultural anthropology,"Perceptions of hate can vary greatly across cultural contexts. Hate speech
(HS) datasets, however, have traditionally been developed by language. This
hides potential cultural biases, as one language may be spoken in different
countries home to different cultures. In this work, we evaluate cultural bias
in HS datasets by leveraging two interrelated cultural proxies: language and
geography. We conduct a systematic survey of HS datasets in eight languages and
confirm past findings on their English-language bias, but also show that this
bias has been steadily decreasing in the past few years. For three
geographically-widespread languages -- English, Arabic and Spanish -- we then
leverage geographical metadata from tweets to approximate geo-cultural contexts
by pairing language and country information. We find that HS datasets for these
languages exhibit a strong geo-cultural bias, largely overrepresenting a
handful of countries (e.g., US and UK for English) relative to their prominence
in both the broader social media population and the general population speaking
these languages. Based on these findings, we formulate recommendations for the
creation of future HS datasets.",175,11,1188,43.53
2709,cultural anthropology,"This study investigates the role of both cultural and technological factors
in determining audience formation on a global scale. It integrates theories of
media choice with theories of global cultural consumption and tests them by
analyzing shared audience traffic between the world's 1000 most popular
Websites. We find that language and geographic similarities are more powerful
predictors of audience overlap than hyperlinks and genre similarity,
highlighting the role of cultural structures in shaping global media use.",76,4,523,20.42
2710,cultural anthropology,"Cultural Heritage can largely profit from the set of technologies that have
recently been developed in Submarine Robotics. In this paper we focus on how
underwater robotics and related technologies can be used to enhance economical
fruition, control, protection and social impact of the cultural heritage.
Robots allow on-line experience, in remote locations, realizing the remote
museum concept as extension and enhancement of the virtual museum. These
solutions push the cultural tourism beyond actual limits of the sites like the
number of simultaneous visitors, the travelling costs, , the difficulties to
access dangerous locations coming to a true, advanced fruition of the Cultural
Heritage goods.",105,5,704,19.71
2711,cultural anthropology,"CR/10 is a digital oral history platform that aims to collect and preserve
the cultural memories of China's Cultural Revolution (1966-1976). This paper
discusses how CR/10 functions as a Warburgian memory atlas and shapes
multifaceted narratives of the historical incident. Through ethnographic
research and semi-structured interviews with users within and outside academia,
I examined the usability of CR/10 among various user groups and proposed design
opportunities to further empower the interface. This paper offered a strong
case on the datafication of cultural memories among cultural heritage
institutions and contributed to digital archiving scholarship with an
innovative methodological lens.",98,5,702,21.23
2712,cultural anthropology,"Based on a nationwide labour-force survey data, this paper investigates the
influence of cultural variance on migrants' settlement intention in China. By
using dialectal distance as a proxy for cultural distance, we find strong
evidence for the negative effects of cultural distance on migrants' settlement
intention. By further investigation into sub-samples separated by gender,
generation and higher education experience, we find that the influence is less
effective for younger migrants and higher-educated migrants, which indicates
that the impact of cultural barrier may gradually diminish with the integration
of society and promotion of education.",93,4,655,6.17
2713,cultural anthropology,"We present a methodology to support the analysis of culture from text such as
news events and demonstrate its usefulness on categorizing news events from
different categories (society, business, health, recreation, science, shopping,
sports, arts, computers, games and home) across different geographical
locations (different places in 117 countries). We group countries based on the
culture that they follow and then filter the news events based on their content
category. The news events are automatically labelled with the help of Hofstedes
cultural dimensions. We present combinations of events across different
categories and check the performances of different classification methods. We
also presents experimental comparison of different number of features in order
to find a suitable set to represent the culture.",119,6,821,30.4
2714,cultural anthropology,"Complex organizations accomplish tasks through many steps of collaboration
among workers. Corporate culture supports collaborations by establishing norms
and reducing misunderstandings. Because a strong corporate culture relies on
costly, voluntary investments by many workers, we model it as an organizational
public good, subject to standard free-riding problems, which become severe in
large organizations. Our main finding is that voluntary contributions to
culture can nevertheless be sustained, because an organization's equilibrium
productivity is endogenously highly sensitive to individual contributions.
However, the completion of complex tasks is then necessarily fragile to small
shocks that damage the organization's culture.",96,6,738,9.69
2715,cultural anthropology,"Human culture has evolved for thousands of years and thrived in the era of
Internet. Due to the availability of big data, we could do research on human
culture by analyzing its representation such as user item rating values on
websites like MovieLens and Douban. Industrial workers have applied recommender
systems in big data to predict user behavior and promote web traffic. In this
paper, we analyze the social impact of an algorithm named ZeroMat to show that
human culture is locked into a state where individual's cultural taste is
predictable at high precision without historic data. We also provide solutions
to this problem and interpretation of current Chinese government's regulations
and policies.",113,6,709,40.08
2716,cultural anthropology,"The surge of interest in culturally aware and adapted Natural Language
Processing (NLP) has inspired much recent research. However, the lack of common
understanding of the concept of ""culture"" has made it difficult to evaluate
progress in this emerging area. Drawing on prior research in NLP and related
fields, we propose an extensive taxonomy of elements of culture that can
provide a systematic framework for analyzing and understanding research
progress. Using the taxonomy, we survey existing resources and models for
culturally aware and adapted NLP, providing an overview of the state of the art
and the research gaps that still need to be filled.",104,5,654,36.63
2717,cultural anthropology,"We model sex-structured population dynamics to analyze pairwise competition
between groups differing both genetically and culturally. A sex-ratio allele is
expressed in the heterogametic sex only, so that assumptions of Fisher's
analysis do not apply. Sex-ratio evolution drives cultural evolution of a
group-associated trait governing mortality in the homogametic sex. The two-sex
dynamics under resource limitation induces a strong Allee effect that depends
on both sex ratio and cultural trait values. We describe the resulting
threshold, separating extinction from positive growth, as a function of female
and male densities. When initial conditions avoid extinction due to the Allee
effect, different sex ratios cannot coexist; in our model, greater female
allocation always invades and excludes a lesser allocation. But the culturally
transmitted trait interacts with the sex ratio to determine the ecological
consequences of successful invasion. The invading female allocation may permit
population persistence at self-regulated equilibrium. For this case, the
resident culture may be excluded, or may coexist with the invader culture. That
is, a single sex-ratio allele in females and a cultural dimorphism in male
mortality can persist; a low-mortality resident trait is maintained by
father-to-son cultural transmission. Otherwise, the successfully invading
female allocation excludes the resident allele and culture, and then drives the
population to extinction via a shortage of males. Finally, we show that the
results obtained under homogeneous mixing hold, with caveats, in a spatially
explicit model with local mating and diffusive dispersal in both sexes.",240,13,1672,25.8
2718,cultural anthropology,"Even this saying itself is a variant of a similar statement attributed to
Bernard of Chartres in the 12th Century, and inspired the title for a book by
Steven Hawking and an album by Oasis. Creative ideas beget other creative ideas
and, as a result, modifications accumulate, and we see an overall increase in
the complexity of cultural novelty over time, a phenomenon sometimes referred
to as the ratchet effect (Tomasello, Kruger, & Ratner, 1993). Although we may
never meet the people or objects that creatively influence us, by assimilating
what we encounter around us and bringing to bear our own insights and
perspectives, we all contribute in our own way, however small, to a second
evolutionary process -- the evolution of culture. This chapter explores how we
can better understand culture by understanding the creative processes that fuel
it, and better understand creativity by examining it from its cultural context.
First, we look at some theoretical frameworks for how culture evolves and what
these frameworks imply for the role of creativity. Then we will see how
questions about the relationship between creativity and cultural evolution have
been addressed using an agent-based model. We will also discuss studies of how
creative outputs are influenced, in perhaps unexpected ways, by other ideas and
individuals, and how individual creative styles ""peek through"" cultural outputs
in different domains.",225,8,1420,30.64
2719,cultural anthropology,"We introduce a novel approach for the quantitative assessment of the
connectivity in neuronal cultures, based on the statistical mechanics of
percolation on a graph. This allows us to follow the development of the culture
and see the emergence of connectivity in the network. The culture becomes fully
connected at a time equivalent to full term. The spontaneous bursting activity
that characterizes cultures develops in parallel with the connectivity. The
average number of inputs per neuron can be quantitatively determined in units
of $m_0$, the number of activated inputs needed to excite the neuron. For
$m_0\sim 10$ we find that hippocampal neurons have on average $\sim 40-80$
inputs while cortical neurons have $\sim 50-100$, depending on neuronal
density. The ratio of excitatory to inhibitory neurons is determined using the
GABA$_\text{A}$ antagonist bicuculine. This ratio changes during development
and reaches the final value at day $7-8$, coinciding with the expected time of
the GABA switch. For hippocampal cultures the inhibitory cells comprise about
$30\%$ of the neurons in the culture while for cortical cultures they are about
$20\%$. Such detailed global information on the connectivity of networks in
neuronal cultures is at present inaccessible by any electrophysiological or
other technique.",199,11,1317,34.36
2720,cultural anthropology,"As the reach of large language models (LMs) expands globally, their ability
to cater to diverse cultural contexts becomes crucial. Despite advancements in
multilingual capabilities, models are not designed with appropriate cultural
nuances. In this paper, we show that multilingual and Arabic monolingual LMs
exhibit bias towards entities associated with Western culture. We introduce
CAMeL, a novel resource of 628 naturally-occurring prompts and 20,368 entities
spanning eight types that contrast Arab and Western cultures. CAMeL provides a
foundation for measuring cultural biases in LMs through both extrinsic and
intrinsic evaluations. Using CAMeL, we examine the cross-cultural performance
in Arabic of 16 different LMs on tasks such as story generation, NER, and
sentiment analysis, where we find concerning cases of stereotyping and cultural
unfairness. We further test their text-infilling performance, revealing the
incapability of appropriate adaptation to Arab cultural contexts. Finally, we
analyze 6 Arabic pre-training corpora and find that commonly used sources such
as Wikipedia may not be best suited to build culturally aware LMs, if used as
they are without adjustment. We will make CAMeL publicly available at:
https://github.com/tareknaous/camel",180,10,1267,25.8
2721,cultural anthropology,"One challenge in text-to-image (T2I) generation is the inadvertent reflection
of culture gaps present in the training data, which signifies the disparity in
generated image quality when the cultural elements of the input text are rarely
collected in the training set. Although various T2I models have shown
impressive but arbitrary examples, there is no benchmark to systematically
evaluate a T2I model's ability to generate cross-cultural images. To bridge the
gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive
evaluation criteria, which can assess how well-suited a model is to a target
culture. By analyzing the flawed images generated by the Stable Diffusion model
on the C3 benchmark, we find that the model often fails to generate certain
cultural objects. Accordingly, we propose a novel multi-modal metric that
considers object-text alignment to filter the fine-tuning data in the target
culture, which is used to fine-tune a T2I model to improve cross-cultural
generation. Experimental results show that our multi-modal metric provides
stronger data selection performance on the C3 benchmark than existing metrics,
in which the object-text alignment is crucial. We release the benchmark, data,
code, and generated images to facilitate future research on culturally diverse
T2I generation (https://github.com/longyuewangdcu/C3-Bench).",197,9,1371,17.57
2722,cultural anthropology,"As the scaling of Large Language Models (LLMs) has dramatically enhanced
their capabilities, there has been a growing focus on the alignment problem to
ensure their responsible and ethical use. While existing alignment efforts
predominantly concentrate on universal values such as the HHH principle, the
aspect of culture, which is inherently pluralistic and diverse, has not
received adequate attention. This work introduces a new benchmark, CDEval,
aimed at evaluating the cultural dimensions of LLMs. CDEval is constructed by
incorporating both GPT-4's automated generation and human verification,
covering six cultural dimensions across seven domains. Our comprehensive
experiments provide intriguing insights into the culture of mainstream LLMs,
highlighting both consistencies and variations across different dimensions and
domains. The findings underscore the importance of integrating cultural
considerations in LLM development, particularly for applications in diverse
cultural settings. Through CDEval, we aim to broaden the horizon of LLM
alignment research by including cultural dimensions, thus providing a more
holistic framework for the future development and evaluation of LLMs. This
benchmark serves as a valuable resource for cultural studies in LLMs, paving
the way for more culturally aware and sensitive models.",186,9,1332,22.45
2723,cultural anthropology,"Constructing a universal moral code for artificial intelligence (AI) is
difficult or even impossible, given that different human cultures have
different definitions of morality and different societal norms. We therefore
argue that the value system of an AI should be culturally attuned: just as a
child raised in a particular culture learns the specific values and norms of
that culture, we propose that an AI agent operating in a particular human
community should acquire that community's moral, ethical, and cultural codes.
How AI systems might acquire such codes from human observation and interaction
has remained an open question. Here, we propose using inverse reinforcement
learning (IRL) as a method for AI agents to acquire a culturally-attuned value
system implicitly. We test our approach using an experimental paradigm in which
AI agents use IRL to learn different reward functions, which govern the agents'
moral values, by observing the behavior of different cultural groups in an
online virtual world requiring real-time decision making. We show that an AI
agent learning from the average behavior of a particular cultural group can
acquire altruistic characteristics reflective of that group's behavior, and
this learned value system can generalize to new scenarios requiring altruistic
judgments. Our results provide, to our knowledge, the first demonstration that
AI agents could potentially be endowed with the ability to continually learn
their values and norms from observing and interacting with humans, thereby
becoming attuned to the culture they are operating in.",241,8,1588,19.64
2724,cultural anthropology,"Research in cultural evolution aims at providing causal explanations for the
change of culture over time. Over the past decades, this field has generated an
important body of knowledge, using experimental, historical, and computational
methods. While computational models have been very successful at generating
testable hypotheses about the effects of several factors, such as population
structure or transmission biases, some phenomena have so far been more complex
to capture using agent-based and formal models. This is in particular the case
for the effect of the transformations of social information induced by evolved
cognitive mechanisms. We here propose that leveraging the capacity of Large
Language Models (LLMs) to mimic human behavior may be fruitful to address this
gap. On top of being an useful approximation of human cultural dynamics,
multi-agents models featuring generative agents are also important to study for
their own sake. Indeed, as artificial agents are bound to participate more and
more to the evolution of culture, it is crucial to better understand the
dynamics of machine-generated cultural evolution. We here present a framework
for simulating cultural evolution in populations of LLMs, allowing the
manipulation of variables known to be important in cultural evolution, such as
network structure, personality, and the way social information is aggregated
and transformed. The software we developed for conducting these simulations is
open-source and features an intuitive user-interface, which we hope will help
to build bridges between the fields of cultural evolution and generative
artificial intelligence.",242,10,1645,18.79
2725,cultural anthropology,"In the globalization trend, China's cultural heritage is in danger of
gradually disappearing. The protection and inheritance of these precious
cultural resources has become a critical task. This paper focuses on the Miao
batik culture in Guizhou Province, China, and explores the application of
knowledge graphs, natural language processing, and deep learning techniques in
the promotion and protection of batik culture. We propose a dual-channel
mechanism that integrates semantic and visual information, aiming to connect
batik pattern features with cultural connotations. First, we use natural
language processing techniques to automatically extract batik-related entities
and relationships from the literature, and construct and visualize a structured
batik pattern knowledge graph. Based on this knowledge graph, users can
textually search and understand the images, meanings, taboos, and other
cultural information of specific patterns. Second, for the batik pattern
classification, we propose an improved ResNet34 model. By embedding average
pooling and convolutional operations into the residual blocks and introducing
long-range residual connections, the classification performance is enhanced. By
inputting pattern images into this model, their subjects can be accurately
identified, and then the underlying cultural connotations can be understood.
Experimental results show that our model outperforms other mainstream models in
evaluation metrics such as accuracy, precision, recall, and F1-score, achieving
99.0%, 99.0%, 98.9%, and 99.0%, respectively. This research provides new ideas
for the digital protection of batik culture and demonstrates the great
potential of artificial intelligence technology in cultural heritage
protection.",237,16,1749,17.54
2726,cultural anthropology,"Context: In agile transformations, there are many challenges such as
alignment between agile practices and the organizational goals and strategies
or issues with shifts in how work is organized and executed. One very important
challenge but less considered and treated in research are cultural challenges
associated with an agile mindset. Although research shows that cultural clashes
and general organizational resistance to change are part of the most
significant agile adoption barriers. Objective: We identify challenges that
arise from the interplay between agile culture and organizational culture. In
doing so, we tackle this field and come up with important contributions for
further research regarding a problem that practitioners face today. Method:
This is done with a mixed-method research approach. First, we gathered
qualitative data among our network of agile practitioners and derived in sum 15
challenges with agile culture. Then, we conducted quantitative data by means of
a questionnaire study with 92 participants. Results: We identified 7 key
challenges out of the 15 challenges with agile culture. These key challenges
refer to the technical agility (doing agile) and the cultural agility (being
agile). The results are presented in type of a conceptual model named the Agile
Cultural Challenges (ACuCa). Conclusion: Based on our results, we started
deriving future work aspects to do more detailed research on the topic of
cultural challenges while transitioning or using agile methods in software
development and beyond.",231,13,1544,34.97
2727,cultural anthropology,"We discuss for the concept of promises within a framework that can be applied
to either humans or technology. We compare promises to the more established
notion of obligations and find promises to be both simpler and more effective
at reducing uncertainty in behavioural outcomes.",45,3,280,48.64
2728,cultural anthropology,"What can relics of the past tell us about the thoughts and beliefs of the
people who invented and used them? Recent collaborations at the frontier of
archaeology, anthropology, and cognitive science are culminating in speculative
but nevertheless increasingly sophisticated efforts to unravel how modern human
cognition came about. By considering objects within their archaeological
context, we have begun to piece together something of the way of life of people
who inhabited particular locales, which in turn reflects their underlying
thought processes.",82,3,555,18.39
2729,cultural anthropology,"The use of digital traces of our social structures and activities is a
reality for some companies and State instances. The exploitation by the
individual and by Society is still incipient. This writing is a brief account
of an immersion to advance this civil empowerment, beginning with experiments
for collection and dissemination of information, and going through social
structures streaming, resource recommendation via complex networks and natural
language processing, linked data and ontological organizations of social and
participatory structures.
  Keywords: complex networks, natural language processing, linked data, social
participation, anthropological physics",91,4,672,6.03
2730,cultural anthropology,"There is currently no evidence for life on any known exoplanet. Here, we
propose a form of ""galactic anthropology"" to detect not only the existence of
life on transiting exoplanets, but also the existence of environmentalism
movements. By observing the planet's atmosphere over long time baselines, the
destruction and recovery of a hole in an exoplanet's ozone layer may be
observable. While not readily detectable for any one system with JWST, by
binning together observations of hundreds of systems we can finally determine
the occurrence rate of environmental movements on Earthlike planets in the
galaxy, a number we term eta-Green-Earth.",100,5,643,29.18
2731,cultural anthropology,"Researchers find weaknesses in current strategies for protecting privacy in
large datasets. Many anonymized datasets are reidentifiable, and norms for
offering data subjects notice and consent over emphasize individual
responsibility. Based on fieldwork with data managers in the City of Seattle, I
identify ways that these conventional approaches break down in practice.
Drawing on work from theorists in sociocultural anthropology, I propose that a
Human Centered Data Science move beyond concepts like dataset identifiability
and sensitivity toward a broader ontology of who is implicated by a dataset,
and new ways of anticipating how data can be combined and used.",99,5,669,29.38
2732,cultural anthropology,"Inspired by the MaCzek Visual Basic program we provide an R package, RMaCzek,
that produces Czekanowski's diagram. Our package permits any seriation and
distance method the user provides. In this paper we focus on the OLO and
QAP_2SUM methods from the seriation package. We illustrate the possibilities of
our package with three anthropological studies, one socio-economical one and a
phylogenetically motivated simulation study.",63,5,429,30.06
2733,cultural anthropology,"We analyze the dynamics toward cultural consensus in the Axelrod model on
scale-free networks. By looking at the microscopic dynamics of the model, we
are able to show how culture traits spread across different cultural features.
We compare the diffusion at the level of cultural features to the growth of
cultural consensus at the global level, finding important differences between
these two processes. In particular, we show that even when most of the cultural
features have reached macroscopic consensus, there are still no signals of
globalization. Finally, we analyze the topology of consensus clusters both for
global culture and at the feature level of representation.",105,6,676,33.24
2734,cultural anthropology,"This study examines the Arabic interface design elements that are largely
influenced by the cultural values. Cultural markers are examined in websites
from educational, business, and media. Cultural values analysis is based on
Geert Hofstede's cultural dimensions. The findings show that there are cultural
markers which are largely influenced by the culture and that the Hofstede's
score for Arab countries is partially supported by the website design
components examined in this study. Moderate support was also found for the long
term orientation, for which Hoftsede has no score.",88,6,583,45.15
2735,cultural anthropology,"The Axelrod model is a spatial stochastic model for the dynamics of cultures
that includes two key social mechanisms: homophily and social influence,
respectively defined as the tendency of individuals to interact more frequently
with individuals who are more similar and the tendency of individuals to become
more similar when they interact. The original model assumes that individuals
are located on the vertex set of an interaction network and are characterized
by their culture, a vector of opinions about $F$ cultural features, each of
which offering the same number $q$ of alternatives. Pairs of neighbors interact
at a rate proportional to the number of cultural features for which they agree,
which results in one more agreement between the two neighbors. In this article,
we study a more general and more realistic version of the standard Axelrod
model that allows for a variable number of opinions across cultural features,
say $q_i$ possible alternatives for the $i$th cultural feature. Our main result
shows that the one-dimensional system with two cultural features fixates when
$q_1 + q_2 \geq 6$.",176,6,1111,27.49
2736,cultural anthropology,"Propinquity between Australian Indigenous communities' social structures and
ICT purposed for cultural preservation is a modern area of research;
historically hindered by the ""digital divide"" thus limiting plentiful
literature and existing information systems in this field in theoretical and
practical applications. Henceforth, community consultation is mandatory in
deriving and delivering empirically effective processes in a cultural and
language preservation IS tool designed to teach future generations of
Indigenous Australians about native culture and language. More than 100 out of
250 languages spoken by Indigenous have become extinct since 1788 (Harrington,
2014) which inaugurates the urgency of this preservation tool. ICT has been
identified as the best provision method; by its capacity to best collect,
eternize and teach cultural knowledge and language. The aim of this research is
to specify requirements and considerations for the development of a socially
integrated, culturally conscious, end-user driven IS to preserve Indigenous
culture in Australia.",150,6,1074,15.65
2737,cultural anthropology,"In this study, a narrative literature review regarding culture and e-commerce
website design has been introduced. Cultural aspect and e-commerce website
design will play a significant role for successful global e-commerce sites in
the future. Future success of businesses will rely on e-commerce. To compete in
the global e-commerce marketplace, local businesses need to focus on designing
culturally friendly e-commerce websites. To the best of my knowledge, there has
been insignificant research conducted on correlations between culture and
e-commerce website design. The research shows that there are correlations
between e-commerce, culture, and website design. The result of the study
indicates that cultural aspects influence e-commerce website design. This study
aims to deliver a reference source for information systems and information
technology researchers interested in culture and e-commerce website design, and
will show lessfocused research areas in addition to future directions.",140,9,996,36.79
2738,cultural anthropology,"Software development requires intensive communication between the
requirements engineers and software stakeholders, particularly during the
Requirements Engineering (RE) phase. Therefore, the individuals' culture might
influence both the RE process and the result. Our aims are to investigate the
extend of cultural influences on the RE process, and to analyze how the RE
process can be adapted to take into account cultural aspects. The model we
present is based on Hofstede's cultural theory. The model was applied on a
pilot case study in the context of the conservative Saudi Arabian culture. The
results reveal 6 RE aspects and 10 cultural factors that have a large impact on
the RE practice.",109,7,697,44.54
2739,cultural anthropology,"The analysis of consumers' personal information (PI) is a significant source
to learn about consumers. In online settings, many consumers disclose PI
abundantly -- this is particularly true for information provided on social
network services. Still, people manage the privacy level they want to maintain
by disclosing by disclosing PI accordingly. In addition, studies have shown
that consumers' online self-disclosure (OSD) differs across cultures.
Therefore, intelligent systems should consider cultural issues when collecting,
processing, storing or protecting data from consumers. However, existing
studies typically rely on a comparison of two cultures, providing valuable
insights but not drawing a comprehensive picture. We introduce an open research
model for cultural OSD research, based on the privacy calculus theory. Our open
research model incorporates six cultural dimensions, six predictors, and 24
structured propositions. It represents a comprehensive approach that provides a
basis to explain possible cultural OSD phenomena in a systematic way.",149,10,1063,29.45
2740,cultural anthropology,"Pakistan as culturally diverse country possesses wide range of cultural
factors. These cultural factors affect the living style, traditions, values and
norms as well as the education. As e-learning is global mode of education so
learners from different backgrounds enrolled in learning management system.
Diversity of culture and learning styles should keep under considerations while
designing e-learning environment. In this research work e learning cultural
factors highlighted by Bentley ET. AL are incorporated to find the learner
level. After assignment of level, learner respective Learning Management System
is allocated to learner. The focus is to concentrate on cultural factor in
e-learning system. Furthermore; a prototype of the proposed system is
implemented for the validation of proposed architecture.",117,10,817,32.9
2741,cultural anthropology,"As the uni-cultural studies of website usability have matured, the paucity of
cross-cultural studies of usability become increasingly apparent. Moving toward
these cross-cultural studies will require the development of a new tool to
assess website usability in the context of cultural dimensions. This paper
introduces the preliminary results from the first phase of this project and
then presents the proposed method for the research in progress that
specifically is directed to the development and quantitative evaluation of a
measurement scale of a culture sensitive measurement of website usability. The
recognition of the need to develop this scale resulted from the identification
of culture-related shortcomings of previous measurement tools that have been
used widely within the Management of Information Systems (MIS) literature.",121,5,838,15.34
2742,cultural anthropology,"The implementors of learning technologies within education environments often
follow strategies that assume the educational environment within which they are
being introduced is culturally neutral. A comprehensive literature review
including 150 papers on educational technology challenges was undertaken. The
purpose of this review is explore different contextual challenges to the
adoption of educational technology in the higher education sector. The cultural
factors that define the key stakeholders (e.g., teachers, lectures, students
and support staff) are often ignored when the implementation processes are
undertaken. Furthermore, it is often assumed that the personnel responsible for
the implementation are also culturally neutral and do not possess any
attributes unique to their culture. It has been shown that cultural factors may
significantly influence the implementation of learning technologies and to
design strategies that fail to consider factors may limit their efficiency and
effectiveness. The challenges are interrelated and based on the findings, this
review proposes a conceptual framework by integrating culture and grit into the
Technology Acceptance Model(TAM) for implementing educational technology in
higher education. The framework will be useful to guide both practice and
research.",182,11,1317,17.13
2743,cultural anthropology,"Many cultural traits characterizing intelligent behaviors are now thought to
be transmitted through statistical learning, motivating us to study its effects
on cultural evolution. We conduct a large-scale music data analysis and observe
that various statistical parameters of musical products approximately follow
the beta distribution and other conjugate distributions. We construct a simple
model of cultural evolution incorporating statistical learning and analytically
show that conjugate distributions emerge at equilibrium in the presence of
oblique transmission. The results demonstrate that the distribution of a
cultural trait within a population depends on the individual's model for
cultural production (the conjugate distribution law), and reveal interesting
possibilities for theoretical and experimental studies on cultural evolution
and social learning.",115,5,868,-8.53
2744,cultural anthropology,"Language embeds information about social, cultural, and political values
people hold. Prior work has explored social and potentially harmful biases
encoded in Pre-Trained Language models (PTLMs). However, there has been no
systematic study investigating how values embedded in these models vary across
cultures. In this paper, we introduce probes to study which values across
cultures are embedded in these models, and whether they align with existing
theories and cross-cultural value surveys. We find that PTLMs capture
differences in values across cultures, but those only weakly align with
established value surveys. We discuss implications of using mis-aligned models
in cross-cultural settings, as well as ways of aligning PTLMs with value
surveys.",110,7,754,35.98
2745,cultural anthropology,"The present paper concerns the design of the semantic infrastructure of the
digital space for cultural heritage as envisaged by the European Commission in
its recent documents. Due to the complexity of the cultural heritage data and
of their intrinsic interrelationships, it is necessary to introduce a novel
ontology, yet compliant with existing standards and interoperable with previous
platforms used in this context, such as Europeana. The digital space
organization must be tailored to the methods and the theory of cultural
heritage, briefly summarized in the introduction. The new ontology is based on
the Digital Twin concept, i.e. the digital counterpart of cultural heritage
assets incorporating all the digital information pertaining to them. This
creates a Knowledge Base on the cultural heritage digital space. The paper
outlines the main features of the proposed Heritage Digital Twin ontology and
provides some examples of application. Future work will include completing the
ontology in all its details and testing it in other real cases and with the
various sectors of the cultural heritage community.",171,10,1118,24.37
2746,cultural anthropology,"Agile methods are well-known approaches in software development and used in
various settings, which may vary wrt. organizational size, culture, or
industrial sector. One important facet for the successful use of agile methods
is the strong focus on social aspects. We know, that cultural values influence
the behaviour of humans. Thus, an in-depth understanding of the influence of
cultural aspects on agile methods is necessary to be able to adapt agile
methods to various cultural contexts. In this paper we focus on an enabler to
this problem. We want to better understand the influence of cultural factors on
agile practices. The core contribution of this paper is MoCA: A model
describing the impact of cultural values on agile elements.",119,9,742,47.89
2747,cultural anthropology,"Detecting offensive language is a challenging task. Generalizing across
different cultures and languages becomes even more challenging: besides
lexical, syntactic and semantic differences, pragmatic aspects such as cultural
norms and sensitivities, which are particularly relevant in this context, vary
greatly. In this paper, we target Chinese offensive language detection and aim
to investigate the impact of transfer learning using offensive language
detection data from different cultural backgrounds, specifically Korean and
English. We find that culture-specific biases in what is considered offensive
negatively impact the transferability of language models (LMs) and that LMs
trained on diverse cultural data are sensitive to different features in Chinese
offensive language detection. In a few-shot learning scenario, however, our
study shows promising prospects for non-English offensive language detection
with limited resources. Our findings highlight the importance of cross-cultural
transfer learning in improving offensive language detection and promoting
inclusive digital spaces.",145,7,1096,13.07
2748,cultural anthropology,"Despite recent progress, large language models (LLMs) still face the
challenge of appropriately reacting to the intricacies of social and cultural
conventions. This paper presents MANGO, a methodology for distilling
high-accuracy, high-recall assertions of cultural knowledge. We judiciously and
iteratively prompt LLMs for this purpose from two entry points, concepts and
cultures. Outputs are consolidated via clustering and generative summarization.
Running the MANGO method with GPT-3.5 as underlying LLM yields 167K
high-accuracy assertions for 30K concepts and 11K cultures, surpassing prior
resources by a large margin. For extrinsic evaluation, we explore augmenting
dialogue systems with cultural knowledge assertions. We find that adding
knowledge from MANGO improves the overall quality, specificity, and cultural
sensitivity of dialogue responses, as judged by human annotators. Data and code
are available for download.",128,10,932,31.68
2749,cultural anthropology,"Large language models (LLMs) have rapidly evolved as the foundation of
various natural language processing (NLP) applications. Despite their wide use
cases, their understanding of culturally-related concepts and reasoning remains
limited. Meantime, there is a significant need to enhance these models'
cultural reasoning capabilities, especially concerning underrepresented
regions. This paper introduces a novel pipeline for extracting high-quality,
culturally-related instruction tuning datasets from vast unstructured corpora.
We utilize a self-instruction generation pipeline to identify cultural concepts
and trigger instruction. By integrating with a general-purpose instruction
tuning dataset, our model demonstrates enhanced capabilities in recognizing and
understanding regional cultural nuances, thereby enhancing its reasoning
capabilities. We conduct experiments across three regions: Singapore, the
Philippines, and the United States, achieving performance improvement of up to
6%. Our research opens new avenues for extracting cultural instruction tuning
sets directly from unstructured data, setting a precedent for future
innovations in the field.",147,9,1163,10.5
2750,cultural anthropology,"Measuring culture and its dynamics through surveys has important limitations,
but the emerging field of computational social science allows us to overcome
them by analyzing large-scale datasets. In this article, we study cultural
dynamics through the votes in the Eurovision song contest, which are decided by
a crowd-based scheme in which viewers vote through mobile phone messages.
Taking into account asymmetries and imperfect perception of culture, we measure
cultural relations among European countries in terms of cultural affinity. We
propose the Friend-or-Foe coefficient, a metric to measure voting biases among
participants of a Eurovision contest. We validate how this metric represents
cultural affinity through its relation with known cultural distances, and
through numerical analysis of biased Eurovision contests. We apply this metric
to the historical set of Eurovision contests from 1975 to 2012, finding new
patterns of stronger modularity than using votes alone. Furthermore, we define
a measure of polarization that, when applied to empirical data, shows a sharp
increase within EU countries during 2010 and 2011. We empirically validate the
relation between this polarization and economic indicators in the EU, showing
how political decisions influence both the economy and the way citizens relate
to the culture of other EU members.",201,9,1355,29.08
2751,cultural anthropology,"Wikipedia is a huge global repository of human knowledge, that can be
leveraged to investigate interwinements between cultures. With this aim, we
apply methods of Markov chains and Google matrix, for the analysis of the
hyperlink networks of 24 Wikipedia language editions, and rank all their
articles by PageRank, 2DRank and CheiRank algorithms. Using automatic
extraction of people names, we obtain the top 100 historical figures, for each
edition and for each algorithm. We investigate their spatial, temporal, and
gender distributions in dependence of their cultural origins. Our study
demonstrates not only the existence of skewness with local figures, mainly
recognized only in their own cultures, but also the existence of global
historical figures appearing in a large number of editions. By determining the
birth time and place of these persons, we perform an analysis of the evolution
of such figures through 35 centuries of human history for each language, thus
recovering interactions and entanglement of cultures over time. We also obtain
the distributions of historical figures over world countries, highlighting
geographical aspects of cross-cultural links. Considering historical figures
who appear in multiple editions as interactions between cultures, we construct
a network of cultures and identify the most influential cultures according to
this network.",204,9,1374,28.67
2752,cultural anthropology,"Purpose: The purpose of the current study was to investigate the effect of
microchannel geometry on neuronal cultures and to maintain these cultures for
long period of time (over several weeks) inside the closed microchannels of
cellular scale dimensions.
  Methods: The primary hippocampal neurons from E-18 rat were cultured inside
the closed polydimethylsiloxane (PDMS) microchannels of varying sizes. The
effect of the channel geometry on the spatial and the temporal variations in
the neural microenvironment was investigated by studying neural maturation and
variation in the media osmolality respectively. The cultures were maintained
for longer time spans by PDMS device pretreatment, control on media evaporation
(by using hydrophobic ethylene propylene membrane) and an effective culture
maintenance protocol. Further, the devices were integrated with the planar
microelectrode arrays (MEA) to record spontaneous electrical activity.
  Results: A direct influence of channel geometry on neuron maturation was
observed with cells in smaller channels maturing faster. The temporal variation
in the microenvironment was caused by several fold increase in osmolality
within 2-3 days due to rapid media evaporation. With our culture methodology,
neurons were maintained in the closed channels as small as 50 microns in height
and width for over 1 month in serum free media condition and the time varying
spontaneous electrical activity was measured for up to 5 weeks using the MEA.
  Conclusions: The understanding of the effect of the culture scale on cellular
microenvironment and such long-term culture maintenance will be helpful in
studying neuronal tissue development; therapeutic drug screening; and for
network level neuronal analysis.",254,10,1748,25.93
2753,cultural anthropology,"It is a long-standing question whether human sexual and reproductive cycles
are affected predominantly by biology or culture. The literature is mixed with
respect to whether biological or cultural factors best explain the reproduction
cycle phenomenon, with biological explanations dominating the argument. The
biological hypothesis proposes that human reproductive cycles are an adaptation
to the seasonal cycles caused by hemisphere positioning, while the cultural
hypothesis proposes that conception dates vary mostly due to cultural factors,
such as vacation schedule or religious holidays. However, for many countries,
common records used to investigate these hypotheses are incomplete or
unavailable, biasing existing analysis towards primarily Christian countries in
the Northern Hemisphere. Here we show that interest in sex peaks sharply online
during major cultural and religious celebrations, regardless of hemisphere
location. This online interest, when shifted by nine months, corresponds to
documented human birth cycles, even after adjusting for numerous factors such
as language, season, and amount of free time due to holidays. We further show
that mood, measured independently on Twitter, contains distinct collective
emotions associated with those cultural celebrations, and these collective
moods correlate with sex search volume outside of these holidays as well. Our
results provide converging evidence that the cyclic sexual and reproductive
behavior of human populations is mostly driven by culture and that this
interest in sex is associated with specific emotions, characteristic of, but
not limited to, major cultural and religious celebrations.",235,9,1672,7.79
2754,cultural anthropology,"Urban economists have put forward the idea that cities that are culturally
interesting tend to attract ""the creative class"" and, as a result, end up being
economically successful. Yet it is still unclear how economic and cultural
dynamics mutually influence each other. By contrast, that has been extensively
studied in the case of individuals. Over decades, the French sociologist Pierre
Bourdieu showed that people's success and their positions in society mainly
depend on how much they can spend (their economic capital) and what their
interests are (their cultural capital). For the first time, we adapt Bourdieu's
framework to the city context. We operationalize a neighborhood's cultural
capital in terms of the cultural interests that pictures geo-referenced in the
neighborhood tend to express. This is made possible by the mining of what users
of the photo-sharing site of Flickr have posted in the cities of London and New
York over 5 years. In so doing, we are able to show that economic capital alone
does not explain urban development. The combination of cultural capital and
economic capital, instead, is more indicative of neighborhood growth in terms
of house prices and improvements of socio-economic conditions. Culture pays,
but only up to a point as it comes with one of the most vexing urban
challenges: that of gentrification.",215,11,1348,41.19
2755,cultural anthropology,"Automatic recognition of emotion from facial expressions is an intense area
of research, with a potentially long list of important application. Yet, the
study of emotion requires knowing which facial expressions are used within and
across cultures in the wild, not in controlled lab conditions; but such studies
do not exist. Which and how many cross-cultural and cultural-specific facial
expressions do people commonly use? And, what affect variables does each
expression communicate to observers? If we are to design technology that
understands the emotion of users, we need answers to these two fundamental
questions. In this paper, we present the first large-scale study of the
production and visual perception of facial expressions of emotion in the wild.
We find that of the 16,384 possible facial configurations that people can
theoretically produce, only 35 are successfully used to transmit emotive
information across cultures, and only 8 within a smaller number of cultures.
Crucially, we find that visual analysis of cross-cultural expressions yields
consistent perception of emotion categories and valence, but not arousal. In
contrast, visual analysis of cultural-specific expressions yields consistent
perception of valence and arousal, but not of emotion categories. Additionally,
we find that the number of expressions used to communicate each emotion is also
different, e.g., 17 expressions transmit happiness, but only 1 is used to
convey disgust.",219,11,1465,42.82
2756,cultural anthropology,"Cities are different around the world, but does this fact have any relation
to culture? The idea that urban form embodies idiosyncrasies related to
cultural identities captures the imagination of many in urban studies, but it
is an assumption yet to be carefully examined. Approaching spatial
configurations in the built environment as a proxy of urban culture, this paper
searches for differences potentially consistent with specific regional cultures
or cultures of planning in urban development. It does so focusing on the
elementary components shaping cities: buildings and how they are aggregated in
cellular complexes of built form. Exploring Shannon's work, we introduce an
entropy measure to analyse the probability distribution of cellular
arrangements in built form systems. We apply it to downtown areas of 45 cities
from different regions of the world as a similarity measure to compare and
cluster cities potentially consistent with specific spatial cultures. Findings
suggest a classification scheme that sheds further light on what we call the
""cultural hypothesis"": the possibility that different cultures and regions find
different ways of ordering space.",176,7,1172,29.08
2757,cultural anthropology,"Two decades ago, Leo Breiman identified two cultures for statistical
modeling. The data modeling culture (DMC) refers to practices aiming to conduct
statistical inference on one or several quantities of interest. The algorithmic
modeling culture (AMC) refers to practices defining a machine-learning (ML)
procedure that generates accurate predictions about an event of interest.
Breiman argued that statisticians should give more attention to AMC than to
DMC, because of the strengths of ML in adapting to data. While twenty years
later, DMC has lost some of its dominant role in statistics because of the
data-science revolution, we observe that this culture is still the leading
practice in the natural and social sciences. DMC is the modus operandi because
of the influence of the established scientific method, called the
hypothetico-deductive scientific method. Despite the incompatibilities of AMC
with this scientific method, among some research groups, AMC and DMC cultures
mix intensely. We argue that this mixing has formed a fertile spawning pool for
a mutated culture that we called the hybrid modeling culture (HMC) where
prediction and inference have fused into new procedures where they reinforce
one another. This article identifies key characteristics of HMC, thereby
facilitating the scientific endeavor and fueling the evolution of statistical
cultures towards better practices. By better, we mean increasingly reliable,
valid, and efficient statistical practices in analyzing causal relationships.
In combining inference and prediction, the result of HMC is that the
distinction between prediction and inference, taken to its limit, melts away.
We qualify our melting-away argument by describing three HMC practices, where
each practice captures an aspect of the scientific cycle, namely, ML for causal
inference, ML for data acquisition, and ML for theory prediction.",280,13,1888,30.91
2758,cultural anthropology,"In a laboratory experiment we compare voluntary cooperation in Iceland and
the US. We furthermore compare the associated thought processes across
cultures. The two countries have similar economic performance, but survey
measures show that they differ culturally. Our hypotheses are based on two such
measures, The Inglehart cultural world map and the Knack and Keefers scale of
civic attitudes toward large-scale societal functioning. We prime the
participants with different social foci, emphasizing in one a narrow grouping
and in the other a larger social unit. In each country we implement this using
two different feedback treatments. Under group feedback, participants only know
the contributions by the four members of their directly cooperating group.
Under session feedback they are informed of the contributions within their
group as well as by everyone else in the session. Under group feedback,
cooperation levels do not differ between the two cultures. However, under
session feedback cooperation levels increase in Iceland and decline in the US.
Even when contribution levels are the same members of the two cultures differ
in their motives to cooperate: Icelanders tend to cooperate unconditionally and
US subjects conditionally. Our findings indicate that different cultures can
achieve similar economic and societal performance through different cultural
norms and suggest that cooperation should be encouraged through culturally
tailored suasion tactics. We also find that some decision factors such as
Inequity Aversion do not differ across the two countries, which raises the
question whether they are human universals.",243,14,1639,35.57
2759,cultural anthropology,"The extensive focus on performance indicators in research evaluation has been
facing critique in science studies. Stemming from a neoliberalist paradigm,
metrics allegedly objectify and create certainty about researchers'
performance. This has created a publish-or-perish culture where deviant
behaviour, such as research misconduct, may have become the rule of the game.
Not only does this culture foster a decrease of scientists' well-being, but
also a decrease in research quality. In recent years, calls for a culture
change have accumulated, from discussing detrimental cultural aspects under
IchbinHannah to studies that demonstrate the connection between research
culture and research integrity. This study is a qualitative analysis of how
astronomers reimagine their research culture. This includes alternative output
formats, alternative evaluation criteria and how they aspire to do research
differently. In summary, we find that the time is ripe for a transformation in
research culture towards a more participative and diverse work environment.
This may include the use of an open knowledge management infrastructure, where
all sorts of research output of various stages can be stored and shared.
Moreover, through a more reflexive evaluation, which is continuously adapted to
the needs of the researchers, scientific quality may be encouraged, rather than
producing more and more publications. This study sets the basis for future
action research with the aim of transforming academic cultures towards more
participative ones, where scientists can let their creative minds thrive and
collaborate beyond disciplinary boundaries.",236,12,1640,32.73
2760,cultural anthropology,"Cultural areas represent a useful concept that cross-fertilizes diverse
fields in social sciences. Knowledge of how humans organize and relate their
ideas and behavior within a society helps to understand their actions and
attitudes towards different issues. However, the selection of common traits
that shape a cultural area is somewhat arbitrary. What is needed is a method
that can leverage the massive amounts of data coming online, especially through
social media, to identify cultural regions without ad-hoc assumptions, biases
or prejudices. This work takes a crucial step in this direction by introducing
a method to infer cultural regions based on the automatic analysis of large
datasets from microblogging posts. The approach presented here is based on the
principle that cultural affiliation can be inferred from the topics that people
discuss among themselves. Specifically, regional variations in written
discourse are measured in American social media. From the frequency
distributions of content words in geotagged Tweets, the regional hotspots of
words' usage are found, and from there, principal components of regional
variation are derived. Through a hierarchical clustering of the data in this
lower-dimensional space, this method yields clear cultural areas and the topics
of discussion that define them. It uncovers a manifest North-South separation,
which is primarily influenced by the African American culture, and further
contiguous (East-West) and non-contiguous divisions that provide a
comprehensive picture of today's cultural areas in the US.",231,11,1573,31.11
2761,cultural anthropology,"This empirical study investigates the impact of the Hofstede cultural
dimensions (HCD) on the Global Innovation Index (GII) scores in four different
years (2007, 2009, 2019 and 2021) to compare the impacts during the pre- and
post-crisis (financial and COVID-19) period by employing ordinary least square
(OLS) and robust least square (Robust) analyses. The purpose of this study is
to identify the impact of cultural factors on the innovation development for
different income groups during the pre- and post-crisis period. We found that,
in general, the same cultural properties were required for countries to enhance
innovation inputs and outputs regardless of pre- and post-crisis periods and
time variances. The significant cultural factors (driving forces) of the
innovation performance do not change over time. However, our empirical results
revealed that not the crisis itself but the income group (either developed or
developing) is the factor that influences the relationship between cultural
properties and innovation. It is also worth noting that cultural properties
have lost much of their impact on innovation, particularly in developing
countries, during recent periods. It is highly likely that in terms of
innovation, no cultural development or change can significantly impact the
innovation output of developing countries without the construction of the
appropriate systems.",206,8,1391,24.71
2762,cultural anthropology,"In order to make the non-heritage culture of Yicheng Flower Drum more
relevant to the trend of the digital era and promote its dissemination and
inheritance, the design and application of gesture recognition and virtual
reality technologies guided by embodied cognition theory in the process of
non-heritage culture dissemination is studied. At the same time, it will
enhance the interaction between people and NRM culture, stimulate the
audience's interest in understanding NRM and spreading NRM, and create
awareness of preserving NRM culture. Using embodied cognition as a theoretical
guide, expanding the unidirectional communication mode through human-computer
interaction close to natural behavior and cooperating with multisensory
information reception channels, so as to construct an embodied and immersive
interactive atmosphere for the participants and enable them to naturally form
the cognition and understanding of the traditional culture in the process of
interaction. The dissemination of the non-heritage culture Yicheng Flower Drum
can take the theory of embodied cognition as an entry point, and through the
virtual and real scenes of Yicheng Flower Drum and the immersive experience, we
can empower the interaction design of non-heritage culture dissemination of the
virtual and real, and provide a new method for the research of digital design
of non-heritage culture.",204,5,1388,-5.68
2763,cultural anthropology,"Context: Social aspects are of high importance for being successful using
agile methods in software development. People are influenced by their cultural
imprint, as the underlying cultural values are guiding us in how we think and
act. Thus, one may assume that in multicultural agile software development
teams, cultural characteristics influence the result in terms of quality of the
team work and consequently, the product to be delivered. Objective: We aim to
identify barriers and potentials that may arise in multicultural agile software
development teams to provide valuable strategies for both researchers and
practitioners faced with barriers or unrealized potentials of cultural
diversity. Method: The study is designed as a single-case study with two units
of analysis using a mixed-method design consisting quantitative and qualitative
methods. Results: First, our results suggest that the cultural characteristics
at the team level need to be analyzed individually in intercultural teams,
Second, we identified key potentials regarding cultural characteristics
providing key potentials such as a individual team subculture that fits agile
values like open communication. Third, we derived strategies supporting the
potentials of cultural diversity in agile software development teams.
Conclusion: Our findings show, that a deeper understanding of cultural
influences in multicultural agile software development teams is needed. Based
on the results, we already prepare future work to validate the results in other
industries.",221,10,1538,21.13
2764,cultural anthropology,"Perception of offensiveness is inherently subjective, shaped by the lived
experiences and socio-cultural values of the perceivers. Recent years have seen
substantial efforts to build AI-based tools that can detect offensive language
at scale, as a means to moderate social media platforms, and to ensure safety
of conversational AI technologies such as ChatGPT and Bard. However, existing
approaches treat this task as a technical endeavor, built on top of data
annotated for offensiveness by a global crowd workforce without any attention
to the crowd workers' provenance or the values their perceptions reflect. We
argue that cultural and psychological factors play a vital role in the
cognitive processing of offensiveness, which is critical to consider in this
context. We re-frame the task of determining offensiveness as essentially a
matter of moral judgment -- deciding the boundaries of ethically wrong vs.
right language within an implied set of socio-cultural norms. Through a
large-scale cross-cultural study based on 4309 participants from 21 countries
across 8 cultural regions, we demonstrate substantial cross-cultural
differences in perceptions of offensiveness. More importantly, we find that
individual moral values play a crucial role in shaping these variations: moral
concerns about Care and Purity are significant mediating factors driving
cross-cultural differences. These insights are of crucial importance as we
build AI models for the pluralistic world, where the values they espouse should
aim to respect and account for moral values in diverse geo-cultural contexts.",235,10,1595,28.17
2765,cultural anthropology,"Recognizing and understanding implicit driving cues across diverse cultures
is imperative for fostering safe and efficient global transportation systems,
particularly when training new immigrants holding driving licenses from
culturally disparate countries. Additionally, it is essential to consider
cross-cultural differences in the development of Automated Driving features
tailored to different countries. Previous piloting studies have compared and
analyzed cross-cultural differences in selected implicit driving cues, but they
typically examine only limited countries. However, a comprehensive worldwide
comparison and analysis are lacking. This study conducts a thorough review of
existing literature, online blogs, and expert insights from diverse countries
to investigate cross-cultural disparities in driving behaviors, specifically
focusing on implicit cues such as non-verbal communication (e.g., hand
gestures, signal lighting, honking), norms, and social expectations. Through
comparative analysis, variations in driving cues are illuminated across
different cultural contexts. Based on the findings and identified gaps, a
research roadmap is proposed for future research to further explore and address
these differences, aiming to enhance intercultural communication, improve road
safety, and increase transportation efficiency on a global scale. This paper
presents the pioneering work towards a comprehensive understanding of the
implicit driving cues across cultures. Moreover, this understanding will inform
the development of automated driving systems tailored to different countries
considering cross-cultural differences.",209,12,1643,7.96
2766,cultural anthropology,"Given the rapid advancement of large-scale language models, artificial
intelligence (AI) models, like ChatGPT, are playing an increasingly prominent
role in human society. However, to ensure that artificial intelligence models
benefit human society, we must first fully understand the similarities and
differences between the human-like characteristics exhibited by artificial
intelligence models and real humans, as well as the cultural stereotypes and
biases that artificial intelligence models may exhibit in the process of
interacting with humans. This study first measured ChatGPT in 84 dimensions of
psychological characteristics, revealing differences between ChatGPT and human
norms in most dimensions as well as in high-dimensional psychological
representations. Additionally, through the measurement of ChatGPT in 13
dimensions of cultural values, it was revealed that ChatGPT's cultural value
patterns are dissimilar to those of various countries/regions worldwide.
Finally, an analysis of ChatGPT's performance in eight decision-making tasks
involving interactions with humans from different countries/regions revealed
that ChatGPT exhibits clear cultural stereotypes in most decision-making tasks
and shows significant cultural bias in third-party punishment and ultimatum
games. The findings indicate that, compared to humans, ChatGPT exhibits a
distinct psychological profile and cultural value orientation, and it also
shows cultural biases and stereotypes in interpersonal decision-making. Future
research endeavors should emphasize enhanced technical oversight and augmented
transparency in the database and algorithmic training procedures to foster more
efficient cross-cultural communication and mitigate social disparities.",226,8,1744,-12.08
2767,cultural anthropology,"Scientists as diplomats (historical examples). Scientists as advisors to
governments and the public. Nongovernmental organisations and international
conferences on security questions, initiated by scientists and based on their
professional culture.",30,4,248,-6.36
2768,cultural anthropology,"It has been proposed that, since the origin of life and the ensuing evolution
of biological species, a second evolutionary process has appeared on our
planet. It is the evolution of culture-e.g., ideas, beliefs, and artifacts.
Does culture evolve in the same genuine sense as biological life? And if so,
does it evolve through natural selection, or by some other means? Why does no
other species remotely approach the degree of cultural complexity of humans?
These questions lie at the foundation of who we are and what makes our lives
meaningful. Although much research has been done on how selective pressures
operating at the biological level affect cognition and culture, little research
has focused on culture as an evolutionary process in its own right. Like
biological forms, cultural forms-ideas, attitudes, artifacts, mannerisms,
etc.-incrementally adapt to the constraints and affordances of their
environment through descent with modification. In some respects culture appears
to be Darwinian, i.e., a process of differential replication and selection
amongst randomly generated variants. This suggests that knowledge of biological
evolution can be put to use to gain insight into culture. However, attempts to
apply Darwinian theory to culture have not yielded the kind of unifying
framework for the social sciences that it provided for the biological sciences,
largely because of the nonrandom manner in which the mind-the hub of cultural
change-generates and assimilates novelty. This paper investigates how and when
humans became capable of supporting culture, and what previously held it back,
focusing on how we attained the creative powers we now possess. To invent in
the strategic, intuitive manner characteristic of humans requires a cognitive
architecture that supports the capacity to spontaneously adapt concepts to new
circumstances and merge them together to conceptualize new situations.",289,16,1914,36.18
2769,cultural anthropology,"This paper utilizes a mixture of qualitative, formal, and statistical
socio-semantic network analyses to examine how cultural homophily works when
field logic meets practice. On the one hand, because individuals in similar
field positions are also imposed with similar cultural orientations, cultural
homophily reproduces objective field structure in intersubjective social
network ties. On the other hand, fields are operative in practice and to
accomplish pragmatic goals individuals who occupy different field positions
often join in groups, creatively reinterpret the field-imposed cultural
orientations, and produce cultural similarities alternative to the
position-specific ones. Drawing on these emergent similarities, the cultural
homophily mechanism might stimulate social network ties between members who
occupy not the same but different field positions, thus contesting fields. I
examine this ambivalent role of cultural homophily in two creative collectives,
each embracing members positioned closer to the opposite poles of the field of
cultural production. I find different types of cultural similarities to affect
different types of social network ties within and between the field positions:
Similarity of vocabularies stimulates friendship and collaboration ties within
positions, thus reproducing the field, while affiliation with the same cultural
structures stimulates collaboration ties between positions, thus contesting the
field. The latter effect is visible under statistical analysis of ethnographic
data, but easy to oversee in qualitative analysis of texts because informants
tend to flag conformity to their positions in their explicit statements. This
highlights the importance of mixed socio-semantic network analysis, both
sensitive to the local context and capable of unveiling the mechanisms
underlying the interplay between the cultural and the social.",260,9,1888,4.65
2770,cultural anthropology,"Motivated by Breiman's rousing 2001 paper on the ""two cultures"" in
statistics, we consider the role that different modeling approaches play in
causal inference. We discuss the relationship between model complexity and
causal (mis)interpretation, the relative merits of plug-in versus targeted
estimation, issues that arise in tuning flexible estimators of causal effects,
and some outstanding cultural divisions in causal inference.",60,3,432,7.19
2771,cultural anthropology,"Cultural astronomy reveals ways in which perception and culture have shaped
the interpretation of the night sky.",17,2,112,37.3
2772,cultural anthropology,"We present extensive numerical simulations of the Axelrod's model for social
influence, aimed at understanding the formation of cultural domains. This is a
nonequilibrium model with short range interactions and a remarkably rich
dynamical behavior. We study the phase diagram of the model and uncover a
nonequilibrium phase transition separating an ordered (culturally polarized)
phase from a disordered (culturally fragmented) one. The nature of the phase
transition can be continuous or discontinuous depending on the model
parameters. At the transition, the size of cultural regions is power-law
distributed.",88,6,611,19.77
2773,cultural anthropology,"We introduce a general modeling framework to predict the outcomes, at the
population level, of individual psychology and behavior. The framework
prescribes that researchers build a cost function that embodies knowledge of
what trait values (opinions, behaviors, etc.) are favored by individual
interactions under given social conditions. Predictions at the population level
are then drawn using methods from statistical mechanics, a branch of
theoretical physics born to link the microscopic and macroscopic behavior of
physical systems. We demonstrate our approach building a model of cultural
contact between two cultures (e.g., immigration), showing that it is possible
to make predictions about how contact changes the two cultures.",106,8,736,28.13
2774,cultural anthropology,"Social interactions and personal tastes shape our consumption behavior of
cultural products. In this study, we present a computational model of a
cultural market and we aim to analyze the behavior of the consumer population
as an emergent phenomena. Our results suggest that the final market shares of
cultural products dramatically depend on consumer heterogeneity and social
interaction pressure. Furthermore, the relation between the resulting market
shares and social interaction is robust with respect to a wide range of
variation in the parameter values and the type of topology.",89,5,585,23.46
2775,cultural anthropology,"To identify cluster of societies and cultures is not easy in subject to the
availability of data. In this study, we propose a novel method to cluster
Chinese regional cultures. Using geotagged online-gaming data of Chinese
internet users playing online card and board games with regional features, 336
Chinese cities are grouped into 17 clusters. The distribution of clustering
units shows great geographical proximity when the boundary of the clusters
coincides well with the geographical boundary of provinces.",78,5,512,43.22
2776,cultural anthropology,"For marketing to function in a globalized world it must respect a diverse set
of local cultures. With marketing efforts extending to social media platforms,
the crossing of cultural boundaries can happen in an instant. In this paper we
examine how culture influences the popularity of marketing messages in social
media platforms. Text mining, automated translation and sentiment analysis
contribute largely to our research. From our analysis of 400 posts on the
localized Google+ pages of German car brands in Germany and the US, we conclude
that posting time and emotions are important predictors for reshare counts.",97,6,618,43.32
2777,cultural anthropology,"We present a model for evolving agents using both genetic and cultural
inheritance mechanisms. Within each agent our model maintains two distinct
information stores we call the genome and the memome. Processes of adaptation
are modeled as evolutionary processes at each level of adaptation
(phylogenetic, ontogenetic, sociogenetic). We review relevant competing models
and we show how our model improves on previous attempts to model genetic and
cultural evolutionary processes. In particular we argue our model can achieve
divergent gene-culture co-evolution.",80,6,560,21.4
2778,cultural anthropology,"Understanding the business systems success factors has been a challenging
process for both public and private organizations. Organizational culture is
measured as a critical factor promoting knowledge sharing among employees.
Based on the competing value framework (CVF), this research shows how various
dimensions of organization culture influence knowledge sharing towards business
systems success at the individual and organization level. A quantitative
approach was applied to test the relationship between organizational cultures,
knowledge sharing and business systems success in Saudi enterprise.",80,5,603,8.88
2779,cultural anthropology,"I point to a deep and unjustly ignored relation between culture and
computation. I first establish interpretations of Piaget's and Vygotsky's
theories of child development with the language of theoretical computer
science. Using these interpretations, I argue that the two different possible
routes to Piagetian disequilibrium -- a tendency to overaccommodate, and a
tendency to overassimilate -- are equivalent to the two distinct cultural
tendencies, collectivistism and individualism. I argue that this simple
characterization of overaccommodation versus overassimilation provides a
satisfying explanation as to why the two cultural tendencies differ in the way
they empirically do. All such notions are grounded on a firm mathematical
framework for those who prefer the computable, and grounded on my personal
history for those who prefer the uncomputable.",124,6,860,12.87
2780,cultural anthropology,"We present a new statistical approach to analyzing an extremely common
archaeological data type -- potsherds -- that infers the structure of cultural
relationships across a set of excavations. This method, applied to data from a
set of complex, culturally heterogeneous sites around the Mandara mountains in
the Lake Chad Basin, articulates currently understood cultural succession into
the Iron Age. We show how the approach can be integrated with radiocarbon dates
to provide detailed portraits of cultural dynamics and deposition patterns
within single excavations that, in this context, indicate historical
ethnolinguistic segregation patterns. We conclude with a discussion of the many
possible model extensions using other archaeological data types.",109,5,755,10.43
2781,cultural anthropology,"We consider a model of cultural evolution for a strategy selection in a
population of individuals who interact in a game theoretic framework. The
evolution combines individual learning of the environment (population strategy
profile), reproduction, proportional to the success of the acquired knowledge,
and social transmission of the knowledge to the next generation. A mean-field
type equation is derived that describes the dynamics of the distribution of
cultural traits, in terms of the rate of learning, the reproduction rate and
population size. We establish global well-posedness of the initial-boundary
value problem for this equation and give several examples that illustrate the
process of the cultural evolution for some classical games.",110,5,748,18.18
2782,cultural anthropology,"Starting from Axelrod's model of cultural dissemination, we introduce a
rewiring probability, enabling agents to cut the links with their unfriendly
neighbors if their cultural similarity is below a tolerance parameter. For low
values of tolerance, rewiring promotes the convergence to a frozen monocultural
state. However, intermediate tolerance values prevent rewiring once the network
is fragmented, resulting in a multicultural society even for values of initial
cultural diversity in which the original Axelrod model reaches globalization.",76,4,544,11.96
2783,cultural anthropology,"The Mayan culture collected exquisite astronomical data for over a
millennium. However, it failed to come up with the breakthrough ideas of modern
astronomy because the data was analyzed within a mythological culture of
astrology that rested upon false but mathematically sophisticated theories
about the Universe. Have we learned the necessary lessons to prevent our
current scientific culture from resembling Mayan Astronomy? Clearly, data
collection by itself is not a guarantee for good science as commonly assumed by
funding agencies. A vibrant scientific culture should cultivate multiple
approaches to analyzing existing data and to collecting new data.",97,5,660,26.4
2784,cultural anthropology,"The paper concerns the definition of a novel ontology for cultural heritage
based on the concept of digital twin. The ontology, called Heritage Digital
Twin ontology, is a compatible extension of the well-known CIDOC CRM ISO
standard for cultural heritage documentation and incorporates all the different
documentation systems presently in use for cultural heritage documentation. In
the authors' view, it supports documentation interoperability at a higher level
than the ones currently in use and enables effective cooperation among
different users.",80,4,551,10.53
2785,cultural anthropology,"Stories are as old as human history - and a powerful means for the engaging
communication of information, especially in combination with visualizations.
The InTaVia project is built on this intersection and has developed a platform
which supports the workflow of cultural heritage experts to create compelling
visualization-based stories: From the search for relevant cultural objects and
actors in a cultural knowledge graph, to the curation and visual analysis of
the selected information, and to the creation of stories based on these data
and visualizations, which can be shared with the interested public.",93,3,610,7.87
2786,cultural anthropology,"With the increasing integration of AI into everyday life, it's becoming
crucial to design AI systems that serve users from diverse backgrounds by
making them culturally aware. In this paper, we present GD-COMET, a geo-diverse
version of the COMET commonsense inference model. GD-COMET goes beyond Western
commonsense knowledge and is capable of generating inferences pertaining to a
broad range of cultures. We demonstrate the effectiveness of GD-COMET through a
comprehensive human evaluation across 5 diverse cultures, as well as extrinsic
evaluation on a geo-diverse task. The evaluation shows that GD-COMET captures
and generates culturally nuanced commonsense knowledge, demonstrating its
potential to benefit NLP applications across the board and contribute to making
NLP more inclusive.",114,6,793,31.41
2787,cultural anthropology,"EVOC (for EVOlution of Culture) is a computer model of culture that enables
us to investigate how various factors such as barriers to cultural diffusion,
the presence and choice of leaders, or changes in the ratio of innovation to
imitation affect the diversity and effectiveness of ideas. It consists of
neural network based agents that invent ideas for actions, and imitate
neighbors' actions. The model is based on a theory of culture according to
which what evolves through culture is not memes or artifacts, but the internal
models of the world that give rise to them, and they evolve not through a
Darwinian process of competitive exclusion but a Lamarckian process involving
exchange of innovation protocols. EVOC shows an increase in mean fitness of
actions over time, and an increase and then decrease in the diversity of
actions. Diversity of actions is positively correlated with population size and
density, and with barriers between populations. Slowly eroding borders increase
fitness without sacrificing diversity by fostering specialization followed by
sharing of fit actions. Introducing a leader that broadcasts its actions
throughout the population increases the fitness of actions but reduces
diversity of actions. Increasing the number of leaders reduces this effect.
Efforts are underway to simulate the conditions under which an agent
immigrating from one culture to another contributes new ideas while still
fitting in.",223,10,1443,37.84
2788,cultural anthropology,"Human communication systems, such as language, evolve culturally; their
components undergo reproduction and variation. However, a role for selection in
cultural evolutionary dynamics is less clear. Often neutral evolution (also
known as 'drift') models, are used to explain the evolution of human
communication systems, and cultural evolution more generally. Under this
account, cultural change is unbiased: for instance, vocabulary, baby names and
pottery designs have been found to spread through random copying.
  While drift is the null hypothesis for models of cultural evolution it does
not always adequately explain empirical results. Alternative models include
cultural selection, which assumes variant adoption is biased. Theoretical
models of human communication argue that during conversation interlocutors are
biased to adopt the same labels and other aspects of linguistic representation
(including prosody and syntax). This basic alignment mechanism has been
extended by computer simulation to account for the emergence of linguistic
conventions. When agents are biased to match the linguistic behavior of their
interlocutor, a single variant can propagate across an entire population of
interacting computer agents. This behavior-matching account operates at the
level of the individual. We call it the Conformity-biased model. Under a
different selection account, called content-biased selection, functional
selection or replicator selection, variant adoption depends upon the intrinsic
value of the particular variant (e.g., ease of learning or use). This second
alternative account operates at the level of the cultural variant. Following
Boyd and Richerson we call it the Content-biased model. The present paper tests
the drift model and the two biased selection models' ability to explain the
spread of communicative signal variants in an experimental micro-society.",266,18,1886,20.79
2789,cultural anthropology,"Understanding the mechanisms underlying the formation of cultural traits,
such as preferences, opinions and beliefs is an open challenge. Trait formation
is intimately connected to cultural dynamics, which has been the focus of a
variety of quantitative models. Recently, some studies have emphasized the
importance of connecting those models to snapshots of cultural dynamics that
are empirically accessible. By analyzing data obtained from different sources,
it has been suggested that culture has properties that are universally present,
and that empirical cultural states differ systematically from randomized
counterparts. Hence, a question about the mechanism responsible for the
observed patterns naturally arises. This study proposes a stochastic structural
model for generating cultural states that retain those robust, empirical
properties. One ingredient of the model, already used in previous work, assumes
that every individual's set of traits is partly dictated by one of several,
universal ""rationalities"", informally postulated by several social science
theories. The second, new ingredient taken from the same theories assumes that,
apart from a dominant rationality, each individual also has a certain exposure
to the other rationalities. It is shown that both ingredients are required for
reproducing the empirical regularities. This key result suggests that the
effects of cultural dynamics in the real world can be described as an interplay
of multiple, mixing rationalities, and thus provides indirect evidence for the
class of social science theories postulating such mixing. The model should be
seen as a static, effective description of culture, while a dynamical, more
fundamental description is left for future research.",252,12,1747,14.39
2790,cultural anthropology,"How long until this paper is forgotten? Collective forgetting is the process
by which the attention received by cultural pieces decays as time passes.
Recent work modeled this decay as the result of two different processes, one
linked to communicative memory --memories sustained by human communication--
and cultural memory --memories sustained by the physical recording of content.
Yet, little is known on how the collective forgetting dynamic changes over
time. Are older cultural pieces forgotten at a lower rate than newer ones?
Here, we study the temporal changes of collective memory and attention by
focusing on two knowledge communities: inventors and physicists. We use data on
patents from the United States Patent and Trademark Office (USPTO) and physics
papers published in the American Physical Society (APS) to quantify how
collective forgetting has changed over time. The model enables us to
distinguish between two branches of forgetting. One branch is short-lived,
going directly from communicative memory to oblivion. The other one is
long-lived going from communicative to cultural memory and then to oblivion.
The data analysis shows an increasing forgetting rate for both communities as
the information grows. Furthermore, these knowledge communities seem to be
increasing their selectivity at storing valuable cultural pieces in their
cultural memory. These findings provide empirical confirmation on the
forgetting as an annulment hypothesis and show that knowledge communities can
effectively slow down the rising of collective forgetting at improving their
cultural selectivity.",237,12,1604,36.08
2791,cultural anthropology,"Existing simulations designed for cultural and interpersonal skill training
rely on pre-defined responses with a menu option selection interface. Using a
multiple-choice interface and restricting trainees' responses may limit the
trainees' ability to apply the lessons in real life situations. This systems
also uses a simplistic evaluation model, where trainees' selected options are
marked as either correct or incorrect. This model may not capture sufficient
information that could drive an adaptive feedback mechanism to improve
trainees' cultural awareness. This paper describes the design of a
dialogue-based simulation for cultural awareness training. The simulation,
built around a disaster management scenario involving a joint coalition between
the US and the Chinese armies. Trainees were able to engage in realistic
dialogue with the Chinese agent. Their responses, at different points, get
evaluated by different multi-label classification models. Based on training on
our dataset, the models score the trainees' responses for cultural awareness in
the Chinese culture. Trainees also get feedback that informs the cultural
appropriateness of their responses. The result of this work showed the
following; i) A feature-based evaluation model improves the design, modeling
and computation of dialogue-based training simulation systems; ii) Output from
current automatic speech recognition (ASR) systems gave comparable end results
compared with the output from manual transcription; iii) A multi-label
classification model trained as a cultural expert gave results which were
comparable with scores assigned by human annotators.",230,12,1639,24.88
2792,cultural anthropology,"Including local participation in cultural heritage management has always been
a concern since the Venice Charter so far (1964). In addition, the Faro
Convention (2005) shifted focus from cultural heritage values to the values of
cultural heritage for society. In this case, it is necessary to achieve the
maximum engagement of stakeholders in all stages of management. Nowadays, the
concept of community engagement in all stages of cultural heritage management
is accepted for almost everyone. But the idea of citizen participation is a
little like eating spinach: no one is against it in principle because it is
good for you. If we accept that community engagement is good for us, the
problem is how to let people participate? Not only communities are not very
aware of their rights on their cultural heritage, but also cultural heritage
authorities are unwilling to involve people in their decision-making process.
Suppose, in an ideal society of course, people know that the cultural heritage
is their properties and they would like to manage their assets by themselves,
and authorities have realized that they are not omni-knowledge and omni-potent,
there is still an unsolved problem, no one knows how we want to implement a
people-centered approach in cultural heritage context. This how is referring to
two main issues related to community engagement approach; lack of recognized
method, on the one hand, and determining an appropriate tool, on the other
hand. This paper is proposing a practical model and a simple tool for including
local community in decision-making process in the Bisotun World heritage Site.",258,10,1620,36.83
2793,cultural anthropology,"In our multicultural world, affect-aware AI systems that support humans need
the ability to perceive affect across variations in emotion expression patterns
across cultures. These systems must perform well in cultural contexts without
annotated affect datasets available for training models. A standard assumption
in affective computing is that affect recognition models trained and used
within the same culture (intracultural) will perform better than models trained
on one culture and used on different cultures (intercultural). We test this
assumption and present the first systematic study of intercultural affect
recognition models using videos of real-world dyadic interactions from six
cultures. We develop an attention-based feature selection approach under
temporal causal discovery to identify behavioral cues that can be leveraged in
intercultural affect recognition models. Across all six cultures, our findings
demonstrate that intercultural affect recognition models were as effective or
more effective than intracultural models. We identify and contribute useful
behavioral features for intercultural affect recognition; facial features from
the visual modality were more useful than the audio modality in this study's
context. Our paper presents a proof-of-concept and motivation for the future
development of intercultural affect recognition systems, especially those
deployed in low-resource situations without annotated data.",196,9,1444,21.23
2794,cultural anthropology,"It has been shown that accurate representation in media improves the
well-being of the people who consume it. By contrast, inaccurate
representations can negatively affect viewers and lead to harmful perceptions
of other cultures. To achieve inclusive representation in generated images, we
propose a culturally-aware priming approach for text-to-image synthesis using a
small but culturally curated dataset that we collected, known here as
Cross-Cultural Understanding Benchmark (CCUB) Dataset, to fight the bias
prevalent in giant datasets. Our proposed approach is comprised of two
fine-tuning techniques: (1) Adding visual context via fine-tuning a pre-trained
text-to-image synthesis model, Stable Diffusion, on the CCUB text-image pairs,
and (2) Adding semantic context via automated prompt engineering using the
fine-tuned large language model, GPT-3, trained on our CCUB culturally-aware
text data. CCUB dataset is curated and our approach is evaluated by people who
have a personal relationship with that particular culture. Our experiments
indicate that priming using both text and image is effective in improving the
cultural relevance and decreasing the offensiveness of generated images while
maintaining quality.",173,7,1226,16.86
2795,cultural anthropology,"This research project seeks to investigate the incorporation of augmented
reality (AR) and virtual reality (VR) technology with human-computer
interaction (HCI) in order to revitalize the Silk Road - specifically in
Kermanshah, Iran - and its effect on cultural tourism. Kermanshah has
underexplored the rich historical significance of the Silk Road, despite the
presence of 24 UNESCO World Heritage sites. From the 2nd century BCE to the
18th century CE, the Silk Road was a vital trade route connecting the West and
the East and had enormous cultural, economic, religious, and political effects.
The purpose of this study is to examine the application of AR/VR technologies
in HCI for the preservation, interpretation, and promotion of the Silk Road's
tangible and intangible cultural heritage in Kermanshah, as well as their
impact on cultural tourism development. The study also investigates how these
innovative technologies can enhance visitors' experiences through immersive and
interactive approaches, promote sustainable tourism practices, and contribute
to the region's broader socioeconomic benefits. The research will analyze the
challenges and opportunities of implementing AR/VR technology in HCI within the
context of cultural heritage and tourism in Kermanshah and the Silk Road region
more broadly. By combining HCI, AR/VR, and cultural tourism, this research
seeks to provide valuable insights into the development of user-centered,
immersive experiences that promote a deeper understanding and appreciation of
the Silk Road's distinctive cultural heritage.",229,8,1575,13.21
2796,cultural anthropology,"Online reviews have become essential for users to make informed decisions in
everyday tasks ranging from planning summer vacations to purchasing groceries
and making financial investments. A key problem in using online reviews is the
overabundance of online that overwhelms the users. As a result, recommendation
systems for providing helpfulness of reviews are being developed. This paper
argues that cultural background is an important feature that impacts the nature
of a review written by the user, and must be considered as a feature in
assessing the helpfulness of online reviews. The paper provides an in-depth
study of differences in online reviews written by users from different cultural
backgrounds and how incorporating culture as a feature can lead to better
review helpfulness recommendations. In particular, we analyze online reviews
originating from two distinct cultural spheres, namely Arabic and Western
cultures, for two different products, hotels and books. Our analysis
demonstrates that the nature of reviews written by users differs based on their
cultural backgrounds and that this difference varies based on the specific
product being reviewed. Finally, we have developed six different review
helpfulness recommendation models that demonstrate that taking culture into
account leads to better recommendations.",196,9,1335,29.69
2797,cultural anthropology,"Designing systems that can reason across cultures requires that they are
grounded in the norms of the contexts in which they operate. However, current
research on developing computational models of social norms has primarily
focused on American society. Here, we propose a novel approach to discover and
compare descriptive social norms across Chinese and American cultures. We
demonstrate our approach by leveraging discussions on a Chinese Q&A platform
(Zhihu) and the existing SocialChemistry dataset as proxies for contrasting
cultural axes, align social situations cross-culturally, and extract social
norms from texts using in-context learning. Embedding Chain-of-Thought
prompting in a human-AI collaborative framework, we build a high-quality
dataset of 3,069 social norms aligned with social situations across Chinese and
American cultures alongside corresponding free-text explanations. To test the
ability of models to reason about social norms across cultures, we introduce
the task of explainable social norm entailment, showing that existing models
under 3B parameters have significant room for improvement in both automatic and
human evaluation. Further analysis of cross-cultural norm differences based on
our dataset shows empirical alignment with the social orientations framework,
revealing several situational and descriptive nuances in norms across these
cultures.",192,8,1385,18.28
2798,cultural anthropology,"The Bias Benchmark for Question Answering (BBQ) is designed to evaluate
social biases of language models (LMs), but it is not simple to adapt this
benchmark to cultural contexts other than the US because social biases depend
heavily on the cultural context. In this paper, we present KoBBQ, a Korean bias
benchmark dataset, and we propose a general framework that addresses
considerations for cultural adaptation of a dataset. Our framework includes
partitioning the BBQ dataset into three classes--Simply-Transferred (can be
used directly after cultural translation), Target-Modified (requires
localization in target groups), and Sample-Removed (does not fit Korean
culture)-- and adding four new categories of bias specific to Korean culture.
We conduct a large-scale survey to collect and validate the social biases and
the targets of the biases that reflect the stereotypes in Korean culture. The
resulting KoBBQ dataset comprises 268 templates and 76,048 samples across 12
categories of social bias. We use KoBBQ to measure the accuracy and bias scores
of several state-of-the-art multilingual LMs. The results clearly show
differences in the bias of LMs as measured by KoBBQ and a machine-translated
version of BBQ, demonstrating the need for and utility of a well-constructed,
culturally-aware social bias benchmark.",198,8,1323,34.29
2799,cultural anthropology,"This paper introduces the necessity and significance of the investigation of
cultural heritage objects. The multi-technique method is useful for the study
of cultural heritage objects, but a comprehensive analytical instrument is a
better choice since it can guarantee that different types of information are
always obtained from the same analytical point on the surface of cultural
heritage objects, which may be crucial for some situations. Thus, the X-ray
fluorescence (XRF)/X-ray diffraction (XRD) and X-ray fluorescence (XRF)/Raman
spectroscopy (RS) comprehensive analytical instruments are more and more widely
used to study cultural heritage objects. The two types of comprehensive
analytical instruments are discussed in detail and the XRF/XRD instruments are
further classified into different types on the basis of structure, type and
number of detectors. A new comprehensive analytical instrument prototype that
can perform XRF, XRD and RS measurements simultaneously has been successfully
developed by our team and the preliminary application has shown the analysis
performance and application potential. This overview contributes to better
understand the research progress and development tendency of comprehensive
analytical instruments for the study of cultural heritage objects. The new
comprehensive instruments will make researchers obtain more valuable
information on cultural heritage objects and further promote the study on
cultural heritage objects.",205,8,1471,16.36
2800,cultural anthropology,"Building upon the considerable advances in Large Language Models (LLMs), we
are now equipped to address more sophisticated tasks demanding a nuanced
understanding of cross-cultural contexts. A key example is recipe adaptation,
which goes beyond simple translation to include a grasp of ingredients,
culinary techniques, and dietary preferences specific to a given culture. We
introduce a new task involving the translation and cultural adaptation of
recipes between Chinese and English-speaking cuisines. To support this
investigation, we present CulturalRecipes, a unique dataset comprised of
automatically paired recipes written in Mandarin Chinese and English. This
dataset is further enriched with a human-written and curated test set. In this
intricate task of cross-cultural recipe adaptation, we evaluate the performance
of various methods, including GPT-4 and other LLMs, traditional machine
translation, and information retrieval techniques. Our comprehensive analysis
includes both automatic and human evaluation metrics. While GPT-4 exhibits
impressive abilities in adapting Chinese recipes into English, it still lags
behind human expertise when translating English recipes into Chinese. This
underscores the multifaceted nature of cultural adaptations. We anticipate that
these insights will significantly contribute to future research on
culturally-aware language models and their practical application in culturally
diverse contexts.",195,11,1448,26.3
2801,cultural anthropology,"Despite the rapid development of large language models (LLMs) for the Korean
language, there remains an obvious lack of benchmark datasets that test the
requisite Korean cultural and linguistic knowledge. Because many existing
Korean benchmark datasets are derived from the English counterparts through
translation, they often overlook the different cultural contexts. For the few
benchmark datasets that are sourced from Korean data capturing cultural
knowledge, only narrow tasks such as bias and hate speech detection are
offered. To address this gap, we introduce a benchmark of Cultural and
Linguistic Intelligence in Korean (CLIcK), a dataset comprising 1,995 QA pairs.
CLIcK sources its data from official Korean exams and textbooks, partitioning
the questions into eleven categories under the two main categories of language
and culture. For each instance in CLIcK, we provide fine-grained annotation of
which cultural and linguistic knowledge is required to answer the question
correctly. Using CLIcK, we test 13 language models to assess their performance.
Our evaluation uncovers insights into their performances across the categories,
as well as the diverse factors affecting their comprehension. CLIcK offers the
first large-scale comprehensive Korean-centric analysis of LLMs' proficiency in
Korean culture and language.",192,10,1334,32.94
2802,cultural anthropology,"We present a survey of 39 recent papers that aim to study cultural
representation and inclusion in large language models. We observe that none of
the studies define ""culture,"" which is a complex, multifaceted concept;
instead, they probe the models on some specially designed datasets which
represent certain aspects of ""culture."" We call these aspects the proxies of
cultures, and organize them across three dimensions of demographic, semantic
and linguistic-cultural interaction proxies. We also categorize the probing
methods employed. Our analysis indicates that only certain aspects of
""culture,"" such as values and objectives, have been studied, leaving several
other interesting and important facets, especially the multitude of semantic
domains (Thompson et al., 2020) and aboutness (Hershcovich et al., 2022),
unexplored. Two other crucial gaps are the lack of robustness and situatedness
of the current methods. Based on these observations, we provide several
recommendations for a holistic and practically useful research agenda for
furthering cultural inclusion in LLMs and LLM-based applications.",160,10,1109,34.26
2803,cultural anthropology,"Cultural accumulation drives the open-ended and diverse progress in
capabilities spanning human history. It builds an expanding body of knowledge
and skills by combining individual exploration with inter-generational
information transmission. Despite its widespread success among humans, the
capacity for artificial learning agents to accumulate culture remains
under-explored. In particular, approaches to reinforcement learning typically
strive for improvements over only a single lifetime. Generational algorithms
that do exist fail to capture the open-ended, emergent nature of cultural
accumulation, which allows individuals to trade-off innovation and imitation.
Building on the previously demonstrated ability for reinforcement learning
agents to perform social learning, we find that training setups which balance
this with independent learning give rise to cultural accumulation. These
accumulating agents outperform those trained for a single lifetime with the
same cumulative experience. We explore this accumulation by constructing two
models under two distinct notions of a generation: episodic generations, in
which accumulation occurs via in-context learning and train-time generations,
in which accumulation occurs via in-weights learning. In-context and in-weights
cultural accumulation can be interpreted as analogous to knowledge and skill
accumulation, respectively. To the best of our knowledge, this work is the
first to present general models that achieve emergent cultural accumulation in
reinforcement learning, opening up new avenues towards more open-ended learning
systems, as well as presenting new opportunities for modelling human culture.",222,11,1670,6.64
2804,cultural anthropology,"We present the formal definition of meme in the sense of the equivalence
between memetics and the theory of cultural evolution. From the formal
definition we find that culture can be seen analytically and persuade that
memetic gives important role in the exploration of sociological theory,
especially in the cultural studies. We show that we are not allowed to assume
meme as smallest information unit in cultural evolution in general, but it is
the smallest information we use on explaining cultural evolution. We construct
a computational model and do simulation in advance presenting the selfish meme
power-law distributed. The simulation result shows that the contagion of meme
as well as cultural evolution is a complex adaptive system. Memetics is the
system and art of importing genetics to social sciences.",129,7,815,32.73
2805,cultural anthropology,"In the context of an extension of Axelrod's model for social influence, we
study the interplay and competition between the cultural drift, represented as
random perturbations, and mass media, introduced by means of an external
homogeneous field. Unlike previous studies [J. C. Gonz\'alez-Avella {\it et
al}, Phys. Rev. E {\bf 72}, 065102(R) (2005)], the mass media coupling proposed
here is capable of affecting the cultural traits of any individual in the
society, including those who do not share any features with the external
message. A noise-driven transition is found: for large noise rates, both the
ordered (culturally polarized) phase and the disordered (culturally fragmented)
phase are observed, while, for lower noise rates, the ordered phase prevails.
In the former case, the external field is found to induce cultural ordering, a
behavior opposite to that reported in previous studies using a different
prescription for the mass media interaction. We compare the predictions of this
model to statistical data measuring the impact of a mass media vasectomy
promotion campaign in Brazil.",169,10,1099,38.55
2806,cultural anthropology,"Modern societies feature an increasing contact between cultures, yet we have
a poor understanding of what the outcomes might be. Here we consider a
mathematical model of contact between social groups, grounded in social
psychology and analyzed using tools from statistical physics. We use the model
to study how a culture might be affected by immigration. We find that in some
cases residents' culture is relatively unchanged, but in other cases residents
may adopt the opinions and beliefs of immigrants. The decisive factors are each
group's cultural legacy and its attitudes towards in- and out-groups. The model
can also predict how social policies may influence the outcome of culture
contact.",110,7,698,44.44
2807,cultural anthropology,"Cultural competition has throughout our history shaped and reshaped the
geography of boundaries between humans. Language and culture are intimately
connected and linguists often use distinctive keywords to quantify the dynamics
of information spreading in societies harbouring strong culture centres. One
prominent example, which is addressed here, is Kyoto's historical impact on
Japanese culture. We construct a first minimal model, based on shared
properties of linguistic maps, to address the interplay between information
flow and geography. In particular, we show that spreading of information over
Japan in the pre-modern time can be described as a Eden growth process, with
noise levels corresponding to coherent spatial patches of sizes given by a
single days walk, and with patch-to-patch communication time comparable to the
time between human generations.",126,6,867,28.98
2808,cultural anthropology,"The application of phylogenetic techniques to the documentation of cultural
history can present a distorted picture due to horizontal transmission and
blending. Moreover, the units of cultural transmission must be communicable
concepts, rather than conveniently measurable attributes, and relatedness
between elements of culture often resides at the conceptual level, something
not captured by phylogenetic methods, which focus on measurable attributes.
(For example, mortars and pestles are as related as two artifacts could be,
despite little similarity at the attribute level.) This paper introduces a new,
cognitively inspired framework for chronicling material cultural history,
building on Lipo's (2005) network-based computational approach. We show that by
incorporating not just superficial attributes of artifact samples (e.g.
fluting) but also conceptual knowledge (e.g. information about function), a
different pattern of cultural ancestry emerges.",129,10,959,18.96
2809,cultural anthropology,"Many species dream, yet there remain many open research questions in the
study of dreams. The symbolism of dreams and their interpretation is present in
cultures throughout history. Analysis of online data sources for dream
interpretation using network science leads to understanding symbolism in dreams
and their associated meaning. In this study, we introduce dream interpretation
networks for English, Chinese and Arabic that represent different cultures from
various parts of the world. We analyze communities in these networks, finding
that symbols within a community are semantically related. The central nodes in
communities give insight about cultures and symbols in dreams. The community
structure of different networks highlights cultural similarities and
differences. Interconnections between different networks are also identified by
translating symbols from different languages into English. Structural
correlations across networks point out relationships between cultures.
Similarities between network communities are also investigated by analysis of
sentiment in symbol interpretations. We find that interpretations within a
community tend to have similar sentiment. Furthermore, we cluster communities
based on their sentiment, yielding three main categories of positive, negative,
and neutral dream symbols.",180,13,1324,22.41
2810,cultural anthropology,"There is surely some truth to the notion that culture evolves, but the
Darwinian view of culture is trivial. Gabora does two things in this paper.
First, she levels a reasoned and devastating attack on the adequacy of a
Darwinian theory of cultural evolution, showing that cultural evolution
violates virtually all prerequisites to be encompassed by Darwin's standard
theory. Second, she advances the central concept that it is whole world views
that evolve. A world view emerges when the capacity of memories to evoke one
another surpasses a phase transition yielding a richly interconnected
conceptual web, a world view. She proposes that cultural evolves not through a
Darwinian process such as meme theory, but through communal exchange of facets
of world views. Each section of her argument is completely convincing.",130,8,821,44.14
2811,cultural anthropology,"CQA services are collaborative platforms where users ask and answer
questions. We investigate the influence of national culture on people's online
questioning and answering behavior. For this, we analyzed a sample of 200
thousand users in Yahoo Answers from 67 countries. We measure empirically a set
of cultural metrics defined in Geert Hofstede's cultural dimensions and Robert
Levine's Pace of Life and show that behavioral cultural differences exist in
community question answering platforms. We find that national cultures differ
in Yahoo Answers along a number of dimensions such as temporal predictability
of activities, contribution-related behavioral patterns, privacy concerns, and
power inequality.",101,6,709,25.59
2812,cultural anthropology,"Rapid development of Internet and information technologies has gifted us with
a new and diverse mode of learning known as e-learning. In the current era,
e-learning has made rapid, influential, universal, interactive, vibrant, and
economic development. Now e-learning has become a global mode of education.
E-learning means the use of internet, computer and communications technologies
to acquire education. Learners with diverse social, cultural, economic,
linguistic, and religious backgrounds from all over the world are taking
benefits from e-learning. In e-learning, culture of target learners plays a
vital role and need to be explored for better results. Diversity of culture and
learning styles should keep under considerations while designing e-learning
environment. It may help to attain the required results. In this research work,
authors proposed and designed a novel architecture for e-learning system
incorporating cultural diversity of learners. The focus is to concentrate on
cultural factors from e-learning system. Furthermore; a prototype of the
proposed system is implemented for the validation of proposed architecture.",163,12,1141,39.53
2813,cultural anthropology,"Culture evolves, not just in the trivial sense that cultures change over
time, but also in the strong sense that such change is governed by Darwinian
principles. Both biological and cultural evolution are essentially cumulative
selection processes in which information (whether genetic or cultural) is
sieved, retained and then transmitted to the next generation. In both domains
such a process will result in recognizable lineages and tree-like phylogenies
so characteristic of Darwinian evolution. Because a principle of inheritance
(i.e., faithful replication of information) holds in both domains, we may trace
back particular transmission histories and identify the forces that influenced
them. The idea that culture evolves is quite old, but only in recent years
there has been a serious effort to turn this idea into science. This article
offers a concise analysis of how a rudimentary idea gradually evolved into a
thriving research program.",144,9,949,42.11
2814,cultural anthropology,"The nursing literature shows that cultural competence is an important
requirement for effective healthcare. We claim that personal assistive robots
should likewise be culturally competent, that is, they should be aware of
general cultural characteristics and of the different forms they take in
different individuals, and take these into account while perceiving, reasoning,
and acting. The CARESSES project is an Europe-Japan collaborative effort that
aims at designing, developing and evaluating culturally competent assistive
robots. These robots will be able to adapt the way they behave, speak and
interact to the cultural identity of the person they assist. This paper
describes the approach taken in the CARESSES project, its initial steps, and
its future plans.",114,6,769,31.41
2815,cultural anthropology,"Experimental evolution has yielded surprising insights into human history and
evolution by shedding light on the roles of chance and contingency in history
and evolution, and on the deep evolutionary roots of cooperation, conflict and
kin discrimination. We argue that an interesting research direction would be to
develop computational and experimental systems for studying evolutionary
processes that involve multiple layers of inheritance (such as genes,
epigenetic inheritance, language, and culture) and feedbacks (such as
gene-culture coevolution and mate choice) as well as open-ended niche
construction---all of which are important in human history and evolution. Such
systems would also be a clear way to motivate evolution and computation to
scholars and students across diverse cultural and socioeconomic backgrounds, as
well as to scholars and students in the social sciences and humanities. In
principle, computational models of cultural evolution could be compared to
data, given that large-scale datasets already exist for tracking cultural
change in real-time. Thus, experimental evolution, as a laboratory and
computational science, is poised to grow as an educational tool for people to
question and study where we come from, why we believe what we believe, and
where we as a species may be headed.",196,6,1316,14.77
2816,cultural anthropology,"Although Darwinian models are rampant in the social sciences, social
scientists do not face the problem that motivated Darwin's theory of natural
selection: the problem of explaining how lineages evolve despite that any
traits they acquire are regularly discarded at the end of the lifetime of the
individuals that acquired them. While the rationale for framing culture as an
evolutionary process is correct, it does not follow that culture is a Darwinian
or selectionist process, or that population genetics provides viable starting
points for modeling cultural change. This paper lays out step-by-step arguments
as to why a selectionist approach to cultural evolution is inappropriate,
focusing on the lack of randomness, and lack of a self-assembly code. It
summarizes an alternative evolutionary approach to culture: self-other
reorganization via context-driven actualization of potential.",131,5,893,21.26
2817,cultural anthropology,"3-demensional (3D) culture model is a valuable in vitro tool to study liver
biology, metabolism, organogenesis, tissue morphology, drug discovery and
cell-based assays. Compelling evidence suggests that cells cultured in 3D model
exhibit superior liver-specific functions over the conventional 2-dimentional
(2D) culture in evaluating hepatobiliary drug disposition and drug-induced
hepatotoxicity due to the in vivo-like physiological condition recapitulated by
3D model technologies. We will review the attributes of 3D culture model in
acquiring relevant liver phenotypes and functionalities, discuss the critical
niche factors found to modulate hepatocytes and highlight recent advancements
on 3D cell culture technologies to achieve next-level in vitro tool for
preclinical study.",105,4,785,-6.36
2818,cultural anthropology,"This paper explores the relations between social ties and cultural constructs
in small groups. The analysis uses cross-sectional data comprising both social
networks within three art groups and semantic networks based on verbal
expressions of their members. We examine how positions of actors in the
intragroup social networks associate with the properties of cultural constructs
they create jointly with other group members accounting for different roles
actors play in collective culture constructing. We find that social popularity
rather hinders sharing of cultural concepts, while those individuals who
socially bridge their groups come to share many concepts with others. Moreover,
focusing and, especially, integration of cultural constructs, rather than mere
thickness of those, accompany intense interactions between the leaders and the
followers.",121,6,856,29.99
2819,cultural anthropology,"This paper outlines the implications of neural-level accounts of insight, and
models of the conceptual interactions that underlie creativity, for a theory of
cultural evolution. Since elements of human culture exhibit cumulative,
adaptive, open-ended change, it seems reasonable to view culture as an
evolutionary process, one fueled by creativity. Associative memory models of
creativity and mathematical models of how concepts combine and transform
through interaction with a context, support a view of creativity that is
incompatible with a Darwinian (selectionist) framework for cultural evolution,
but compatible with a non-Darwinian (Self-Other Reorganization) framework. A
theory of cultural evolution in which creativity is centre stage could provide
the kind of integrative framework for the behavioral sciences that Darwin
provided for the life sciences.",121,5,864,6.88
2820,cultural anthropology,"Storytelling has the potential to revolutionize the way we engage with
cultural heritage and has been widely recognized as an important direction for
attracting and satisfying the audience of museums and other cultural heritage
sites. This approach has been investigated in various research projects, but
its adoption outside research remains limited due to the challenges inherent in
its creation. In this work, we present the web-based Narralive Storyboard
Editor and the Narralive Mobile Player app, developed with the objective to
assist the creative process and promote research on different aspects of the
application of mobile digital storytelling in cultural heritage settings. The
tools have been applied and evaluated in a variety of contexts and sites, and
the main findings of this process are presented and discussed, concluding in
general findings about the authoring of digital storytelling experiences in
cultural heritage.",140,5,939,19.03
2821,cultural anthropology,"Cultural Astronomy is interdisciplinary connecting the arts, humanities,
social & physical sciences. Data collection methods and theories are used from
many disciplines and meld with methods and theories within cultural astronomy.
The burden on the student is that to do cultural astronomy research it is
necessary to be widely read within and across disciplines. I developed a series
of courses that divided cultural astronomy content into broad regions such as
Africa, North America, and the Pacific. The courses were structured to
accommodate students from all parts of the university, but had to have enough
mathematics and science to serve as a general science requirement. The majority
of the grade for the course lay with the final project, which included a
presentation and a written document. Thus, the course was designed to give the
students a foundation for doing this final project that had to be original
research. The students rarely opted to collect their own data, instead they
reanalyzed existing materials. The students learned critical thinking,
formulating hypotheses, and how to test their hypotheses, as well as how to
understand cultural astronomy data.",183,10,1177,34.05
2822,cultural anthropology,"We present an individual based model of cultural evolution, where interacting
agents are coded by binary strings standing for strategies for action,
blueprints for products or attitudes and beliefs. The model is patterned on an
established model of biological evolution, the Tangled Nature Model (TNM),
where a `tangle' of interactions between agents determines their reproductive
success. In addition, our agents also have the ability to copy part of each
other's strategy, a feature inspired by the Axelrod model of cultural
diversity. Unlike the latter, but similarly to the TNM, the model dynamics goes
through a series of metastable stages of increasing length, each characterized
by mutually enforcing cultural patterns. These patterns are abruptly replaced
by other patterns characteristic of the next metastable period. We analyze the
time dependence of the population and diversity in the system, show how
different cultures are formed and merge, and how their survival probability
lacks, in the model, a finite average life-time. Finally, we use historical
data on the number of car manufacturers after the introduction of the
automobile to the market, to argue that ourmodel can qualitatively reproduce
the flurry of cultural activity which follows a disruptive innovation.",194,8,1284,26.44
2823,cultural anthropology,"YouTube, a world-famous video sharing website, maintains a list of the top
trending videos on the platform. Due to its huge amount of users, it enables
researchers to understand people's preference by analyzing the trending videos.
Trending videos vary from country to country. By analyzing such differences and
changes, we can tell how users' preferences differ over locations. Previous
work focuses on analyzing such culture preferences from videos' metadata, while
the culture information hidden within the visual content has not been
discovered. In this study, we explore culture preferences among countries using
the thumbnails of YouTube trending videos. We first process the thumbnail
images of the videos using object detectors. The collected object information
is then used for various statistical analysis. In particular, we examine the
data from three perspectives: geographical locations, video genres and users'
reactions. Experimental results indicate that the users from similar cultures
shares interests in watching similar videos on YouTube. Our study demonstrates
that discovering the culture preference through the thumbnails can be an
effective mechanism for video social media analysis.",175,12,1207,46.88
2824,cultural anthropology,"Cultural code-switching concerns how we adjust our overall behaviours,
manners of speaking, and appearance in response to a perceived change in our
social environment. We defend the need to investigate cultural code-switching
capacities in artificial intelligence systems. We explore a series of ethical
and epistemic issues that arise when bringing cultural code-switching to bear
on artificial intelligence. Building upon Dotson's (2014) analysis of
testimonial smothering, we discuss how emerging technologies in AI can give
rise to epistemic oppression, and specifically, a form of self-silencing that
we call 'cultural smothering'. By leaving the socio-dynamic features of
cultural code-switching unaddressed, AI systems risk negatively impacting
already-marginalised social groups by widening opportunity gaps and further
entrenching social inequalities.",115,6,860,14.29
2825,cultural anthropology,"Stroke is a leading cause of serious, long-term disability in the United
States. There exist disparities in both stroke prevalence and outcomes between
people with stroke in Hispanic and Latinx communities and the general stroke
population. Current stroke technology - which aims to improve quality of life
and bring people with stroke to the most functional, independent state possible
- has shown promising results for the general stroke population, but has failed
to close the recovery outcome gap for underserved Hispanic and Latinx people
with stroke. Previous work in health education, digital health, and HRI has
improved human health outcomes by incorporating social-cultural factors, though
not for stroke. In this position paper, we aim to justify accounting for unique
cultural factors in stroke technology design for the Hispanic and Latinx
community. We review examples of successful culturally appropriate
interventions and suggest design considerations (mutually beneficial community
consultation, accommodating for barriers beforehand, building on culture, and
incorporating education of the family) to provide more culturally appropriate
design of Hispanic and Latinx stroke technology and reduce the disparity gap.",177,7,1232,16.46
2826,cultural anthropology,"Within the cultural heritage sector, there has been a growing and concerted
effort to consider a critical sociotechnical lens when applying machine
learning techniques to digital collections. Though the cultural heritage
community has collectively developed an emerging body of work detailing
responsible operations for machine learning in libraries and other cultural
heritage institutions at the organizational level, there remains a paucity of
guidelines created specifically for practitioners embarking on machine learning
projects. The manifold stakes and sensitivities involved in applying machine
learning to cultural heritage underscore the importance of developing such
guidelines. This paper contributes to this need by formulating a detailed
checklist with guiding questions and practices that can be employed while
developing a machine learning project that utilizes cultural heritage data. I
call the resulting checklist the ""Collections as ML Data"" checklist, which,
when completed, can be published with the deliverables of the project. By
surveying existing projects, including my own project, Newspaper Navigator, I
justify the ""Collections as ML Data"" checklist and demonstrate how the
formulated guiding questions can be employed and operationalized.",176,7,1269,16.36
2827,cultural anthropology,"As digitized traditional cultural heritage documents have rapidly increased,
resulting in an increased need for preservation and management, practical
recognition of entities and typification of their classes has become essential.
To achieve this, we propose KoCHET - a Korean cultural heritage corpus for the
typical entity-related tasks, i.e., named entity recognition (NER), relation
extraction (RE), and entity typing (ET). Advised by cultural heritage experts
based on the data construction guidelines of government-affiliated
organizations, KoCHET consists of respectively 112,362, 38,765, 113,198
examples for NER, RE, and ET tasks, covering all entity types related to Korean
cultural heritage. Moreover, unlike the existing public corpora, modified
redistribution can be allowed both domestic and foreign researchers. Our
experimental results make the practical usability of KoCHET more valuable in
terms of cultural heritage. We also provide practical insights of KoCHET in
terms of statistical and linguistic analysis. Our corpus is freely available at
https://github.com/Gyeongmin47/KoCHET.",149,11,1102,18.86
2828,cultural anthropology,"In the contemporary interconnected world, the concept of cultural
responsibility occupies paramount importance. As the lines between nations
become less distinct, it is incumbent upon individuals, communities, and
institutions to assume the responsibility of safeguarding and valuing the
landscape of diverse cultures that constitute our global society. This paper
explores the socio-cultural and ethical challenges stemming from the
implementation of AI algorithms and highlights the necessity for their
culturally responsive development. It also offers recommendations on essential
elements required to enhance AI systems' adaptability to meet the demands of
contemporary multicultural societies. The paper highlights the need for further
multidisciplinary research to create AI models that effectively address these
challenges. It also advocates the significance of AI enculturation and
underlines the importance of regulatory measures to promote cultural
responsibility in AI systems.",132,7,988,6.84
2829,cultural anthropology,"Instruction tuning has emerged as a prominent methodology for teaching Large
Language Models (LLMs) to follow instructions. However, current instruction
datasets predominantly cater to English or are derived from English-dominated
LLMs, resulting in inherent biases toward Western culture. This bias
significantly impacts the linguistic structures of non-English languages such
as Arabic, which has a distinct grammar reflective of the diverse cultures
across the Arab region. This paper addresses this limitation by introducing
CIDAR: https://hf.co/datasets/arbml/CIDAR, the first open Arabic
instruction-tuning dataset culturally-aligned by human reviewers. CIDAR
contains 10,000 instruction and output pairs that represent the Arab region. We
discuss the cultural relevance of CIDAR via the analysis and comparison to
other models fine-tuned on other datasets. Our experiments show that CIDAR can
help enrich research efforts in aligning LLMs with the Arabic culture. All the
code is available at https://github.com/ARBML/CIDAR.",139,11,1031,38.92
2830,cultural anthropology,"There is an urgent need to incorporate the perspectives of culturally diverse
groups into AI developments. We present a novel conceptual framework for
research that aims to expand, reimagine, and reground mainstream visions of AI
using independent and interdependent cultural models of the self and the
environment. Two survey studies support this framework and provide preliminary
evidence that people apply their cultural models when imagining their ideal AI.
Compared with European American respondents, Chinese respondents viewed it as
less important to control AI and more important to connect with AI, and were
more likely to prefer AI with capacities to influence. Reflecting both cultural
models, findings from African American respondents resembled both European
American and Chinese respondents. We discuss study limitations and future
directions and highlight the need to develop culturally responsive and relevant
AI to serve a broader segment of the world population.",144,7,980,30.2
2831,cultural anthropology,"In this paper we delve into the historical evolution of data as a fundamental
element in communication and knowledge transmission. The paper traces the
stages of knowledge dissemination from oral traditions to the digital era,
highlighting the significance of languages and cultural diversity in this
progression. It also explores the impact of digital technologies on memory,
communication, and cultural preservation, emphasizing the need for promoting a
culture of the digital (rather than a digital culture) in Africa and beyond.
Additionally, it discusses the challenges and opportunities presented by data
biases in AI development, underscoring the importance of creating diverse
datasets for equitable representation. We advocate for investing in data as a
crucial raw material for fostering digital literacy, economic development, and,
above all, cultural preservation in the digital age.",129,6,895,11.45
2832,cultural anthropology,"The increasing frequency of mass shootings in the United States has,
unfortunately, become a norm. While the issue of gun control in the US involves
complex legal concerns, there are also societal issues at play. One such social
issue is so-called ""gun culture,"" i.e., a general set of beliefs and actions
related to gun ownership. However relatively little is known about gun culture,
and even less is known when it comes to fringe online communities. This is
especially worrying considering the aforementioned rise in mass shootings and
numerous instances of shooters being radicalized online.
  To address this gap, we explore gun culture on /k/, 4chan's weapons board.
More specifically, using a variety of quantitative techniques, we examine over
4M posts on /k/ and position their discussion within the larger body of
theoretical understanding of gun culture. Among other things, our findings
suggest that gun culture on /k/ covers a relatively diverse set of topics (with
a particular focus on legal discussion), some of which are signals of
fetishism.",168,11,1059,44.03
2833,cultural anthropology,"This report provide a detailed description of the method that we explored and
proposed in the WECIA Emotion Prediction Competition (EPC), which predicts a
person's emotion through an artistic work with a comment. The dataset of this
competition is ArtELingo, designed to encourage work on diversity across
languages and cultures. The dataset has two main challenges, namely modal
imbalance problem and language-cultural differences problem. In order to
address this issue, we propose a simple yet effective approach called
single-multi modal with Emotion-Cultural specific prompt(ECSP), which focuses
on using the single modal message to enhance the performance of multimodal
models and a well-designed prompt to reduce cultural differences problem. To
clarify, our approach contains two main blocks:
(1)XLM-R\cite{conneau2019unsupervised} based unimodal model and
X$^2$-VLM\cite{zeng2022x} based multimodal model (2) Emotion-Cultural specific
prompt. Our approach ranked first in the final test with a score of 0.627.",142,8,1018,38.96
2834,cultural anthropology,"Gender inequality is a significant concern in many cultures, as women face
significant barriers to asset acquisition particularly land ownership and
control. Land acquisition and land tenure security are complex issues that
affect various cultural groups differently, leading to disparities in access
and ownership especially when superimposed with other socio-economic issues
like gender inequality. Measuring the severity of these issues across different
cultural groups is challenging due to variations in cultural norms,
expectations and effectiveness of the measurement framework to correctly assess
the level of severity. While nominal measures of gender asset gap provide
valuable insights into land acquisition and tenure security issues, they do not
fully capture the nuances of cultural differences and the impact of
governmental and corporate policies that influence gender disparity in land
ownership and control. The proposed framework aims to fill this gap by
incorporating cultural and policy factors in developing a new measurement
framework equipped with a more robust, comprehensive metric to standardize the
approach to assessing the severity of gender asset disparity in a general sense
but with a focus on land acquisition and tenure security to engender more
effective interventions and policy recommendations.",191,6,1332,-1.15
2835,cultural anthropology,"Inspiration is linked to various positive outcomes, such as increased
creativity, productivity, and happiness. Although inspiration has great
potential, there has been limited effort toward identifying content that is
inspiring, as opposed to just engaging or positive. Additionally, most research
has concentrated on Western data, with little attention paid to other cultures.
This work is the first to study cross-cultural inspiration through machine
learning methods. We aim to identify and analyze real and AI-generated
cross-cultural inspiring posts. To this end, we compile and make publicly
available the InspAIred dataset, which consists of 2,000 real inspiring posts,
2,000 real non-inspiring posts, and 2,000 generated inspiring posts evenly
distributed across India and the UK. The real posts are sourced from Reddit,
while the generated posts are created using the GPT-4 model. Using this
dataset, we conduct extensive computational linguistic analyses to (1) compare
inspiring content across cultures, (2) compare AI-generated inspiring posts to
real inspiring posts, and (3) determine if detection models can accurately
distinguish between inspiring content across cultures and data sources.",171,9,1205,24.37
2836,cultural anthropology,"We consider the model proposed by Axelrod for dissemination of cultures on a
2-dimensional squared lattice. We review this model from an analytic point of
view. We define $\left\langle s(t)\right\rangle$ to quantify possible culture
configurations at time $t$ in a society. Typical initial culture configurations
of this model are characterised. Equation of motion in terms of $\left\langle
s(t)\right\rangle$ is derived. We study the graph of development of this
Axelrod system toward to its culture configurations equilibrium. Generically,
we observe that this model undergoes three phases of development. We give a
quantitative explanation about these three different phases of development.
  Keeping up with this Axelrod model, we characterize its culture
configurations space at equilibrium point where $\left\langle
s(t_{\text{eq}})\right\rangle = 1$. This space is called monoculture space.
Understanding this space is equivalent to restrict to the space of culture
configurations from one individual in the model. This individual culture space
is identified to the space $V_N^{\otimes F}$ up to isomorphisms. Action of the
permutation group $S_N$ on the space $V_{N}^{\otimes F}$ is considered. Under
this action, the observable $\left\langle s(t)\right\rangle$ is an invariant of
the Axelrod system. We explore this symmetry and classify the different
inequivalent classes of culture configurations composing the monoculture space.
To achieve this, we consider the case $N\geq F$. We propose techniques from
group representation theory to perform this classification. The inequivalent
classes of culture configurations are indexed by the Dickau diagrams which are
associated to the Bell number $B_F$. A concrete example with $F=4$ and $N\geq
4$ is considered for a full illustration of our analysis.",259,20,1808,32.29
2837,cultural anthropology,"Deception detection is a task with many applications both in direct physical
and in computer-mediated communication. Our focus is on automatic deception
detection in text across cultures. We view culture through the prism of the
individualism/collectivism dimension and we approximate culture by using
country as a proxy. Having as a starting point recent conclusions drawn from
the social psychology discipline, we explore if differences in the usage of
specific linguistic features of deception across cultures can be confirmed and
attributed to norms in respect to the individualism/collectivism divide. We
also investigate if a universal feature set for cross-cultural text deception
detection tasks exists. We evaluate the predictive power of different feature
sets and approaches. We create culture/language-aware classifiers by
experimenting with a wide range of n-gram features based on phonology,
morphology and syntax, other linguistic cues like word and phoneme counts,
pronouns use, etc., and token embeddings. We conducted our experiments over 11
datasets from 5 languages i.e., English, Dutch, Russian, Spanish and Romanian,
from six countries (US, Belgium, India, Russia, Mexico and Romania), and we
applied two classification methods i.e, logistic regression and fine-tuned BERT
models. The results showed that our task is fairly complex and demanding. There
are indications that some linguistic cues of deception have cultural origins,
and are consistent in the context of diverse domains and dataset settings for
the same language. This is more evident for the usage of pronouns and the
expression of sentiment in deceptive language. The results of this work show
that the automatic deception detection across cultures and languages cannot be
handled in a unified manner, and that such approaches should be augmented with
knowledge about cultural differences and the domains of interest.",282,17,1905,35.47
2838,cultural anthropology,"Facial analysis permits many investigations some of the most important of
which are craniofacial identification, facial recognition, and age and sex
estimation. In forensics, photo-anthropometry describes the study of facial
growth and allows the identification of patterns in facial skull development by
using a group of cephalometric landmarks to estimate anthropological
information. In several areas, automation of manual procedures has achieved
advantages over and similar measurement confidence as a forensic expert. This
manuscript presents an approach using photo-anthropometric indexes, generated
from frontal faces cephalometric landmarks, to create an artificial neural
network classifier that allows the estimation of anthropological information,
in this specific case age and sex. The work is focused on four tasks: i) sex
estimation over ages from 5 to 22 years old, evaluating the interference of age
on sex estimation; ii) age estimation from photo-anthropometric indexes for
four age intervals (1 year, 2 years, 4 years and 5 years); iii) age group
estimation for thresholds of over 14 and over 18 years old; and; iv) the
provision of a new data set, available for academic purposes only, with a large
and complete set of facial photo-anthropometric points marked and checked by
forensic experts, measured from over 18,000 faces of individuals from Brazil
over the last 4 years. The proposed classifier obtained significant results,
using this new data set, for the sex estimation of individuals over 14 years
old, achieving accuracy values greater than 0.85 by the F_1 measure. For age
estimation, the accuracy results are 0.72 for measure with an age interval of 5
years. For the age group estimation, the measures of accuracy are greater than
0.93 and 0.83 for thresholds of 14 and 18 years, respectively.",280,13,1825,30.91
2839,cultural anthropology,"In this work the impact of the Internet culture on standard mainstream
societies has been analyzed. After analytically establishing the fact that the
Net can be viewed as a pan-societal superstructure which supports its own
distinct culture, an ethnographic analysis is provided to find out the key
aspects of this culture. The elements of this culture which have an empowering
impacts on the standard mainstream societies, as well as the elements in it
which can cause discouraging social effects are then discussed by a global
investigation of the present status of various fundamental aspects (e,g,
education, economics, politics, entertainment etc) of the mainstream societies
as well as their links with the Net culture. Though immensely potential for
providing various prominent positive impacts, the key findings of this work
indicate that misuse of Internet can create tremendous harm to the members of
the mainstream societies by generating a set of morally crippled people as well
as a future generation completely void of principles and ethics. This
structured diagnostic approach to the social problems caused by the manhandling
of Internet leads to a concrete effort of providing the measures that can be
taken to enhance or to overcome the supporting and limiting effects of the Net
culture respectively with the intent to benefit our society and to protect the
teratoidation of certain ethical values.",222,6,1416,17.95
2840,cultural anthropology,"We study the effects of different forms of information feedback associated
with mass media on an agent-agent based model of the dynamics of cultural
dissemination. In addition to some processes previously considered, we also
examine a model of local mass media influence in cultural dynamics. Two
mechanisms of information feedback are investigated: (i) direct mass media
influence, where local or global mass media act as an additional element in the
network of interactions of each agent, and (ii) indirect mass media influence,
where global media acts as a filter of the influence of the existing network of
interactions of each agent. Our results generalize previous findings showing
that cultural diversity builds-up by increasing the strength of the mass media
influence. We find that this occurs independently of the mechanisms of action
(direct or indirect) of the mass media message. However, through an analysis of
the full range of parameters measuring cultural diversity, we establish that
the enhancement of cultural diversity produced by interaction with mass media
only occurs for strong enough mass media messages. In comparison with previous
studies a main different result is that weak mass media messages, in
combination with agent-agent interaction, are efficient in producing cultural
homogeneity. Moreover, the homogenizing effect of weak mass media messages are
more efficient for direct local mass media messages than for global mass media
messages or indirect global mass media influences.",230,9,1514,16.86
2841,cultural anthropology,"Cultural transmission models are coming to the fore in explaining increases
in the Paleolithic toolkit richness and diversity. During the later
Paleolithic, technologies increase not only in terms of diversity but also in
their complexity and interdependence. As Mesoudi and O'Brien (2008) have shown,
selection broadly favors social learning of information that is hierarchical
and structured, and multiple studies have demonstrated that teaching within a
social learning environment can increase fitness. We believe that teaching also
provides the scaffolding for transmission of more complex cultural traits.
Here, we introduce an extension of the Axelrod (1997} model of cultural
differentiation in which traits have prerequisite relationships, and where
social learning is dependent upon the ordering of those prerequisites. We
examine the resulting structure of cultural repertoires as learning
environments range from largely unstructured imitation, to structured teaching
of necessary prerequisites, and we find that in combination with individual
learning and innovation, high probabilities of teaching prerequisites leads to
richer cultural repertoires. Our results point to ways in which we can build
more comprehensive explanations of the archaeological record of the Paleolithic
as well as other cases of technological change.",188,8,1339,18.79
2842,cultural anthropology,"Why is our society multicultural? Based on the two mechanisms of homophily
and social influence, the classical model for the dissemination of cultures
proposed by Axelrod predicts the existence of a fragmented regime where
different cultures can coexist in a social network. However, in such model the
multicultural regime is achievable only when a high number of cultural traits
is present, and is not robust against cultural drift, i.e. the spontaneous
mutations of agents' traits. In real systems, social influence is inherently
organised in layers, meaning that individuals tend to diversify their
connections according to the topic on which they interact. In this work we show
that the observed persistence of multiculturality in real-world social systems
is a natural consequence of the layered organisation of social influence. We
find that the critical number of cultural traits that separates the
monocultural and the multicultural regimes depends on the redundancy of
pairwise connections across layers. Surprisingly, for low values of structural
redundancy the system is always in a multicultural state, independently on the
number of traits, and is robust to the presence of cultural drift. Moreover, we
show that layered social influence allows the coexistence of different levels
of consensus on different topics. The insight obtained from simulations on
synthetic graphs are confirmed by the analysis of two real-world social
networks, where the multicultural regime persists even for a very small number
of cultural traits, suggesting that the layered organisation of social
interactions might indeed be at the heart of multicultural societies.",250,11,1660,29.18
2843,cultural anthropology,"The aims of the current study were to establish a system of culture for
induction of paralysed chondrocytes and to investigate if these cells are
really dying. Chondrocytes were isolated from the growth cartilage of fetal
equines, centrifuged and cultured as pellets in either 10% fetal calf serum or
10% horse serum for 28 days and processed for light and electron microscopy.
Different cell types were counted and expressed as a percentage to the total
cell number. Growth kinetics including the pellet weight and thickness and the
cellular density were evaluated. After 7 days in culture, paralysed
chondrocytes with similar morphology to those described in the rabbit growth
cartilage could be identified in pellets in each serum type, however, the
proportion of the cells was different. In pellet cultured with 10% fetal calf
serum, more than 50% of the cells were paralysed chondrocytes but in 10% horse
serum, less than 10% of cells were of paralysed type. At day 14, about 50% of
the cells in pellets cultured in either serum type differentiated into
hypertrophic dark chondrocytes and the proportion of paralysed cells was
markedly decreased. After 21 days in each culture, more than 70% of the cells
were hypertrophic dark chondrocytes and no paralysed chondrocytes could be
observed. The paralysed chondrocytes may be not dying and they likely to be an
immature form of hypertrophic dark chondrocytes. It is better to use the term
immature dark chondrocytes instead of paralysed cells. This culture system will
be useful for further molecular studies on paralysed chondrocytes and to
explore the functions of these cells.",263,12,1632,55.68
2844,cultural anthropology,"Axelrod's model for the dissemination of culture combines two key ingredients
of social dynamics: social influence, through which people become more similar
when they interact, and homophily, which is the tendency of individuals to
interact preferentially with similar others. In Axelrod's model, the agents are
fixed to the nodes of a network and are allowed to interact with a
predetermined set of peers only, resulting in the frustration of a large number
of agents that end up culturally isolated. Here we modify this model by
allowing the agents to move away from their cultural opposites and stay put
when near their cultural likes. The comfort, i.e., the tendency of an agent to
stay put in a neighborhood, is determined by the cultural similarity with its
neighbors. The less the comfort, the higher the odds that the agents will move
apart a fixed step size. We find that the comfort-driven mobility fragments
severely the influence network for low initial cultural diversity, resulting in
a network composed of only microscopic components in the thermodynamic limit.
For high initial cultural diversity and intermediate values of the step size,
we find that a macroscopic component coexists with the microscopic ones. The
transition between these two fragmentation regimes changes from continuous to
discontinuous as the step size increases. In addition, we find that for both
very small and very large step sizes the influence network is severely
fragmented.",233,12,1469,39.37
2845,cultural anthropology,"Social fragmentation caused by widening differences among constituents has
recently become a highly relevant issue to our modern society. Theoretical
models of social fragmentation using the adaptive network framework have been
proposed and studied in earlier literature, which are known to either converge
to a homogeneous, well-connected network or fragment into many disconnected
sub-networks with distinct states. Here we introduced the diversities of
behavioral attributes among social constituents and studied their effects on
social network evolution. We investigated, using a networked agent-based
simulation model, how the resulting network states and topologies would be
affected when individual constituents' cultural tolerance, cultural state
change rate, and edge weight change rate were systematically diversified. The
results showed that the diversity of cultural tolerance had the most direct
effect to keep the cultural diversity within the society high and
simultaneously reduce the average shortest path length of the social network,
which was not previously reported in the earlier literature. Diversities of
other behavioral attributes also had effects on final states of the social
network, with some nonlinear interactions. Our results suggest that having a
broad distribution of cultural tolerance levels within society can help promote
the coexistence of cultural diversity and structural connectivity.",199,8,1427,8.81
2846,cultural anthropology,"Research has repeatedly demonstrated the influence of social connection and
communication on convergence in cultural tastes, opinions and ideas. Here we
review recent studies and consider the implications of social connection on
cultural, epistemological and ideological contraction, then formalize these
intuitions within the language of information theory. To systematically examine
connectivity and cultural diversity, we introduce new methods of manifold
learning to map both social networks and topic combinations into comparable,
two-dimensional hyperbolic spaces or Poincar\'e disks, which represent both
hierarchy and diversity within a system. On a Poincar\'e disk, radius from
center traces the position of an actor in a social hierarchy or an idea in a
cultural hierarchy. The angle of the disk required to inscribe connected actors
or ideas captures their diversity. Using this method in the epistemic culture
of 21st Century physics, we empirically demonstrate that denser university
collaborations systematically contract the space of topics discussed and ideas
investigated more than shared topics drive collaboration, despite the extreme
commitments academic physicists make to research programs over the course of
their careers. Dense connections unleash flows of communication that contract
otherwise fragmented semantic spaces into convergent hubs or polarized
clusters. We theorize the dynamic interplay between structural expansion and
cultural contraction and explore how this introduces an essential tension
between the enjoyment and protection of difference.",219,9,1582,9.82
2847,cultural anthropology,"The paper discusses the experience of producing and distributing an iPhone
app for promotion of the Maltese Cultural Heritage on behalf of the Malta
Tourism Authority. Thanks to its position at the heart of the Mediterranean
Sea, Malta has been a crossroads of civilisations whose traces are still
visible today, leaving a particularly rich and varied cultural heritage, from
megalithic temples to baroque palaces and Caravaggio masterpieces. Conveying
all these different aspects within a single application, using textual, visual,
and audio means, has raised many different issues about the planning and
production of cultural content for mobile usage, together with usability
aspects regarding design and distribution of a mobile app. In this paper, we
outline all of these aspects, focusing on the design and planning strategies
for a long-term user commitment and how to evaluate results for cultural mobile
applications. We include experience of all the steps of developing a mobile
app, information that is of possible benefit to other app developers in the
cultural sector.",166,6,1081,20.86
2848,cultural anthropology,"We demonstrate the utility of a new methodological tool, neural-network word
embedding models, for large-scale text analysis, revealing how these models
produce richer insights into cultural associations and categories than possible
with prior methods. Word embeddings represent semantic relations between words
as geometric relationships between vectors in a high-dimensional space,
operationalizing a relational model of meaning consistent with contemporary
theories of identity and culture. We show that dimensions induced by word
differences (e.g. man - woman, rich - poor, black - white, liberal -
conservative) in these vector spaces closely correspond to dimensions of
cultural meaning, and the projection of words onto these dimensions reflects
widely shared cultural connotations when compared to surveyed responses and
labeled historical data. We pilot a method for testing the stability of these
associations, then demonstrate applications of word embeddings for
macro-cultural investigation with a longitudinal analysis of the coevolution of
gender and class associations in the United States over the 20th century and a
comparative analysis of historic distinctions between markers of gender and
class in the U.S. and Britain. We argue that the success of these
high-dimensional models motivates a move towards ""high-dimensional theorizing""
of meanings, identities and cultural processes.",197,10,1401,4.95
2849,cultural anthropology,"It is generally agreed that one origin of machine bias is resulting from
characteristics within the dataset on which the algorithms are trained, i.e.,
the data does not warrant a generalized inference. We, however, hypothesize
that a different `mechanism', hitherto not articulated in the literature, may
also be responsible for machine's bias, namely that biases may originate from
(i) the programmers' cultural background, such as education or line of work, or
(ii) the contextual programming environment, such as software requirements or
developer tools. Combining an experimental and comparative design, we studied
the effects of cultural metaphors and contextual metaphors, and tested whether
each of these would `transfer' from the programmer to program, thus
constituting a machine bias. The results show (i) that cultural metaphors
influence the programmer's choices and (ii) that `induced' contextual metaphors
can be used to moderate or exacerbate the effects of the cultural metaphors.
This supports our hypothesis that biases in automated systems do not always
originate from within the machine's training data. Instead, machines may also
`replicate' and `reproduce' biases from the programmers' cultural background by
the transfer of cultural metaphors into the programming process. Implications
for academia and professional practice range from the micro programming-level
to the macro national-regulations or educational level, and span across all
societal domains where software-based systems are operating such as the popular
AI-based automated decision support systems.",227,10,1587,17.27
2850,cultural anthropology,"The cultural integration of immigrants conditions their overall
socio-economic integration as well as natives' attitudes towards globalisation
in general and immigration in particular. At the same time, excessive
integration -- or acculturation -- can be detrimental in that it implies
forfeiting one's ties to the home country and eventually translates into a loss
of diversity (from the viewpoint of host countries) and of global connections
(from the viewpoint of both host and home countries). Cultural integration can
be described using two dimensions: the preservation of links to the home
country and culture, which we call home attachment, and the creation of new
links together with the adoption of cultural traits from the new residence
country, which we call destination attachment. In this paper we introduce a
means to quantify these two aspects based on Twitter data. We build home and
destination attachment indexes and analyse their possible determinants (e.g.,
language proximity, distance between countries), also in relation to Hofstede's
cultural dimension scores. The results stress the importance of host language
proficiency to explain destination attachment, but also the link between
language and home attachment. In particular, the common language between home
and destination countries corresponds to increased home attachment, as does low
proficiency in the host language. Common geographical borders also seem to
increase both home and destination attachment. Regarding cultural dimensions,
larger differences among home and destination country in terms of
Individualism, Masculinity and Uncertainty appear to correspond to larger
destination attachment and lower home attachment.",247,12,1709,21.23
2851,cultural anthropology,"The goal of Artificial Life research, as articulated by Chris Langton, is ""to
contribute to theoretical biology by locating life-as-we-know-it within the
larger picture of life-as-it-could-be"" (1989, p.1). The study and pursuit of
open-ended evolution in artificial evolutionary systems exemplifies this goal.
However, open-ended evolution research is hampered by two fundamental issues;
the struggle to replicate open-endedness in an artificial evolutionary system,
and the fact that we only have one system (genetic evolution) from which to
draw inspiration. Here we argue that cultural evolution should be seen not only
as another real-world example of an open-ended evolutionary system, but that
the unique qualities seen in cultural evolution provide us with a new
perspective from which we can assess the fundamental properties of, and ask new
questions about, open-ended evolutionary systems, especially in regard to
evolved open-endedness and transitions from bounded to unbounded evolution.
Here we provide an overview of culture as an evolutionary system, highlight the
interesting case of human cultural evolution as an open-ended evolutionary
system, and contextualise cultural evolution under the framework of (evolved)
open-ended evolution. We go on to provide a set of new questions that can be
asked once we consider cultural evolution within the framework of open-ended
evolution, and introduce new insights that we may be able to gain about evolved
open-endedness as a result of asking these questions.",224,8,1520,16.7
2852,cultural anthropology,"Cumulative cultural evolution occurs when adaptive innovations are passed
down to consecutive generations through social learning. This process has
shaped human technological innovation, but also occurs in non-human species.
While it is traditionally argued that cumulative culture relies on
high-fidelity social transmission and advanced cognitive skills, here I show
that a much simpler system suffices. Cumulative culture spontaneously emerged
in artificial agents who navigate with a minimal cognitive architecture of
goal-direction, social proximity, and route memory. Within each generation,
naive individuals benefitted from being paired with experienced navigators
because they could follow previously established routes. Crucially, experienced
navigators also benefitted from the presence of naive individuals through
regression to the goal. As experienced agents followed their memorised path,
their naive counterparts (unhindered by route memory) were more likely to err
towards than away from the goal, and thus biased the pair in that direction.
This improved route efficiency within each generation. In control experiments,
cumulative culture was attenuated when agents' social proximity or route memory
were lesioned, whereas eliminating goal-direction only reduced efficiency.
These results demonstrate that cumulative cultural evolution occurs even in the
absence of sophisticated communication or thought. One interpretation of this
finding is that current definitions are too loose, and should be narrowed. An
alternative conclusion is that rudimentary cumulative culture is an emergent
property of systems that seek social proximity and have an imprecise memory
capacity, providing a flexible complement to traditional evolutionary
mechanisms.",238,13,1763,17.54
2853,cultural anthropology,"Context: Within agile transformations, there are a lot of different
challenges coming up. One very important but less considered and treated in
research are cultural challenges. Although research shows that cultural clashes
and general organizational resistance to change are part of the most
significant agile adoption barriers. Objective: Thus, our objective is to
tackle this field and come up with important contributions for further
research. To this end, we want to identify challenges that arise from the
interplay between agility and organizational culture. Method: This is done
based on an iterative research approach. On the one hand, we gathered
qualitative data among our network of agile practitioners. Then, we derived in
sum 15 challenges with agile culture. On the other hand, we gathered
quantitative data by means of a questionnaire study with 92 participants.
Results: We identified 7 key challenges out of the 15 challenges with agile
culture. The results that are presented in a conceptual model show a focus on
human aspects that we need to deal with more in future. Conclusion: Based on
our results, we started deriving future work aspects to do more detailed
research on the topic of cultural challenges while transitioning or using agile
methods in software development and beyond.",205,13,1306,45.66
2854,cultural anthropology,"The space of possible human cultures is vast, but some cultural
configurations are more consistent with cognitive and social constraints than
others. This leads to a ``landscape'' of possibilities that our species has
explored over millennia of cultural evolution. But what does this fitness
landscape, which constrains and guides cultural evolution, look like? The
machine-learning algorithms that can answer these questions are typically
developed for large-scale datasets. Applications to the sparse, inconsistent,
and incomplete data found in the historical record have received less
attention, and standard recommendations can lead to bias against marginalized,
under-studied, or minority cultures. We show how to adapt the Minimum
Probability Flow algorithm and the Inverse Ising model, a physics-inspired
workhorse of machine learning, to the challenge. A series of natural extensions
-- including dynamical estimation of missing data, and cross-validation with
regularization -- enables reliable reconstruction of the underlying
constraints. We demonstrate our methods on a curated subset of the Database of
Religious History: records from 407 religious groups throughout human history,
ranging from the Bronze Age to the present day. This reveals a complex, rugged,
landscape, with both sharp, well-defined peaks where state-endorsed religions
tend to concentrate, and diffuse cultural floodplains where evangelical
religions, non-state spiritual practices, and mystery religions can be found.",209,9,1502,31.21
2855,cultural anthropology,"The study of cultural evolution benefits from detailed analysis of cultural
transmission in specific human domains. Chess provides a platform for
understanding the transmission of knowledge due to its active community of
players, precise behaviors, and long-term records of high-quality data. In this
paper, we perform an analysis of chess in the context of cultural evolution,
describing multiple cultural factors that affect move choice. We then build a
population-level statistical model of move choice in chess, based on the
Dirichlet-multinomial likelihood, to analyze cultural transmission over decades
of recorded games played by leading players. For moves made in specific
positions, we evaluate the relative effects of frequency-dependent bias,
success bias, and prestige bias on the dynamics of move frequencies. We observe
that negative frequency-dependent bias plays a role in the dynamics of certain
moves, and that other moves are compatible with transmission under prestige
bias or success bias. These apparent biases may reflect recent changes, namely
the introduction of computer chess engines and online tournament broadcasts.
Our analysis of chess provides insights into broader questions concerning how
social learning biases affect cultural evolution.",183,9,1272,31.31
2856,cultural anthropology,"Recommender systems have gained increasing attention to personalise consumer
preferences. While these systems have primarily focused on applications such as
advertisement recommendations (e.g., Google), personalized suggestions (e.g.,
Netflix and Spotify), and retail selection (e.g., Amazon), there is potential
for these systems to benefit from a more global, socio-economic, and culturally
aware approach, particularly as companies seek to expand into diverse markets.
This paper aims to investigate the potential of a recommender system that
considers cultural identity and socio-economic factors. We review the most
recent developments in recommender systems and explore the impact of cultural
identity and socio-economic factors on consumer preferences. We then propose an
ontology and approach for incorporating these factors into recommender systems.
To illustrate the potential of our approach, we present a scenario in consumer
subscription plan selection within the entertainment industry. We argue that
existing recommender systems have limited ability to precisely understand user
preferences due to a lack of awareness of socio-economic factors and cultural
identity. They also fail to update recommendations in response to changing
socio-economic conditions. We explore various machine learning models and
develop a final artificial neural network model (ANN) that addresses this gap.
We evaluate the effectiveness of socio-economic and culturally aware
recommender systems across four dimensions: Precision, Accuracy, F1, and
Recall. We find that a highly tuned ANN model incorporating domain-specific
data, select cultural indices and relevant socio-economic factors predicts user
preference in subscriptions with an accuracy of 95%, a precision of 94%, a F1
Score of 92\%, and a Recall of 90\%.",253,18,1812,19.26
2857,cultural anthropology,"An outstanding open problem is whether collective social phenomena occurring
over short timescales can systematically reduce cultural heterogeneity in the
long run, and whether offline and online human interactions contribute
differently to the process. Theoretical models suggest that short-term
collective behavior and long-term cultural diversity are mutually excluding,
since they require very different levels of social influence. The latter
jointly depends on two factors: the topology of the underlying social network
and the overlap between individuals in multidimensional cultural space.
However, while the empirical properties of social networks are well understood,
little is known about the large-scale organization of real societies in
cultural space, so that random input specifications are necessarily used in
models. Here we use a large dataset to perform a high-dimensional analysis of
the scientific beliefs of thousands of Europeans. We find that inter-opinion
correlations determine a nontrivial ultrametric hierarchy of individuals in
cultural space, a result unaccessible to one-dimensional analyses and in
striking contrast with random assumptions. When empirical data are used as
inputs in models, we find that ultrametricity has strong and counterintuitive
effects, especially in the extreme case of long-range online-like interactions
bypassing social ties. On short time-scales, it strongly facilitates a
symmetry-breaking phase transition triggering coordinated social behavior. On
long time-scales, it severely suppresses cultural convergence by restricting it
within disjoint groups. We therefore find that, remarkably, the empirical
distribution of individuals in cultural space appears to optimize the
coexistence of short-term collective behavior and long-term cultural diversity,
which can be realized simultaneously for the same moderate level of mutual
influence.",258,11,1899,2.99
2858,cultural anthropology,"Yeast cells grown in culture can spontaneously synchronize their respiration,
metabolism, gene expression and cell division. Such metabolic oscillations in
synchronized cultures reflect single-cell oscillations, but the relationship
between the oscillations in single cells and synchronized cultures is poorly
understood. To understand this relationship and the coordination between
metabolism and cell division, we collected and analyzed DNA-content,
gene-expression and physiological data, at hundreds of time-points, from
cultures metabolically-synchronized at different growth rates, carbon sources
and biomass densities. The data enabled us to extend and generalize an
ensemble-average-over-phases (EAP) model that connects the population-average
gene-expression of asynchronous cultures to the gene-expression dynamics in the
single-cells comprising the cultures. The extended model explains the
carbon-source specific growth-rate responses of hundreds of genes. Our data
demonstrate that for a given growth rate, the frequency of metabolic cycling in
synchronized cultures increases with the biomass density. This observation
underscores the difference between metabolic cycling in synchronized cultures
and in single cells and suggests entraining of the single-cell cycle by a
quorum-sensing mechanism. Constant levels of residual glucose during the
metabolic cycling of synchronized cultures indicate that storage carbohydrates
are required to fuel not only the G1/S transition of the division cycle but
also the metabolic cycle. Despite the large variation in profiled conditions
and in the time-scale of their dynamics, most genes preserve invariant dynamics
of coordination with each other and with the rate of oxygen consumption.
Similarly, the G1/S transition always occurs at the beginning, middle or end of
the high oxygen consumption phases, analogous to observations in human and
drosophila cells.",259,11,1915,11.35
2859,cultural anthropology,"Physical disabled access is something that most cultural institutions such as
museums consider very seriously. Indeed, there are normally legal requirements
to do so. However, online disabled access is still a relatively novel and
developing field. Many cultural organizations have not yet considered the
issues in depth and web developers are not necessarily experts either. The
interface for websites is normally tested with major browsers, but not with
specialist software like text to audio converters for the blind or against the
relevant accessibility and validation standards. We consider the current state
of the art in this area, especially with respect to aspects of particular
importance to the access of cultural heritage.",111,7,734,35.78
2860,cultural anthropology,"We present a theory of cultural evolution based upon a renormalization group
scheme. We consider rational but cognitively limited agents who optimize their
decision making process by iteratively updating and refining the mental
representation of their natural and social environment. These representations
are built around the most important degrees of freedom of their world. Cultural
coherence among agents is defined as the overlap of mental representations and
is characterized using an adequate order parameter. As the importance of social
interactions increases or agents become more intelligent, we observe and
quantify a series of dynamic phase transitions by which cultural coherence
advances in the society. A similar phase transition may explain the so-called
""cultural explosion"" in human evolution some 50,000 years ago.",121,7,833,25.59
2861,cultural anthropology,"We study the effect of mass media, modeled as an applied external field, on a
social system based on Axelrod's model for the dissemination of culture. The
numerical simulations show that the system undergoes a nonequilibrium phase
transition between an ordered phase (homogeneous culture) specified by the mass
media and a disordered (culturally fragmented) one. The critical boundary
separating these phases is calculated on the parameter space of the system,
given by the intensity of the mass media influence and the number of options
per cultural attribute. Counterintuitively, mass media can induce cultural
diversity when its intensity is above some threshold value. The nature of the
phase transition changes from continuous to discontinuous at some critical
value of the number of options.",122,6,797,21.33
2862,cultural anthropology,"We study the consequences of introducing individual nonconformity in social
interactions, based on Axelrod's model for the dissemination of culture. A
constraint on the number of situations in which interaction may take place is
introduced in order to lift the unavoidable ho mogeneity present in the final
configurations arising in Axelrod's related models. The inclusion of this
constraint leads to the occurrence of complex patterns of intracultural
diversity whose statistical properties and spatial distribution are
characterized by means of the concepts of cultural affinity and cultural cli
ne. It is found that the relevant quantity that determines the properties of
intracultural diversity is given by the fraction of cultural features that
characterizes the cultural nonconformity of individuals.",117,5,806,7.9
2863,cultural anthropology,"We relax a simplification of Axelrod's (1997) model of cultural dissemination
that has not yet been studied, the assumption that all cultural states are
nominal. We integrate metric states into the original model. Computational
experiments demonstrate that metric states undermine cultural diversity, even
without noise, by creating sufficient overlap between agents for mutual
influence. We then show how adding ""bounded confidence"" - a recent innovation
in models of social influence - allows cultural diversity to persist. However,
further experiments reveal that the solution is fragile. Diversity can be
sustained only with a relatively small number of metric states, low levels of
noise or narrow confidence intervals.",106,7,724,20.08
2864,cultural anthropology,"Recent extensions of the Axelrod model of cultural dissemination (Klemm et al
2003) showed that global diversity is extremely fragile with small amounts of
cultural mutation. This seemed to undermine the original Axelrod theory that
homophily preserves diversity. We show that cultural diversity is surprisingly
robust if we increase the tendency towards homophily as follows. First, we
raised the threshold of similarity below which influence is precluded. Second,
we allowed agents to be influenced by all neighbors simultaneously, instead of
only one neighbor as assumed in the orginal model. Computational experiments
show how both modifications strongly increase the robustness of diversity
against mutation. We also find that our extensions may reverse at least one of
the main results of Axelrod. While Axelrod predicted that a larger number of
cultural dimensions (features) reduces diversity, we find that more features
may entail higher levels of diversity.",144,9,967,27.83
2865,cultural anthropology,"Language is one of the most important aspects of human cognition; it
represents the way we think, act and communicate with each other. Each language
has its own history, background, and form. A language represents a lot of
important cultural aspects of the nation speaking it. Languages differ and so
do cultures. In this paper we analyze cultural differences between East and
West in a multi-linguistic context from a complex networks point of view. There
has been considerable work on the topic of cultural differences by psychologist
and sociologist. Also studies on complex networks that make use of WordNet have
been done, but until now there is no previous work that uses WordNets from
different Eastern and Western languages as complex lexical networks in order to
obtain possible differences or similarities between the cultures using those
respective languages. Our work aims to do this.",144,9,896,44.75
2866,cultural anthropology,"Because human cognition is creative and socially situated, knowledge
accumulates, diffuses, and gets applied in new contexts, generating cultural
analogs of phenomena observed in population genetics such as adaptation and
drift. It is therefore commonly thought that elements of culture evolve through
natural selection. However, natural selection was proposed to explain how
change accumulates despite lack of inheritance of acquired traits, as occurs
with template-mediated replication. It cannot accommodate a process with
significant retention of acquired or horizontally (e.g. socially) transmitted
traits. Moreover, elements of culture cannot be treated as discrete lineages
because they constantly interact and influence one another. It is proposed that
what evolves through culture is the mind; ideas and artifacts are merely
reflections of its current evolved state. Interacting minds transform (in part)
through through a non-Darwinian autopoietic process similar to that by which
early life evolved, involving not survival of the fittest but actualization of
their potential.",152,10,1086,26.81
2867,cultural anthropology,"Axelrod model describes the dissemination of a set of cultural traits in a
society constituted by individual agents. In a social context, nevertheless,
individual choices toward a specific attitude are also at the basis of the
formation of communities, groups, parties. The membership in a group changes
completely the behavior of single agents who start acting according to a social
identity. Groups act and interact among them as single entities, but still
conserve an internal dynamics. We show that, under certain conditions on social
dynamics, the introduction of group dynamics in a cultural dissemination
process avoids the flattening of the culture on a single thought and preserve
the multiplicity of cultural attitudes. We also considered an innovation
diffusion process on this dynamical background, showing under which conditions
innovative ideas can survive in a scenario where the groups choices determine
the social structure.",142,7,941,22.04
2868,cultural anthropology,"An important feature of Axelrod's model for culture dissemination or social
influence is the emergence of many multicultural absorbing states, despite the
fact that the local rules that specify the agents interactions are explicitly
designed to decrease the cultural differences between agents. Here we
re-examine the problem of introducing an external, global interaction -- the
mass media -- in the rules of Axelrod's model: in addition to their
nearest-neighbors, each agent has a certain probability $p$ to interact with a
virtual neighbor whose cultural features are fixed from the outset. Most
surprisingly, this apparently homogenizing effect actually increases the
cultural diversity of the population. We show that, contrary to previous claims
in the literature, even a vanishingly small value of $p$ is sufficient to
destabilize the homogeneous regime for very large lattice sizes.",133,5,891,12.8
2869,cultural anthropology,"We study the Axelrod's cultural adaptation model using the concept of cluster
size entropy, $S_{c}$ that gives information on the variability of the cultural
cluster size present in the system. Using networks of different topologies,
from regular to random, we find that the critical point of the well-known
nonequilibrium monocultural-multicultural (order-disorder) transition of the
Axelrod model is unambiguously given by the maximum of the $S_{c}(q)$
distributions. The width of the cluster entropy distributions can be used to
qualitatively determine whether the transition is first- or second-order. By
scaling the cluster entropy distributions we were able to obtain a relationship
between the critical cultural trait $q_c$ and the number $F$ of cultural
features in regular networks. We also analyze the effect of the mass media
(external field) on social systems within the Axelrod model in a square
network. We find a new partially ordered phase whose largest cultural cluster
is not aligned with the external field, in contrast with a recent suggestion
that this type of phase cannot be formed in regular networks. We draw a new
$q-B$ phase diagram for the Axelrod model in regular networks.",186,8,1202,36.02
2870,cultural anthropology,"The historical interplay between societies are governed by many factors,
including in particular spreading of languages, religion and other symbolic
traits. Cultural development, in turn, is coupled to emergence and maintenance
of information spreading. Strong centralized cultures exist thanks to attention
from their members, which faithfulness in turn relies on supply of information.
Here, we discuss a culture evolution model on a planar geometry that takes into
account aspects of the feedback between information spreading and its
maintenance. Features of model are highlighted by comparing it to cultural
spreading in ancient and medieval Europe, where it in particular suggests that
long lived centers should be located in geographically remote regions.",110,6,762,23.77
2871,cultural anthropology,"Breiman (2001) proposed to statisticians awareness of two cultures: 1.
Parametric modeling culture, pioneered by R.A.Fisher and Jerzy Neyman; 2.
Algorithmic predictive culture, pioneered by machine learning research.
  Parzen (2001), as a part of discussing Breiman (2001), proposed that
researchers be aware of many cultures, including the focus of our research: 3.
Nonparametric, quantile based, information theoretic modeling. We provide a
unification of many statistical methods for traditional small data sets and
emerging big data sets in terms of comparison density, copula density, measure
of dependence, correlation, information, new measures (called LP score
comoments) that apply to long tailed distributions with out finite second order
moments. A very important goal is to unify methods for discrete and continuous
random variables. Our research extends these methods to modern high dimensional
data modeling.",131,11,922,39.74
2872,cultural anthropology,"The advent of social media has provided data and insights about how people
relate to information and culture. While information is composed by bits and
its fundamental building bricks are relatively well understood, the same cannot
be said for culture. The fundamental cultural unit has been defined as a
""meme"". Memes are defined in literature as specific fundamental cultural
traits, that are floating in their environment together. Just like genes
carried by bodies, memes are carried by cultural manifestations like songs,
buildings or pictures. Memes are studied in their competition for being
successfully passed from one generation of minds to another, in different ways.
In this paper we choose an empirical approach to the study of memes. We
downloaded data about memes from a well-known website hosting hundreds of
different memes and thousands of their implementations. From this data, we
empirically describe the behavior of these memes. We statistically describe
meme occurrences in our dataset and we delineate their fundamental traits,
along with those traits that make them more or less apt to be successful.",175,11,1124,45.25
2873,cultural anthropology,"This chapter begins by outlining a promising, new theoretical framework for
the process by which human culture evolves inspired by the views of complexity
theorists on the problem of how life began. Elements of culture, like species,
evolve over time; that is, they exhibit cumulative change that is adaptive in
nature. By studying how biological evolution got started, we gain insight into
not just the specifics of biological evolution, but also general insights into
the initiation of any evolutionary process that may be applicable to culture.
We then explore the implications of this new framework for culture on the
transformative processes of individuals. Specifically, we will address what
this emerging perspective on cultural evolution implies for to go about
attaining a sustainable worldview; that is, a web of habits, understandings,
and ways of approaching situations that is conducive to the development of a
sustainable world.",145,6,942,33.58
2874,cultural anthropology,"The Kamilaroi people and their neighbours, the Euahlayi, Ngemba, and
Murrawarri, are an Aboriginal cultural grouping located in the northwest and
north central of New South Wales. They have a rich history, but have been
missed in much of the literature concerned with sky knowledge in culture. This
study collected stories, some of which have not previously been reported in an
academic format, from Aboriginal people practicing their culture, augmented
with stories from the literature, and analysed the data to create a database of
sky knowledge that will be added to the larger body of Aboriginal cultural
knowledge in Australia. We found that there is a strong sky culture reflected
in the stories, and we also explored the stories for evidence of an
ethnoscientific approach to knowledge of the sky.",130,5,804,38.49
2875,cultural anthropology,"Shame has clear biological roots and its precise form of expression affects
social cohesion and cultural characteristics. Here we explore the relative
importance between shame and guilt by using Google Translate to produce
translation for the words shame, guilt, pain, embarrassment and fear to the 64
languages covered. We also explore the meanings of these concepts among the
Yanomami, a horticulturist hunter-gatherer tribe in the Orinoquia. Results show
that societies previously described as 'guilt societies' have more words for
guilt than for shame, but the large majority, including the societies
previously described as 'shame societies', have more words for shame than for
guilt. Results are consistent with evolutionary models of shame which predict a
wide scatter in the relative importance between guilt and shame, suggesting
that cultural evolution of shame has continued the work of biological
evolution, and that neither provides a strong adaptive advantage to either
shame or guilt. We propose that the study of shame will improve our
understanding of the interaction between biological and cultural evolution in
the evolution of cognition and emotions.",176,7,1170,33.28
2876,cultural anthropology,"There are both benefits and drawbacks to cultural diversity. It can lead to
friction and exacerbate differences. However, as with biological diversity,
cultural diversity is valuable in times of upheaval; if a previously effective
solution no longer works, it is good to have alternatives available. What
factors give rise to cultural diversity? This paper describes a preliminary
investigation of this question using a computational model of cultural
evolution. The model is composed of neural network based agents that evolve
fitter ideas for actions by (1) inventing new ideas through modification of
existing ones, and (2) imitating neighbors' ideas. Numerical simulations
indicate that the diversity of ideas in a population is positively correlated
with both the proportion of creators to imitators in the population, and the
rate at which creators create. This is the case for both minimum and peak
diversity of actions over the duration of a run.",148,8,954,35.78
2877,cultural anthropology,"Was the spread of agropastoralism from the Eurasian founder regions dominated
by demic or by cultural diffusion? This study employs a mathematical model of
regional sociocultural development that includes different diffusion processes,
local innovation and societal adaptation. Simulations hindcast the emergence
and expansion of agropastoral life style in 294 regions of Eurasia and North
Africa. Different scenarios for demic and diffusive exchange processes between
adjacent regions are contrasted and the spatiotemporal pattern of diffusive
events is evaluated. This study supports from a modeling perspective the
hypothesis that there is no simple or exclusive demic or cultural diffusion,
but that in most regions of Eurasia a combination of demic and cultural
processes were important. Furthermore, we demonstrate the strong spatial and
temporal variability in the balance of spread processes. Each region shows
sometimes more demic, and at other times more cultural diffusion. Only few,
possibly environmentally marginal, areas show a dominance of demic diffusion.
This study affirms that diffusion processes should be investigated in a
diachronic fashion and not from a time-integrated perspective.",172,9,1207,26.71
2878,cultural anthropology,"Consumer trust is one of the key obstacles to online vendors seeking to
extend their consumers across cultures. This research identifies culture at the
individual consumer level. Based on the Stimulus-Organism-Response (SOR) model,
this study focuses on the moderating role of uncertainty avoidance culture
value on privacy and security as cognition influences, joy and fear as
emotional influences (Stimuli), and individualism-collectivism on social
networking services as social influence and subsequently on interpersonal trust
(cognitive and affect-based trust) (Organism) towards purchase intention
(Response). Data were collected in Australia and the Partial least squares
(PLS) approach was used to test the research model. The findings confirmed the
moderating role of individual level culture on consumer's cognitive and
affect-based trust in B2Ce-commerce websites with diverse degrees of
uncertainty avoidance and individualism.",128,6,939,11.65
2879,cultural anthropology,"Words shift in meaning for many reasons, including cultural factors like new
technologies and regular linguistic processes like subjectification.
Understanding the evolution of language and culture requires disentangling
these underlying causes. Here we show how two different distributional measures
can be used to detect two different types of semantic change. The first
measure, which has been used in many previous works, analyzes global shifts in
a word's distributional semantics, it is sensitive to changes due to regular
processes of linguistic drift, such as the semantic generalization of promise
(""I promise."" -> ""It promised to be exciting.""). The second measure, which we
develop here, focuses on local changes to a word's nearest semantic neighbors;
it is more sensitive to cultural shifts, such as the change in the meaning of
cell (""prison cell"" -> ""cell phone""). Comparing measurements made by these two
methods allows researchers to determine whether changes are more cultural or
linguistic in nature, a distinction that is essential for work in the digital
humanities and historical linguistics.",168,9,1114,38.96
2880,cultural anthropology,"The use of Internet and Internet-based services on PCs, Laptops, Net Pads,
Mobile Phones, PDAs etc have not only changed the global economy but also the
way people communicate and their life styles. It also has evolved people from
different origins, cultures, beliefs across the national boundaries. As a
result it has become an absolute necessity to address the cross-cultural issues
of information systems (IS) reflecting the user behaviours and influencing the
way the mobile broadband technology is being accepted as well as the way it is
changing the life styles of different groups of people. This paper reports on
an on-going research effort which studies the impacts of culture and
socio-economic circumstances on users' behavior and mobile broadband technology
diffusion trends.",122,5,787,32.06
2881,cultural anthropology,"The value and relevance of indigenous knowledge towards sustainability of
human societies drives for its preservation. This work explored the use of
Facebook groups to promote indigenous knowledge among Igorot peoples in the
diaspora. The virtual communities help intensify the connection of Igorot
migrants to their traditional culture despite the challenges of assimilation to
a different society. A survey of posts on 20 Facebook groups identified and
classified the indigenous cultural elements conveyed through social media. A
subsequent survey of 56 Igorot migrants revealed that popular social media has
a significant role in the exchange, revitalization, practice, and learning of
indigenous culture; inciting an effective medium to leverage preservation
strategies.",110,6,774,23.77
2882,cultural anthropology,"Word choice is dependent on the cultural context of writers and their
subjects. Different words are used to describe similar actions, objects, and
features based on factors such as class, race, gender, geography and political
affinity. Exploratory techniques based on locating and counting words may,
therefore, lead to conclusions that reinforce culturally inflected boundaries.
We offer a new method, the DualNeighbors algorithm, for linking thematically
similar documents both within and across discursive and linguistic barriers to
reveal cross-cultural connections. Qualitative and quantitative evaluations of
this technique are shown as applied to two cultural datasets of interest to
researchers across the humanities and social sciences. An open-source
implementation of the DualNeighbors algorithm is provided to assist in its
application.",118,7,848,26.1
2883,cultural anthropology,"The degree to which Mexican immigrants in the U.S. are assimilating
culturally has been widely debated. To examine this question, we focus on
musical taste, a key symbolic resource that signals the social positions of
individuals. We adapt an assimilation metric from earlier work to analyze
self-reported musical interests among immigrants in Facebook. We use the
relative levels of interest in musical genres, where a similarity to the host
population in musical preferences is treated as evidence of cultural
assimilation. Contrary to skeptics of Mexican assimilation, we find significant
cultural convergence even among first-generation immigrants, which
problematizes their use as assimilative ""benchmarks"" in the literature.
Further, 2nd generation Mexican Americans show high cultural convergence
vis-\`a-vis both Anglos and African-Americans, with the exception of those who
speak Spanish. Rather than conforming to a single assimilation path, our
findings reveal how Mexican immigrants defy simple unilinear theoretical
expectations and illuminate their uniquely heterogeneous character.",152,10,1096,9.89
2884,cultural anthropology,"We consider the problem of localizing visitors in a cultural site from
egocentric (first person) images. Localization information can be useful both
to assist the user during his visit (e.g., by suggesting where to go and what
to see next) and to provide behavioral information to the manager of the
cultural site (e.g., how much time has been spent by visitors at a given
location? What has been liked most?). To tackle the problem, we collected a
large dataset of egocentric videos using two cameras: a head-mounted HoloLens
device and a chest-mounted GoPro. Each frame has been labeled according to the
location of the visitor and to what he was looking at. The dataset is freely
available in order to encourage research in this domain. The dataset is
complemented with baseline experiments performed considering a state-of-the-art
method for location-based temporal segmentation of egocentric videos.
Experiments show that compelling results can be achieved to extract useful
information for both the visitor and the site-manager.",163,12,1034,46.47
2885,cultural anthropology,"The phenomenon of Iks was first found by anthropologists and biologists, but
it is actually a problem of human geography. However, it has not yet drawn
extensive attention of geographers. In this paper, a hypothesis of ikization is
presented that sudden and violent change of geographical environments results
in dismantling of traditional culture, which then result in collective
depravity of a nationality. By quantitative analysis and mathematical modeling,
the causality between urbanization and ikization is discussed, and the theory
of replacement dynamics is employed to interpret the process of ikization.
Urbanization is in essence a nonlinear process of population replacement.
Urbanization may result in ikization because that the migration of population
from rural regions to urban regions always give rise to abrupt changes of
geographical environments and traditional culture. It is necessary to protect
the geographical environment against disruption, and to inherit and develop
traditional culture in order to avoid ikization of a nation. The approach to
solving the problems caused by fast urbanization is to reconstruct geographical
environment so that rural culture will be naturally replaced by urban culture.",180,9,1229,14.8
2886,cultural anthropology,"The use of information technology in the study of human behavior is a subject
of great scientific interest. Cultural and personality aspects are factors that
influence how people interact with one another in a crowd. This paper presents
a methodology to detect cultural characteristics of crowds in video sequences.
Based on filmed sequences, pedestrians are detected, tracked and characterized.
Such information is then used to find out cultural differences in those videos,
based on the Big-five personality model. Regarding cultural differences of each
country, results indicate that this model generates coherent information when
compared to data provided in literature.",99,7,674,29.35
2887,cultural anthropology,"The profound impact of Darwin's theory of evolution on biology has led to the
acceptance of the theory in many complex systems that lie well beyond its
original domain. Culture is one example that also exhibits key Darwinian
evolutionary properties: Differential adoption of cultural variants (variation
and selection), new entities imitating older ones (inheritance), and
convergence toward the most suitable state (adaptation). In this work we
present a framework for capturing the details of the evolutionary dynamics in
cultural systems on the ""meme""- the cultural analog of the biological
gene-level, and analyze large-scale, comprehensive movie-meme association data
to construct a timeline of the history of cinema via the evolution of genres
and the rise and fall of prominent sub-genres. We also identify the impactful
movies that were harbingers to popular memes that we may say correspond to the
proverbial ""Eve"" of the human race, shining light on the process by which
certain genres form and grow. Finally, we measure how the impact of movies
correlates with the experts' and the public's assessment.",172,6,1113,28.1
2888,cultural anthropology,"ArCo is the Italian Cultural Heritage knowledge graph, consisting of a
network of seven vocabularies and 169 million triples about 820 thousand
cultural entities. It is distributed jointly with a SPARQL endpoint, a software
for converting catalogue records to RDF, and a rich suite of documentation
material (testing, evaluation, how-to, examples, etc.). ArCo is based on the
official General Catalogue of the Italian Ministry of Cultural Heritage and
Activities (MiBAC) - and its associated encoding regulations - which collects
and validates the catalogue records of (ideally) all Italian Cultural Heritage
properties (excluding libraries and archives), contributed by CH administrators
from all over Italy. We present its structure, design methods and tools, its
growing community, and delineate its importance, quality, and impact.",121,6,835,15.85
2889,cultural anthropology,"This paper outlines a perspective on the future of AI, discussing directions
for machines models of human-like intelligence. We explain how developmental
and evolutionary theories of human cognition should further inform artificial
intelligence. We emphasize the role of ecological niches in sculpting
intelligent behavior, and in particular that human intelligence was
fundamentally shaped to adapt to a constantly changing socio-cultural
environment. We argue that a major limit of current work in AI is that it is
missing this perspective, both theoretically and experimentally. Finally, we
discuss the promising approach of developmental artificial intelligence,
modeling infant development through multi-scale interaction between
intrinsically motivated learning, embodiment and a fastly changing
socio-cultural environment. This paper takes the form of an interview of
Pierre-Yves Oudeyer by Mandred Eppe, organized within the context of a KI -
K{\""{u}}nstliche Intelligenz special issue in developmental robotics.",139,7,1020,5.83
2890,cultural anthropology,"Partial classification popularly known as nugget discovery comes under
descriptive knowledge discovery. It involves mining rules for a target class of
interest. Classification ""If-Then"" rules are the most sought out by decision
makers since they are the most comprehensible form of knowledge mined by data
mining techniques. The rules have certain properties namely the rule metrics
which are used to evaluate them. Mining rules with user specified properties
can be considered as a multi-objective optimization problem since the rules
have to satisfy more than one property to be used by the user. Cultural
algorithm (CA) with its knowledge sources have been used in solving many
optimization problems. However research gap exists in using cultural algorithm
for multi-objective optimization of rules. In the current study a
multi-objective cultural algorithm is proposed for partial classification.
Results of experiments on benchmark data sets reveal good performance.",143,10,971,38.42
2891,cultural anthropology,"In a landmark paper published in 2001, Leo Breiman described the tense
standoff between two cultures of data modeling: parametric statistical and
algorithmic machine learning. The cultural division between these two
statistical learning frameworks has been growing at a steady pace in recent
years. What is the way forward? It has become blatantly obvious that this
widening gap between ""the two cultures"" cannot be averted unless we find a way
to blend them into a coherent whole. This article presents a solution by
establishing a link between the two cultures. Through examples, we describe the
challenges and potential gains of this new integrated statistical thinking.",105,6,673,45.25
2892,cultural anthropology,"When we teach physics to prospective scientists and engineers we are teaching
more than the ""facts"" of physics - more, even, than the methods and concepts of
physics. We are introducing them to a complex culture - a mode of thinking and
the cultural code of behavior of a community of practicing scientists. This
culture has components that are often part of our hidden curriculum:
epistemology - how we decide that we know something; ontology - how we parse
the observable world into categories, objects, and concepts; and discourse -
how we hold a conversation in order to generate new knowledge and
understanding. Underlying all of this is intuition - a culturally created sense
of meaning. To explicitly identify teach our hidden curriculum we must pay
attention to students' intuition and perception of physics, not just to their
reasoning.",139,6,845,36.02
2893,cultural anthropology,"The Extended Evolutionary Synthesis (EES) is beginning to fulfill the whole
promise of Darwinian insight through its extension of evolutionary
understanding from the biological domain to include cultural information
evolution. Several decades of important foundation-laying work took a social
Darwinist approach and exhibited and ecologically-deterministic elements. This
is not the case with more recent developments to the evolutionary study of
culture, which emphasize non-Darwinian processes such as self-organization,
potentiality, and epigenetic change.",72,4,559,-3.65
2894,cultural anthropology,"One of the fundamental questions of cultural evolutionary research is how
individual-level processes scale up to generate population-level patterns.
Previous studies in music have revealed that frequency-based bias (e.g.
conformity and novelty) drives large-scale cultural diversity in different ways
across domains and levels of analysis. Music sampling is an ideal research
model for this process because samples are known to be culturally transmitted
between collaborating artists, and sampling events are reliably documented in
online databases. The aim of the current study was to determine whether
frequency-based bias has played a role in the cultural transmission of music
sampling traditions, using a longitudinal dataset of sampling events across
three decades. Firstly, we assessed whether turn-over rates of popular samples
differ from those expected under neutral evolution. Next, we used agent-based
simulations in an approximate Bayesian computation framework to infer what
level of frequency-based bias likely generated the observed data. Despite
anecdotal evidence of novelty bias, we found that sampling patterns at the
population-level are most consistent with conformity bias.",168,10,1196,24.78
2895,cultural anthropology,"Color is an essential component of graphic design, acting not only as a
visual factor but also carrying cultural implications. However, existing
research on algorithmic color palette generation and colorization largely
ignores the cultural aspect. In this paper, we contribute to this line of
research by first constructing a unique color dataset inspired by a specific
culture, i.e., Chinese Youth Subculture (CYS), which is an vibrant and trending
cultural group especially for the Gen Z population. We show that the colors
used in CYS have special aesthetic and semantic characteristics that are
different from generic color theory. We then develop an interactive multi-modal
generative framework to create CYS-styled color palettes, which can be used to
put a CYS twist on images using our automatic colorization model. Our framework
is illustrated via a demo system designed with the human-in-the-loop principle
that constantly provides feedback to our algorithms. User studies are also
conducted to evaluate our generation results.",156,10,1037,34.76
2896,cultural anthropology,"A snowclone is a customizable phrasal template that can be realized in
multiple, instantly recognized variants. For example, ``* is the new *"" (Orange
is the new black, 40 is the new 30). Snowclones are extensively used in social
media. In this paper, we study snowclones originating from pop-culture quotes;
our goal is to automatically detect cultural references in text. We introduce a
new, publicly available data set of pop-culture quotes and their corresponding
snowclone usages and train models on them. We publish code for Catchphrase, an
internet browser plugin to automatically detect and mark references in
real-time, and examine its performance via a user study. Aside from assisting
people to better comprehend cultural references, we hope that detecting
snowclones can complement work on paraphrasing and help to tackle long-standing
questions in social science about the dynamics of information propagation.",140,8,922,34.56
2897,cultural anthropology,"Art and culture, at their best, lie in the act of discovery and exploration.
This paper describes Resurrect3D, an open visualization platform for both
casual users and domain experts to explore cultural artifacts. To that end,
Resurrect3D takes two steps. First, it provides an interactive cultural
heritage toolbox, providing not only commonly used tools in cultural heritage
such as relighting and material editing, but also the ability for users to
create an interactive ""story"": a saved session with annotations and
visualizations others can later replay. Second, Resurrect3D exposes a set of
programming interfaces to extend the toolbox. Domain experts can develop custom
tools that perform artifact-specific visualization and analysis.",109,7,741,27.62
2898,cultural anthropology,"Spatial separation is often included in models of ethnic divergence but it
has also been realised that urban subcultures can, and frequently do, emerge in
sympatry. Previous research tended to attribute this phenomenon to the human
tendency to imitate self-similar individuals and actively differentiate oneself
from individuals recognized as members of an outgroup. Application of such a
model to non-human animals has been, however, viewed as problematic. We present
a parsimonious model of subculture emergence where the algorithm of social
learning does not require the assumption of an 'imitation threshold'. All it
takes is a slight modification of Galton-Pearson's biometric model previously
used to approximate cultural inheritance. The new model includes
proportionality between the variance of inputs (cultural 'parents') and the
variance of outputs (cultural 'offspring'). In this model, assortment alone can
lead to the formation of distinct cohesive clusters of individuals
(subcultures) with a low within-group and large between-group variability even
in absence of a spatial separation or disruptive natural selection. Sympatric
emergence of arbitrary behavioural varieties preceding ecological divergence
may thus represent the norm, not the exception, in all cultural animals.",183,9,1293,14.39
2899,cultural anthropology,"Knowledge Graphs (KGs) have proven to be a reliable way of structuring data.
They can provide a rich source of contextual information about cultural
heritage collections. However, cultural heritage KGs are far from being
complete. They are often missing important attributes such as geographical
location, especially for sculptures and mobile or indoor entities such as
paintings. In this paper, we first present a framework for ingesting knowledge
about tangible cultural heritage entities from various data sources and their
connected multi-hop knowledge into a geolocalized KG. Secondly, we propose a
multi-view learning model for estimating the relative distance between a given
pair of cultural heritage entities, based on the geographical as well as the
knowledge connections of the entities.",118,7,798,34.56
2900,cultural anthropology,"Recent years have seen both a revival of space programs, mostly propelled by
private industry's increasing interest, but also the emergence of strong
resistance to human space activities on several levels. This is partly a
manifestation of a wider counter-Enlightenment Zeitgeist, as detectable in
other sectors of public life in the West, and partly a reaction against the
widespread engagement of the private sector. While it still does not dominate
the discourse on space issues, space skepticism is surprisingly wide-ranging
and decentralized phenomenon, gathering together heterogeneous strands of
thought from pro-Enlightenment liberals to rabid ""deep ecology"" activists to
philosophical pessimists to antiglobalists of all colors. There has been
precious little in way of actively opposing this cultural trend so far,
however. While space engineers and entrepreneurs conduct their ""business as
usual"", there are plethora of risks hidden in this cultural climate, esp. if
one adopts much repeated (and rarely adequately understood) maxim that
""politics is downstream of culture."" The present article will review major
strands of thought within this big tent cultural movement, offer plausible
counter-arguments to space skeptics, and outline important cultural and
public-outreach work which needs to be done to balance the scales.",195,8,1337,34.7
2901,cultural anthropology,"This paper introduces ArtELingo, a new benchmark and dataset, designed to
encourage work on diversity across languages and cultures. Following ArtEmis, a
collection of 80k artworks from WikiArt with 0.45M emotion labels and
English-only captions, ArtELingo adds another 0.79M annotations in Arabic and
Chinese, plus 4.8K in Spanish to evaluate ""cultural-transfer"" performance. More
than 51K artworks have 5 annotations or more in 3 languages. This diversity
makes it possible to study similarities and differences across languages and
cultures. Further, we investigate captioning tasks, and find diversity improves
the performance of baseline models. ArtELingo is publicly available at
https://www.artelingo.org/ with standard splits and baseline models. We hope
our work will help ease future research on multilinguality and culturally-aware
AI.",118,13,846,43.69
2902,cultural anthropology,"Recent research has revealed undesirable biases in NLP data and models.
However, these efforts largely focus on social disparities in the West, and are
not directly portable to other geo-cultural contexts. In this position paper,
we outline a holistic research agenda to re-contextualize NLP fairness research
for the Indian context, accounting for Indian societal context, bridging
technological gaps in capability and resources, and adapting to Indian cultural
values. We also summarize findings from an empirical study on various social
biases along different axes of disparities relevant to India, demonstrating
their prevalence in corpora and models.",95,5,655,13.48
2903,cultural anthropology,"Understanding the COVID-19 vaccine hesitancy, such as who and why, is very
crucial since a large-scale vaccine adoption remains as one of the most
efficient methods of controlling the pandemic. Such an understanding also
provides insights into designing successful vaccination campaigns for future
pandemics. Unfortunately, there are many factors involving in deciding whether
to take the vaccine, especially from the cultural point of view. To obtain
these goals, we design a novel culture-aware machine learning (ML) model, based
on our new data collection, for predicting vaccination willingness. We further
analyze the most important features which contribute to the ML model's
predictions using advanced AI explainers such as the Probabilistic Graphical
Model (PGM) and Shapley Additive Explanations (SHAP). These analyses reveal the
key factors that most likely impact the vaccine adoption decisions. Our
findings show that Hispanic and African American are most likely impacted by
cultural characteristics such as religions and ethnic affiliation, whereas the
vaccine trust and approval influence the Asian communities the most. Our
results also show that cultural characteristics, rumors, and political
affiliation are associated with increased vaccine rejection.",181,9,1271,23.16
2904,cultural anthropology,"Figurative language permeates human communication, but at the same time is
relatively understudied in NLP. Datasets have been created in English to
accelerate progress towards measuring and improving figurative language
processing in language models (LMs). However, the use of figurative language is
an expression of our cultural and societal experiences, making it difficult for
these phrases to be universally applicable. In this work, we create a
figurative language inference dataset, \datasetname, for seven diverse
languages associated with a variety of cultures: Hindi, Indonesian, Javanese,
Kannada, Sundanese, Swahili and Yoruba. Our dataset reveals that each language
relies on cultural and regional concepts for figurative expressions, with the
highest overlap between languages originating from the same region. We assess
multilingual LMs' abilities to interpret figurative language in zero-shot and
few-shot settings. All languages exhibit a significant deficiency compared to
English, with variations in performance reflecting the availability of
pre-training and fine-tuning data, emphasizing the need for LMs to be exposed
to a broader range of linguistic and cultural variation during training.",169,8,1211,13.17
2905,cultural anthropology,"The Axelrod model is a cellular automaton which can be used to describe the
emergence and development of cultural domains, where culture is represented by
a fixed number of cultural features taking a discrete set of possible values
(traits). The Axelrod model is based on two sociological phenomena: homophily
(a tendency for individuals to form bonds with people similar to themselves)
and social influence (the way how individuals change their behavior due to
social pressure). However, the Axelrod model does not take into account the
fact that cultural attributes may have different significance for a given
individual. This is a limitation in the context of how the model reflects
mechanisms driving the evolution of real societies. The study aims to modify
the Axelrod model by giving individual features different weights that have a
decisive impact on the possibility of aligning cultural traits between
(interacting) individuals. The comparison of the results obtained for the
classic Axelrod model and its modified version shows that introduced weights
have a significant impact on the course of the system development, in
particular, increasing the final polarization of the system and increasing the
time needed to reach the final state.",194,7,1249,21.77
2906,cultural anthropology,"Moral norms vary across cultures. A recent line of work suggests that English
large language models contain human-like moral biases, but these studies
typically do not examine moral variation in a diverse cultural setting. We
investigate the extent to which monolingual English language models contain
knowledge about moral norms in different countries. We consider two levels of
analysis: 1) whether language models capture fine-grained moral variation
across countries over a variety of topics such as ``homosexuality'' and
``divorce''; 2) whether language models capture cultural diversity and shared
tendencies in which topics people around the globe tend to diverge or agree on
in their moral judgment. We perform our analyses with two public datasets from
the World Values Survey (across 55 countries) and PEW global surveys (across 40
countries) on morality. We find that pre-trained English language models
predict empirical moral norms across countries worse than the English moral
norms reported previously. However, fine-tuning language models on the survey
data improves inference across countries at the expense of a less accurate
estimate of the English moral norms. We discuss the relevance and challenges of
incorporating cultural knowledge into the automated inference of moral norms.",193,9,1301,38.55
2907,cultural anthropology,"Recent developments in MIR have led to several benchmark deep learning models
whose embeddings can be used for a variety of downstream tasks. At the same
time, the vast majority of these models have been trained on Western pop/rock
music and related styles. This leads to research questions on whether these
models can be used to learn representations for different music cultures and
styles, or whether we can build similar music audio embedding models trained on
data from different cultures or styles. To that end, we leverage transfer
learning methods to derive insights about the similarities between the
different music cultures to which the data belongs to. We use two Western music
datasets, two traditional/folk datasets coming from eastern Mediterranean
cultures, and two datasets belonging to Indian art music. Three deep audio
embedding models are trained and transferred across domains, including two
CNN-based and a Transformer-based architecture, to perform auto-tagging for
each target domain dataset. Experimental results show that competitive
performance is achieved in all domains via transfer learning, while the best
source dataset varies for each music culture. The implementation and the
trained models are both provided in a public repository.",192,9,1267,47.12
2908,cultural anthropology,"Large language models (LLMs) are highly adept at question answering and
reasoning tasks, but when reasoning in a situational context, human
expectations vary depending on the relevant cultural common ground. As
languages are associated with diverse cultures, LLMs should also be
culturally-diverse reasoners. In this paper, we study the ability of a wide
range of state-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and
sayings in a conversational context. Our experiments reveal that: (1) mLLMs
""know"" limited proverbs and memorizing proverbs does not mean understanding
them within a conversational context; (2) mLLMs struggle to reason with
figurative proverbs and sayings, and when asked to select the wrong answer
(instead of asking it to select the correct answer); and (3) there is a
""culture gap"" in mLLMs when reasoning about proverbs and sayings translated
from other languages. We construct and release our evaluation dataset MAPS
(MulticultrAl Proverbs and Sayings) for proverb understanding with
conversational context for six different languages.",158,6,1075,30.94
2909,cultural anthropology,"We use a large-scale experiment (N=8000) to determine whether GPT-4 can
replicate cross-cultural differences in the Big Five, measured using the
Ten-Item Personality Inventory. We used the US and South Korea as the cultural
pair, given that prior research suggests substantial personality differences
between people from these two countries. We manipulated the target of the
simulation (US vs. Korean), the language of the inventory (English vs. Korean),
and the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4
replicated the cross-cultural differences for each factor. However, mean
ratings had an upward bias and exhibited lower variation than in the human
samples, as well as lower structural validity. Overall, we provide preliminary
evidence that LLMs can aid cross-cultural psychological research.",120,11,819,30.87
2910,cultural anthropology,"Accurate representation in media is known to improve the well-being of the
people who consume it. Generative image models trained on large web-crawled
datasets such as LAION are known to produce images with harmful stereotypes and
misrepresentations of cultures. We improve inclusive representation in
generated images by (1) engaging with communities to collect a culturally
representative dataset that we call the Cross-Cultural Understanding Benchmark
(CCUB) and (2) proposing a novel Self-Contrastive Fine-Tuning (SCoFT) method
that leverages the model's known biases to self-improve. SCoFT is designed to
prevent overfitting on small datasets, encode only high-level information from
the data, and shift the generated distribution away from misrepresentations
encoded in a pretrained model. Our user study conducted on 51 participants from
5 different countries based on their self-selected national cultural
affiliation shows that fine-tuning on CCUB consistently generates images with
higher cultural relevance and fewer stereotypes when compared to the Stable
Diffusion baseline, which is further improved with our SCoFT technique.",159,6,1139,13.82
2911,cultural anthropology,"While human annotations play a crucial role in language technologies,
annotator subjectivity has long been overlooked in data collection. Recent
studies that have critically examined this issue are often situated in the
Western context, and solely document differences across age, gender, or racial
groups. As a result, NLP research on subjectivity have overlooked the fact that
individuals within demographic groups may hold diverse values, which can
influence their perceptions beyond their group norms. To effectively
incorporate these considerations into NLP pipelines, we need datasets with
extensive parallel annotations from various social and cultural groups. In this
paper we introduce the \dataset dataset: a large-scale cross-cultural dataset
of parallel annotations for offensive language in over 4.5K sentences annotated
by a pool of over 4k annotators, balanced across gender and age, from across 21
countries, representing eight geo-cultural regions. The dataset contains
annotators' moral values captured along six moral foundations: care, equality,
proportionality, authority, loyalty, and purity. Our analyses reveal
substantial regional variations in annotators' perceptions that are shaped by
individual moral values, offering crucial insights for building pluralistic,
culturally sensitive NLP models.",181,9,1322,23.16
2912,cultural anthropology,"We study cultural and socioeconomic diversity in contrastive vision-language
models (VLMs). Using a broad range of benchmark datasets and evaluation
metrics, we bring to attention several important findings. First, the common
filtering of training data to English image-text pairs disadvantages
communities of lower socioeconomic status and negatively impacts cultural
understanding. Notably, this performance gap is not captured by - and even at
odds with - the currently popular evaluation metrics derived from the
Western-centric ImageNet and COCO datasets. Second, pretraining with global,
unfiltered data before fine-tuning on English content can improve cultural
understanding without sacrificing performance on said popular benchmarks.
Third, we introduce the task of geo-localization as a novel evaluation metric
to assess cultural diversity in VLMs. Our work underscores the value of using
diverse data to create more inclusive multimodal systems and lays the
groundwork for developing VLMs that better represent global perspectives.",145,8,1042,16.93
2913,cultural anthropology,"Popularity bias in music recommendation systems -- where artists and tracks
with the highest listen counts are recommended more often -- can also propagate
biases along demographic and cultural axes. In this work, we identify these
biases in recommendations for artists from underrepresented cultural groups in
prototype-based matrix factorization methods. Unlike traditional matrix
factorization methods, prototype-based approaches are interpretable. This
allows us to directly link the observed bias in recommendations for minority
artists (the effect) to specific properties of the embedding space (the cause).
We mitigate popularity bias in music recommendation through capturing both
users' and songs' cultural nuances in the embedding space. To address these
challenges while maintaining recommendation quality, we propose two novel
enhancements to the embedding space: i) we propose an approach to filter-out
the irrelevant prototypes used to represent each user and item to improve
generalizability, and ii) we introduce regularization techniques to reinforce a
more uniform distribution of prototypes within the embedding space. Our results
demonstrate significant improvements in reducing popularity bias and enhancing
demographic and cultural fairness in music recommendations while achieving
competitive -- if not better -- overall performance.",186,8,1356,11.25
2914,cultural anthropology,"We propose the use of hierarchical taxonomy to analyze the legislative
election results as a model of multi-party system to show the robustness in
political system. As an example we use the result of Indonesian legislative
election 2004 is analyzed with certain comparative with the previous one
(1999). We construct the graph theoretical analysis by finding the Euclidean
distances among political parties. The distances are then treated in
ultrametric spaces by using the minimum spanning tree algorithm. By having the
Indonesian hierarchical taxonomy model of political parties we show some
patterns emerging the pattern agrees with the classical anthropological
analysis of socio-political system in Indonesia. This fact accentuates a
character of robustness in Indonesian political society as a self-organized
system evolves to critical state. Some small perturbations i.e.: different
voting process resulting the same pattern and occasions statistically, emerges
from the social structure based upon political streams: Islamic, secular,
traditional, and some complements of all.",155,10,1084,17.94
2915,cultural anthropology,"Questions of participant understanding of the nature of an activity have been
addressed in anthropology and sociolinguistics with the concepts of frames and
framing. For example, a student may frame a learning activity as an opportunity
for sensemaking or as an assignment to fill out a worksheet. The student's
understanding of the nature of the activity affects what she notices, what
knowledge she accesses, and how she thinks to act. Previous analyses have found
evidence of framing primarily in linguistic markers associated with speech
acts. In this paper, we show that there is useful evidence of framing in easily
observed features of students' behavior. We apply this observational
methodology to explore dynamics among behavior, framing, and the conceptual
substance of student reasoning in the context of collaborative active-learning
activities in an introductory university physics course.",135,7,902,23.26
2916,cultural anthropology,"Mapping human genetic variation is fundamentally interesting in fields such
as anthropology and forensic inference. At the same time patterns of genetic
diversity confound efforts to determine the genetic basis of complex disease.
Due to technological advances it is now possible to measure hundreds of
thousands of genetic variants per individual across the genome. Principal
component analysis (PCA) is routinely used to summarize the genetic similarity
between subjects. The eigenvectors are interpreted as dimensions of ancestry.
We build on this idea using a spectral graph approach. In the process we draw
on connections between multidimensional scaling and spectral kernel methods.
Our approach, based on a spectral embedding derived from the normalized
Laplacian of a graph, can produce more meaningful delineation of ancestry than
by using PCA. The method is stable to outliers and can more easily incorporate
different similarity measures of genetic data than PCA. We illustrate a new
algorithm for genetic clustering and association analysis on a large,
genetically heterogeneous sample.",162,11,1098,29.65
2917,cultural anthropology,"Ecosystems monitoring is essential to properly understand their development
and the effects of events, both climatological and anthropological in nature.
The amount of data used in these assessments is increasing at very high rates.
This is due to increasing availability of sensing systems and the development
of new techniques to analyze sensor data. The Enviro-Net Project encompasses
several of such sensor system deployments across five countries in the
Americas. These deployments use a few different ground-based sensor systems,
installed at different heights monitoring the conditions in tropical dry
forests over long periods of time. This paper presents our experience in
deploying and maintaining these systems, retrieving and pre-processing the
data, and describes the Web portal developed to help with data management,
visualization and analysis.",124,7,859,25.08
2918,cultural anthropology,"Given a pair of distinct vertices u, v in a graph G, we say that s is a
junction of u, v if there are in G internally vertex disjoint directed paths
from s to u and from s to v. We show how to characterize junctions in directed
acyclic graphs. We also consider the two problems in the following and derive
efficient algorithms to solve them. Given a directed acyclic graph G and a
vertex s in G, how can we find all pairs of vertices of G such that s is a
junction of them? And given a directed acyclic graph G and k pairs of vertices
of G, how can we preprocess G such that all junctions of k given pairs of
vertices could be listed quickly? All junctions of k pairs problem arises in an
application in Anthropology and we apply our algorithm to find such junctions
on kinship networks of some brazilian indian ethnic groups.",160,5,826,61.29
2919,cultural anthropology,"In the high dimensional Stochastic Blockmodel for a random network, the
number of clusters (or blocks) K grows with the number of nodes N. Two previous
studies have examined the statistical estimation performance of spectral
clustering and the maximum likelihood estimator under the high dimensional
model; neither of these results allow K to grow faster than N^{1/2}. We study a
model where, ignoring log terms, K can grow proportionally to N. Since the
number of clusters must be smaller than the number of nodes, no reasonable
model allows K to grow faster; thus, our asymptotic results are the ""highest""
dimensional. To push the asymptotic setting to this extreme, we make additional
assumptions that are motivated by empirical observations in physical
anthropology (Dunbar, 1992), and an in depth study of massive empirical
networks (Leskovec et al 2008). Furthermore, we develop a regularized maximum
likelihood estimator that leverages these insights and we prove that, under
certain conditions, the proportion of nodes that the regularized estimator
misclusters converges to zero. This is the first paper to explicitly introduce
and demonstrate the advantages of statistical regularization in a parametric
form for network analysis.",189,8,1240,27.15
2920,cultural anthropology,"How did the human species evolve the capacity not just to communicate complex
ideas to one another but to hold such conversations from across the globe,
using remote devices constructed from substances that do not exist in the
natural world, the raw materials for which may have been hauled up from the
bowels of the earth? How did we come to be so intelligent? Research at the
interface of psychology, biology, anthropology, archaeology, and cognitive
science is culminating in an increasingly sophisticated understanding of how
human intelligence evolved. Studies of the brains of living humans and great
apes and the intellectual abilities they support are enabling us to assess what
is unique about human intelligence and what we share with our primate
relatives. Examining the habitats and skeletons of our ancestors gives cues as
to environmental, social, and anatomical factors that both constrain and enable
the evolution of human intelligence. Relics of the past also have much to tell
us about the thoughts, beliefs, and abilities of the individuals who invented
and used them.",174,5,1087,33.58
2921,cultural anthropology,"Growth in brain volume is one of the most spectacular changes in the hominid
lineage. The anthropological community agrees on that point. No consensus,
however, has been reached on selection pressures contributing to that growth.
In that respect Martin (1984) can be invoked. In his review of size
relationships among primates he stated that despite the relationship between
brain size, body size and feeding behavior no single interpretation could be
provided that revealed the causality of such relationship.
  This paper deals with one specific aspect of hominid brain growth; the fact
that for most of the hominid period, growth in brain volume was exponential in
character. To the best of our knowledge, no attempt has been made to identify a
selection mechanism that can facilitate just the exponential features of that
growth (as distinct from any of its other characteristics). It is broadly
accepted that the dynamics of this growth were peculiar. Growth was very fast,
or even rapid in the evolutionary scale of time. The most profound evidence of
that opinion was expressed by Haldane that this dramatic increase in brain size
was the most rapid evolutionary change known to him.",192,11,1190,51.99
2922,cultural anthropology,"Social network analysis emerged as an important research topic in sociology
decades ago, and it has also attracted scientists from various fields of study
like psychology, anthropology, geography and economics. In recent years, a
significant number of researches has been conducted on using social network
analysis to design e-commerce recommender systems. Most of the current
recommender systems are designed for B2C e-commerce websites. This paper
focuses on building a recommendation algorithm for C2C e-commerce business
model by considering special features of C2C e-commerce websites. In this
paper, we consider users and their transactions as a network; by this mapping,
link prediction technique which is an important task in social network analysis
could be used to build the recommender system. The proposed tow-level
recommendation algorithm, rather than topology of the network, uses nodes
features like: category of items, ratings of users, and reputation of sellers.
The results show that the proposed model can be used to predict a portion of
future trades between users in a C2C commercial network.",168,8,1114,30.2
2923,cultural anthropology,"The problem of link prediction has attracted considerable recent attention
from various domains such as sociology, anthropology, information science, and
computer sciences. A link prediction algorithm is proposed based on link
similarity score propagation by a random walk in networks with nodes
attributes. In the algorithm, each link in the network is assigned a
transmission probability according to the similarity of the attributes on the
nodes connected by the link. The link similarity score between the nodes are
then propagated via the links according to their transmission probability. Our
experimental results show that it can obtain higher quality results on the
networks with node attributes than other algorithms.",108,6,726,24.17
2924,cultural anthropology,"Evolutionary and Interpretive Archaeologies, edited by Ethan E. Cochrane and
Andrew Gardner, grew out of a seminar at the Institute for Archaeology at
University College London in 2007. It consists of 15 chapters by archaeologists
who self-identify themselves as practitioners who emphasize the benefits of
evolutionary or interpretive approaches to the study of the archaeological
record. While the authors' theoretical views are dichotomous, the editors' aim
for the book as a whole is not to expound on the differences between these two
kinds of archaeology but to bring forward a richer understanding of the
discipline and to highlight areas of mutual concern. Some chapters come across
as a bit of a sales pitch, but the majority of the contributions emphasize how
each approach can be productively used to address the goals of the other. The
book seeks to contribute to a mutually beneficial and more productive
discipline, and overall, it succeeds in this effort.",154,7,970,36.93
2925,cultural anthropology,"The genetic structure of human populations is extraordinarily complex and of
fundamental importance to studies of anthropology, evolution, and medicine.
  As increasingly many individuals are of mixed origin, there is an unmet need
for tools that can infer multiple origins. Misclassification of such
individuals can lead to incorrect and costly misinterpretations of genomic
data, primarily in disease studies and drug trials.
  We present an advanced tool to infer ancestry that can identify the
biogeographic origins of highly mixed individuals.
  reAdmix is an online tool available at
http://chcb.saban-chla.usc.edu/reAdmix/.",87,9,630,19.97
2926,cultural anthropology,"Provided n points in an (n-1)-dimensional affine space, and one ordering of
the points for each coordinate, we address the problem of testing whether these
orderings determine if the points are the vertices of a simplex (i.e. are
affinely independent), regardless of the real values of the coordinates. We
also attempt to determine the orientation of this simplex. In other words,
given a matrix whose columns correspond to affine points, we want to know when
the sign (or the non-nullity) of its determinant is implied by orderings given
to each row for the values of the row. We completely solve the problem in
dimensions 2 and 3. We provide a direct combinatorial characterization, along
with a formal calculus method. It can also be viewed as a decision algorithm,
and is based on testing the existence of a suitable inductive cofactor
expansion of the determinant. We conjecture that our method generalizes in
higher dimensions. This work aims to be part of a study on how oriented
matroids encode shapes of 3-dimensional landmark-based objects. Specifically,
applications include the analysis of anatomical data for physical anthropology
and clinical research.",186,12,1166,44.14
2927,cultural anthropology,"Aboriginal Australians carefully observe the properties and positions of
stars, including both overt and subtle changes in their brightness, for
subsistence and social application. These observations are encoded in oral
tradition. I examine two Aboriginal oral traditions from South Australia that
describe the periodic changing brightness in three pulsating, red-giant
variable stars: Betelgeuse (Alpha Orionis), Aldebaran (Alpha Tauri), and
Antares (Alpha Scorpii). The Australian Aboriginal accounts stand as the only
known descriptions of pulsating variable stars in any Indigenous oral tradition
in the world. Researchers examining these oral traditions over the last
century, including anthropologists and astronomers, missed the description of
these stars as being variable in nature as the ethnographic record contained
several misidentifications of stars and celestial objects. Arguably,
ethnographers working on Indigenous Knowledge Systems should have academic
training in both the natural and social sciences.",138,7,1021,22.75
2928,cultural anthropology,"Studies in Australian Indigenous astronomical knowledge reveal few accounts
of the visible planets in the sky. However, what information we do have tells
us that Aboriginal people were close observers of planets and their motions,
noting the relative brightness of the planets, their motions along the
ecliptic, retrograde motion, the relationship between Venus and its proximity
to the Sun, Venus' connection to the Sun through zodiacal light, and the
synodic cycle of Venus, particularly as it transitions from the Evening Star to
the Morning Star. The dearth of descriptions of planets in Aboriginal
traditions may be due to the gross incompleteness of recorded astronomical
traditions, and of ethnographic bias and misidentification in the
anthropological record. Ethnographic fieldwork with Aboriginal and Torres
Strait Islander communities is revealing new, previously unrecorded knowledge
about the planets and their related phenomena.",137,5,942,19.74
2929,cultural anthropology,"This paper focuses on two mathematical topics, namely continuous probability
distributions (CPD) and integral calculus (IC). These two sectors that are
linked by a formula are quite compartmented in teaching classes in France. The
main objective is to study whether French students can mobilize the sector of
IC to solve tasks in CPD and vice versa at the transition from high school to
higher education. Applying the theoretical framework of the Anthropological
Theory of the Didactic (ATD), we describe a reference epistemological model
(REM) and use it to elaborate a questionnaire in order to test the capacity of
students to bridge CPD and IC at the onset of university. The analysis of the
data essentially confirms the compartmentalisation of CPD and IC.",122,6,761,29.79
2930,cultural anthropology,"English: To the Meriam Mir people of Mer (Murray Island) in the eastern
Torres Strait, bright meteors are an important element of death customs and
beliefs. We draw from a combination of ethno-historic studies and interviews
with Meriam elders to understand the role of bright meteors (Maier) in Torres
Strait traditions relating to spiritual elements of death rites using a
framework of symbolic anthropology. We find that bright meteors serve as
symbolic representations of death and mortuary purification practices and show
how the physical properties of meteors are incorporated in ritual, belief,
spirituality, and custom.
  Meriam Mir: Meriamgize maier oditautlare nade eud onagri a mokakalam eud
kerker. Kemerkemer daratkapda kikem kerkerira pardar, dorge a oka nako Torres
Straitge eud tonar bud ueplare. Debe bibi maieride onatager eud ia onagri a
nalu tonar able maierira seri/kakaper a dum able tonar umerem a simir akedrem.",143,7,935,38.86
2931,cultural anthropology,"Motivation: In forensic or medico-legal investigation as well as in
anthropology the gender determination of the subject (hit by a disastrous or
any kind of traumatic situation) is mostly the first step. In state-of-the-art
techniques the gender is determined by examining dimensions of the bones of
skull and the pelvis area. In worse situations when there is only a small
portion of the human remains to be investigated and the subject is a child, we
need alternative techniques to determine the gender of the subject. In this
work we propose a technique called GDCNN (Gender Determination with
Convolutional Neural Networks), where the left hand radio-graphs of the
children between a wide range of ages in 1 month to 18 years are examined to
determine the gender. To our knowledge this technique is first of its kind.
Further to identify the area of the attention we used Class Activation Mapping
(CAM). Results: The results suggest the accuracy of the model is as high as
98%, which is very convincing by taking into account the incompletely grown
skeleton of the children. The attention observed with CAM discovers that the
lower part of the hand around carpals (wrist) is more important for child
gender determination.",202,9,1225,45.8
2932,cultural anthropology,"The seriation problem is an important ordering issue which consists of
finding the best ordering of a set of units whose interrelationship is defined
by a bipartite graph. It has important applications in, e.g., archaeology,
anthropology, psychology, and biology. This paper presents a Matlab
implementation of an algorithm for spectral seriation by Atkins et al., based
on the use of the Fiedler vector of the Laplacian matrix associated to the
problem, which encodes the set of admissible solutions into a PQ-tree. We
introduce some numerical technicalities in the original algorithm to improve
its performance, and point out that the presence of a multiple Fiedler value
may have a substantial influence on the computation of an approximated
solution, in the presence of inconsistent data sets. Practical examples and
numerical experiments show how to use the toolbox to process data sets deriving
from real-world applications.",143,9,930,25.39
2933,cultural anthropology,"There is a marked lack of literature on user-submitted sexual videos from
Latin America. To start filling that gap, we present a formal statistical
testing of several hypotheses about the characteristics of 214 videos from
Nereliatube.com posted from the inauguration of the site until December 2010.
We found that in most cases the video was made consensually and the camera was
operated by the man. The most frequent practice shown was fellatio, followed by
vaginal penetration. The great majority of videos showed the sexual
interactions of one woman with one man; group sex was rare. Violence and
manifestations of power were rare and when there was violence it was mostly
simulated. Latin American user-submitted sexual videos in Nereliatube generally
reflect a society in which women and men have a variety of sexual practices
that are mostly consensual and that do not differ from the biologically and
anthropologically expected patterns.",149,9,945,35.68
2934,cultural anthropology,"Computational social scientists often harness the Web as a ""societal
observatory"" where data about human social behavior is collected. This data
enables novel investigations of psychological, anthropological and sociological
research questions. However, in the absence of demographic information, such as
gender, many relevant research questions cannot be addressed. To tackle this
problem, researchers often rely on automated methods to infer gender from name
information provided on the web. However, little is known about the accuracy of
existing gender-detection methods and how biased they are against certain
sub-populations. In this paper, we address this question by systematically
comparing several gender detection methods on a random sample of scientists for
whom we know their full name, their gender and the country of their workplace.
We further suggest a novel method that employs web-based image retrieval and
gender recognition in facial images in order to augment name-based approaches.
Our findings show that the performance of name-based gender detection
approaches can be biased towards countries of origin and such biases can be
reduced by combining name-based an image-based gender detection methods.",177,9,1223,23.66
2935,cultural anthropology,"Many scientific areas are faced with the challenge of extracting information
from large, complex, and highly structured data sets. A great deal of modern
statistical work focuses on developing tools for handling such data. This paper
presents a new subfield of functional data analysis, FDA, which we call
Manifold Data Analysis, or MDA. MDA is concerned with the statistical analysis
of samples where one or more variables measured on each unit is a manifold,
thus resulting in as many manifolds as we have units. We propose a framework
that converts manifolds into functional objects, an efficient 2-step functional
principal component method, and a manifold-on-scalar regression model. This
work is motivated by an anthropological application involving 3D facial imaging
data, which is discussed extensively throughout the paper. The proposed
framework is used to understand how individual characteristics, such as age and
genetic ancestry, influence the shape of the human face.",149,8,982,32.94
2936,cultural anthropology,"This paper analyzes the evolution of coauthorship in Spain in the social
sciences between 2000 and 2013. The goal is to explore to which extent
limitations on the number of coauthors established by Spanish national
evaluation agencies are justified. The analysis of 11681 papers authored by
researchers affiliated to Spanish institutions in 20 subject categories of the
social sciences reveals that there is no inflation in the number of authors,
team size is similar to that found in foreign papers and the number of authors
is dependent on international and institutional collaboration. With the
exception of Anthropology and Special Education, in no area the average of
authors by paper is higher than four. However, papers with a higher number of
authors receive more citations. Overall, our results suggest that there is no
justification on limiting the number of coauthors in publications,
acknowledging that their inclusion in the criteria employed by Spanish
evaluation agencies is to prevent honorary authors. Such limitation endangers
institutional and international collaboration, and consequently, high impact
research.",170,8,1131,21.43
2937,cultural anthropology,"The Vim text editor is very rich in capabilities and thus complex. This
article is a description of Vim and a set of considerations about its usage and
design. It results from more than ten years of experience in using Vim for
writing and editing various types of documents, e.g. Python, C++, JavaScript,
ChucK programs; \LaTeX, Markdown, HTML, RDF, Make and other markup files; % TTM
binary files. It is commonplace, in the Vim users and developers communities,
to say that it takes about ten years to master (or start mastering) this text
editor, and I find that other experienced users have a different view of Vim
and that they use a different set of features. Therefore, this document exposes
my understandings in order to confront my usage with that of other Vim users.
Another goal is to make available a reference document with which new users can
grasp a sound overview by reading it and the discussions that it might
generate. Also, it should be useful for users of any degree of experience,
including me, as a compendium of commands, namespaces and tweaks. Upon
feedback, and maturing of my Vim usage, this document might be enhanced and
expanded.",199,11,1158,57.61
2938,cultural anthropology,"Studying how diverse human populations are related is of historical and
anthropological interest, in addition to providing a realistic null model for
testing for signatures of natural selection or disease associations.
Furthermore, understanding the demographic histories of other species is
playing an increasingly important role in conservation genetics. A number of
statistical methods have been developed to infer population demographic
histories using whole-genome sequence data, with recent advances focusing on
allowing for more flexible modeling choices, scaling to larger data sets, and
increasing statistical power. Here we review coalescent hidden Markov models, a
powerful class of population genetic inference methods that can effectively
utilize linkage disequilibrium information. We highlight recent advances, give
advice for practitioners, point out potential pitfalls, and present possible
future research directions.",125,6,935,-4.67
2939,cultural anthropology,"Shape analysis is important in anthropology, bioarchaeology and forensic
science for interpreting useful information from human remains. In particular,
teeth are morphologically stable and hence well-suited for shape analysis. In
this work, we propose a framework for tooth morphometry using quasi-conformal
theory. Landmark-matching Teichm\""uller maps are used for establishing a 1-1
correspondence between tooth surfaces with prescribed anatomical landmarks.
Then, a quasi-conformal statistical shape analysis model based on the
Teichm\""uller mapping results is proposed for building a tooth classification
scheme. We deploy our framework on a dataset of human premolars to analyze the
tooth shape variation among genders and ancestries. Experimental results show
that our method achieves much higher classification accuracy with respect to
both gender and ancestry when compared to the existing methods. Furthermore,
our model reveals the underlying tooth shape difference between different
genders and ancestries in terms of the local geometric distortion and
curvatures.",147,9,1075,18.96
2940,cultural anthropology,"We show how to compute the circular area invariant of planar curves, and the
spherical volume invariant of surfaces, in terms of line and surface integrals,
respectively. We use the Divergence Theorem to express the area and volume
integrals as line and surface integrals, respectively, against particular
kernels; our results also extend to higher dimensional hypersurfaces. The
resulting surface integrals are computable analytically on a triangulated mesh.
This gives a simple computational algorithm for computing the spherical volume
invariant for triangulated surfaces that does not involve discretizing the
ambient space. We discuss potential applications to feature detection on broken
bone fragments of interest in anthropology.",105,6,737,16.32
2941,cultural anthropology,"In addition to their security properties, adversarial machine-learning
attacks and defenses have political dimensions. They enable or foreclose
certain options for both the subjects of the machine learning systems and for
those who deploy them, creating risks for civil liberties and human rights. In
this paper, we draw on insights from science and technology studies,
anthropology, and human rights literature, to inform how defenses against
adversarial attacks can be used to suppress dissent and limit attempts to
investigate machine learning systems. To make this concrete, we use real-world
examples of how attacks such as perturbation, model inversion, or membership
inference can be used for socially desirable ends. Although the predictions of
this analysis may seem dire, there is hope. Efforts to address human rights
concerns in the commercial spyware industry provide guidance for similar
measures to ensure ML systems serve democratic, not authoritarian ends",144,6,972,30.2
2942,cultural anthropology,"Chronometric dating is becoming increasingly important in areas such as the
Origin and evolution of Life on Earth and other planets, Origin and evolution
of the Earth and the Solar System... Electron Spin Resonance (ESR) dating is
based on exploiting effects of contamination by chemicals or ionizing
radiation, on ancient matter through its absorption spectrum and lineshape.
Interpreting absorption spectra as probability density functions (pdf), we use
the notion of Information Theory (IT) distance allowing us to position the
measured lineshape with respect to standard limiting pdf's (Lorentzian and
Gaussian). This paves the way to perform dating when several interaction
patterns between unpaired spins are present in geologic, planetary, meteorite
or asteroid matter namely classical-dipolar (for ancient times) and
quantum-exchange-coupled (for recent times). In addition, accurate bounds to
age are provided by IT from the evaluation of distances with respect to the
Lorentz and Gauss distributions. Dating arbitrary periods of
times~\cite{Anderson} and exploiting IT to introduce rigorous and accurate date
values might have interesting far reaching implications not only in Geophysics,
Geochronology~\cite{Bahain}, Planetary Science but also in Mineralogy,
Archaeology, Biology, Anthropology~\cite{Aitken},
Paleoanthropology~\cite{Taylor,Richter}...",182,11,1362,6.88
2943,cultural anthropology,"The analysis of record-breaking events is of interest in fields such as
climatology, hydrology or anthropology. In connection with the record
occurrence, we propose three distribution-free statistics for the changepoint
detection problem. They are CUSUM-type statistics based on the upper and/or
lower record indicators observed in a series. Using a version of the functional
central limit theorem, we show that the CUSUM-type statistics are
asymptotically Kolmogorov distributed. The main results under the null
hypothesis are based on series of independent and identically distributed
random variables, but a statistic to deal with series with seasonal component
and serial correlation is also proposed. A Monte Carlo study of size, power and
changepoint estimate has been performed. Finally, the methods are illustrated
by analyzing the time series of temperatures at Madrid, Spain.
  The R package $\texttt{RecordTest}$ publicly available on CRAN implements the
proposed methods.",141,9,983,36.69
2944,cultural anthropology,"Figurative drawing is a skill that takes time to learn, and evolves during
different childhood phases that begin with scribbling and end with
representational drawing. Between these phases, it is difficult to assess when
and how children demonstrate intentions and representativeness in their
drawings. The marks produced are increasingly goal-oriented and efficient as
the child's skills progress from scribbles to figurative drawings.
Pre-figurative activities provide an opportunity to focus on drawing processes.
We applied fourteen metrics to two different datasets (N=65 and N=345) to
better understand the intentional and representational processes behind
drawing, and combined these metrics using principal component analysis (PCA) in
different biologically significant dimensions. Three dimensions were
identified: efficiency based on spatial metrics, diversity with colour metrics,
and temporal sequentiality. The metrics at play in each dimension are similar
for both datasets, and PCA explains 77% of the variance in both datasets. These
analyses differentiate scribbles by children from those drawn by adults. The
three dimensions highlighted by this study provide a better understanding of
the emergence of intentions and representativeness in drawings. We have already
discussed the perspectives of such findings in Comparative Psychology and
Evolutionary Anthropology.",191,11,1384,26.71
2945,cultural anthropology,"Semantic segmentation is a challenging computer vision task demanding a
significant amount of pixel-level annotated data. Producing such data is a
time-consuming and costly process, especially for domains with a scarcity of
experts, such as medicine or forensic anthropology. While numerous
semi-supervised approaches have been developed to make the most from the
limited labeled data and ample amount of unlabeled data, domain-specific
real-world datasets often have characteristics that both reduce the
effectiveness of off-the-shelf state-of-the-art methods and also provide
opportunities to create new methods that exploit these characteristics. We
propose and evaluate a semi-supervised method that reuses available labels for
unlabeled images of a dataset by exploiting existing similarities, while
dynamically weighting the impact of these reused labels in the training
process. We evaluate our method on a large dataset of human decomposition
images and find that our method, while conceptually simple, outperforms
state-of-the-art consistency and pseudo-labeling-based methods for the
segmentation of this dataset. This paper includes graphic content of human
decomposition.",162,7,1183,18.69
2946,cultural anthropology,"The cyber-physical convergence, the fast expansion of the Internet at its
edge, and tighter interactions between human users and their personal mobile
devices push towards a data-centric Internet where the human user becomes more
central than ever. We argue that this will profoundly impact primarily on the
way data should be handled in the Next Generation Internet. It will require a
radical change of the Internet data-management paradigm, from the current
platform-centric to a human-centric model. In this paper we present a new
paradigm for Internet data management that we name Internet of People (IoP)
because it embeds human behavior models in its algorithms. To this end, IoP
algorithms exploit quantitative models of the humans' individual and social
behavior, from sociology, anthropology, psychology, economics, physics. IoP is
not a replacement of the current Internet networking infrastructure, but it
exploits legacy Internet services as (reliable) primitives to achieve
end-to-end connectivity on a global-scale. In this opinion paper, we first
discuss the key features of the IoP paradigm along with the underlying research
issues and challenges. Then, we present emerging data-management paradigms that
are anticipating IoP.",184,9,1243,31.21
2947,cultural anthropology,"Networks have always played a special role for human beings in shaping social
relations, forming public opinion, and driving economic equilibria. Nowadays,
online networked platforms dominate digital markets and capitalization
leader-boards, while social networks drive public discussion. Despite the
importance of networks in many economic and social domains (economics,
sociology, anthropology, psychology,...), the knowledge about the laws that
dominate their dynamics is still scarce and fragmented. Here, we analyse a wide
set of online networks (those financed by advertising) by investigating their
value dynamics from several perspectives: the type of service, the geographic
scope, the merging between networks, and the relationship between economic and
financial value. The results show that the networks are dominated by strongly
nonlinear dynamics. The existence of non-linearity is often underestimated in
social sciences because it involves contexts that are difficult to deal with,
such as the presence of multiple equilibria -- some of which are unstable. Yet,
these dynamics must be fully understood and addressed if we aim to understand
the recent evolution in the economic, political and social milieus, which are
precisely characterised by corner equilibria (e.g., polarization,
winner-take-all solutions, increasing inequality) and nonlinear patterns.",191,13,1372,24.68
2948,cultural anthropology,"Paleoclimatology -- the study of past climate -- is relevant beyond climate
science itself, such as in archaeology and anthropology for understanding past
human dispersal. Information about the Earth's paleoclimate comes from
simulations of physical and biogeochemical processes and from proxy records
found in naturally occurring archives. Climate-field reconstructions (CFRs)
combine these data into a statistical spatial or spatiotemporal model. To date,
there exists no consensus spatiotemporal paleoclimate model that is continuous
in space and time, produces predictions with uncertainty, and can include data
from various sources. A Gaussian process (GP) model would have these desired
properties; however, GPs scale unfavorably with data of the magnitude typical
for building CFRs. We propose to build on recent advances in sparse
spatiotemporal GPs that reduce the computational burden by combining
variational methods based on inducing variables with the state-space
formulation of GPs. We successfully employ such a doubly sparse GP to construct
a probabilistic model of European paleoclimate from the Last Glacial Maximum
(LGM) to the mid-Holocene (MH) that synthesizes paleoclimate simulations and
fossilized pollen proxy data.",175,8,1240,21.02
2949,cultural anthropology,"Domain experts often possess valuable physical insights that are overlooked
in fully automated decision-making processes such as Bayesian optimisation. In
this article we apply high-throughput (batch) Bayesian optimisation alongside
anthropological decision theory to enable domain experts to influence the
selection of optimal experiments. Our methodology exploits the hypothesis that
humans are better at making discrete choices than continuous ones and enables
experts to influence critical early decisions. At each iteration we solve an
augmented multi-objective optimisation problem across a number of alternate
solutions, maximising both the sum of their utility function values and the
determinant of their covariance matrix, equivalent to their total variability.
By taking the solution at the knee point of the Pareto front, we return a set
of alternate solutions at each iteration that have both high utility values and
are reasonably distinct, from which the expert selects one for evaluation. We
demonstrate that even in the case of an uninformed practitioner, our algorithm
recovers the regret of standard Bayesian optimisation.",164,7,1141,18.39
2950,cultural anthropology,"AI is about learning algorithms and huge amounts of data and are drivers of
economic growth -- what does this mean for the field of development studies?
Can we re-orient to twin AI studies and development theory and practice to
generate how development challenges are identified and researched? To do this a
good grasp is needed of AI internal mechanisms and outcomes in addressing
development issues -- this argument will be developed through a case study of
the ADAS [Advanced Driver Assistance System] deployment in India. Over and
above discussing the ADAS we bring an anthropological lens to understand the
social context that surrounds the system. Focusing on bus drivers, we offer
findings from a qualitative and ethnographic study of drivers in a
collaborative effort to achieve road safety by deploying AI-driven technology
and empowering stakeholders in the transport industry in India especially, bus
drivers as critical actors in the city transport network.",153,4,969,32.36
2951,cultural anthropology,"Vertebral morphological measurements are important across various
disciplines, including spinal biomechanics and clinical applications, pre- and
post-operatively. These measurements also play a crucial role in
anthropological longitudinal studies, where spinal metrics are repeatedly
documented over extended periods. Traditionally, such measurements have been
manually conducted, a process that is time-consuming. In this study, we
introduce a novel, fully automated method for measuring vertebral morphology
using 3D meshes of lumbar and thoracic spine models.Our experimental results
demonstrate the method's capability to accurately measure low-resolution
patient-specific vertebral meshes with mean absolute error (MAE) of 1.09 mm and
those derived from artificially created lumbar spines, where the average MAE
value was 0.7 mm. Our qualitative analysis indicates that measurements obtained
using our method on 3D spine models can be accurately reprojected back onto the
original medical images if these images are available.",138,9,1031,9.18
2952,cultural anthropology,"The article is an attempt to contribute to explorations of a common origin
for language and planned-collaborative action. It gives `semantics of change'
the central stage in the synthesis, from its history and recordkeeping to its
development, its syntax, delivery and reception, including substratal aspects.
  It is suggested that to arrive at a common core, linguistic semantics must be
understood as studying through syntax mobile agent's representing, tracking and
coping with change and no change. Semantics of actions can be conceived the
same way, but through plans instead of syntax. The key point is the following:
Sequencing itself, of words and action sequences, brings in more structural
interpretation to the sequence than which is immediately evident from the
sequents themselves. Mobile sequencers can be understood as subjects
structuring reporting, understanding and keeping track of change and no change.
The idea invites rethinking of the notion of category, both in language and in
planning.
  Understanding understanding change by mobile agents is suggested to be about
human extended practice, not extended-human practice. That's why linguistics is
as important as computer science in the synthesis. It must rely on
representational history of acts, thoughts and expressions, personal and
public, crosscutting overtness and covertness of these phenomena. It has
implication for anthropology in the extended practice, which is covered
briefly.",216,12,1465,34.66
2953,cultural anthropology,"We study the one-dimensional behavior of a cellular automaton aimed at the
description of the formation and evolution of cultural domains. The model
exhibits a non-equilibrium transition between a phase with all the system
sharing the same culture and a disordered phase of coexisting regions with
different cultural features. Depending on the initial distribution of the
disorder the transition occurs at different values of the model parameters.
This phenomenology is qualitatively captured by a mean-field approach, which
maps the dynamics into a multi-species reaction-diffusion problem.",85,5,591,16.02
2954,cultural anthropology,"Archaeological American mirrors are common findings and the images obtained
with them are often described by archaeologists as possessing high quality.
However, photographs attesting this fact are rare, if any. To the best of my
knowledge, only two papers show that quality concerning the Olmeca culture, and
only one of them mentions the pre-Inca cultures case. Certainly more images are
needed to increase awareness of the importance of the existence of
sophisticated imaging elements, particularly when evaluating the cultural
degree of the pre-Columbian civilizations. In this paper we show images made in
two museums in Lima, Peru, by means of mirrors and the lens action on a
necklace element.",109,6,699,32.43
2955,cultural anthropology,"It is shown that, contrary to the claims in a recent letter by Haldeman and
Beggs (PRL, 94, 058101, 2005), the branching ratio in epileptic cortical
cultures is smaller than one. In addition, and also in contrast to claims made
in that paper, the number of metastable states is not significantly different
between cortical cultures in the critical state and cultures made epileptic
using picrotoxin.",65,3,399,38.49
2956,cultural anthropology,"A mathematical model of the interaction mechanism for the
intuitive-imaginative and heuristic-logical thinking responsible for the rift
in the intellectual activity into two cultures has been suggested. The said
model proceeds from the assumption that human thinking is based on the
principles of the many-channel quantum-mechanical logic of the ""both ... and""
type surpassing the rigid confines of the ""either ... or"" type classical logic.
The aggregate product of the person equally endowed in the said two-cultural
space has been calculated. The interferential part of the latter achieves its
maximum at the extreme values of such parameters as the inter-state exchange
frequency and the difference of the states phases.",109,11,723,36.49
2957,cultural anthropology,"A powerful experimental approach for investigating computation in networks of
biological neurons is the use of cultured dissociated cortical cells grown into
networks on a multi-electrode array. Such preparations allow investigation of
network development, activity, plasticity, responses to stimuli, and the
effects of pharmacological agents. They also exhibit whole-culture pathological
bursting; understanding the mechanisms that underlie this could allow creation
of more useful cell cultures and possibly have medical applications.",70,4,536,-2.94
2958,cultural anthropology,"Society's view of astronomers has changed over time and from culture to
culture. This review discusses some of the many ways that astronomers have been
perceived by their societies and suggests ways that astronomers can influence
public perception of ourselves and our profession in the future.",46,3,294,56.59
2959,cultural anthropology,"A survey of the worldwide litterature reveals that the question ""Are We Alone
in the Universe?"" has been formulated only in the western litterature. Here I
try to understand why it is so. To investigate this problem it is first
necessary to clarify what western culture means.",47,4,276,59.5
2960,cultural anthropology,"In social sciences, there is currently no consensus on the mechanism for
cultural evolution. The evolution of first names of newborn babies offers a
remarkable example for the researches in the field. Here we perform statistical
analyses on over 100 years of data in the United States. We focus in particular
on how the frequency-rank distribution and inequality of baby names change over
time. We propose a stochastic model where name choice is determined by
personalized preference and social influence. Remarkably, variations on the
strength of personalized preference can account satisfactorily for the observed
empirical features. Therefore, we claim that personalization drives cultural
evolution, at least in the example of baby names.",112,8,742,38.32
2961,cultural anthropology,"In this work we propose a subtle change in Axelrod's model for the
dissemination of culture. The mechanism consists of excluding non-interacting
neighbours from the set of neighbours out of which an agent is drawn for
potential cultural interactions. Although the alteration proposed does not
alter topologically the configuration space, it yields significant qualitative
changes, specifically the emergence of surface tension, driving the system in
some cases to metastable states. The transient behaviour is considerably
richer, and cultural regions have become stable leading to the formation of
different spatio-temporal structures. A new metastable ""glassy"" phase emerges
between the globalised phase and the polarised, multicultural phase.",105,6,745,33.24
2962,cultural anthropology,"The Australian National Curriculum promotes Indigenous culture in school
education programs. To foster a broader appreciation of cultural astronomy, to
utilise the unique astronomical heritage of the site, and to develop an
educational program within the framework of the National Curriculum, Sydney
Observatory launched Dreamtime Astronomy, a program incorporating Australian
Indigenous culture, astronomy, and Sydney's astronomical history and heritage.
This paper reviews the development and implementation of this program and
discusses modifications following an evaluation by schools.",77,4,589,-5.38
2963,cultural anthropology,"In recent years, code projects in the nuclear weapons program at Los Alamos
National Laboratory (LANL) have given increased attention to modern software
productivity practices. We found that some of the biggest barriers to adoption
of new practices were not technical but cultural. This paper describes several
of the cultural differences between the physics and computer science
communities at LANL.",60,4,400,34.26
2964,cultural anthropology,"Neuro-electronic hybrid promises to bring up a model architecture for
computing. Such computing architecture could help to bring the power of
biological connection and electronic circuits together for better computing
paradigm. Such paradigms for solving real world tasks with higher accuracy is
on demand now. A robot as a autonomous system is modeled here to navigate
following a particular line. Sensory inputs from robot is directed as input to
the cell culture in response to which motor commands are generated from the
culture.",83,6,533,29.25
2965,cultural anthropology,"We study the relationship between national culture and the disposition effect
by investigating international differences in the degree of investors'
disposition effect. We utilize brokerage data of 387,993 traders from 83
countries and find great variation in the degree of the disposition effect
across the world. We find that the cultural dimensions of long-term orientation
and indulgence help to explain why certain nationalities are more prone to the
disposition effect. We also find support on an international level for the role
of age and gender in explaining the disposition effect.",90,5,591,31.72
2966,cultural anthropology,"Our aim here is to plead for the significance of cultural considerations of
overlapping inter-attitudinal patterns right next to well established
structural considerations of interorganizational networks based on overlapping
membership patterns. In particular, we examine how the analytical sociological
methodological incorporation of cultural attributes or attitudes might enhance
our understanding of structural community categorizations in
interorganizational networks. For this purpose, we analyze data of the
International Peace Protest Survey (IPPS) on the world-wide peace protests of
February, 15, 2003, in order to manifest the added value offered by the
consideration of the culture-structure duality in participation studies.",97,4,737,-12.08
2967,cultural anthropology,"Categorization is a fundamental function of minds, with wide ranging
implications for the rest of the cognitive system. In humans, categories are
shared and communicated between minds, thus requiring explanations at the
population level. In this paper, we discuss the current state of research on
the cultural evolution of categorization. We begin by delineating key
properties of categories in need of evolutionary explanation. We then review
computational modeling and laboratory studies of category evolution, including
their major insights and limitations. Finally, we discuss remaining challenges
for understanding the cultural evolution of categorization.",92,7,661,13.65
2968,cultural anthropology,"The twenty-first century is the century of encounter of the different races,
nations, cultures, religions and customs. In the twenty-first century, man is
more and more exposed to various influences that leave a trace on the entire
sphere of his social life, including education. Given that education systems
play one of the key roles in the formation of both physically and morally
healthy communities, it is of an enormous importance to analyze the phenomenon
of a classroom composed of culturally diverse students.",82,4,517,35.31
2969,cultural anthropology,"Cultural transmission of reproductive success states that successful men have
more children and pass this raised fecundity to their offspring. Balaresque and
colleagues found high frequency haplotypes in a Central Asian Y chromosome
dataset, which they attribute to cultural transmission of reproductive success
by prominent historical men, including Genghis Khan. Using coalescent
simulation, we show that these high frequency haplotypes are consistent with a
neutral model, where they commonly appear simply by chance. Hence, explanations
invoking cultural transmission of reproductive success are statistically
unnecessary.",84,5,626,24.78
2970,cultural anthropology,"Virtual Reality (VR) storytelling enhances the immersion of users into
virtual environments (VE). Its use in virtual cultural heritage presentations
helps the revival of the genius loci (the spirit of the place) of cultural
monuments. This paper aims to show that the use of actors in VR storytelling
adds to the quality of user experience and improves the edutainment value of
virtual cultural heritage applications. We will describe the Baiae dry visit
application which takes us to a time travel in the city considered by the Roman
elite as ""Little Rome (Pusilla Roma)"" and presently is only partially preserved
under the sea.",102,5,629,37.13
2971,cultural anthropology,"Breiman organizes ""Statistical modeling: The two cultures"" around a simple
visual. Data, to the far right, are compelled into a ""black box"" with an arrow
and then catapulted left by a second arrow, having been transformed into an
output. Breiman then posits two interpretations of this visual as encapsulating
a distinction between two cultures in statistics. The divide, he argues is
about what happens in the ""black box."" In this comment, I argue for a broader
perspective on statistics and, in doing so, elevate questions from ""before"" and
""after"" the box as fruitful areas for statistical innovation and practice.",99,6,617,51.38
2972,cultural anthropology,"This essay shows the impact of deepfake technology on fan culture. The
innovative technology provided the male audience with an instrument to express
its ideas and plots. Which subsequently led to the rise of deepfake
pornography. It is often seen as a part of celebrity studies; however, the
essay shows that it could also be considered a type of fanfic and a product of
participatory culture, sharing community origin, exploitation by commercial
companies and deep sexualisation. These two branches of fanfic evolution can be
connected via the genre of machinima pornography. Textual fanfics are mainly
created by females for females, depicting males; otherwise, deepfake
pornography and machinima are made by males and for males targeting females.",116,7,750,34.97
2973,cultural anthropology,"Introduction of DevOps into the software development life cycle represents a
cultural shift in the IT culture, amalgamating development and operations to
improve delivery speed in a rapid and maintainable manner. At the same time,
security threats and breaches are expected to grow as more enterprises move to
new agile frameworks for rapid product delivery. Meanwhile, DevSecOps is a
mindset change that revolutionizes software development by embedding security
at each step of the software cycle, leading to resilient software. This paper
discusses a framework organization can use to embed DevSecOps swiftly and
efficiently into the general IT culture.",98,5,655,21.23
2974,cultural anthropology,"Engaging in interdisciplinary projects on the intersection between
visualization and humanities research can be a challenging endeavor. Challenges
can be finding valuable outcomes for both domains, or how to apply
state-of-the-art visual analytics methods like supervised machine learning
algorithms. We discuss these challenges when working with cultural heritage
data. Further, there is a gap in applying these methods to intangible heritage.
To give a reflection on some interdisciplinary projects, we present three case
studies focusing on the labeling of cultural heritage collections, the problems
and challenges with the data, the participatory design process, and takeaways
for the visualization scholars from these collaborations.",102,6,739,25.39
2975,cultural anthropology,"The University of Bologna has a long tradition in Digital Humanities, both at
the level of research and teaching. In this article, we want to introduce some
experiences in developing new educational models based on the idea of
transversal learning, collaborative approaches and projects-oriented outputs,
together with the definition of research fields within this vast domain,
accompanied by practical examples. The creation of an international master's
degree (DHDK), a PhD (CHeDE) and a research centre (/DH.arc) are the results of
refining our notion of Digital Humanities in a new bidirectional way: to
reflect on computational methodologies and models in the cultural sphere and to
suggest a cultural approach to Informatics.",110,5,731,18.18
2976,cultural anthropology,"Tissue culture environment liberates cells from ordinary laws of
multi-cellular organisms. This liberation enables cells several behaviors, such
as proliferation, dedifferentiation, acquisition of pluripotency,
immortalization, and reprogramming. Recently, the quantitative value of
cellular dedifferentiation and differentiation was defined as liberality, which
is measurable as Shannon entropy of numerical transcriptome data and Lempel-Zip
complexity of nucleotide sequence transcriptome data. The increasing liberality
induced by the culture environment had first been observed in animal cells and
had reconfirmed in plant cells. The phenomena may be common across the kingdom,
also in a social amoeba. We measured the liberality of the social amoeba which
disaggregated from multicellular aggregates and transferred into a liquid
medium.",111,7,842,1.94
2977,cultural anthropology,"During batch growth on mixtures of two growth-limiting substrates, microbes
consume the substrates either sequentially or simultaneously. These growth
patterns are manifested in all types of bacteria and yeasts. The ubiquity of
these growth patterns suggests that they are driven by a universal mechanism
common to all microbial species. In previous work, we showed that a minimal
model accounting only for enzyme induction and dilution explains the phenotypes
observed in batch cultures of various wild-type and mutant/recombinant cells.
Here, we examine the extension of the minimal model to continuous cultures. We
show that: (1) Several enzymatic trends, usually attributed to specific
regulatory mechanisms such as catabolite repression, are completely accounted
for by dilution. (2) The bifurcation diagram of the minimal model for
continuous cultures, which classifies the substrate consumption pattern at any
given dilution rate and feed concentrations, provides a a precise explanation
for the empirically observed correlation between the growth patterns in batch
and continuous cultures. (3) Numerical simulations of the model are in
excellent agreement with the data. The model captures the variation of the
steady state substrate concentrations, cell densities, and enzyme levels during
the single- and mixed-substrate growth of bacteria and yeasts at various
dilution rates and feed concentrations. (4) This variation is well-approximated
by simple analytical expressions that furnish physical insights into the steady
states of continuous cultures. The minimal model provides a framework for
quantitating the effect of regulatory mechanisms. We illustrate this by
analyzing several data sets from the literature.",247,13,1726,25.19
2978,cultural anthropology,"In vitro primary cultures of dissociated invertebrate neurons from locust
ganglia are used to experimentally investigate the morphological evolution of
assemblies of living neurons, as they self-organize from collections of
separated cells into elaborated, clustered, networks. At all the different
stages of the culture's development, identification of neurons' and neurites'
location by means of a dedicated software allows to ultimately extract an
adjacency matrix from each image of the culture. In turn, a systematic
statistical analysis of a group of topological observables grants us the
possibility of quantifying and tracking the progression of the main network's
characteristics during the self-organization process of the culture. Our
results point to the existence of a particular state corresponding to a
small-world network configuration, in which several relevant graph's micro- and
meso-scale properties emerge. Finally, we identify the main physical processes
ruling the culture's morphological transformations, and embed them into a
simplified growth model qualitatively reproducing the overall set of
experimental observations.",158,6,1146,-2.91
2979,cultural anthropology,"In addition to chemical and mechanical interactions between cells
electromagnetic field produced by cells has been considered as another form of
signaling for cell-cell communication. The aim of this study is evaluation of
electromagnetic effects on viability of Adipose-derived stem cells (ADSCs)
without co-culturing. In this study, stem cells were isolated from human
adipose tissue enzymatically and proliferated in monolayer culture. Then,
5.(10^4) adipose-derived stem cells were cultured in each well of the test
plate. In the first row (4 wells), ADSCs as inducer cells were cultured in
DMEM1 with 10 ng/ml Fibroblast growth factor (FGF). In adjacent and the last
rows, ADSCs were cultured without FGF (as detector cells). After the three and
five days the viability of cells were evaluated. Moreover, ADSCs were cultured
in the same conditions but the inducer cells were placed once in the UV-filter
tube and once in the quartz tube to see whether there is electromagnetic
interaction among cells. Inducer cells caused significant cell proliferation in
adjacent row cells (p- value<0.01) in the fifth day. However, using the
UV-filter tube and quartz tube both reduced the effect of inducer cells on
adjacent cells significantly. As a conclusion, we could detect distant cellular
interaction (DCI) among adipose derived stem cells (ADSCs), but it was not
electromagnetic signaling. Our results show that ADSCs affect each other via
volatile signaling as a chemical distant cellular interaction (CDCI).",231,15,1510,44.95
2980,cultural anthropology,"Online social media is a social vehicle in which people share various moments
of their lives with their friends, such as playing sports, cooking dinner or
just taking a selfie for fun, via visual means, that is, photographs. Our study
takes a closer look at the popular visual concepts illustrating various
cultural lifestyles from aggregated, de-identified photographs. We perform
analysis both at macroscopic and microscopic levels, to gain novel insights
about global and local visual trends as well as the dynamics of interpersonal
cultural exchange and diffusion among Facebook friends. We processed images by
automatically classifying the visual content by a convolutional neural network
(CNN). Through various statistical tests, we find that socially tied
individuals more likely post images showing similar cultural lifestyles. To
further identify the main cause of the observed social correlation, we use the
Shuffle test and the Preference-based Matched Estimation (PME) test to
distinguish the effects of influence and homophily. The results indicate that
the visual content of each user's photographs are temporally, although not
necessarily causally, correlated with the photographs of their friends, which
may suggest the effect of influence. Our paper demonstrates that Facebook
photographs exhibit diverse cultural lifestyles and preferences and that the
social interaction mediated through the visual channel in social media can be
an effective mechanism for cultural diffusion.",218,9,1495,26.85
2981,cultural anthropology,"Music sampling is a common practice among hip-hop and electronic producers
that has played a critical role in the development of particular subgenres.
Artists preferentially sample drum breaks, and previous studies have suggested
that these may be culturally transmitted. With the advent of digital sampling
technologies and social media the modes of cultural transmission may have
shifted, and music communities may have become decoupled from geography. The
aim of the current study was to determine whether drum breaks are culturally
transmitted through musical collaboration networks, and to identify the factors
driving the evolution of these networks. Using network-based diffusion analysis
we found strong evidence for the cultural transmission of drum breaks via
collaboration between artists, and identified several demographic variables
that bias transmission. Additionally, using network evolution methods we found
evidence that the structure of the collaboration network is no longer biased by
geographic proximity after the year 2000, and that gender disparity has relaxed
over the same period. Despite the delocalization of communities by the
internet, collaboration remains a key transmission mode of music sampling
traditions. The results of this study provide valuable insight into how
demographic biases shape cultural transmission in complex networks, and how the
evolution of these networks has shifted in the digital age.",208,9,1441,19.71
2982,cultural anthropology,"The ideas that we forge creatively as individuals and groups build on one
another in a manner that is cumulative and adaptive, forming open-ended
lineages across space and time. Thus, human culture is believed to evolve. The
pervasiveness of cross-domain creativity--as when a song inspires a
painting--would appear indicative of discontinuities in cultural lineages.
However, if what evolves through culture is our worldviews--the webs of
thoughts, ideas, and attitudes that constitutes our way of seeing being in the
world--then the problem of discontinuities is solved. The state of a worldview
can be affected by information assimilated in one domain, and this
change-of-state can be expressed in another domain. In this view, the gesture,
narrative, or artifact that constitutes a specific creative act is not what is
evolving; it is merely the external manifestation of the state of an evolving
worldview. Like any evolutionary process, cultural evolution requires a balance
between novelty, via the generation of variation, and continuity, via the
preservation of variants that are adaptive. In cultural evolution, novelty is
generated through creativity, and continuity is provided by social learning
processes, e.g., imitation. Both the generative and imitative aspects of
cultural evolution are affected by social media. We discuss the trajectory from
social ideation to social innovation, focusing on the role of
self-organization, renewal, and perspective-taking at the individual and social
group level.",224,13,1516,31.82
2983,cultural anthropology,"The spontaneous activity pattern of cortical neurons in dissociated culture
is characterized by burst firing that is highly synchronized among a wide
population of cells. The degree of synchrony, however, is excessively higher
than that in cortical tissues. Here, we employed polydimethylsiloxane (PDMS)
elastomers to establish a novel system for culturing neurons on a scaffold with
an elastic modulus resembling brain tissue, and investigated the effect of the
scaffold's elasticity on network activity patterns in cultured rat cortical
neurons. Using whole-cell patch clamp to assess the scaffold effect on the
development of synaptic connections, we found that the amplitude of excitatory
postsynaptic current, as well as the frequency of spontaneous transmissions,
was reduced in neuronal networks grown on an ultrasoft PDMS with an elastic
modulus of 0.5 kPa. Furthermore, the ultrasoft scaffold was found to suppress
neural correlations in the spontaneous activity of the cultured neuronal
network. The dose of GsMTx-4, an antagonist of stretch-activated cation
channels (SACs), required to reduce the generation of the events below 1.0
event/min on PDMS substrates was lower than that for neurons on a glass
substrate. This suggests that the difference in the baseline level of SAC
activation is a molecular mechanism underlying the alteration in neuronal
network activity depending on scaffold stiffness. Our results demonstrate the
potential application of PDMS with biomimetic elasticity as cell-culture
scaffold for bridging the in vivo-in vitro gap in neuronal systems.",233,11,1582,28.27
2984,cultural anthropology,"Cultural phylogenies, or ""trees"" of culture, are typically built using
methods from biology that use similarities and differences in artifacts to
infer the historical relationships between the populations that produced them.
While these methods have yielded important insights, particularly in
linguistics, researchers continue to debate the extent to which cultural
phylogenies are tree-like or reticulated due to high levels of horizontal
transmission. In this study, we propose a novel method for phylogenetic
reconstruction using dynamic community detection that explicitly accounts for
transmission between lineages. We used data from 1,498,483 collaborative
relationships between electronic music artists to construct a cultural
phylogeny based on observed population structure. The results suggest that,
although the phylogeny is fundamentally tree-like, horizontal transmission is
common and populations never become fully isolated from one another. In
addition, we found evidence that electronic music diversity has increased
between 1975 and 1999. The method used in this study is available as a new R
package called DynCommPhylo. Future studies should apply this method to other
cultural systems such as academic publishing and film, as well as biological
systems where high resolution reproductive data is available, to assess how
levels of reticulation in evolution vary across domains.",197,9,1399,21.13
2985,cultural anthropology,"The question that how cultural variation emerges has drawn lots of interest
in sociological inquiry. Sociologists predominantly study such variation
through the lens of social contagion, which mostly attributes cultural
variation to the underlying structural segregation, making it epiphenomenal to
the pre-existing segregated structure. On the other hand, arguing culture
doesn't spread like a virus, an alternative called associative diffusion was
proposed, in which cultural transmission occurs not at the preference of
practices, but at the association between practices. The associative diffusion
model then successfully explains cultural variation without attributing it to a
segregated social structure. The contagion model and associative diffusion
model require different types of relationships and interactions to make
cultural transmission possible. In reality, both types of relationships exist.
In light of this concern, we proposed combining the two models with the
multilayer network framework. On one layer, agents casually observed the
behaviors of others, updating their belief about the association between
practices; on another layer, agents' preference of practices are directly
influenced by closed others. In the meantime, the constraint satisfaction
between preference and association is used to link the update of both, thereby
making each individual a coherent entity in terms of preference and
association. Using this approach, we entangle the effect of social contagion
and associative diffusion through multilayer networks. For the baseline, we
explore the model dynamics on three common network models: fully connected,
small-world, and scale-free. The results show nontrivial dynamics between the
two extremes of the contagion model and the associative diffusion model,
justifying our claim that it is necessary to consider the two models at the
same time.",268,13,1887,23.46
2986,cultural anthropology,"Equipping visitors of a cultural site with a wearable device allows to easily
collect information about their preferences which can be exploited to improve
the fruition of cultural goods with augmented reality. Moreover, egocentric
video can be processed using computer vision and machine learning to enable an
automated analysis of visitors' behavior. The inferred information can be used
both online to assist the visitor and offline to support the manager of the
site. Despite the positive impact such technologies can have in cultural
heritage, the topic is currently understudied due to the limited number of
public datasets suitable to study the considered problems. To address this
issue, in this paper we propose EGOcentric-Cultural Heritage (EGO-CH), the
first dataset of egocentric videos for visitors' behavior understanding in
cultural sites. The dataset has been collected in two cultural sites and
includes more than $27$ hours of video acquired by $70$ subjects, with labels
for $26$ environments and over $200$ different Points of Interest. A large
subset of the dataset, consisting of $60$ videos, is associated with surveys
filled out by real visitors. To encourage research on the topic, we propose $4$
challenging tasks (room-based localization, point of interest/object
recognition, object retrieval and survey prediction) useful to understand
visitors' behavior and report baseline results on the dataset.",214,9,1427,35.81
2987,cultural anthropology,"Do people from different cultural backgrounds perceive the mood in music the
same way? How closely do human ratings across different cultures approximate
automatic mood detection algorithms that are often trained on corpora of
predominantly Western popular music? Analyzing 166 participants responses from
Brazil, South Korea, and the US, we examined the similarity between the ratings
of nine categories of perceived moods in music and estimated their alignment
with four popular mood detection algorithms. We created a dataset of 360 recent
pop songs drawn from major music charts of the countries and constructed
semantically identical mood descriptors across English, Korean, and Portuguese
languages. Multiple participants from the three countries rated their
familiarity, preference, and perceived moods for a given song. Ratings were
highly similar within and across cultures for basic mood attributes such as
sad, cheerful, and energetic. However, we found significant cross-cultural
differences for more complex characteristics such as dreamy and love. To our
surprise, the results of mood detection algorithms were uniformly correlated
across human ratings from all three countries and did not show a detectable
bias towards any particular culture. Our study thus suggests that the mood
detection algorithms can be considered as an objective measure at least within
the popular music context.",206,8,1402,31.31
2988,cultural anthropology,"Warning: this paper contains content that may be offensive or upsetting.
  Most hate speech datasets neglect the cultural diversity within a single
language, resulting in a critical shortcoming in hate speech detection. To
address this, we introduce CREHate, a CRoss-cultural English Hate speech
dataset. To construct CREHate, we follow a two-step procedure: 1) cultural post
collection and 2) cross-cultural annotation. We sample posts from the SBIC
dataset, which predominantly represents North America, and collect posts from
four geographically diverse English-speaking countries (Australia, United
Kingdom, Singapore, and South Africa) using culturally hateful keywords we
retrieve from our survey. Annotations are collected from the four countries
plus the United States to establish representative labels for each country. Our
analysis highlights statistically significant disparities across countries in
hate speech annotations. Only 56.2% of the posts in CREHate achieve consensus
among all countries, with the highest pairwise label difference rate of 26%.
Qualitative analysis shows that label disagreement occurs mostly due to
different interpretations of sarcasm and the personal bias of annotators on
divisive topics. Lastly, we evaluate large language models (LLMs) under a
zero-shot setting and show that current LLMs tend to show higher accuracies on
Anglosphere country labels in CREHate. Our dataset and codes are available at:
https://github.com/nlee0212/CREHate",206,13,1482,35.57
2989,cultural anthropology,"This chapter presents the potential of interoperability and standardised data
publication for cultural heritage resources, with a focus on community-driven
approaches and web standards for usability. The Linked Open Usable Data (LOUD)
design principles, which rely on JSON-LD as lingua franca, serve as the
foundation.
  We begin by exploring the significant advances made by the International
Image Interoperability Framework (IIIF) in promoting interoperability for
image-based resources. The principles and practices of IIIF have paved the way
for Linked Art, which expands the use of linked data by demonstrating how it
can easily facilitate the integration and sharing of semantic cultural heritage
data across portals and institutions.
  To provide a practical demonstration of the concepts discussed, the chapter
highlights the implementation of LUX, the Yale Collections Discovery platform.
LUX serves as a compelling case study for the use of linked data at scale,
demonstrating the real-world application of automated enrichment in the
cultural heritage domain.
  Rooted in empirical study, the analysis presented in this chapter delves into
the broader context of community practices and semantic interoperability. By
examining the collaborative efforts and integration of diverse cultural
heritage resources, the research sheds light on the potential benefits and
challenges associated with LOUD.",200,9,1408,20.72
2990,cultural anthropology,"Ascertaining the collective viability of cells in different cell culture
conditions has typically relied on averaging colorimetric indicators and is
often reported out in simple binary readouts. Recent research has combined
viability assessment techniques with image-based deep-learning models to
automate the characterization of cellular properties. However, further
development of viability measurements to assess the continuity of possible
cellular states and responses to perturbation across cell culture conditions is
needed. In this work, we demonstrate an image processing algorithm for
quantifying cellular viability in 3D cultures without the need for assay-based
indicators. We show that our algorithm performs similarly to a pair of human
experts in whole-well images over a range of days and culture matrix
compositions. To demonstrate potential utility, we perform a longitudinal study
investigating the impact of a known therapeutic on pancreatic cancer spheroids.
Using images taken with a high content imaging system, the algorithm
successfully tracks viability at the individual spheroid and whole-well level.
The method we propose reduces analysis time by 97% in comparison to the
experts. Because the method is independent of the microscope or imaging system
used, this approach lays the foundation for accelerating progress in and for
improving the robustness and reproducibility of 3D culture analysis across
biological and clinical research.",208,10,1463,14.19
2991,cultural anthropology,"Content moderation at scale faces the challenge of considering local cultural
distinctions when assessing content. While global policies aim to maintain
decision-making consistency and prevent arbitrary rule enforcement, they often
overlook regional variations in interpreting natural language as expressed in
content. In this study, we are looking into how moderation systems can tackle
this issue by adapting to local comprehension nuances. We train large language
models on extensive datasets of media news and articles to create culturally
attuned models. The latter aim to capture the nuances of communication across
geographies with the goal of recognizing cultural and societal variations in
what is considered offensive content. We further explore the capability of
these models to generate explanations for instances of content violation,
aiming to shed light on how policy guidelines are perceived when cultural and
societal contexts change. We find that training on extensive media datasets
successfully induced cultural awareness and resulted in improvements in
handling content violations on a regional basis. Additionally, these
advancements include the ability to provide explanations that align with the
specific local norms and nuances as evidenced by the annotators' preference in
our conducted study. This multifaceted success reinforces the critical role of
an adaptable content moderation approach in keeping pace with the ever-evolving
nature of the content it oversees.",214,10,1492,21.94
2992,cultural anthropology,"Texts written in different languages reflect different culturally-dependent
beliefs of their writers. Thus, we expect multilingual LMs (MLMs), that are
jointly trained on a concatenation of text in multiple languages, to encode
different cultural values for each language. Yet, as the 'multilinguality' of
these LMs is driven by cross-lingual sharing, we also have reason to belief
that cultural values bleed over from one language into another. This limits the
use of MLMs in practice, as apart from being proficient in generating text in
multiple languages, creating language technology that can serve a community
also requires the output of LMs to be sensitive to their biases (Naous et al.,
2023). Yet, little is known about how cultural values emerge and evolve in MLMs
(Hershcovich et al., 2022a). We are the first to study how languages can exert
influence on the cultural values encoded for different test languages, by
studying how such values are revised during fine-tuning. Focusing on the
fine-tuning stage allows us to study the interplay between value shifts when
exposed to new linguistic experience from different data sources and languages.
Lastly, we use a training data attribution method to find patterns in the
fine-tuning examples, and the languages that they come from, that tend to
instigate value shifts.",209,11,1329,36.52
2993,cultural anthropology,"This paper introduces the ""CIVICS: Culturally-Informed & Values-Inclusive
Corpus for Societal impacts"" dataset, designed to evaluate the social and
cultural variation of Large Language Models (LLMs) across multiple languages
and value-sensitive topics. We create a hand-crafted, multilingual dataset of
value-laden prompts which address specific socially sensitive topics, including
LGBTQI rights, social welfare, immigration, disability rights, and surrogacy.
CIVICS is designed to generate responses showing LLMs' encoded and implicit
values. Through our dynamic annotation processes, tailored prompt design, and
experiments, we investigate how open-weight LLMs respond to value-sensitive
issues, exploring their behavior across diverse linguistic and cultural
contexts. Using two experimental set-ups based on log-probabilities and
long-form responses, we show social and cultural variability across different
LLMs. Specifically, experiments involving long-form responses demonstrate that
refusals are triggered disparately across models, but consistently and more
frequently in English or translated statements. Moreover, specific topics and
sources lead to more pronounced differences across model answers, particularly
on immigration, LGBTQI rights, and social welfare. As shown by our experiments,
the CIVICS dataset aims to serve as a tool for future research, promoting
reproducibility and transparency across broader linguistic settings, and
furthering the development of AI technologies that respect and reflect global
cultural diversities and value pluralism. The CIVICS dataset and tools will be
made available upon publication under open licenses; an anonymized version is
currently available at https://huggingface.co/CIVICS-dataset.",224,11,1748,12.46
2994,cultural anthropology,"In this work we present a model for the propagation of culture on networks of
different topology and by considering different underlying dynamics. We extend
a previous model proposed by Axelrod by letting a majority govern the dynamics
of changes. This in turn allows us to define a Lyapunov functional for the
system.",53,4,318,36.59
2995,cultural anthropology,"What are the dynamics behind youth subcultures such as punk, hippie, or
hip-hop cultures? How does the global dynamics of these subcultures relate to
the individual's search for a personal identity? We propose a simple dynamical
model to address these questions and find that only a few assumptions of the
individual's behaviour are necessary to regenerate known features of youth
culture.",61,2,389,42.41
2996,cultural anthropology,"This brief article discusses some aspects of quantum theory and their impact
on popular culture. The basic features of quantum entanglement between two or
more parties are introduced in a language suitable for a general audience, and
metaphorically connected to love and faithfulness in human relationships.",46,3,307,31.21
2997,cultural anthropology,"Possible variant of people's infection by bird flu pathogenic culture in
passing of everyday infection is presented in the work: through the contact of
open parts of the skin with infected surfaces of the vehicle, that is the
sequent of the reused water, which contains all species spectrum of pathogen
accumulated on the urban areas, used in process of washing",60,1,361,10.58
2998,cultural anthropology,"In this paper we present modern texture mapping techniques and several
applications of polynomial texture mapping in cultural heritage programs. We
also consider some well-known and some new methods for mathematical procedure
that is involved in generation of polynomial texture maps.",41,3,284,25.29
2999,cultural anthropology,"Food and drink are two of the most basic needs of human beings. However, as
society evolved, food and drink became also a strong cultural aspect, being
able to describe strong differences among people. Traditional methods used to
analyze cross-cultural differences are mainly based on surveys and, for this
reason, they are very difficult to represent a significant statistical sample
at a global scale. In this paper, we propose a new methodology to identify
cultural boundaries and similarities across populations at different scales
based on the analysis of Foursquare check-ins. This approach might be useful
not only for economic purposes, but also to support existing and novel
marketing and social applications. Our methodology consists of the following
steps. First, we map food and drink related check-ins extracted from Foursquare
into users' cultural preferences. Second, we identify particular individual
preferences, such as the taste for a certain type of food or drink, e.g., pizza
or sake, as well as temporal habits, such as the time and day of the week when
an individual goes to a restaurant or a bar. Third, we show how to analyze this
information to assess the cultural distance between two countries, cities or
even areas of a city. Fourth, we apply a simple clustering technique, using
this cultural distance measure, to draw cultural boundaries across countries,
cities and regions.",223,13,1406,42.41
3000,cultural anthropology,"This article explains how natural selection works and how it has been
inappropriately applied to the description of cultural change. It proposes an
alternative evolutionary explanation for cultural evolution that describes it
in terms of communal exchange.",37,3,256,18.86
3001,cultural anthropology,"Understanding the dynamics of opinions, preferences and of culture as whole
requires more use of empirical data than has been done so far. It is clear that
an important role in driving this dynamics is played by social influence, which
is the essential ingredient of many quantitative models. Such models require
that all traits are fixed when specifying the ""initial cultural state"".
Typically, this initial state is randomly generated, from a uniform
distribution over the set of possible combinations of traits. However, recent
work has shown that the outcome of social influence dynamics strongly depends
on the nature of the initial state. If the latter is sampled from empirical
data instead of being generated in a uniformly random way, a higher level of
cultural diversity is found after long-term dynamics, for the same level of
propensity towards collective behavior in the short-term. Moreover, if the
initial state is randomized by shuffling the empirical traits among people, the
level of long-term cultural diversity is in-between those obtained for the
empirical and uniformly random counterparts. The current study repeats the
analysis for multiple empirical data sets, showing that the results are
remarkably similar, although the matrix of correlations between cultural
variables clearly differs across data sets. This points towards robust
structural properties inherent in empirical cultural states, possibly due to
universal laws governing the dynamics of culture in the real world. The results
also suggest that this dynamics might be characterized by criticality and
involve mechanisms beyond social influence.",247,11,1633,29.48
3002,cultural anthropology,"We trace the initiative by Professor Meghnad Saha to develop a (statistical)
physics model of market economy and his search for the mechanism to constrain
the entropy maximized width of the income distribution in a society such that
the spread of inequality can be minimized.",45,2,275,17.34
3003,cultural anthropology,"We consider an extension of Leo Breiman's thesis from ""Statistical Modeling:
The Two Cultures"" to include a bifurcation of algorithmic modeling, focusing on
parametric regressions, interpretable algorithms, and complex (possibly
explainable) algorithms.",32,2,253,-11.77
3004,cultural anthropology,"At NeurIPS, American and Chinese institutions cite papers from each other's
regions substantially less than they cite endogamously. We build a citation
graph to quantify this divide, compare it to European connectivity, and discuss
the causes and consequences of the separation.",41,3,278,25.29
3005,cultural anthropology,"The future of mathematics is described, by using the WZ algorithmic proof
theory as a parable.",16,2,94,38.32
3006,cultural anthropology,"Following Axelrod's model of cultural dissemination, formal computational
studies of cultural influence have suggested that more contact between
geographically distant regions may increase overall cultural homogeneity and
reduce societal polarization. In the present paper, we show that two plausible
modifications of Axelrod's original mechanism turn the effect of range of
communication upside-down. We assume a continuous rather than a nominal state
space and we add the negative side of social influence, heterophobia and
rejection. Computational analyses of the resulting model demonstrate that now a
larger range of contact can increase rather than decrease the extent of
polarization in the population. Further experiments identify the window of
conditions under which the effect obtains.",112,6,795,14.9
3007,cultural anthropology,"The cultural variation of economic activity is wide and multidimensional. In
my presentation I will refer to the analyses of the culture of capitalism
provided by Alfons Trompenaars and Charles Hampden-Turner. According to them
there are seven processes and related dilemmas which are important in analyzing
the construction of a cultural system of economy. I will focus only on one of
them, universalism versus particularism. Using the database of Trompenaars and
Hampden-Turner I will show how this dilemma was solved by managers from
different European countries. That will be starting point for my analysis of
universalism-particularism attitudes of respondents of European Social Survey
(ESS). I will be particularly interested in verification of hypothesis on the
place of Poland on the mosaic of European cultures of capitalism.",126,8,835,27.83
3008,cultural anthropology,"The analysis of secreted proteins represents a challenge for current
proteomics techniques. Proteins are usually secreted at low concentrations in
the culture media, which makes their recovery difficult. In addition, culture
media are rich in salts and other compounds interfering with most proteomics
techniques, which makes selective precipitation of proteins almost mandatory
for a correct subsequent proteomics analysis. Last but not least, the
non-secreted proteins liberated in the culture medium upon lysis of a few dead
cells heavily contaminate the so-called secreted proteins preparations. Several
techniques have been used in the past for concentration of proteins secreted in
culture media. These techniques present several drawbacks, such as
coprecipitation of salts or poor yields at low protein concentrations. Improved
techniques based on carrier-assisted trichloroacetic acid precipitation are
described and discussed in this paper. These techniques have been used to
analyse the secretome of myeloid cells (macrophages, dendritic cells) and
enabled to analyze proteins secreted at concentrations close to 1 ng/ml,
thereby allowing to detect some of the cytokines (TNF, IL-12) secreted by the
myeloid cells upon activation by bacterial products.",179,9,1262,31.82
3009,cultural anthropology,"The population dynamics of mixed-culture and sequential-cultures in
fruit-must fermentation is a very interesting problem from both the theoretical
and technological stand point. By mixed-culture we refer to those fermentations
in which more that one strain/species are present from the beginning of the
process; and by sequential to those in which different microorganisms are added
along the process. These kinds of fermentations play a key role in industry of
fermented beverages. The mathematical models of such processes should represent
the dynamics of multiple species growing in a mixture of substrates as the
fruit must composition includes an important proportion of hexoses and
pentoses. Since the flavor is a basic aspect of beverages, and in general of
all fermented foods, it is fundamental to study the population dynamics and its
impact in the organoleptic properties, through the influence in the volatile
compound profile. The goal of this paper is to present a panorama of the
investigations of these fermentative ecosystems from a biological,
mathematical, and technological stand point.",167,7,1107,34.8
3010,cultural anthropology,"Evolution of the spatial arrangement of cells in a primary culture of cardiac
tissue derived from newborn rats was studied experimentally over extended
period. It was found that cells attract each other spontaneously to form a
clustered structure over the timescale of several days. These clusters exhibit
spontaneous rhythmic contraction and have been confirmed to consist of cardiac
muscle cells. Addition of a contraction inhibitor (2,3-butanedione-2-monoxime)
to the culture medium resulted in the inhibition of both the spontaneous
contractions exhibited by the cells as well as the formation of clusters.
Furthermore, the formation of clusters is suppressed when high concentrations
of collagen are used for coating the substratum to which the cells adhere. From
these experimental observations, it was deduced that the cells are mechanically
stressed by the tension associated with repeated contractions and that this
results in the cells becoming compact and attracting each other, finally
resulting in the formation of clusters. This process can be interpreted as
modulation of a cellular network by the activity associated with contraction,
which could be employed to control cellular networks by modifying the dynamics
associated with the contractions in cardiac tissue culture.",190,8,1289,27.05
3011,cultural anthropology,"We address the problem of diversification in religions by studying selection
on cultural memes that colonize humans hosts. In analogy to studying the
evolution of pathogens or symbionts colonizing animal hosts, we use models for
host-pathogen dynamics known from theoretical epidemiology. In these models,
religious memes colonize individual humans. Rates of transmission of memes
between humans, i.e., transmission of cultural content, and rates of loss of
memes (loss of faith) are determined by the phenotype of the cultural memes,
and by interactions between hosts carrying different memes. In particular,
based on the notion that religion can lead to oppression of lower classes once
a religious society has reached a certain size, we assume that the rate of loss
increases as the number of humans colonized by a particular meme phenotype
increases. This generates frequency-dependent selection on cultural memes, and
we use evolutionary theory to show that this frequency dependence can generate
the emergence of coexisting clusters of different meme types. The different
clusters correspond to different religions, and hence our model describes the
emergence of distinct descendent religions from single ancestral religions.",182,10,1231,31.41
3012,cultural anthropology,"Mathematical notations around the world are diverse. Not as much as requiring
computing machines' makers to adapt to each culture, but as much as to
disorient a person landing on a web-page with a text in mathematics. In order
to understand better this diversity, we are building a census of notations: it
should allow any content creator or mathematician to grasp which mathematical
notation is used in which language and culture. The census is built
collaboratively, collected in pages with a given semantic and presenting
observations of the widespread notations being used in existing materials by a
graphical extract. We contend that our approach should dissipate the fallacies
found here and there about the notations in ""other cultures"" so that a better
understanding of the cultures can be realized. The exploitation of the census
in the math-bridge project is also presented: this project aims at taking
learners ""where they are in their math-knowledge"" and bring them to a level
ready to start engineering studies. The census serves as definitive reference
for the transformation elements that generate the rendering of formul{\ae} in
web-browsers.",182,8,1158,36.63
3013,cultural anthropology,"We present models of dormancy in a planktonic culture and in biofilm, and
examine the relative advantage of short dormancy versus long dormancy times in
each case. Simulations and analyses indicate that in planktonic batch cultures
and in chemostats, live biomass is maximized by the fastest possible exit from
dormancy. The lower limit of time to reawakening is thus perhaps governed by
physiological, biochemical or other constraints within the cells. In biofilm we
see that the slower waker has a defensive advantage over the fast waker due to
a larger amount of dormant biomass, without an appreciable difference in total
live biomass. Thus it would seem that typical laboratory culture conditions can
be unrepresentative of the natural state. We discuss the computational methods
developed for this work.",127,7,809,41.5
3014,cultural anthropology,"Axelrod's model describes the dissemination of a set of cultural traits in a
society constituted by individual agents. In a social context, nevertheless,
individual choices toward a specific attitude are also at the basis of the
formation of communities, groups and parties. The membership in a group changes
completely the behavior of single agents who start acting according to a social
identity. Groups act and interact among them as single entities, but still
conserve an internal dynamics. We show that, under certain conditions of social
dynamics, the introduction of group dynamics in a cultural dissemination
process avoids the flattening of the culture into a single entity and preserves
the multiplicity of cultural attitudes. We also considered diffusion processes
on this dynamical background, showing the conditions under which information as
well as innovation can spread through the population in a scenario where the
groups' choices determine the social structure.",148,7,980,21.02
3015,cultural anthropology,"We revisit the problem of introducing an external global field -- the mass
media -- in Axelrod's model of social dynamics, where in addition to their
nearest neighbors, the agents can interact with a virtual neighbor whose
cultural features are fixed from the outset. The finding that this apparently
homogenizing field actually increases the cultural diversity has been
considered a puzzle since the phenomenon was first reported more than a decade
ago. Here we offer a simple explanation for it, which is based on the
pedestrian observation that Axelrod's model exhibits more cultural diversity,
i.e., more distinct cultural domains, when the agents are allowed to interact
solely with the media field than when they can interact with their neighbors as
well. In this perspective, it is the local homogenizing interactions that work
towards making the absorbing configurations less fragmented as compared with
the extreme situation in which the agents interact with the media only.",154,7,983,23.7
3016,cultural anthropology,"The question of how to increase the number of women and minorities in
astronomy has been approached from several directions in the United States
including examination of admission policies, mentoring, and hiring practices.
These point to departmental efforts to improve conditions for some of the
students which has the overall benefit of improving conditions for all of the
students. However, women and minority astronomers have managed to obtain
doctorates even within the non-welcoming environment of certain astronomy and
physics departments. I present here six strategies used by African American men
and women to persevere if not thrive long enough to earn their doctorate.
Embedded in this analysis is the idea of 'astronomy culture' and experiencing
astronomy culture as a cross-cultural experience including elements of culture
shock. These survival strategies are not exclusive to this small subpopulation
but have been used by majority students, too.",144,7,961,30.2
3017,cultural anthropology,"It is arguable whether history is made by great men and women or vice versa,
but undoubtably social connections shape history. Analysing Wikipedia, a global
collective memory place, we aim to understand how social links are recorded
across cultures. Starting with the set of biographies in the English Wikipedia
we focus on the networks of links between these biographical articles on the 15
largest language Wikipedias. We detect the most central characters in these
networks and point out culture-related peculiarities. Furthermore, we reveal
remarkable similarities between distinct groups of language Wikipedias and
highlight the shared knowledge about connections between persons across
cultures.",102,6,701,42.31
3018,cultural anthropology,"The preferences to color quality of illumination were investigated for
American and Chinese subjects using a solid-state source of white light with
the continuously tunable color saturation ability and correlated color
temperature of quadrichromatic blends. Subjects were asked to identify both
most natural and preferred blends. For very familiar objects, cultural
differences did not affect the average of the selected blends. For less
familiar objects (various paintings), cultural differences in the average
selected blends depended on the level of the familiarity of the content. An
unfamiliar painting also showed preferences to color temperature being
dependent on the cultural background. In all cases, the American subjects
exhibited noticeably wider distributions.",109,7,774,19.16
3019,cultural anthropology,"Food occupies a central position in every culture and it is therefore of
great interest to understand the evolution of food culture. The advent of the
World Wide Web and online recipe repositories has begun to provide
unprecedented opportunities for data-driven, quantitative study of food
culture. Here we harness an online database documenting recipes from various
Chinese regional cuisines and investigate the similarity of regional cuisines
in terms of geography and climate. We found that the geographical proximity,
rather than climate proximity is a crucial factor that determines the
similarity of regional cuisines. We develop a model of regional cuisine
evolution that provides helpful clues to understand the evolution of cuisines
and cultures.",113,6,755,31.62
3020,cultural anthropology,"It is important to be clear as to whether a theory such as evolutionary
archaeology pertains to biological evolution, in which acquired change is
obliterated at the end of each generation, or cultural change, in which
acquired change is retained. In evolutionary archaeology, (1) the population is
said to consist of artifacts, yet (2) artifacts are said to be phenotypic.
Neither (1) nor (2) is necessarily problematic in and of itself, but the two
are inconsistent, as the first pertains to cultural change whereas the second
to the biological evolution of humans. A first step to avoiding this problem is
to recognize that there is a need for a theory of change specific to human
culture. Referring to ongoing work using a related approach to cultural change,
it is suggested that the inconsistencies in evolutionary archaeology, though
problematic, are not insurmountable.",141,6,876,25.93
3021,cultural anthropology,"The speed and transformative power of human cultural evolution is evident
from the change it has wrought on our planet. This chapter proposes a human
computation program aimed at (1) distinguishing algorithmic from
non-algorithmic components of cultural evolution, (2) computationally modeling
the algorithmic components, and amassing human solutions to the non-algorithmic
(generally, creative) components, and (3) combining them to develop
human-machine hybrids with previously unforeseen computational power that can
be used to solve real problems. Drawing on recent insights into the origins of
evolutionary processes from biology and complexity theory, human minds are
modeled as self-organizing, interacting, autopoietic networks that evolve
through a Lamarckian (non-Darwinian) process of communal exchange. Existing
computational models as well as directions for future research are discussed.",121,5,901,-1.59
3022,cultural anthropology,How to manage knowledge on the Web.,7,2,35,89.75
3023,cultural anthropology,"Information and knowledge (IK) are very important for any institution
including education higher institution. Those IK are stored in every single
individual in organization in the form of experiences, skills, etc. The growth
of the higher education institution nowadays relies on how an institution
manage the dissemination of those IK over the organization by using information
technology (IT). This article discusses several ways and tools for engaging
persons in the organization to build sharing cultures. This article gives some
view of freely availabe application over internet to be used for IK sharing
cultures.",93,6,619,27.22
3024,cultural anthropology,"Although a number of models have been developed to investigate the emergence
of culture and evolutionary phases in social systems, one important aspect has
not yet been sufficiently emphasized. This is the structure of the underlaying
network of social relations serving as channels in transmitting cultural
traits, which is expected to play a crucial role in the evolutionary processes
in social systems. In this paper we contribute to the understanding of the role
of the network structure by developing a layered ego-centric network structure
based model, inspired by the social brain hypothesis, to study transmission of
cultural traits and their evolution in social network. For this model we first
find analytical results in the spirit of mean-field approximation and then to
validate the results we compare them with the results of extensive numerical
simulations.",134,5,871,20.55
3025,cultural anthropology,"Excess individual creativity can be detrimental to society because creators
invest in unproven ideas at the expense of propagating proven ones. Moreover, a
proportion of individuals can benefit from creativity without being creative
themselves by copying creators. We hypothesized that (1) societies increase
their rate of cultural evolution by tempering the novelty-generating effects of
creativity with the novelty-preserving effects of imitation, and (2) this is
carried out by selectively rewarding and punishing creativity according to the
value of the individuals' creative outputs. We tested this using an agent-based
model of cultural evolution in which each agent self-regulated its
invention-to-imitation ratio as a function of the fitness of its cultural
outputs. In self-regulating societies, agents segregated into creators and
imitators. The mean fitness of cultural outputs was higher than in
non-self-regulating societies, and changes in diversity were rapider and more
pronounced. We discuss limitations and possible social implications of our
findings.",150,8,1070,15.91
3026,cultural anthropology,"Axelrod's model in the square lattice with nearest-neighbors interactions
exhibits culturally homogeneous as well as culturally fragmented absorbing
configurations. In the case the agents are characterized by $F=2$ cultural
features and each feature assumes $k$ states drawn from a Poisson distribution
of parameter $q$ these regimes are separated by a continuous transition at $q_c
= 3.10 \pm 0.02$. Using Monte Carlo simulations and finite size scaling we show
that the mean density of cultural domains $\mu$ is an order parameter of the
model that vanishes as $\mu \sim \left ( q - q_c \right)^\beta$ with $\beta =
0.67 \pm 0.01$ at the critical point. In addition, for the correlation length
critical exponent we find $\nu = 1.63 \pm 0.04$ and for Fisher's exponent,
$\tau = 1.76 \pm 0.01$. This set of critical exponents places the continuous
phase transition of Axelrod's model apart from the known universality classes
of nonequilibrium lattice models.",151,14,959,41.16
3027,cultural anthropology,"We present a fluorescence-lifetime based method for monitoring cell and
tissue activity in situ, during cell culturing and in the presence of a strong
autofluorescence background. The miniature fiber-optic probes are easily
incorporated in the tight space of a cell culture chamber or in an endoscope.
As a first application we monitored the cytosolic calcium levels in porcine
tracheal explant cultures using the Calcium Green-5N (CG5N) indicator. Despite
the simplicity of the optical setup we are able to detect changes of calcium
concentration as small as 2.5 nM, with a monitoring time resolution of less
than 1 s.",98,6,619,43.12
3028,cultural anthropology,"Interstellar exploration will advance human knowledge and culture in multiple
ways. Scientifically, it will advance our understanding of the interstellar
medium, stellar astrophysics, planetary science and astrobiology. In addition,
significant societal and cultural benefits will result from a programme of
interstellar exploration and colonisation. Most important will be the cultural
stimuli resulting from expanding the horizons of human experience, and
increased opportunities for the spread and diversification of life and culture
through the Galaxy. Ultimately, a programme of interstellar exploration may be
the only way for human (and post-human) societies to avoid the intellectual
stagnation predicted for the ""end of history"".",101,6,738,17.13
3029,cultural anthropology,"The Axelrod model for the dissemination of culture exhibits a rich spatial
distribution of cultural domains, which depends on the values of the two model
parameters: $F$, the number of cultural features and $q$, the common number of
states each feature can assume. In the one-dimensional model with $F=q=2$,
which is closely related to the constrained voter model, Monte Carlo
simulations indicate the existence of multicultural absorbing configurations in
which at least one macroscopic domain coexist with a multitude of microscopic
ones in the thermodynamic limit. However, rigorous analytical results for the
infinite system starting from the configuration where all cultures are equally
likely show convergence to only monocultural or consensus configurations. Here
we show that this disagreement is due simply to the order that the
time-asymptotic limit and the thermodynamic limit are taken in the simulations.
In addition, we show how the consensus-only result can be derived using Monte
Carlo simulations of finite chains.",155,6,1031,14.63
3030,cultural anthropology,"In randomized studies evaluating treatments for tuberculosis (TB),
individuals are scheduled to be routinely evaluated for the presence of TB
using sputum cultures. One important endpoint in such studies is the time of
culture conversion, the first visit at which a patient's sputum culture is
negative and remains negative. This article addresses how to draw inference
about treatment effects when sputum cultures are intermittently missing on some
patients. We discuss inference under a novel benchmark assumption and under a
class of assumptions indexed by a treatment-specific sensitivity parameter that
quantify departures from the benchmark assumption. We motivate and illustrate
our approach using data from a randomized trial comparing the effectiveness of
two treatments for adult TB patients in Brazil.",119,6,812,21.94
3031,cultural anthropology,"Whilst affective responses to various forms and genres of multimedia content
have been well researched, precious few studies have investigated the combined
impact that multimedia system parameters and human factors have on affect.
Consequently, in this paper we explore the role that two primordial dimensions
of human factors - personality and culture - in conjunction with system factors
- frame rate, resolution, and bit rate - have on user affect and enjoyment of
multimedia presentations. To this end, a two-site, cross-cultural study was
undertaken, the results of which produced three predictve models. Personality
and Culture traits were shown statistically to represent 5.6% of the variance
in positive affect, 13.6% in negative affect and 9.3% in enjoyment. The
correlation between affect and enjoyment, was significant. Predictive modeling
incorporating human factors showed about 8%, 7% and 9% improvement in
predicting positive affect, negative affect and enjoyment respectively when
compared to models trained only on system factors. Results and analysis
indicate the significant role played by human factors in influencing affect
that users experience while watching multimedia.",174,11,1193,28.84
3032,cultural anthropology,"Advancements in information and communication technologies have enhanced our
possibilities to communicate worldwide, eliminating borders and making it
possible to interact with people coming from other cultures like never happened
before. Such powerful tools have brought us to reconsider our concept of
privacy and social involvement in order to make them fit into this wider
environment. It is possible to claim that the ICT revolution is changing our
world and is having a core role as a mediating factor for social movements
(e.g., Arab spring) and political decisions (e.g., Brexit), shaping the world
in a faster and shared brand new way. It is then interesting to explore how the
perception of this brand new environment (in terms of social engagement,
privacy perception and sense of belonging to a community) differs even in
similar cultures separated by recent historical reasons, as for example in
Italian and Turkish cultures.",147,9,938,38.15
3033,cultural anthropology,"Synchronized bursts (SBs) with complex structures are common in neuronal
cultures. Although the origin of SBs is still unclear, they have been studied
for their information processing capabilities. Here, we investigate the
properties of these SBs in a culture on multi-electrode array system. We find
that structures of these SBs are related to the different developmental stages
of the cultures. A model based on short term synaptic plasticity, recurrent
connections and astrocytic recycling of neurotransmitters has been developed
successfully to understand these structures. A phase diagram obtained from this
model shows that networks exhibiting SBs are in an oscillatory state due to
large enough positive feedback provided by synaptic facilitation and recurrent
connections. In this model, the structures of the SBs are the results of
intrinsic synaptic interactions; not information stored in the network.",134,8,912,35.17
3034,cultural anthropology,"The complex nature of organizational culture challenges our ability to infers
its underlying dynamics from observational studies. Recent computational
studies have adopted a distinct different view, where plausible mechanisms are
proposed to describe a wide range of social phenomena, including the onset and
evolution of organizational culture. In this spirit, this work introduces an
empirically-grounded, agent-based model which relaxes a set of assumptions that
describes past work - (a) omittance of an individual's strive for achieving
cognitive coherence, (b) limited integration of important contextual factors -
by utilizing networks of beliefs and incorporating social rank into the
dynamics. As a result, we illustrate that: (i) an organization may appear to be
increasingly coherent in terms of organizational culture, yet be composed of
individuals with reduced levels of coherence, (ii) the components of social
conformity - peer-pressure and social rank - are influential at different
aggregation levels.",146,5,1019,1.6
3035,cultural anthropology,"Websites and applications that match and connect individuals for romantic
purposes are commonly used in the Western world. However, there have not been
many previous investigations focusing on cultural factors that affect the
adoption of similar technologies in religiously conservative non-Western
cultures. In this study, we examine the socio-technical and cultural factors
that influence the perceptions and use of matchmaking technologies in Saudi
Arabia. We report the methods and findings of interviews with 18 Saudi
nationals (nine males and nine females) with diverse demographics and
backgrounds. We provide qualitatively generated insights into the major themes
reported by our participants related to the common approaches to matchmaking,
the current role of technology, and concerns regarding matchmaking technologies
in this cultural con-text. We relate these themes to specific implications for
designing marital matchmaking technologies in Saudi Arabia and we outline
opportunities for future investigations.",142,7,1023,13.58
3036,cultural anthropology,"The current article explores interesting, significant and recently identified
nuances in the relationship ""culture-strategy"". The shared views of leading
scholars at the University of National and World Economy in relation with the
essence, direction, structure, role and hierarchy of ""culture-strategy""
relation are defined as a starting point of the analysis. The research emphasis
is directed on recent developments in interpreting the observed realizations of
the aforementioned link among the community of international scholars and
consultants, publishing in selected electronic scientific databases. In this
way a contemporary notion of the nature of ""culture-strategy"" relationship for
the entities from the world of business is outlined.",103,5,746,11.45
3037,cultural anthropology,"This article aims to outline the diversity of cultural phenomena that occur
at organizational level, emphasizing the place and role of the key attributes
of professed firm culture for the survival and successful development of big
business organizations. The holding companies, members of the Bulgarian
Industrial Capital Association, are chosen as a survey object as the mightiest
driving engines of the local economy. That is why their emergence and
development in the transition period is monitored and analyzed. Based on an
empirical study of relevant website content, important implications about
dominating attributes of professed firm culture on them are found and several
useful recommendations to their senior management are made.",110,5,739,18.18
3038,cultural anthropology,"The growing interest in archaeology has enabled the discovery of an immense
number of cultural heritage assets and historical sites. Hence, preservation of
CH through digitalisation is becoming a primordial requirement for many
countries as a part of national cultural programs. However, CH digitalisation
is still posing serious challenges such as cost and time-consumption. In this
manuscript, 3D holoscopic (H3D) technology is applied to capture small sized CH
assets. The H3D camera utilises micro lens array within a single aperture lens
and typical 2D sensor to acquire 3D information. This technology allows 3D
autostereoscopic visualisation with full motion parallax if convenient
Microlens Array (MLA)is used on the display side. Experimental works have shown
easiness and simplicity of H3D acquisition compared to existing technologies.
In fact, H3D capture process took an equal time of shooting a standard 2D
image. These advantages qualify H3D technology to be cost effective and
time-saving technology for cultural heritage 3D digitisation.",155,10,1054,28.64
3039,cultural anthropology,"This paper presents a video analysis application to detect personality,
emotion and cultural aspects from pedestrians in video sequences, along with a
visualizer of features. The proposed model considers a series of
characteristics of the pedestrians and the crowd, such as number and size of
groups, distances, speeds, among others, and performs the mapping of these
characteristics in personalities, emotions and cultural aspects, considering
the Cultural Dimensions of Hofstede (HCD), the Big-Five Personality Model
(OCEAN) and the OCC Emotional Model. The main hypothesis is that there is a
relationship between so-called intrinsic human variables (such as emotion) and
the way people behave in space and time. The software was tested in a set of
videos from different countries and results seem promising in order to identify
these three different levels of psychological traits in the filmed sequences.
In addition, the data of the people present in the videos can be seen in a
crowd viewer.",155,6,997,31.55
3040,cultural anthropology,"In this paper we present the Wikipedia Cultural Diversity dataset. For each
existing Wikipedia language edition, the dataset contains a classification of
the articles that represent its associated cultural context, i.e. all concepts
and entities related to the language and to the territories where it is spoken.
We describe the methodology we employed to classify articles, and the rich set
of features that we defined to feed the classifier, and that are released as
part of the dataset. We present several purposes for which we envision the use
of this dataset, including detecting, measuring and countering content gaps in
the Wikipedia project, and encouraging cross-cultural research in the field of
digital humanities.",112,7,725,40.28
3041,cultural anthropology,Explaining Cybersecurity with Films and the Arts,7,1,48,30.53
3042,cultural anthropology,"Resilience and vulnerability of societies to large-scale events such as wars,
climate catastrophes, immigration waves, and institutional collapses is not
well-understood. Some societies prove more resilient, while others collapse.
Diversity has been proposed in the literature as a potential cause of
resilience in areas such as ecology, computer science and biology, and could
also be a potential factor in sociocultural contexts. Using CulSim (Ulloa
2016), a cultural simulator that enables the study of cultural complexity and
diversity based on Axelrod's (1997b) model of local convergence and global
polarization and its extension including institutions (Ulloa et al 2016), the
resilience of diverse societies and monocultural societies to nine different
types of events is compared, while varying event sizes and distributions.
Results show a strong positive relation between cultural diversity and
resilience, in particular for events such as foreign invasions and settlements,
and institutional damage and conversion.",145,6,1025,16.66
3043,cultural anthropology,"This paper is devoted to a new classification of the twenty amino acids based
on the heronian (integer) tetrahedron.",19,2,116,43.73
3044,cultural anthropology,"World population and the number of cultural artifacts are growing
exponentially or faster, while cultural interaction approaches the fidelity of
a global nervous system. Every day hundreds of millions of images are loaded
into social networks by users all over the world. As this myriad of new
artifacts veils the view into the past, like city lights covering the night
sky, it is easy to forget that there is more than one Starry Night, the
painting by Van Gogh. Like in ecology, where saving rare species may help us in
treating disease, art and architectural history can reveal insights into the
past, which may hold keys to our own future. With humanism under threat, facing
the challenge of understanding the structure and dynamics of art and culture,
both qualitatively and quantitatively, is more crucial now than it ever was.
The purpose of this article is to provide perspective in the aim of figuring
out the process of art history - not art history as a discipline, but the
actual history of all made things, in the spirit of George Kubler and Marcel
Duchamp. In other words, this article deals with the grand challenge of
developing a systematic science of art and culture, no matter what, and no
matter how.",209,8,1220,49.79
3045,cultural anthropology,"We interpret attitudes towards science and pseudosciences as cultural traits
that diffuse in society through communication efforts exerted by agents. We
present a tractable model that allows us to study the interaction among the
diffusion of an epidemic, vaccination choices, and the dynamics of cultural
traits. We apply it to study the impact of homophily between pro-vaxxers and
anti-vaxxers on the total number of cases (the cumulative infection). We show
that, during the outbreak of a disease, homophily has the direct effect of
decreasing the speed of recovery. Hence, it may increase the number of cases
and make the disease endemic. The dynamics of the shares of the two cultural
traits in the population is crucial in determining the sign of the total effect
on the cumulative infection: more homophily is beneficial if agents are not too
flexible in changing their cultural trait, is detrimental otherwise.",146,7,917,38.35
3046,cultural anthropology,"Accompanied by the development of digital media, the threat of information
cocoon has become a significant issue. However, little is known about the
measure of information cocoon as a cultural space and its relationship with
social class. This study addresses this problem by constructing the cultural
space with word embedding models and random shuffling methods among three
large-scale digital media use datasets. In the light of field theory of
cultural production, we investigate the information cocoon effect on different
social classes among 979 computer users, 100,000 smartphone users, and 159,373
mobile reading application users. Our analysis reveals that information cocoons
widely exist in the daily use of digital media. Moreover, people of lower
social class have a higher probability of getting stuck in the information
cocoon filled with the entertainment content. In contrast, the people of higher
social class have more capability to stride over the constraints of the
information cocoon. The results suggest that the disadvantages for vulnerable
groups in acquiring knowledge may further widen social inequality.",168,9,1131,33.24
3047,cultural anthropology,"Culturing cells confined in microscale geometries has been reported in many
studies this last decade, in particular following the development of
microfluidic-based applications and lab-on-a-chip devices. Such studies usually
examine growth of Escherichia coli. In this article, we show that E. coli may
be a poor model and that spatial confinement can severely prevent the growth of
many micro-organisms. By studying different bacteria and confinement
geometries, we determine that the growth inhibition observed for some bacteria
results from fast dioxygen depletion, inherent to spatial confinement, and not
to any depletion of nutriments. This article unravels the physical origin of
confinement problems in cell culture, highlighting the importance of oxygen
depletion, and paves the way for the effective culture of bacteria in confined
geometries by demonstrating enhanced cell growth in confined geometries in the
proximity of air bubbles.",137,7,946,31.41
3048,cultural anthropology,"This paper illustrates the intergenerational transmission of the gender gap
in education among first and second-generation immigrants. Using the Current
Population Survey (1994-2018), we find that the difference in female-male
education persists from the home country to the new environment. A one standard
deviation increase of the ancestral country female-male difference in schooling
is associated with 17.2% and 2.5% of a standard deviation increase in the
gender gap among first and second generations, respectively. Since gender
perspective in education uncovers a new channel for cultural transmission among
families, we interpret the findings as evidence of cultural persistence among
first generations and partial cultural assimilation of second generations.
Moreover, Disaggregation into country-groups reveals different paths for this
transmission: descendants of immigrants of lower-income countries show fewer
attachments to the gender opinions of their home country. Average local
education of natives can facilitate the acculturation process. Immigrants
residing in states with higher education reveal a lower tendency to follow
their home country attitudes regarding the gender gap.",165,10,1198,19.06
3049,cultural anthropology,"There are two puzzles surrounding the Pleiades, or Seven Sisters. First, why
are the mythological stories surrounding them, typically involving seven young
girls being chased by a man associated with the constellation Orion, so similar
in vastly separated cultures, such as the Australian Aboriginal cultures and
Greek mythology? Second, why do most cultures call them ""Seven Sisters"" even
though most people with good eyesight see only six stars? Here we show that
both these puzzles may be explained by a combination of the great antiquity of
the stories combined with the proper motion of the stars, and that these
stories may predate the departure of most modern humans out of Africa around
100,000 BC.",114,3,706,42.55
3050,cultural anthropology,"Globalization and information technology enable people to join the movement
of global citizenship and work without borders. However, different type of
barriers existed that could affect collaboration in todays work environment, in
which different generations are involved. Although researchers have identified
several technical barriers to intergenerational collaboration (iGOAL), the
influence of cultural diversity on iGOAL has rarely been studied. Therefore,
using a quantitative study approach, this paper investigates the impact of
differences in cultural background on perceived technical and operational
barriers to iGOAL. Our study reveals six barriers to IGC that are perceived
differently by culturally diverse people (CDP) and non-CDP. Furthermore, CDP
can foster IGC because CDP consider the barriers to be of less of a reason to
avoid working with different generations than do non-CDP.",127,7,899,16.12
3051,cultural anthropology,"The music genre perception expressed through human annotations of artists or
albums varies significantly across language-bound cultures. These variations
cannot be modeled as mere translations since we also need to account for
cultural differences in the music genre perception. In this work, we study the
feasibility of obtaining relevant cross-lingual, culture-specific music genre
annotations based only on language-specific semantic representations, namely
distributed concept embeddings and ontologies. Our study, focused on six
languages, shows that unsupervised cross-lingual music genre annotation is
feasible with high accuracy, especially when combining both types of
representations. This approach of studying music genres is the most extensive
to date and has many implications in musicology and music information
retrieval. Besides, we introduce a new, domain-dependent cross-lingual corpus
to benchmark state of the art multilingual pre-trained embedding models.",131,7,976,15.51
3052,cultural anthropology,"Fashion is intertwined with external cultural factors, but identifying these
links remains a manual process limited to only the most salient phenomena. We
propose a data-driven approach to identify specific cultural factors affecting
the clothes people wear. Using large-scale datasets of news articles and
vintage photos spanning a century, we present a multi-modal statistical model
to detect influence relationships between happenings in the world and people's
choice of clothing. Furthermore, on two image datasets we apply our model to
improve the concrete vision tasks of visual style forecasting and photo
timestamping. Our work is a first step towards a computational, scalable, and
easily refreshable approach to link culture to clothing.",110,6,747,32.22
3053,cultural anthropology,"For centuries, the rich nocturnal environment of the starry sky could be
modelled only by analogue tools such as paper planispheres, atlases, globes and
numerical tables. The immersive sky simulator of the twentieth century, the
optomechanical planetarium, provided new ways for representing and teaching
about the sky, but the high construction and running costs meant that they have
not become common. However, in recent decades, ""desktop planetarium programs""
running on personal computers have gained wide attention. Modern incarnations
are immensely versatile tools, mostly targeted towards the community of amateur
astronomers and for knowledge transfer in transdisciplinary research. Cultural
astronomers also value the possibilities they give of simulating the skies of
past times or other cultures. With this paper, we provide an extended
presentation of the open-source project Stellarium, which in the last few years
has been enriched with capabilities for cultural astronomy research not found
in similar, commercial alternatives.",149,7,1042,20.92
3054,cultural anthropology,"Here, I provide some reflections on Prof. Leo Breiman's ""The Two Cultures""
paper. I focus specifically on the phenomenon that Breiman dubbed the ""Rashomon
Effect"", describing the situation in which there are many models that satisfy
predictive accuracy criteria equally well, but process information in the data
in substantially different ways. This phenomenon can make it difficult to draw
conclusions or automate decisions based on a model fit to data. I make
connections to recent work in the Machine Learning literature that explore the
implications of this issue, and note that grappling with it can be a fruitful
area of collaboration between the algorithmic and data modeling cultures.",108,6,692,41.09
3055,cultural anthropology,"In the last decades the rapid development of technologies and methodologies
in the field of digitization and 3D modelling has led to an increasing
proliferation of 3D technologies in the Cultural Heritage domain. Despite the
great potential of 3D digital heritage, the ""special effects"" of 3D may often
overwhelm its importance in research. Projects and consortia of scholars have
tried to put order in the different fields of application of these
technologies, providing guidelines and proposing workflows. The use of computer
graphics as an effective methodology for CH research and communication
highlighted the need of transparent provenance data to properly document
digital assets and understand the degree of scientific quality and reliability
of their outcomes. The building and release of provenance knowledge, consisting
in the complete formal documentation of each phase of the process, is therefore
of fundamental importance to ensure its repeatability and to guarantee the
integration and interoperability of the generated metadata on the Semantic Web.
This paper proposes a methodology for documenting the planning and creation of
3D models used in archaeology and Cultural Heritage, by means of an application
profile based on the CIDOC CRM ecosystem and other international standards.",194,7,1300,13.31
3056,cultural anthropology,"Scales, sets of discrete pitches that form the basis of melodies, are thought
to be one of the most universal hallmarks of music. But we know relatively
little about cross-cultural diversity of scales or how they evolved. To remedy
this, we assemble a cross-cultural database (Database of Musical Scales:
DaMuSc) of scale data, collected over the past century by various
ethnomusicologists. Statistical analyses of the data highlight that certain
intervals (e.g., the octave, fifth, second) are used frequently across
cultures. Despite some diversity among scales, it is the similarities across
societies which are most striking - most scales are found close to equidistant
5- and 7-note scales. We discuss the mechanisms of variation and selection in
the evolution of scales, and how the assembled data may be used to examine the
root causes of convergent evolution.",136,9,867,51.89
3057,cultural anthropology,"Moral psychology is a domain that deals with moral identity, appraisals and
emotions. Previous work has primarily focused on moral development and the
associated role of culture. Knowing that language is an inherent element of a
culture, we used the social media platform Twitter to compare moral behaviors
of Japanese tweets with English tweets. The five basic moral foundations, i.e.,
Care, Fairness, Ingroup, Authority and Purity, along with the associated
emotional valence were compared between English and Japanese tweets. The tweets
from Japanese users depicted relatively higher Fairness, Ingroup, and Purity,
whereas English tweets expressed more positive emotions for all moral
dimensions. Considering moral similarities in connecting users on social media,
we quantified homophily concerning different moral dimensions using our
proposed method. The moral dimensions Care, Authority and Purity for English
and Ingroup, Authority and Purity for Japanese depicted homophily on Twitter.
Overall, our study uncovers the underlying cultural differences with respect to
moral behavior in English- and Japanese-speaking users.",160,11,1130,28.03
3058,cultural anthropology,"Cultural heritage sites in Italy typically attract a large number of tourists
every year. However, the lack of support for i) locating contents of interest;
ii) discovering information on specific contents; and iii) ease of navigation
within the heritage site; hinders the overall experience of the visitor. To
this end, in this work, we present a Digital Object Space Management service
developed as a part of the VASARI project. The service generates a digital twin
(with 3D visualization) of a given cultural heritage site and further provides
support for navigation and localization, thereby providing an immersive
cultural experience to the visitor.",101,5,654,28.88
3059,cultural anthropology,"We propose a new scheme to infer the metabolic fluxes of cell cultures in a
chemostat. Our approach is based on the Maximum Entropy Principle and exploits
the understanding of the chemostat dynamics and its connection with the actual
metabolism of cells. We show that, in continuous cultures with limiting
nutrients, the inference can be done with {\it limited information about the
culture}: the dilution rate of the chemostat, the concentration in the feed
media of the limiting nutrient and the cell concentration at steady state.
Also, we remark that our technique provides information, not only about the
mean values of the fluxes in the culture, but also its heterogeneity. We first
present these results studying a computational model of a chemostat. Having
control of this model we can test precisely the quality of the inference, and
also unveil the mechanisms behind the success of our approach. Then, we apply
our method to E. coli experimental data from the literature and show that it
outperforms alternative formulations that rest on a Flux Balance Analysis
framework.",175,9,1082,40.79
3060,cultural anthropology,"Pop culture is an important aspect of communication. On social media people
often post pop culture reference images that connect an event, product or other
entity to a pop culture domain. Creating these images is a creative challenge
that requires finding a conceptual connection between the users' topic and a
pop culture domain. In cognitive theory, this task is called conceptual
blending. We present a system called PopBlends that automatically suggests
conceptual blends. The system explores three approaches that involve both
traditional knowledge extraction methods and large language models. Our
annotation study shows that all three methods provide connections with similar
accuracy, but with very different characteristics. Our user study shows that
people found twice as many blend suggestions as they did without the system,
and with half the mental demand. We discuss the advantages of combining large
language models with knowledge bases for supporting divergent and convergent
thinking.",149,10,1001,37.71
3061,cultural anthropology,"Cultural items like songs have an important impact in creating and
reinforcing stereotypes, biases, and discrimination. But the actual nature of
such items is often less transparent. Take songs, for example. Are lyrics
biased against women? And how have any such biases changed over time? Natural
language processing of a quarter of a million songs over 50 years quantifies
misogyny. Women are less likely to be associated with desirable traits (i.e.,
competence), and while this bias has decreased, it persists. Ancillary analyses
further suggest that song lyrics may help drive shifts in societal stereotypes
towards women, and that lyrical shifts are driven by male artists (as female
artists were less biased to begin with). Overall, these results shed light on
cultural evolution, subtle measures of bias and discrimination, and how natural
language processing and machine learning can provide deeper insight into
stereotypes and cultural change.",145,10,951,56.76
3062,cultural anthropology,"Effective leadership is one of the key drivers of business and project
success, and one of the most active areas of management research. But how does
leadership work in agile software development, which emphasizes self-management
and self-organization and marginalizes traditional leadership roles? To find
out, this study examines agile leadership from the perspective of thirteen
professionals who identify as agile leaders, in different roles, at ten
different software development companies of varying sizes. Data from
semi-structured interviews reveals that leadership: (1) is dynamically shared
among team members; (2) engenders a sense of belonging to the team; and (3)
involves balancing competing organizational cultures (e.g. balancing the new
agile culture with the old milestone-driven culture). In other words, agile
leadership is a property of a team, not a role, and effectiveness depends on
agile team members' identifying with the team, accepting responsibility, and
being sensitive to cultural conflict.",147,7,1021,29.69
3063,cultural anthropology,"It was recently suggested in a study published in Nature Human Behaviour that
the historical loosening of American culture was associated with a trade-off
between higher creativity and lower order. To this end, Jackson et al. generate
a linguistic index of cultural tightness based on the Google Books Ngram corpus
and use this index to show that American norms loosened between 1800 and 2000.
While we remain agnostic toward a potential loosening of American culture and a
statistical association with creativity/order, we show here that the methods
used by Jackson et al. are neither suitable for testing the validity of the
index nor for establishing possible relationships with creativity/order.",109,6,699,32.43
3064,cultural anthropology,"Various efforts in the Natural Language Processing (NLP) community have been
made to accommodate linguistic diversity and serve speakers of many different
languages. However, it is important to acknowledge that speakers and the
content they produce and require, vary not just by language, but also by
culture. Although language and culture are tightly linked, there are important
differences. Analogous to cross-lingual and multilingual NLP, cross-cultural
and multicultural NLP considers these differences in order to better serve
users of NLP systems. We propose a principled framework to frame these efforts,
and survey existing and potential strategies.",95,6,657,35.27
3065,cultural anthropology,"This paper employs two major natural language processing techniques, topic
modeling and clustering, to find patterns in folktales and reveal cultural
relationships between regions. In particular, we used Latent Dirichlet
Allocation and BERTopic to extract the recurring elements as well as K-means
clustering to group folktales. Our paper tries to answer the question what are
the similarities and differences between folktales, and what do they say about
culture. Here we show that the common trends between folktales are family,
food, traditional gender roles, mythological figures, and animals. Also,
folktales topics differ based on geographical location with folktales found in
different regions having different animals and environment. We were not
surprised to find that religious figures and animals are some of the common
topics in all cultures. However, we were surprised that European and Asian
folktales were often paired together. Our results demonstrate the prevalence of
certain elements in cultures across the world. We anticipate our work to be a
resource to future research of folktales and an example of using natural
language processing to analyze documents in specific domains. Furthermore,
since we only analyzed the documents based on their topics, more work could be
done in analyzing the structure, sentiment, and the characters of these
folktales.",206,11,1373,42.11
3066,cultural anthropology,"Compartment models of cell culture are widely used in cytology, pharmacology,
toxicology and other fields. Numerical simulation, data modeling and prediction
of compartment models can be realized by traditional differential equation
modeling methods. At the same time, with the development of software and
hardware, Physical Informed Neural Network (PINN) is widely used to solve
differential equation models. This work models, simulates and predicts the cell
culture compartment model based on the machine learning framework PyTorch with
an 16 hidden layers neural network, including 8 linear layers and 8 feedback
active layers. The results showed a loss value of 0.0004853 for three-component
four-parameter quantitative pharmacodynamic model predictions in this way,
which is evaluated by Mean Square Error (MSE). In summary, Physical Informed
Neural Network can serve as an effective tool to deal with cell culture
compartment models and may perform better in dealing with big datasets.",145,8,991,33.54
3067,cultural anthropology,"Multiple studies have addressed what influences the fundamental diagram in
single-file experiments. Several studies indicate that there are differences by
gender when group composition is taken into account. Even for the simplest
systems, such as pedestrian flows in corridors, there are still some
deficiencies in the detailed understanding of this fundamental relationship.
The effect of cultural differences can only be seen in a different density and
velocity interval if a comparison is conducted between the two different
cultural groups. Our results indicate that the velocities of male and female
pedestrians are different. For instance, when N = 20, the velocity is 0.65 to
0.69m/s for Chinese, while for Ghanaians, the velocity is 0.51 to 0.62m/s.
Similarly, when the densities change N = 40 in Chinese, they are 0.26 to
0.32m/s, while the Ghanaians are 0.21 to 0.28m/s. In addition, we investigated
whether pedestrian behavior, corridor length, body weight, and height between
Chinese and Ghanaian pedestrians influence cultural differences in a
single-file fundamental diagram. Regression analysis makes it possible to
determine whether there is a difference between the two groups.",179,18,1194,42.58
3068,cultural anthropology,"Structured knowledge is important for many AI applications. Commonsense
knowledge, which is crucial for robust human-centric AI, is covered by a small
number of structured knowledge projects. However, they lack knowledge about
human traits and behaviors conditioned on socio-cultural contexts, which is
crucial for situative AI. This paper presents CANDLE, an end-to-end methodology
for extracting high-quality cultural commonsense knowledge (CCSK) at scale.
CANDLE extracts CCSK assertions from a huge web corpus and organizes them into
coherent clusters, for 3 domains of subjects (geography, religion, occupation)
and several cultural facets (food, drinks, clothing, traditions, rituals,
behaviors). CANDLE includes judicious techniques for classification-based
filtering and scoring of interestingness. Experimental evaluations show the
superiority of the CANDLE CCSK collection over prior works, and an extrinsic
use case demonstrates the benefits of CCSK for the GPT-3 language model. Code
and data can be accessed at https://candle.mpi-inf.mpg.de/.",142,12,1055,19.57
3069,cultural anthropology,"In this paper, we examine how generative machine learning systems produce a
new politics of visual culture. We focus on DALL-E 2 and related models as an
emergent approach to image-making that operates through the cultural techniques
of feature extraction and semantic compression. These techniques, we argue, are
inhuman, invisual, and opaque, yet are still caught in a paradox that is
ironically all too human: the consistent reproduction of whiteness as a latent
feature of dominant visual culture. We use Open AI's failed efforts to 'debias'
their system as a critical opening to interrogate how systems like DALL-E 2
dissolve and reconstitute politically salient human concepts like race. This
example vividly illustrates the stakes of this moment of transformation, when
so-called foundation models reconfigure the boundaries of visual culture and
when 'doing' anti-racism means deploying quick technical fixes to mitigate
personal discomfort, or more importantly, potential commercial loss.",148,6,997,24.51
3070,cultural anthropology,"The photogrammetric and reconstructive modeling of cultural heritage sites is
mostly focused on visually perceivable aspects, but if their intended purpose
is the performance of cultural acts with a sonic emphasis, it is important to
consider the preservation of their acoustical behaviour to make them audible in
an authentic way. This applies in particular to sacral and concert environments
as popular objects for photogrammetric models, which contain geometrical and
textural information that can be used to locate and classify acoustically
relevant surface properties. With the advancing conversion or destruction of
historical acoustical spaces, it becomes even more important to preserve their
unique sonic characters, while three-dimensional auralizations become widely
applicable. The proposed study presents the current state of a new
methodological approach to acoustical modeling using photogrammetric data and
introduces a parameterizable pipeline that will be accessible as an open-source
software with a graphical user interface.",146,5,1044,0.59
3071,cultural anthropology,"Toxicity and abuse are common in online peer-production communities. The
social structure of peer-production communities that aim to produce accurate
and trustworthy information require some conflict and gate-keeping to spur
content production and curation. However, conflict and gate-keeping often
devolve into hierarchical power structures which punish newcomers and lock out
marginalized groups through entrenched cultural norms. Community administrators
often focus on content quality, rather than consideration for all user safety,
to promote community growth and survival. Once toxic cultural norms dominate a
peer-production community, it is very difficult for community administrators to
stop these behaviors from undermining inclusive peer-production. We propose
developing a ""handbook of intelligent system design"" that attempts to frame
design protocols to better read user-community culture and accurately
distinguish toxic negative interactions from beneficial conflict.",128,7,983,7.56
3072,cultural anthropology,"The rapidly expanding market for regenerative medicines and cell therapies
highlights the need to advance the understanding of cellular metabolisms and
improve the prediction of cultivation production process for human induced
pluripotent stem cells (iPSCs). In this paper, a metabolic kinetic model was
developed to characterize underlying mechanisms of iPSC culture process, which
can predict cell response to environmental perturbation and support process
control. This model focuses on the central carbon metabolic network, including
glycolysis, pentose phosphate pathway (PPP), tricarboxylic acid (TCA) cycle,
and amino acid metabolism, which plays a crucial role to support iPSC
proliferation. Heterogeneous measures of extracellular metabolites and multiple
isotopic tracers collected under multiple conditions were used to learn
metabolic regulatory mechanisms. Systematic cross-validation confirmed the
model's performance in terms of providing reliable predictions on cellular
metabolism and culture process dynamics under various culture conditions. Thus,
the developed mechanistic kinetic model can support process control strategies
to strategically select optimal cell culture conditions at different times,
ensure cell product functionality, and facilitate large-scale manufacturing of
regenerative medicines and cell therapies.",174,7,1343,-0.27
3073,cultural anthropology,"The technique presented here identifies tethered mould designs, optimised for
growing cultured tissue with very highly-aligned cells. It is based on a
microscopic biophysical model for polarised cellular hydrogels. There is an
unmet need for tools to assist mould and scaffold designs for the growth of
cultured tissues with bespoke cell organisations, that can be used in
applications such as regenerative medicine, drug screening and cultured meat.
High-throughput biophysical calculations were made for a wide variety of
computer-generated moulds, with cell-matrix interactions and tissue-scale
forces simulated using a contractile-network dipole-orientation model.
Elongated moulds with central broadening and one of the following tethering
strategies are found to lead to highly-aligned cells: (1) tethers placed within
the bilateral protrusions resulting from an indentation on the short edge, to
guide alignment (2) tethers placed within a single vertex to shrink the
available space for misalignment. As such, proof-of-concept has been shown for
mould and tethered scaffold design based on a recently developed biophysical
model. The approach is applicable to a broad range of cell types that align in
tissues and is extensible for 3D scaffolds.",182,8,1253,36.63
3074,cultural anthropology,"We provide quantitative evidence suggesting social learning in sperm whales
across socio-cultural boundaries, using acoustic data from the Pacific and
Atlantic Oceans. Traditionally, sperm whale populations are categorized into
clans based on their vocal repertoire: the rhythmically patterned click
sequences (codas) that they use. Among these codas, identity codas function as
symbolic markers for each clan, accounting for 35-60% of codas they produce. We
introduce a computational method to model whale speech, which encodes rhythmic
micro-variations within codas, capturing their vocal style. We find that vocal
style-clans closely align with repertoire-clans. However, contrary to vocal
repertoire, we show that sympatry increases vocal style similarity between
clans for non-identity codas, i.e. most codas, suggesting social learning
across cultural boundaries. More broadly, this subcoda structure model offers a
framework for comparing communication systems in other species, with potential
implications for deeper understanding of vocal and cultural transmission within
animal societies.",148,10,1098,27.32
3075,cultural anthropology,"Creating high-quality annotated data for task-oriented dialog (ToD) is known
to be notoriously difficult, and the challenges are amplified when the goal is
to create equitable, culturally adapted, and large-scale ToD datasets for
multiple languages. Therefore, the current datasets are still very scarce and
suffer from limitations such as translation-based non-native dialogs with
translation artefacts, small scale, or lack of cultural adaptation, among
others. In this work, we first take stock of the current landscape of
multilingual ToD datasets, offering a systematic overview of their properties
and limitations. Aiming to reduce all the detected limitations, we then
introduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD
dataset. It is large-scale and offers culturally adapted dialogs in 4 languages
to enable training and evaluation of multilingual and cross-lingual ToD
systems. We describe a complex bottom-up data collection process that yielded
the final dataset, and offer the first sets of baseline scores across different
ToD-related tasks for future reference, also highlighting its challenging
nature.",161,7,1143,27.35
3076,cultural anthropology,"While connections between climate and the human mind and culture are widely
acknowledged, they are not thoroughly quantified. Analyzing 100,000 paintings
and data on 2,000 artists from the 13th to 21st centuries, the study reveals
that the lightness of the paintings exhibited an interesting U-shaped pattern
mirroring global temperature trends. There is a significant association between
the two, even after controlling for various factors. Event study analysis using
the artist-level data further reveals that high-temperature shocks resulted in
brighter paintings in later periods for artists who experienced them compared
to the control group. The effect is particularly pronounced in art genres that
rely on artists' imaginations, indicating a notable influence on artists'
minds. These findings underscore the enduring impact of climate on the human
mind and culture throughout history and highlight art as a valuable tool for
understanding people's minds and cultures.",142,7,975,30.5
3077,cultural anthropology,"Rogers' diffusion of innovations theory asserts that cultural similarity
among individuals plays a crucial role in the acceptance of an innovation in a
community. However, most studies on the diffusion of innovations have relied on
epidemic-like models where the individuals have no preference on whom they
interact with. Here, we use an agent-based model to study the diffusion of
innovations in a community of synthetic heterogeneous agents whose interaction
preferences depend on their cultural similarity. The community heterogeneity
and the agents' interaction preferences are described by Axelrod's model,
whereas the diffusion of innovations is described by a variant of the Daley and
Kendall model of rumour propagation. The interplay between the social dynamics
and the spreading of the innovation is controlled by the parameter $p \in
[0,1]$, which yields the probability that the agent engages in social
interaction or attempts to spread the innovation. Our findings support Roger's
empirical observations that cultural heterogeneity curbs the diffusion of
innovations.",158,7,1080,19.4
3078,cultural anthropology,"This paper explores using generative AI and aesthetics to promote cultural
creativity in rural China amidst COVID-19's impact. Through literature reviews,
case studies, surveys, and text analysis, it examines art and technology
applications in rural contexts and identifies key challenges. The study finds
artworks often fail to resonate locally, while reliance on external artists
limits sustainability. Hence, nurturing grassroots ""artist villagers"" through
AI is proposed. Our approach involves training machine learning on subjective
aesthetics to generate culturally relevant content. Interactive AI media can
also boost tourism while preserving heritage. This pioneering research puts
forth original perspectives on the intersection of AI and aesthetics to
invigorate rural culture. It advocates holistic integration of technology and
emphasizes AI's potential as a creative enabler versus replacement. Ultimately,
it lays the groundwork for further exploration of leveraging AI innovations to
empower rural communities. This timely study contributes to growing interest in
emerging technologies to address critical issues facing rural China.",156,11,1148,21.8
3079,philosophy,"In this paper I review the problematic relationship between science and
philosophy; in particular, I will address the question of whether science needs
philosophy, and I will offer some positive perspectives that should be helpful
in developing a synergetic relationship between the two. I will review three
lines of reasoning often employed in arguing that philosophy is useless for
science: a) philosophy's death diagnosis ('philosophy is dead'); b) the
historic-agnostic argument/challenge ""show me examples where philosophy has
been useful for science, for I don't know of any""; c) the division of property
argument (or: philosophy and science have different subject matters, therefore
philosophy is useless for science).
  These arguments will be countered with three contentions to the effect that
the natural sciences need philosophy. I will: a) point to the fallacy of
anti-philosophicalism (or: 'in order to deny the need for philosophy, one must
do philosophy') and examine the role of paradigms and presuppositions (or: why
science can't live without philosophy); b) point out why the historical
argument fails (in an example from quantum mechanics, alive and kicking); c)
briefly sketch some domains of intersection of science and philosophy and how
the two can have mutual synergy. I will conclude with some implications of this
synergetic relationship between science and philosophy for the liberal arts and
sciences.",217,6,1431,10.5
3080,philosophy,"An assessment of the anthology, 'Many Worlds? Everett, Quantum Theory and
Reality', edited by Simon Saunders, Jonathan Barrett, Adrian Kent and David
Wallace.",23,2,158,42.88
3081,philosophy,"This is a short (and personal) introduction in German to the connections
between artificial intelligence, philosophy, and logic, and to the author's
work.
  Dies ist eine kurze (und persoenliche) Einfuehrung in die Zusammenhaenge
zwischen Kuenstlicher Intelligenz, Philosophie, und Logik, und in die Arbeiten
des Autors.",45,3,320,31.72
3082,philosophy,"We examine the sub-field of philosophy of science using a new method
developed in information science, Referenced Publication Years Spectroscopy
(RPYS). RPYS allows us to identify peak years in citations in a field, which
promises to help scholars identify the key contributions to a field, and
revolutionary discoveries in a field. We discovered that philosophy of science,
a sub-field in the humanities, differs significantly from other fields examined
with this method. Books play a more important role in philosophy of science
than in the sciences. Further, Einstein's famous 1905 papers created a citation
peak in the philosophy of science literature. But rather than being a
contribution to the philosophy of science, their importance lies in the fact
that they are revolutionary contributions to physics with important
implications for philosophy of science.",131,7,865,32.43
3083,philosophy,"We propose the concepts of philomatics and psychomatics as hybrid
combinations of philosophy and psychology with mathematics. We explain four
motivations for this combination which are fulfilling the desire of analytical
philosophy, proposing science of philosophy, justifying mathematical algorithms
by philosophy, and abstraction in both philosophy and mathematics. We enumerate
various examples for philomatics and psychomatics, some of which are explained
in more depth. The first example is the analysis of relation between the
context principle, semantic holism, and the usage theory of meaning with the
attention mechanism in mathematics. The other example is on the relations of
Plato's theory of forms in philosophy with the holographic principle in string
theory, object-oriented programming, and machine learning. Finally, the
relation between Wittgenstein's family resemblance and clustering in
mathematics is explained. This paper opens the door of research for combining
philosophy and psychology with mathematics.",143,8,1028,16.93
3084,philosophy,"This paper argues that philosophers of science have before them an important
new task that they urgently need to take up. It is to convince the scientific
community to adopt and implement a new philosophy of science that does better
justice to the deeply problematic basic intellectual aims of science than that
which we have at present. Problematic aims evolve with evolving knowledge, that
part of philosophy of science concerned with aims and methods thus becoming an
integral part of science itself. The outcome of putting this new philosophy
into scientific practice would be a new kind of science, both more
intellectually rigorous and one that does better justice to the best interests
of humanity.",115,5,705,42.24
3085,philosophy,"We show that the Bub-Clifton uniqueness theorem for 'no collapse'
interpretations of quantum mechanics (Studies in the History and Philosophy of
Modern Physics 27, 181-219 (1996)) can be proved without the 'weak
separability' assumption.",34,2,237,20.05
3086,philosophy,"The role of operational quantum mechanics, quantum axiomatics and quantum
structures in general is presented as a contribution to a compendium on quantum
physics, its history and philosophy.",28,2,190,17.68
3087,philosophy,"The recent discovery that Einstein once attempted - and quickly abandoned - a
steady-state model of the expanding universe sheds new light on his
philosophical journey from static to dynamic cosmologies.",31,2,203,25.12
3088,philosophy,"I discuss several issues related to ""classical"" spacetime structure. I review
Galilean, Newtonian, and Leibnizian spacetimes, and briefly describe more
recent developments. The target audience is undergraduates and early graduate
students in philosophy; the presentation avoids mathematical formalism as much
as possible.",42,4,321,14.97
3089,philosophy,"In this paper we discuss a design philosophy for interoperable blockchain
systems, using the design philosophy of the Internet architecture as the basis
to identify key design principles. Several interoperability challenges are
discussed in the context of cross-domain transactions. We illustrate how these
principles are informing the interoperability architecture of the MIT Tradecoin
system.",54,4,394,10.91
3090,philosophy,"The dissemination of natural philosophy in the 18th-century, which was based
primarily on Newton's pioneering work in mechanics, optics and astrophysics, is
presented as seen through a remarkable textbook written by a little known Irish
mathematics teacher, Robert Gibson. Later, he became the deputy surveyor
general of Ireland (1752-1760).",49,3,341,21.23
3091,philosophy,"This essay provides a historical, philosophical, and critical overview of the
development of the Transactional Interpretation of Quantum Mechanics (TI). It
is separated into two parts. Part I presents the history and development of TI
from 1986 up to 2016 (the time of writing). Part II lays out current areas of
divergence among researchers in TI.",56,5,348,48.81
3092,philosophy,"The following annotated bibliography contains a reasonably complete survey of
contemporary work in the philosophy of astrophysics. Spanning approximately
forty years from the early 1980s to the present day, the bibliography should
help researchers entering the field to acquaint themselves with its major
texts, while providing an opportunity for philosophers already working on
astrophysics to expand their knowledge base and engage with unfamiliar
material.",64,3,459,13.62
3093,philosophy,"Duerer's engraving ``MELENCOLIA I'' was circulated in two versions not
previously distinguished. Besides their conspicuous early Renaissance
scientific instruments and tools, they contain numerous apparently unreported
concealments whose detection reveals heresies expressed in the work. The main
one is encoded in the motto {\em MELENCOLIA I} itself: Natural Philosophy, not
Mathematical Philosophy or Theological Philosophy, is the way to knowledge.
Unusual optical illusions and subliminal images, differing between the two
versions, declare the relativity and ambiguity of perception, and indicate that
the work was a Humanist document intended for a Humanist viewership.",92,5,675,-2.64
3094,philosophy,"The philosophy of the trajectory representation is contrasted with the
Copenhagen and Bohmian philosophies.",14,2,107,14.97
3095,philosophy,We present a history and analysis of this experiment.,9,2,53,45.42
3096,philosophy,A pedagogical account of entropy and its history.,8,2,49,29.52
3097,philosophy,"The philosophy of science is a discipline concerning the metaphysical aspect
of science. Recently, I proposed measurement theory, which is characterized as
the metaphysical and linguistic interpretation of quantum mechanics. I assert
that this theory is one of the most fundamental languages in science, and thus,
it is located at the central position in science. This assertion will be
examined throughout this preprint, which is written as the draft of my future
book (concerning the philosophy of science). Hence, I hope to hear various
opinions about this draft.",88,6,566,36.69
3098,philosophy,"In the ML fairness literature, there have been few investigations through the
viewpoint of philosophy, a lens that encourages the critical evaluation of
basic assumptions. The purpose of this paper is to use three ideas from the
philosophy of science and computer science to tease out blind spots in the
assumptions that underlie ML fairness: abstraction, induction, and measurement.
Through this investigation, we hope to warn of these methodological blind spots
and encourage further interdisciplinary investigation in fair-ML through the
framework of philosophy.",83,4,565,26.44
3099,philosophy,"Determinism and indeterminism in physical theories are reviewed and some
broader implications of determinism are discussed.",16,2,123,-3.99
3100,philosophy,"A portrait of Kurt Goedel with emphasis on his work on relativity theory and
idealistic philosophy.",16,2,99,29.86
3101,philosophy,"This paper follows up a recent debate as to whether classical electrodynamics
is inconsistent. I suggest that disagreements can be managed by disambiguating
'theory' in two different ways.",28,3,188,31.89
3102,philosophy,"The life and accomplishments of Grete Hermann are described. During the early
twentieth century, she worked in physics, mathematics, philosophy and
education. Her most notable accomplishments in physics were in the
interpretation of quantum theory.",35,4,248,34.22
3103,philosophy,"This paper appeared in a collection of papers titled ""Scientific Papers
Presented to Max Born on his retirement from the Tait Chair of Natural
Philosophy in the University of Edinburgh"", published in 1953 (Oliver and
Boyd).",36,2,223,26.48
3104,philosophy,"We briefly comment (in italian) on present relations between the traditional
philosophy and modern positive sciences, in particular exact sciences.",20,2,147,17.34
3105,philosophy,"Essay Review of ""Einsteins Gegner. Die \""offentliche Kontroverse um die
Relativit\""atstheorie in den 1920er Jahren"" by Milena Wazeck.",18,3,133,36.96
3106,philosophy,"We provide a mathematic model for the Traditional Yin-and-Yang Double Fish
Diagram which from Chinese Traditional Philosophy.",17,2,125,11.92
3107,philosophy,"A slightly(!!!) philosophical article which looks at some interesting
overlaps between some fine mathematical brains and a celestial mechanics legend
from Japan.",22,2,161,23.77
3108,philosophy,"This paper reviews the hole argument as an argument against spacetime
substantivalism. After a careful presentation of the argument itself I review
possible responses.",24,3,167,25.46
3109,philosophy,"This is a translation into English of my Masters thesis (hovedoppgave) from
1991. The main topic of the thesis is the relation between fundamental physics
and philosophy, and a discussion of several possible ontologies of quantum
field theory.",38,3,243,35.27
3110,philosophy,"This paper appeared in a collection of papers titled ""Scientific Papers
Presented to Max Born on his retirement from the Tait Chair of Natural
Philosophy in the University of Edinburgh"", published in 1953 (Oliver and
Boyd), pages 33-40.",38,2,236,24.45
3111,philosophy,"This is a short memoriam celebrating the life and work of the general
relativist Joshua N. Goldberg, who passed away in October, 2020.",23,3,134,68.26
3112,philosophy,"This paper is a short introduction to a special issue on philosophy of
cosmology, published in the May 2014 issue of Studies in History and Philosophy
of Modern Physics. I briefly introduce the philosophy of cosmology, and then
provide a short outline of the contents of the papers in the special issue. The
contributors are George Ellis, Dominico Giulini, Marc Lachi\`eze-Rey, Helge
Kragh, Jeremy Butterfield, Jean-Christophe Hamilton, Mart\'in
L\'opez-Corredoira, Brigitte Falkenburg, Robert Brandenberger and Chris Smeenk.
I conclude with a few remarks on the relationship between aesthetics and
cosmology.",89,5,609,40.38
3113,philosophy,"Editorial of a special issue on dark matter & modified gravity, distributed
across the journals Studies in History and Philosophy of Modern Physics and
Studies in History and Philosophy of Science. Published version of the open
access editorial (in SHPS) available here:
https://doi.org/10.1016/j.shpsa.2021.08.015. The six papers are collected here:
https://www.sciencedirect.com/journal/studies-in-history-and-philosophy-of-science-part-b-studies-in-history-and-philosophy-of-modern-physics/special-issue/10CR71RJLWM.",50,12,519,-29.68
3114,philosophy,"Wolfgang Pauli's philosophy and physics were intertwined. His philosophy was
a variety of Platonism, in which Pauli's affiliation with Carl Jung formed an
integral part, but Pauli's philosophical explorations in physics appeared
before he met Jung. Jung validated Pauli's psycho-philosophical perspective.
Thus, the roots of Pauli's physics and philosophy are important in the history
of modern physics. In his early physics, Pauli attempted to ground his
theoretical physics in positivism. He then began instead to trust his intuitive
visualizations of entities that formed an underlying reality to the sensible
physical world. These visualizations included holistic kernels of
mathematical-physical entities that later became for him synonymous with Jung's
mandalas. I have connected Pauli's visualization patterns in physics during the
period 1900 to 1930 to the psychological philosophy of Jung and displayed some
examples of Pauli's creativity in the development of quantum mechanics. By
looking at Pauli's early physics and philosophy, we gain insight into Pauli's
contributions to quantum mechanics. His exclusion principle, his influence on
Werner Heisenberg in the formulation of matrix mechanics, his emphasis on firm
logical and empirical foundations, his creativity in formulating electron
spinors, his neutrino hypothesis, and his dialogues with other quantum
physicists, all point to Pauli being the dominant genius in the development of
quantum theory. Because Pauli was in a difficult individuation process during
his early years, his own writings on philosophy tend to be sparse and often
contradictory. My analysis of Pauli's physics and philosophy is based upon
published and unpublished sources, and Pauli's later reflections. A pattern has
emerged. Pauli changed his mind from relying on high rationality and
empiricism, to valuing intuitive metaphysical visualizations. This coupled with
disturbing events in his life precipitated a breakdown and led Pauli to seek
treatment at the Jung Clinic. Pauli's psychological tension diminished after
1932. His physics consistently involved symmetry and invariants. His philosophy
allied with Jung's resembled a Platonism of combined psyche and physics. Pauli
sought a rational unification and foundation for his philosophy, but that goal
was cut short by his untimely death at the age of 58.",344,20,2355,36.18
3115,philosophy,"When we try to search for extraterrestrial life and intelligence, we have to
follow some guidelines. The first step is to clarify what is to be meant by
""Life"" and ""intelligence"", i.e. an attempt to define these words. The word
""definition"" refers to two different situations. First, it means an arbitrary
convention. On the other hand it also often designates an attempt to clarify
the content of a pre-existing word for which we have some spontaneous
preconceptions, whatever their grounds, and to catch an (illusory) ""essence"" of
what is defined. It is then made use of pre-existing plain language words which
carry an a priori pre-scientific content likely to introduce some confusion in
the reader's mind. The complexity of the problem will be analyzed and we will
show that some philosophical prejudice is unavoidable. There are two types of
philosophy: ""Natural Philosophy"", seeking for some essence of things, and
""Critical (or analytical) Philosophy"", devoted to the analysis of the
procedures by which we claim to construct a reality. An extension of Critical
Philosophy, Epistemo-Analysis (i.e. the Psycho-Analysis of concepts) is
presented and applied to the defintion of Life and to Astrobiology.",191,14,1209,45.35
3116,philosophy,"The paper defends the thesis that it's possible to maintain some conceptual
preconditions of overcoming of relativistic intentions in modern philosophy of
science (""there are no any general foundations in philosophy of science""). We
found two general foundations in philosophy of science as a minimum. From the
first side it's realistic to reveal on the base of special understanding of
time the value of time not only in natural thought (especially in theory of
gravity) but also in humanitarian knowledge. That's why philosophy of science
has independent position in epistemology and ontology corresponding to
interpretation of time as a general category of scientific thinking. The nature
of time has internally inconsistent (paradoxical) character. Time is phenomenon
which existing and not existing at the same time. This phenomenon is identified
with imaginary movement and also ideal (formal) process of formation of the
nature. The general understanding of time is connected with its ""mathematical""
meaning as calculable formal regulation of language practice and also the
universal organization rules of quantitative parameters of intelligence of
natural (physical) processes. From the second side we can say that exist an
actual branch of philosophy of science. It exists on the basis of disclosure of
aprioristic limits of consciousness of its cultural and historical development.
There is possible a special interpretation of time. In that context time is the
connection of an action of the cultural phenomenon or its ""energy"" with some
kind of ""weight"", the historical importance of a separate limit of
consciousness through analog of ""distance"" as intensity of cultural and
historical space (or ""oppositional nature of interaction of mental
intentions"").",267,13,1768,23.46
3117,philosophy,"Feyerabend frequently discussed physics. He also referred to the history of
the subject when motivating his philosophy of science. Alas, as some examples
show, his understanding of physics remained superficial. In this respect,
Feyerabend is like Popper; the difference being his self-criticism later on,
and the much more tolerant attitude toward the allowance of methods. Quite
generally, partly due to the complexity of the formalism and the new challenges
of their findings, which left philosophy proper at a loss, physicists have
attempted to developed their own meaning of their subject. For instance, in
recent years, the interpretation of quantum mechanics has stimulated a new type
of experimental philosophy, which seeks to operationalize emerging
philosophical issues; issues which are incomprehensible for most philosophers.
In this respect, physics often appears to be a continuation of philosophy by
other means. Yet, Feyerabend has also expressed profound insights into the
possibilities for the progress of physics, a legacy which remains to be
implemented in the times to come: the conquest of abundance, the richness of
reality, the many worlds which still await discovery, and the vast openness of
the physical universe.",187,9,1239,39.26
3118,philosophy,"This paper deals with the ways that the issue of completing quantum mechanics
was brought into laboratories and became a topic in mainstream quantum optics.
It focuses on the period between 1965, when Bell published what now we call
Bell's theorem, and 1982, when Aspect published the results of his experiments.
I argue that what was considered good physics after Aspect's experiments was
once considered by many a philosophical matter instead of a scientific one, and
that the path from philosophy to physics required a change in the physics
community's attitude about the status of the foundations of quantum mechanics.",100,4,622,37.68
3119,philosophy,"About twenty years ago, we proposed the mathematical formulation of
Heisenberg's uncertainty principle, and further, we concluded that Heisenberg's
uncertainty principle and EPR-paradox are not contradictory. This is true,
however we now think that we should have argued about it under a certain firm
interpretation of quantum mechanics. Recently we proposed the linguistic
quantum interpretation (called quantum and classical measurement theory), which
was characterized as a kind of metaphysical and linguistic turn of the
Copenhagen interpretation. This turn from physics to language does not only
extend quantum theory to classical systems but also yield the quantum
mechanical world view (i.e., the philosophy of quantum mechanics, in other
words, quantum philosophy). In fact, we can consider that traditional
philosophies have progressed toward quantum philosophy. In this paper, we first
review the linguistic quantum interpretation, and further, clarify the relation
between EPR-paradox and Heisenberg's uncertainty principle. That is, the
linguistic interpretation says that EPR-paradox is closely related to the fact
that syllogism does not generally hold in quantum physics. This fact should be
compared to the non-locality of Bell's inequality.",178,11,1257,26.0
3120,philosophy,"I observe that, as the physics side of the OPERA-anomaly story is apparently
unfolding, there can still be motivation for philosophy of science to analyze
the six months of madness physicists spent chasing the dream of a new
fundamental-physics revolution. I here mainly report data on studies of the
OPERA anomaly that could be relevant for analyses from the perspective of
phenomenology of philosophy of science. Most of what I report is an insider's
perspective on the debate that evolved from the original announcement by the
OPERA collaboration of evidence of superluminal neutrinos. I also sketch out,
from a broader perspective, some of the objectives I view as achievable for the
phenomenology of philosophy of science.",116,5,727,33.58
3121,philosophy,"Contrary to claims about the irrelevance of philosophy for science, I argue
that philosophy has had, and still has, far more influence on physics than is
commonly assumed. I maintain that the current anti-philosophical ideology has
had damaging effects on the fertility of science. I also suggest that recent
important empirical results, such as the detection of the Higgs particle and
gravitational waves, and the failure to detect supersymmetry where many
expected to find it, question the validity of certain philosophical assumptions
common among theoretical physicists, inviting us to engage in a clearer
philosophical reflection on scientific method.",98,4,656,12.9
3122,philosophy,"This paper puts forward an ontology that is indebted to QBism, Kant, Bohr,
Schr\""odinger, the philosophy of the Upanishads, and the evolutionary
philosophy of Sri Aurobindo. Central to it is that reality is relative to
consciousness or experience. Instead of a single mind-independent reality,
there are different poises of consciousness, including a consciousness to which
``we are all really only various aspects of the One'' (Schr\""odinger). This
ontology helps clear up unresolved issues in the philosophy of science, such as
arise from the reification of either instruments or calculational tools, or
from a disregard of the universal context of science, which is human
experience. It further helps clear up unresolved issues in the philosophy of
mind, among them the problem of intentionality and the dilemma posed by the
mutual inclusion of self and world (Husserl's paradox of human subjectivity).",139,6,905,26.34
3123,philosophy,"I reflect on some of the basic aspects of present day Beyond the Standard
Model particle physics, focusing mostly on the issues of naturalness, in
particular on the so-called hierarchy problem. To all of us, physics as natural
science emerged with Galileo and Newton, and led to centuries of unparalleled
success in explaining and often predicting new phenomena of nature. I argue
here that the long standing obsession with the hierarchy problem as a guiding
principle for the future of our field has had the tragic consequence of
deviating high energy physics from its origins as natural philosophy, and
turning it into a philosophy of naturalness.",106,4,649,27.19
3124,philosophy,"Recent interest in codifying fairness in Automated Decision Systems (ADS) has
resulted in a wide range of formulations of what it means for an algorithmic
system to be fair. Most of these propositions are inspired by, but inadequately
grounded in, political philosophy scholarship. This paper aims to correct that
deficit. We introduce a taxonomy of fairness ideals using doctrines of Equality
of Opportunity (EOP) from political philosophy, clarifying their conceptions in
philosophy and the proposed codification in fair machine learning. We arrange
these fairness ideals onto an EOP spectrum, which serves as a useful frame to
guide the design of a fair ADS in a given context.
  We use our fairness-as-EOP framework to re-interpret the impossibility
results from a philosophical perspective, as the in-compatibility between
different value systems, and demonstrate the utility of the framework with
several real-world and hypothetical examples. Through our EOP-framework we hope
to answer what it means for an ADS to be fair from a moral and political
philosophy standpoint, and to pave the way for similar scholarship from ethics
and legal experts.",177,8,1153,28.88
3125,philosophy,"There is a deeply entrenched view in philosophy and physics, the closed
systems view, according to which isolated systems are conceived of as
fundamental. On this view, when a system is under the influence of its
environment this is described in terms of a coupling between it and a separate
system which taken together are isolated. We argue against this view, and in
favor of the alternative open systems view, for which systems interacting with
their environment are conceived of as fundamental, and the environment's
influence is represented via the dynamical equations that govern the system's
evolution. Taking quantum theories of closed and open systems as our case
study, and considering three alternative notions of fundamentality: (i)~ontic
fundamentality, (ii)~epistemic fundamentality, and (iii)~explanatory
fundamentality, we argue that the open systems view is fundamental, and that
this has important implications for the philosophy of physics, the philosophy
of science, and for metaphysics.",150,5,1007,16.49
3126,philosophy,"Issues related to a materialist philosophy are explored as concerns the
implied equivalence of computers running software and human observers. One
issue explored concerns the measurement process in quantum mechanics. Another
issue explored concerns the nature of experience as revealed by the existence
of dreams. Some difficulties stemming from a materialist philosophy as regards
these issues are pointed out. For example, a gedankenexperiment involving what
has been called ""negative"" observation is discussed that illustrates the
difficulty with a materialist assumption in quantum mechanics. Based on an
exploration of these difficulties, specifications are outlined briefly that
would provide a means to demonstrate the equivalence of of computers running
software and human experience given a materialist assumption.",115,7,823,18.15
3127,philosophy,"This is a contribution to a book on quantum gravity and philosophy. I discuss
nature and origin of the problem of quantum gravity. I examine the knowledge
that may guide us in addressing this problem, and the reliability of such
knowledge. In particular, I discuss the subtle modification of the notions of
space and time engendered by general relativity, and how these might merge into
quantum theory. I also present some reflections on methodological questions,
and on some general issues in philosophy of science which are are raised by, or
a relevant for, the research on quantum gravity.",98,6,592,43.12
3128,philosophy,"Given a bipartite quantum system represented by a tensor product of two
Hilbert spaces, we give an elementary argument showing that if either component
space is infinite-dimensional, then the set of nonseparable density operators
is trace-norm dense in the set of all density operators (and the separable
density operators nowhere dense). This result complements recent detailed
investigations of separability, which show that when both component Hilbert
spaces are finite-dimensional, there is a separable neighborhood (perhaps very
small for large dimensions) of the maximally mixed state.",85,3,591,-5.51
3129,philosophy,"Mathematics cannot anymore be assimilated to a linguistic game, where formal
proofs are strongly differentiated with conjectural thinking, without building
any category of knowledge to understand the passage (Wittgenstein's gist).
Nowadays, philosophy has to face with the growing, exponential ramified tree of
speculative mathematical thinking. Our main (problematical) theses are: 1. In
mathematics, there is no empirical automatism, and no separate, physical-like
motricity. 2: The irreversible-synthetical must force to complexify the
exegetical game of philosophy; numerical experiments in algebra and in number
theory are a kind of letting blow up all possible problems; 4. The nature of
mathematical questioning still remains in question.",103,7,745,20.18
3130,philosophy,"The term complexity derives etymologically from the Latin plexus, which means
interwoven. Intuitively, this implies that something complex is composed by
elements that are difficult to separate. This difficulty arises from the
relevant interactions that take place between components. This lack of
separability is at odds with the classical scientific method - which has been
used since the times of Galileo, Newton, Descartes, and Laplace - and has also
influenced philosophy and engineering. In recent decades, the scientific study
of complexity and complex systems has proposed a paradigm shift in science and
philosophy, proposing novel methods that take into account relevant
interactions.",102,6,694,34.26
3131,philosophy,"In this paper, I present a critical discussion of mathematical arguments
employed in the philosophy of event of Alain Badiou. On the basis of ""Being and
Event"" as well as his other writings, I analyze the main notions of his
philosophy such as the indiscernible, the undecidable, and the unnameable. The
focus of my analysis is both on their mathematical consistency, and their
philosophical consequences. I argue that the mathematical approach developed by
Badiou is seriously defective, and, as a result, that it cannot serve as an
ontological basis for the concept of event as presented in ""Being and Event"".",100,5,611,37.64
3132,philosophy,"Article purpose is the analysis of a question of possibility of
technologization of philosophical knowledge. We understand the organization of
cognitive activity which is guided by the set of methods guaranteed bringing to
successful (i.e. to precisely corresponding set parameters) to applied results
as technologization. Transformation of sense of philosophy allows revealing
possibilities of its technologization. The leading role in this process is
played by philosophy of science which creates conditions for such
transformation. At the same time there is justified an appeal to branch
combination theory of the directions of scientific knowledge and partial
refusal of understanding of philosophy as synthetic knowledge in which the main
task is permission, instead of generation of paradoxes.",115,8,799,18.15
3133,philosophy,"The purpose of this paper is to provide a confession of sorts from an
economist to political science and philosophy. A confession of the weaknesses
of the political position of the economist. It is intended as a guide for
political scientists and philosophers to the ostensible policy criteria of
economics, and an illustration of an argument that demonstrates
logico-mathematically, therefore incontrovertibly, that any policy statement by
an economist contains, or is, a political statement. It develops an inescapable
compulsion that the absolute primacy and priority of political theory and
philosophy in the development of policy criteria must be recognised. Economic
policy cannot be divorced from politics as a matter of mathematical fact, and
rather, as Amartya Sen has done, it ought embrace political theory and
philosophy.",126,6,833,12.06
3134,philosophy,"Vagueness is a linguistic phenomenon as well as a property of physical
objects. Fuzzy set theory is a mathematical model of vagueness that has been
used to define vague models of computation. The prominent model of vague
computation is the fuzzy Turing machine. This conceptual computing device gives
an idea of what computing under vagueness means, nevertheless, it is not the
most natural model. Based on the properties of this and other models of vague
computing, it is aimed to formulate a basis for a philosophy of a theory of
fuzzy computation.",92,6,550,44.34
3135,philosophy,"We focus here on the work of the italian physicist Ettore Majorana, and more
particularly on his 1937 article on the symmetrical theory of the electron and
the positron, probably one of the most important theory for contemporary
thought. We recall the context of this article (Dirac relativistic electron
wave equation) and analyze how Majorana deduces his own equation from a very
general variational principle. After having rewritten Majorana equation in a
more contemporary language, we study its implications in condensed matter
physics and their possible applications in quantum computing. Finally, we
describe some of the consequences of Majorana approach to philosophy.",102,5,676,28.67
3136,philosophy,"In this paper we interrogate the practices of imagining in human-computer
interaction (HCI), particularly in scenario building (SBE) and persona
construction. We discuss the philosophical premises of HCI imaginings in
rationalism, cognitivism and phenomenology, and we propose (feminist) new
materialist philosophy as an enriching perspective that helps generate a
holistic, relational perspective of users, imaginaries and technologies. In the
end we explore the method of figurations as a potential tool for HCI design.",73,4,521,12.97
3137,philosophy,"This is a philosophy-intense physics article, or, if you wish, a
physics-intense philosophy article. Also, being a mathematician, I tend to view
the physics, in particular the essence of quantum physics, in emphasizing the
mathematical structure that serves as its language. However, I do express views
on typically philosophical/epistemological matters. Since these points of view
do not seem to me too widely expressed in the literature, while I find them
quite compelling, I think this note has some interest.",79,5,512,42.92
3138,philosophy,"The paper addresses the phenomenon of cross-cultural resonance, which arises
when ideas coming from different cultures and view systems show mutual
correlation, or coherence. We particularly dwell on the parallels between
modern physics and Indian classical philosophy. The coherence in ideological,
methodological, and ethical spheres is noted and exemplified. Interpretation of
correlations in terms of the Jaspers 'ciphers of transcendence' is proposed. A
brief survey of studies also dealing with coherence between modern science and
ancient teachings is given. In conclusion, a broader perspective of
interrelations between rational science and spiritual tradition is discussed.",94,7,683,21.7
3139,philosophy,"This article proposes a fresh and direct reading of foundational texts of
philosophy and aims at bringing back the inflamed debates that are
contemporaneous with the birth of Greek axiomatics, and indeed at understanding
what is timeless in the questions addressed by Zeno.
  --
  Cet article propose une lecture fraiche et directe de textes fondateurs de la
philosophie et veut faire revivre les d{\'e}bats enflamm{\'e}s qui ont vu
naitrel'axiomatique l{\'e}gu{\'e}e par les Grecs, voire de comprendre ce qu'il
y a d'intemporel dans les questions pos{\'e}es par Z{\'e}non.]",87,3,574,27.83
3140,philosophy,"I provide some philosophical groundwork for the recently proposed
'trans-Planckian censorship' conjecture in theoretical physics. In particular,
I argue that structure formation in early universe cosmology is, at least as we
typically understand it, autonomous with regards to quantum gravity, the high
energy physics that governs the Planck regime in our universe. Trans-Planckian
censorship is then seen as a means of rendering this autonomy an empirical
constraint within ongoing quantum gravity research.",72,4,508,21.74
3141,philosophy,"I discuss Ren{\'e} Thom's approach to philosophy based on his mathematical
background. At the same time, I will highlight his connection with Aristotle,
his criticism of the modern view of science as a predictive process, his ideas
on mathematical education, his position with respect to the French school of
mathematics that was dominent in his time and his relationship with the
philosophical community. I will also touch upon the connections between Thom's
ideas and those of Leibniz, Riemann, Freud and others. The last version of this
paper will appear as a chapter in the book Handbook of the History and
Philosophy of Mathematical Practice (ed. Bharath Sriraman), Springer.",108,6,680,49.55
3142,philosophy,"Philosophy of science attempts to describe all parts of the scientific
process in a general way in order to facilitate the description, execution and
improvements of this process.
  So far, all proposed philosophies have only covered existing processes and
disciplines partially and imperfectly. In particular logical approaches have
always received a lot of attention due to attempts to fundamentally address
issues with the definition of science as a discipline with reductionist
theories.
  We propose a new way to approach the problem from the perspective of
computational complexity and argue why this approach may be better than
previous propositions based on pure logic and mathematics.",104,5,693,19.71
3143,philosophy,"Programs in quantum gravity often claim that time emerges from fundamentally
timeless physics. In the semiclassical time program time arises only after
approximations are taken. Here we ask what justifies taking these
approximations and show that time seems to sneak in when answering this
question. This raises the worry that the approach is either unjustified or
circular in deriving time from no-time.",62,5,404,47.28
3144,philosophy,"We discuss the influential role of Niels Bohr's work in the anti-realist
realist re-foundation of physics that took place during the 20th century. We
will focus in how, developing the modern co-relational matrix of scientific
understanding, his essentially anti-realist scheme was able to capture, subvert
and defeat the realist program of science through the establishment of a
weakened impotent form of ""religious realism"" grounded on faith instead of
scientific conditions. Finally, we will focus in how, still today, anti-realist
realism continues to rule the contemporary post-modern research in both
(quantum) physics and philosophy.",93,4,639,14.63
3145,philosophy,"I argue that research in physics operates under an implicit community
philosophy, and I offer a definition I think physicists would accept, by and
large. I compare this definition to what philosophers, sociologists, and
historians of science, with physicists, say we are doing.",43,3,277,32.73
3146,philosophy,"Self-supervised learning (SSL) for graph neural networks (GNNs) has attracted
increasing attention from the graph machine learning community in recent years,
owing to its capability to learn performant node embeddings without costly
label information. One weakness of conventional SSL frameworks for GNNs is that
they learn through a single philosophy, such as mutual information maximization
or generative reconstruction. When applied to various downstream tasks, these
frameworks rarely perform equally well for every task, because one philosophy
may not span the extensive knowledge required for all tasks. To enhance the
task generalization across tasks, as an important first step forward in
exploring fundamental graph models, we introduce PARETOGNN, a multi-task SSL
framework for node representation learning over graphs. Specifically, PARETOGNN
is self-supervised by manifold pretext tasks observing multiple philosophies.
To reconcile different philosophies, we explore a multiple-gradient descent
algorithm, such that PARETOGNN actively learns from every pretext task while
minimizing potential conflicts. We conduct comprehensive experiments over four
downstream tasks (i.e., node classification, node clustering, link prediction,
and partition prediction), and our proposal achieves the best overall
performance across tasks on 11 widely adopted benchmark datasets. Besides, we
observe that learning from multiple philosophies enhances not only the task
generalization but also the single task performances, demonstrating that
PARETOGNN achieves better task generalization via the disjoint yet
complementary knowledge learned from different philosophies. Our code is
publicly available at https://github.com/jumxglhf/ParetoGNN.",229,13,1740,22.85
3147,philosophy,"We compare and contrast the basic principles of two philosophies: Bayesianism
and relationalism. These two philosophies are both based upon criteria of
rationality. The analogy invoked in such a comparison seems rather apt when
discussing tentative proofs of quantum nonlocality. We argue that Bayesianism
is almost to quantum theory, what general covariance is to general relativity.
This is because the Bayesian interpretation of quantum theory can be given a
relational flavour.",71,6,481,31.68
3148,philosophy,"It is argued that string theory may pose new conceptual issues for the
history and philosophy of science.",18,2,105,44.75
3149,philosophy,"I show how quantum mechanics, like the theory of relativity, can be
understood as a 'principle theory' in Einstein's sense, and I use this notion
to explore the approach to the problem of interpretation developed in my book
Interpreting the Quantum World (Cambridge: Cambridge University Press, 1999).",47,2,301,15.31
3150,philosophy,"In this article we review some key time cycles in ancient Indian astronomy,
especially those that have emerged from researches in the past couple of
decades expressing knowledge of the changing frame of earth's axis. The article
also briefly reviews the philosophy related to the interconnection between the
inner and the outer cosmos that was used in the analytical narrative related to
this astronomy.",64,3,403,22.08
3151,philosophy,"It is proved the falsity of idea that the Uncertainty Relations (UR) have
crucial significances for physics. Additionally one argues for the necesity of
an UR-disconnected quantum philosophy.",28,3,191,31.89
3152,philosophy,"What do we do when cosmology raises questions it cannot answer? These include
the existence of a multiverse and the universality of the laws of physics. We
cannot settle any of these issues by experiment, and this is where philosophers
enter the debate. Drawing the line between philosophy and physics has never
been easy. Perhaps it is time to stop trying. The interface is ripe for
exploration.",67,6,396,60.11
3153,philosophy,"The purpose of this project is to outline various philosophies on the
metaphysics of mathematics that have been prominent since the time of Cantor,
highlighting some biographical aspects that have influenced these ideas as
well. The main topics will be the independent existence of mathematics and
controversies over the nature of the mathematical infinite. After describing
these ideas, I will demonstrate some of the similarities that are common to
these philosophies, showing that despite reaching different conclusions many
are guided by the same driving idea.",85,4,564,34.29
3154,philosophy,"This essay presents an accessible introduction to the basic motivations to
seek a quantum theory of gravity. It focuses on one approach- loop quantum
gravity - as an example of the rich philosophical issues that arise when we try
to combine spacetime and quantum physics.",45,3,271,40.69
3155,philosophy,"We make some remarks on the mathematics and metaphysics of the hole argument,
in response to a recent article in this journal by Weatherall ([2018]). Broadly
speaking, we defend the mainstream philosophical literature from the claim that
correct usage of the mathematics of general relativity 'blocks' the argument.",48,3,315,30.2
3156,philosophy,"We reminisce and discuss applications of algorithmic probability to a wide
range of problems in artificial intelligence, philosophy and technological
society. We propose that Solomonoff has effectively axiomatized the field of
artificial intelligence, therefore establishing it as a rigorous scientific
discipline. We also relate to our own work in incremental machine learning and
philosophy of complexity.",56,4,407,1.73
3157,philosophy,"This is the summary of the parallel session entitled ""Time and Philosophy in
Physics"", chaired by Shokoufe Faraji at the sixteenth Marcel Grossmann Meeting.
This parallel session aimed to discuss open issues related to Time and
fundamental laws from different perspectives in a complementary point of view.",47,3,306,39.16
3158,philosophy,"The paper offers an argument against an intuitive reading of the Stone-von
Neumann theorem as a categoricity result, thereby pointing out that, against
what is usually taken to be the case, this theorem does not entail any
model-theoretical difference between the theories that validate it and those
that don't.",49,2,311,13.28
3159,philosophy,"We offer an argument against simplicity as a sole intrinsic criterion for
nomic realism. The argument is based on the simplicity bubble effect.
Underdetermination in quantum foundations illustrates the case.",30,4,207,19.03
3160,philosophy,"After a survey of the present state of cosmological theory and observations,
this article discusses a series of major themes underlying the relation of
philosophy to cosmology. These are: A: The uniqueness of the universe; B: The
large scale of the universe in space and time; C: The unbound energies in the
early universe; D: Explaining the universe -- the question of origins; E: The
universe as the background for existence; F: The explicit philosophical basis;
G: The Anthropic question: fine tuning for life; H: The possible existence of
multiverses; I: The natures of existence. Each of these themes is explored and
related to a series of Theses that set out the major issues confronting
cosmology in relation to philosophy.",120,4,730,22.72
3161,philosophy,A very brief and popular account of the time machine problem.,11,2,61,68.77
3162,philosophy,"Talk given at the 6th Philosophy-and-Physics-Workshop ``Epistemological
Aspects of the Role of Mathematics in Physical Science'', FEST, Heidelberg,
Feb. 1993",20,2,157,17.34
3163,philosophy,Homage is paid to E. Majorana by dedicating our recent work in his memory.,14,3,74,64.37
3164,philosophy,In memoria of Vladimir Naumovich Gribov,6,1,39,73.85
3165,philosophy,One of Darboux's seminal results is archived here,8,1,49,71.82
3166,philosophy,Crum's seminal result of 1955 is archived here,8,1,46,80.28
3167,philosophy,"Schroedinger's famous quadruple of factorizations of the hypergeometric
equation is archived here",12,1,97,33.92
3168,philosophy,"Short note by Marcel Brillouin on the representation of the mass point in
general relativity.",15,2,93,39.33
3169,philosophy,"It has been shown at other occasions that recent results of modern physics
can be used to shed some more light onto the foundations of the world, provided
the actual task of philosophy is being re-interpreted in terms of a theory
which is following up the results of science rather than laying the grounds for
the latter, contrary to what the original intention of Aristotelian ""prima
philo- sophia"" would imply. As it turns out, the interpretation of the main
results of present research dealing with aspects of quantum information theory
and quantum gravity, respectively, as well as with self-organized criticality,
suffices to re-construct a large class of phenomena not only within the field
of physics proper, but also within chemistry, biology, and even the social
sciences. We show that questions of ultimate reality and meaning can only be
answered within a framework of speculative philosophy which is rooted though in
what sceptic philosophy is able to derive from scientific results.",160,4,995,8.92
3170,philosophy,"The paper presents shortly the geometric approach to the problem of a general
quantization formalism, both physically meaningful and mathematically
consistent.",21,2,159,-0.61
3171,philosophy,"The author recollects Sergio Fubini's impact on field theory (radial
quantization, merons, conformal quantum mechanics) and on MIT.",18,2,131,10.91
3172,philosophy,"Public lecture given at The Fields Institute, June 2, 2005.",10,2,59,69.79
3173,philosophy,"Even if Einstein brought major contributions as a founder of quantum
mechanics, he remained deeply unsatisfied with the bases of this structure he
knew to be so efficient for physics. His critics are often known through his
numerous controversies wih N. Bohr for a few decades. It has long been
suggested that his critics were obsolete and came from an aging man and that it
was more a question of philosophy anyway. After J. Bell's contribution however
it was claimed that the debate could be closed by an experimental proof, a
strange experimental intrusion in philosophy or a strange philosophy. Finally,
the experiment being performed, in particular in Orsay with the repeatedly
successful experiments of A. Aspect, it was claimed that N. Bohr won. Would the
debate be closed? Today and fifty years after his death, it seems that
Einstein's critics to quantum mechanics are being regarded differently. Why is
it so? Is it due to physics coming back to the debate? It will be attempted to
accurately report Einstein's writings on the matter and to find elements of
answer to the raised questions.",184,12,1099,55.95
3174,philosophy,"History of Neutrino Physics is revied with special emphasis on anecdotal
events often neglected.",14,2,96,31.89
3175,philosophy,"It is said that Einstein's conceptual base for the theory of relativity was
the philosophy formulated by Immanuel Kant. Then, is it possible to see how
Kant played a role in Einstein's thinking without reading Kant's books? This
question arises because it is not possible for physicists to read Kant's
writings. Yes, it is possible if we use the method of physics. It is known also
that Kant's mode of thinking was profoundly affected by the geography of
Koenigsberg where he spent eighty years of entire life. We examine what aspect
of this geography led Kant to create his philosophy upon which Einstein's
concept of relativity was based. It is pointed out that the Eastern philosophy
of Taoism is a product of the geographical environment similar to that of
Kant's Koenigsberg, and therefore that Kantianism is strikingly similar to
Taoism.",140,7,843,51.18
3176,philosophy,Samuel Preston's 1875 postulates concerning the nature ether are reviewed.,10,2,74,52.87
3177,philosophy,"This paper introduces terms like inference, substance, etc. and discusses
atomic reactions as understood by the ancient Indian physicists of the
Nyaya-Vaisesika School.",23,3,168,42.88
3178,philosophy,"While philosophy of science is the study of problems of knowledge concerning
science in general, there also exists - or should exist - a '' philosophy in
science'' directed at finding out in what ways our actual scientific knowledge
may validly contribute to the basic philosophical quest. Contrary to philosophy
of science, which is a subject for philosophers, philosophy in science calls on
the services of physicists. When, in its spirit, quantum theory and Bell's
theorem are used as touchstones, the two main traditional philosophical
approaches, realism and idealism, are found wanting. A more suitable conception
seems to be an intermediate one, in which the mere postulated existence of a
holistic and hardly knowable Mind-Independent Reality is found to have an
explaining power. Some corrections to comments by Schins of a previous work on
the same subject are incorporated.",139,6,884,35.41
3179,philosophy,"Peter Lewis ([1997]) has recently argued that the wavefunction collapse
theory of GRW (Ghirardi, Rimini, and Weber [1986]) can only solve the problem
of wavefunction tails at the expense of predicting that arithmetic does not
apply to ordinary macroscopic objects. More specifically, Lewis argues that the
GRW theory must violate the enumeration principle: that `if marble 1 is in the
box and marble 2 is in the box and so on through marble $n$, then all $n$
marbles are in the box' ([1997], p. 321). Ghirardi and Bassi ([1999]) have
replied that it is meaningless to say that the enumeration principle is
violated because the wavefunction Lewis uses to exhibit the violation cannot
persist, according to the GRW theory, for more than a split second ([1999], p.
709). On the contrary, we argue that Lewis's argument survives Ghirardi and
Bassi's criticism unscathed. We then go on to show that, while the enumeration
principle can fail in the GRW theory, the theory itself guarantees that the
principle can never be empirically falsified, leaving the applicability of
arithmetical reasoning to both micro- and macroscopic objects intact.",184,8,1137,25.66
3180,philosophy,"In a previous article (cf. quant-ph/9905065) we argued that, while Lewis is
correct that the enumeration principle fails in dynamical wavepacket reduction
theories, one need not following Lewis in rejecting these theories. Because the
dynamical reduction process itself prevents the failure of enumeration from
ever becoming manifest, and because one can treat the semantics for dynamical
reduction theories as not adding anything of ontological import to them, it is
reasonable to accept these theories notwithstanding Lewis's counting anomaly.
In their response to our paper (cf. quant-ph/9907050), Bassi and Ghirardi
reject our criticisms of their own response to Lewis, as well as our argument
against Lewis that dynamical reduction precludes failures of enumeration from
ever becoming manifest. Our intention here is to demonstrate that Bassi and
Ghirardi's responses to us do not succeed.",132,7,894,32.22
3181,philosophy,"The Aharonov-Casher effect, entry in the Compendium of Quantum Physics:
Concepts, Experiments, History and Philosophy, ed. F. Weinert, K. Hentschel, D.
Greenberger and B. Falkenburg (Springer), to appear",28,6,203,45.12
3182,philosophy,"Berry's phase, entry in the Compendium of Quantum Physics: Concepts,
Experiments, History and Philosophy, ed. F. Weinert, K. Hentschel, D.
Greenberger and B. Falkenburg (Springer), to appear",27,6,190,53.88
3183,philosophy,"Errors and paradoxes in quantum mechanics, entry in the Compendium of Quantum
Physics: Concepts, Experiments, History and Philosophy, ed. F. Weinert, K.
Hentschel, D. Greenberger and B. Falkenburg (Springer), to appear",31,6,218,44.1
3184,philosophy,"A review of the term ""counterfactuals"" in various contexts of quantum
mechanics.",12,2,80,33.92
3185,philosophy,"This article was originally written for scholarpedia.org. It describes the
origins and related background of Bethe-Salpeter equation.",17,4,133,37.47
3186,philosophy,"Invited contribution to the collective book ""The Birth of String Theory""",11,1,72,43.39
3187,philosophy,"The subject of uranium isotope separation by the use of gas cenrifuges is a
very active one. I present the physics of this process and some of its history.",29,3,155,73.68
3188,philosophy,"A critical discussion of recent attempts to revise the modern physics history
is presented.",14,2,91,31.89
3189,philosophy,"Multiverse scenarios in cosmology assume that other universes exist ""beyond""
our own universe. They are an exciting challenge both for empirical and
theoretical research as well as for philosophy of science. They could be
necessary to understand why the big bang occurred, why (some of) the laws of
nature and the values of certain physical constants are the way they are, and
why there is an arrow of time. This essay clarifies competing notions of
""universe"" and ""multiverse""; it proposes a classification of different
multiverse types according to various aspects how the universes are or are not
separated from each other; it reviews the main reasons for assuming the
existence of other universes: empirical evidence, theoretical explanation, and
philosophical arguments; and, finally, it argues that some attempts to
criticize multiverse scenarios as ""unscientific"", insisting on a narrow
understanding of falsification, is neither appropriate nor convincing from a
philosophy of science point of view. --
  Keywords: big bang, universe, multiverse, cosmic inflation, time, quantum
gravity, string theory, laws of nature, physical constants, fine-tuning,
anthropic principle, philosophy of science, metaphysics, falsificationism",179,5,1233,9.96
3190,philosophy,This article discusses aspects of Dirac's work that are less familiar.,11,2,70,60.31
3191,philosophy,"Dirac's contributions to the discovery of non-relativistic quantum mechanics
and quantum electrodynamics, prior to his discovery of the relativistic wave
equation, are described.",23,2,178,5.83
3192,philosophy,An account of some of the life and work of John Bell,12,1,52,101.6
3193,philosophy,"This article discusses von Neumann's ""proof"" that hidden variable theories
are impossible.",12,2,90,25.46
3194,philosophy,"It is argued that it is possible to give operational meaning to free will and
the process of making a choice without employing metaphysics.",24,2,139,55.58
3195,philosophy,"Sommerfeld shows that the Wien displacement formula implies the existence of
Planck's constant.",13,2,95,41.36
3196,philosophy,"I briefly present a personal view about alleged scientific results on free
will.",13,2,80,66.74
3197,philosophy,A critical look at the history of relativistic dynamics.,9,2,56,28.5
3198,philosophy,"Lundmark established observational evidence that the Universe is expanding.
Lema\^itre established theoretical evidence. Hubble established observational
proof.",17,4,160,-18.92
3199,philosophy,"This short paper focuses on Schr\""oder's contribute towards a structural view
of group theory.",14,2,94,57.27
3200,philosophy,Ken Wilson is remembered.,4,2,25,50.5
3201,philosophy,"In a recent article, Luciano Floridi explains his view of Turing's legacy in
connection to the philosophy of information. I will very briefly survey one of
Turing's other contributions to the philosophy of information and computation,
including similarities to Shannon's own methodological approach to information
through communication, showing how crucial they are and have been as
methodological strategies to understanding key aspects of these concepts. While
Floridi's concept of Levels of Abstraction is related to the novel methodology
of Turing's imitation game for tackling the question of machine intelligence,
Turing's other main contribution to the philosophy of information runs contrary
to it. Indeed, the seminal concept of computation universality strongly
suggests the deletion of fundamental differences among seemingly different
levels of description. How might we reconcile these apparently contradictory
contributions? I will argue that Turing's contribution should prompt us to plot
some directions for a philosophy of information and computation, one that
closely parallels the most important developments in computer science, one that
understands the profound implications of the works of Turing, Shannon and
others.",175,6,1239,16.46
3202,philosophy,I correct a misrepresentation of QBism as antirealist.,8,2,54,21.06
3203,philosophy,"Wilson was a physicist who changed both the substance and style of
theoretical science.",14,2,87,57.27
3204,philosophy,"We interpret the philosophy of Niels Bohr as related to the so called
""linguistic turn"" and consider paraconsistency in the light of the Bohrian
notion of complementarity. Following [16], Jean-Yves Beziau has discussed the
seemingly contradictory perspectives found in the quantum mechanical double
slit experiment in terms of paraconsistent view-points [7, 8]. This
interpretation goes in line with the well known Bohrian Neo-Kantian
epistemological account of quantum mechanics. In the present paper, we put
forward the idea that one can also consider, within quantum mechanics and
departing from the philosophy of the danish physicist, a more radical
paraconsistency found within one of the main formal elements of the theory,
namely, quantum superpositions. We will argue that, rather than
epistemological, the contradictions found within quantum superpositions could
be interpreted as ontological contradictions.",131,6,917,19.5
3205,philosophy,"A brief account of interesting moments in the genesis of the quark paradigm
is presented.",15,2,89,47.79
3206,philosophy,"This article is dedicated to the 80th birthday of the outstanding Georgian
and Soviet nuclear physicist Professor R. I. Jibuti (1934-1992).",21,4,139,33.24
3207,philosophy,"I try to recreate the scientific atmosphere during Wilson's visits to Moscow
in '60-s and '70-s",16,1,95,55.24
3208,philosophy,"We propose an interpretation of the Newton's second law that is suggested by
Galilean Relativity theory.",16,2,104,29.86
3209,philosophy,"A review is presented of the origin and development of the atomic hypothesis
from antiquity till about the first millennium of the common era.",24,2,142,30.2
3210,philosophy,"This dissertation is about The history of quaternions and their associated
rotation groups as it relates to theoretical physics.",19,2,128,26.81
3211,philosophy,"This article gives a sketch of teachers and colleagues who have had strong
influence on my becoming a particle physicist.",20,2,121,51.18
3212,philosophy,"The marvelous Les Houches summer school of 1970 bore the trademark of Raymond
Stora.",14,2,84,74.19
3213,philosophy,Response to William A. Wilson on the limits and fallibility of science.,12,3,71,56.93
3214,philosophy,"Unless we change direction, we are likely to wind up where we are headed.
(Ancient Chinese proverb)",17,2,99,79.77
3215,philosophy,"This study analyzes how the accumulation of knowledge takes place in
para-scientific areas, focusing on the case of Analytic Philosophy. The
theoretical framework chosen for the analysis is Kuhn's theory of normal
science. The methodology employed is qualitative citation context analysis. A
sample of 60 papers published in leading Analytic Philosophy journals between
1950 and 2009 is analyzed, and a specific classsificatory scheme is developed
to classify citations according to their epistemological function. Compared to
previous studies of citation context, this is the first paper that includes the
temporal dimension into the analysis of citation context, in order to gain
insights into the process of knowledge accumulation. Interestingly, the results
show that Analytic Philosophy started accumulating after Second World War, but
in a peculiar way. The accumulation was not matched by a corresponding rising
consensus. This can be explained by the hypothesis that AP underwent a process
of fragmentation in sub-fields during the second half of the century.",158,9,1067,26.0
3216,philosophy,Stimulated by a recent preprint of Bricmont and Goldstein.,9,2,58,45.42
3217,philosophy,"This is the memoir of Brian Dennis - his life story to date, and his
involvement with high energy solar physics.",21,2,112,59.64
3218,philosophy,"We describe the Discovery of Kepler-16b, the first widely accepted detection
of a circumbinary planet.",15,2,102,30.87
3219,philosophy,"Speech on the occasion of accepting the Dagmar and Vaclav Havel Foundation
VIZE 97 Prize for 2017. Delivered at Prague Crossroads, October 5, 2017",24,2,146,59.3
3220,philosophy,"A few thoughts on physical meaning of geometry, space and time.",11,2,63,68.77
3221,philosophy,"Computational philosophy is the use of mechanized computational techniques to
unearth philosophical insights that are either difficult or impossible to find
using traditional philosophical methods. Computational metaphysics is
computational philosophy with a focus on metaphysics. In this paper, we (a)
develop results in modal metaphysics whose discovery was computer assisted, and
(b) conclude that these results work not only to the obvious benefit of
philosophy but also, less obviously, to the benefit of computer science, since
the new computational techniques that led to these results may be more broadly
applicable within computer science. The paper includes a description of our
background methodology and how it evolved, and a discussion of our new results.",113,5,768,17.37
3222,philosophy,"This paper will attempt to show that the Doppler principle was of major
relevance to Einstein for the genesis of the special theory of relativity.",25,2,146,37.64
3223,philosophy,"We show a possibility to apply certain philosophical concepts to the analysis
of concrete mathematical structures. Such application gives a clear
justification of topological and geometric properties of considered
mathematical objects.",31,3,235,-3.49
3224,philosophy,A collection of articles reviewing Trinity on its 75th anniversary.,10,2,67,27.49
3225,philosophy,"Einstein's 1932 efforts of persuasion to renounce the cosmological constant
and his possible influence on Robertson.",16,2,116,29.86
3226,philosophy,"I analyze the meaning of mass in Newtonian mechanics. First, I explain the
notion of primitive ontology, which was originally introduced in the philosophy
of quantum mechanics. Then I examine the two common interpretations of mass:
mass as a measure of the quantity of matter and mass as a dynamical property. I
claim that the former is ill-defined, and the latter is only plausible with
respect to a metaphysical interpretation of laws of nature. I explore the
following options for the status of laws: Humeanism, primitivism about laws,
dispositionalism, and ontic structural realism.",93,6,586,35.68
3227,philosophy,History of Quark Matter '84 is presented,7,1,40,55.91
3228,philosophy,"This article is a theoretical study on the effectiveness of educational
research in the context of Philosophy of science. This topic of discussion, in
the area of educational research, has been the subject of intellectual debate
and arises again at the beginning of the 21st century. This article outlines
the challenges and opportunities for scientific effectiveness facing
educational research if it aspires to contribute to the ideal of an education
of excellence and quality. Nine strategies to improve scientific effectiveness
in educational research are identified and discussed. As a conclusion, it is
argued that the foundations of contemporary educational research need to be
revisited and reformulated, parallel to the new concepts present in the
philosophy of science, to face the new problems present in our society.",126,6,828,20.52
3229,philosophy,"We recently presented the so-called allagmatic method, which includes a
system metamodel providing a framework for describing, modelling, simulating,
and interpreting complex systems. Its development and programming was guided by
philosophy, especially by Gilbert Simondon's philosophy of individuation,
Alfred North Whitehead's philosophy of organism, and concepts from cybernetics.
Here, a mathematical formalism is presented to better describe and define the
system metamodel of the allagmatic method, thereby further generalising it and
extending its reach to a more formal treatment and allowing more theoretical
studies. By using the formalism, an example for such a further study is
provided with mathematical definitions and proofs for model creation and
equivalence of cellular automata and artificial neural networks.",114,5,827,0.25
3230,philosophy,"This is a personal history of the Hastings-Michalakis proof of quantum Hall
conductance quantization.",14,2,101,31.89
3231,philosophy,"After the advent of the theory of special relativity, the existence of
absolute time in nature was rejected within the society of physics. In recent
decades, William Lane Craig has endeavoured to offer an interpretation of the
empirical evidences that support the theory of relativity while maintaining the
concept of absolute time. His interpretation, however, is based upon
supernatural presuppositions due to which it cannot be accepted as a scientific
argument. After explaining Craig's view, we attempt to reconstruct his
explanation for absolute time using the concept of general substantial motion
of nature well-known in Mulla Sadra's philosophy as the most important
approaches in Islamic philosophy, thereby proving general time for the natural
world. Although Craig considers some evidence from modern physics in his
reasoning for absolute time, here, after pointing out to some evidence, it is
discussed that the approach used here is better bridges the gap that exists
between the metaphysics and the physics of the argument.",159,6,1038,22.28
3232,philosophy,"We discuss an extension of classical combinatorics theory to the case of
spatially distributed objects.",15,2,103,22.41
3233,philosophy,"Unperformed measurements have no results. Unobserved results can affect
future measurements.",11,3,92,23.59
3234,philosophy,"We suggest a forcing version of Yablo's paradox and discuss its implication
on self-reference.",14,2,94,31.89
3235,philosophy,"The ""universality"" of critical phenomena is much discussed in philosophy of
scientific explanation, idealizations and philosophy of physics. Lange and
Reutlinger recently opposed Batterman concerning the role of some deliberate
distortions in unifying a large class of phenomena, regardless of microscopic
constitution. They argue for an essential explanatory role for ""commonalities""
rather than that of idealizations. Building on Batterman's insight, this
article aims to show that assessing the differences between the universality of
critical phenomena and two paradigmatic cases of ""commonality strategy"" - the
ideal gas model and the harmonic oscillator model-is necessary to avoid the
objections raised by Lange and Reutlinger. Taking these universal explanations
as benchmarks for critical phenomena reveals the importance of the different
roles played by analogies underlying the use of the models. A special
combination of physical and formal analogies allows one to explain the
epistemic autonomy of the universality of critical phenomena through an
explicative loop.",152,7,1078,12.06
3236,philosophy,This is a pedagogical discussion of the foundations of the quantum theory.,12,2,74,33.92
3237,philosophy,"Career opportunities are often a matter of chance, but also of willingness to
cross interdisciplinary boundaries.",16,2,113,21.4
3238,philosophy,A short autobiography written for a centennial party.,8,2,53,4.14
3239,philosophy,"We study some aspects of the emergence of logos from chaos on a basal model
of the universe using methods and techniques from algorithmic information and
Ramsey theories. Thereby an intrinsic and unusual mixture of meaningful and
spurious, emerging laws surfaces. The spurious, emergent laws abound, they can
be found almost everywhere. In accord with the ancient Greek theogony one could
say that logos, the Gods and the laws of the universe, originate from ""the
void,"" or from chaos, a picture which supports the unresolvable/irreducible
lawless hypothesis. The analysis presented in this paper suggests that the
""laws"" discovered in science correspond merely to syntactical correlations, are
local and not universal.",110,6,719,40.69
3240,philosophy,"The ongoing debate on the ethics of self-driving cars typically focuses on
two approaches to answering ethical questions: moral philosophy and social
science. I argue that these two approaches are both lacking. We should neither
deduce answers from individual moral theories nor should we expect social
science to give us complete answers. To supplement these approaches, we should
turn to political philosophy. The issues we face are collective decisions that
we make together rather than individual decisions we make in light of what we
each have reason to value. Political philosophy adds three basic concerns to
our conceptual toolkit: reasonable pluralism, human agency, and legitimacy.
These three concerns have so far been largely overlooked in the debate on the
ethics of self-driving cars.",123,8,798,36.69
3241,philosophy,"These are author's recollections of informal discussions on foundations of
quantum mechanics, which happened in his presence in 1970-80s",19,1,136,35.27
3242,philosophy,"This lecture recalls the memory of Baron Roland Eotvos, an outstanding figure
of the experimental exploration of the gravitational interaction.",20,2,143,17.34
3243,philosophy,A short history of Russian researches in Chinese astronomy in 19-20 centuries,12,1,77,42.38
3244,philosophy,"Karl Popper and Paul Feyerabend have been among the most influential
philosophers of science of the twentieth century. Extensive studies have been
dedicated to the development of their controversial relationship, which saw
Feyerabend turning from a student and supporter of Popper to one of his
harshest critics. Yet, it is not as well known that the rift between Popper and
Feyerabend generated mainly in the context of their studies on the foundation
of quantum mechanics, which has been the main subject of their discussions for
about two decades. This paper reconstructs in detail their diatribe over the
foundations of quantum mechanics, emphasizing also the major role that their
personal relationship played in their distancing.",114,5,735,34.09
3245,philosophy,"In this small note I try to summarize some observations about Euclid's
remarkable role in mathematics and about the ambient philosophy.",21,2,135,33.24
3246,philosophy,"I describe the early, from the nineteen sixties, history of attempts at
quantizing General Relativity.",15,2,102,22.41
3247,philosophy,"Philosophy has nurtured fundamental science by asking the right questions.
This scientific growth has fuelled research in various domains and introduced
diverse disciplines. Nanotechnology is an interdisciplinary domain with
numerous applications ranging from medical diagnostics and food technology to
electronics and psychology. Exploring nanotechnology's philosophical and social
perspective can better understand these domains and may open new doors for
research. This review addresses philosophical and other aspects of
nanotechnology, such as history, definitions, vision, language, laws, politics,
and ethics. This is an attempt to equip anyone in the field of nanotechnology
with philosophical and social insights. We expect this review to provide an
introductory understanding of philosophy and other aspects to the
nanotechnologists, which are usually excluded from their degree curriculum.",121,8,900,20.08
3248,philosophy,"Brief recollections by the author about how he contributed to the production
of the Feynman Lectures in Physics",18,1,111,53.21
3249,philosophy,"Brief recollections by the author of how he interacted with Feynman and was
influenced by him.",16,2,94,55.24
3250,philosophy,"Brief recollections of how the author interacted with Steve Weinberg over
issues in quantum mevhanics",15,1,101,47.79
3251,philosophy,"Recollections by the author about how his interactions with John Wheeler
influenced his career in physics.",16,2,106,46.78
3252,philosophy,"Choosing pessimism makes one cynical to and necessitates their destruction of
information.",12,2,90,25.46
3253,philosophy,"Brief recollections by the author about how his work with Kip Thorne
influenced his career in physics.",17,2,102,71.14
3254,philosophy,"The arrow of time refers to the curious asymmetry that distinguishes the
future from the past. Reversing the Arrow of Time argues that there is an
intimate link between the symmetries of 'time itself' and time reversal
symmetry in physical theories, which has wide-ranging implications for both
physics and its philosophy. This link helps to clarify how we can learn about
the symmetries of our world; how to understand the relationship between
symmetries and what is real, and how to overcome pervasive illusions about the
direction of time. Roberts explains the significance of time reversal in a way
that intertwines physics and philosophy, to establish what the arrow of time
means and how we can come to know it. This book is both mathematically and
philosophically rigorous yet remains accessible to advanced undergraduates in
physics and philosophy of physics.",139,6,867,34.8
3255,philosophy,"We scan Paul K. Feyerabend's work in philosophy of physics and of science
more generally for insights that could be useful for the contemporary debate on
the foundations of quantum mechanics. We take as our starting point what
Feyerabend has actually written about quantum mechanics, but we extend our
analysis to his general views on realism, objectivity, pluralism, and the
relation between physics and philosophy, finding that these more general views
could in fact offer many interesting insights for physicists and philosophers
working on quantum foundations.",86,4,564,33.88
3256,philosophy,"Taking the formal analogies between black holes and classical thermodynamics
seriously seems to first require that classical thermodynamics applies to
relativistic regimes. Yet, by scrutinizing how classical temperature is
extended into special relativity, I argue that it falls apart. I examine four
consilient procedures for establishing classical temperature - the Carnot
process, the thermometer, kinetic theory, and black-body radiation. I show how
their relativistic counterparts demonstrate no such consilience in defining
relativistic temperature. Hence, classical temperature does not appear to
survive a relativistic extension. I suggest two interpretations for this
situation - eliminativism akin to simultaneity, or pluralism akin to rotation.",101,7,755,12.43
3257,philosophy,"This is a brief account of the life and work of G\""oran Lindblad.",13,2,65,92.12
3258,philosophy,"This book concerns the metasemantics of quantum mechanics (QM). Roughly, it
pursues an investigation at an intersection of the philosophy of physics and
the philosophy of semantics, and it offers a critical analysis of rival
explanations of the semantic facts of standard QM. Two problems for such
explanations are discussed: categoricity and permanence of rules. New results
include 1) a reconstruction of Einstein's incompleteness argument, which
concludes that a local, separable, and categorical QM cannot exist, 2) a
reinterpretation of Bohr's principle of correspondence, grounded in the
principle of permanence, 3) a meaning-variance argument for quantum logic,
which follows a line of critical reflections initiated by Weyl, and 4) an
argument for semantic indeterminacy leveled against inferentialism about QM,
inspired by Carnap's work in the philosophy of classical logic.",129,5,883,13.31
3259,philosophy,"Deep learning has enabled major advances across most areas of artificial
intelligence research. This remarkable progress extends beyond mere engineering
achievements and holds significant relevance for the philosophy of cognitive
science. Deep neural networks have made significant strides in overcoming the
limitations of older connectionist models that once occupied the centre stage
of philosophical debates about cognition. This development is directly relevant
to long-standing theoretical debates in the philosophy of cognitive science.
Furthermore, ongoing methodological challenges related to the comparative
evaluation of deep neural networks stand to benefit greatly from
interdisciplinary collaboration with philosophy and cognitive science. The time
is ripe for philosophers to explore foundational issues related to deep
learning and cognition; this perspective paper surveys key areas where their
contributions can be especially fruitful.",126,7,952,7.86
3260,philosophy,"English translation of John von Neumann's 1927 trilogy on the foundations of
quantum mechanics with an introduction and detailed commentary.",20,2,140,25.8
3261,philosophy,"A derivation of Balmer's formula is presented, guided by the principles of
simplicity and harmony.",15,2,98,30.87
3262,philosophy,"This article aims at applying the approaches peculiar to analytic philosophy
to the question about representation of the concept of time as a symbol which
can reflect the bases of the modern natural sciences, social sciences and
humanities. The main methods, which the author of this article uses, are
speculative analysis and modeling. The symbolic meaning of the concept of time
demonstrates preconditions for the organization of the bases of the natural
sciences, and social and humanitarian knowledge as well. Judgments for the
meaning of time reveal the essence of the problem in two aspects of discussion
on the dissociation of the foundations in the modern philosophy of physics and
the philosophical analysis of the humanities as well. 1) The formation of the
image of human nature in contemporary philosophy reveals the special role of
the concept of time in epistemology and philosophy of science. 2) This research
reveals the perspective of understanding natural and cultural processes, which
is based on the unification of branches of science. As a result, the research
shows the basics of communication of the natural sciences with the social
science, and humanitarian knowledge as well. This way, the problem of whether
time is a natural process or it is only a human invention can be solved. In
general, time is not exhausted by the meaning of either of the understandings,
and acts as one of the artificial measures people apply. In the same way, the
solution of another problem is reached: the modern discrepancy between separate
bases of science decreases considerably, if not disappears completely.",260,11,1617,36.63
3263,philosophy,"This is an editorial report on the outcomes of an international conference
sponsored by a grant from the National Science Foundation (NSF) (REESE-1205273)
to the School of Education at Boston University and the Center for Philosophy
and History of Science at Boston University for a conference titled: How Can
the History and Philosophy of Science Contribute to Contemporary U.S. Science
Teaching? The presentations of the conference speakers and the reports of the
working groups are reviewed. Multiple themes emerged for K-16 education from
the perspective of the history and philosophy of science. Key ones were that:
students need to understand that central to science is argumentation,
criticism, and analysis; students should be educated to appreciate science as
part of our culture; students should be educated to be science literate; what
is meant by the nature of science as discussed in much of the science education
literature must be broadened to accommodate a science literacy that includes
preparation for socioscientific issues; teaching for science literacy requires
the development of new assessment tools; and, it is difficult to change what
science teachers do in their classrooms. The principal conclusions drawn by the
editors are that: to prepare students to be citizens in a participatory
democracy, science education must be embedded in a liberal arts education;
science teachers alone cannot be expected to prepare students to be
scientifically literate; and, to educate students for scientific literacy will
require a new curriculum that is coordinated across the humanities,
history/social studies, and science classrooms.",249,7,1649,-4.46
3264,philosophy,"In this thought-provoking book, Richard Healey proposes a new interpretation
of quantum theory inspired by pragmatist philosophy. Healey puts forward the
interpretation as an alternative to realist quantum theories on the one hand
such as Bohmian mechanics, spontaneous collapse theories, and many-worlds
interpretations, which are different proposals for describing what the quantum
world is like and what the basic laws of physics are, and non-realist
interpretations on the other hand such as quantum Bayesianism, which proposes
to understand quantum theory as describing agents' subjective epistemic states.
The central idea of Healey's proposal is to understand quantum theory as
providing not a description of the physical world but a set of authoritative
and objectively correct prescriptions about how agents should act. The book
provides a detailed development and defense of that idea, and it contains
interesting discussions about a wide range of philosophical issues such as
representation, probability, explanation, causation, objectivity, meaning, and
fundamentality. Healey's project is at the intersection of physics and
philosophy. The book is divided into two parts. Part I of the book discusses
the foundational questions in quantum theory from the perspective of the
prescriptive interpretation. In Part II, Healey discusses the philosophical
implications of the view. Both parts are written in a way that is largely
accessible to non-specialists. In this brief book review, I will focus on two
questions: (1) How does Healey's idea work? (2) What reasons are there to
believe in it?",239,10,1603,32.53
3265,philosophy,"A distinct feature of Hindu religious and philosophical text is that they
come from a library of texts rather than single source. The Upanishads is known
as one of the oldest philosophical texts in the world that forms the foundation
of Hindu philosophy. The Bhagavad Gita is core text of Hindu philosophy and is
known as a text that summarises the key philosophies of the Upanishads with
major focus on the philosophy of karma. These texts have been translated into
many languages and there exists studies about themes and topics that are
prominent; however, there is not much study of topic modelling using language
models which are powered by deep learning. In this paper, we use advanced
language produces such as BERT to provide topic modelling of the key texts of
the Upanishads and the Bhagavad Gita. We analyse the distinct and overlapping
topics amongst the texts and visualise the link of selected texts of the
Upanishads with Bhagavad Gita. Our results show a very high similarity between
the topics of these two texts with the mean cosine similarity of 73%. We find
that out of the fourteen topics extracted from the Bhagavad Gita, nine of them
have a cosine similarity of more than 70% with the topics of the Upanishads. We
also found that topics generated by the BERT-based models show very high
coherence as compared to that of conventional models. Our best performing model
gives a coherence score of 73% on the Bhagavad Gita and 69% on The Upanishads.
The visualization of the low dimensional embeddings of these texts shows very
clear overlapping among their topics adding another level of validation to our
results.",276,12,1634,46.0
3266,philosophy,"I argue that Immanuel Kant's critical philosophy -- in particular the
doctrine of transcendental idealism which grounds it -- is best understood as
an `epistemic' or `metaphilosophical' doctrine. As such it aims to show how one
may engage in the natural sciences and in metaphysics under the restriction
that certain conditions are imposed on our cognition of objects. Underlying
Kant's doctrine, however, is an ontological posit, of a sort, regarding the
fundamental nature of our cognition. This posit, sometimes called the
`discursivity thesis', while considered to be completely obvious and
uncontroversial by some, has nevertheless been denied by thinkers both before
and after Kant. One such thinker is Jakob Friedrich Fries, an early neo-Kantian
who, despite his rejection of discursivity, also advocated for a
metaphilosophical understanding of critical philosophy. As I will explain, a
consequence for Fries of the denial of discursivity is a radical
reconceptualisation of the method of critical philosophy; whereas this method
is a priori for Kant, for Fries it is in general empirical. I discuss these
issues in the context of quantum theory, and I focus in particular on the views
of the physicist Niels Bohr and the Neo-Friesian philosopher Grete Hermann. I
argue that Bohr's understanding of quantum mechanics can be seen as a natural
extension of an orthodox Kantian viewpoint in the face of the challenges posed
by quantum theory, and I compare this with the extension of Friesian philosophy
that is represented by Hermann's view.",242,9,1547,32.57
3267,philosophy,"During the last three decades, there has been a growing realization among
physicists and cosmologists that the relation between particle physics and
cosmology may constitute yet another successful example of the unity of
science. However, there are important conceptual problems in the unification of
the two disciplines, e.g. in connection with the cosmological constant and the
conjecture of inflation. The present article will outline some of these
problems, and argue that the victory for the unity of science in the context of
cosmology and particle physics is still far from obvious.",91,6,589,39.87
3268,philosophy,"This article presents an overview of computability logic -- the
game-semantically constructed logic of interactive computational tasks and
resources. There is only one non-overview, technical section in it, devoted to
a proof of the soundness of affine logic with respect to the semantics of
computability logic. A comprehensive online source on the subject can be found
at http://www.cis.upenn.edu/~giorgi/cl.html",58,7,414,26.81
3269,philosophy,"Whitehead's 1922 theory of gravitation continues to attract the attention of
philosophers, despite evidence presented in 1971 that it violates experiment.
We demonstrate that the theory strongly fails five quite different experimental
tests, and conclude that, notwithstanding its meritorious philosophical
underpinnings, Whitehead's theory is truly dead.",46,3,355,5.83
3270,philosophy,"The paper presents a fresh new comprehensive ideology on Neutrosophic Logic
based on contradiction study. It does a survey on Chinese philosophy. The paper
aims to solve the chaos of logic and exhibit the potential power of
neutrosophy: a new branch of scientific philosophy.",44,4,275,39.63
3271,philosophy,"Perhaps one of the most intriguing questions in philosophy concerns the true
nature of external reality. In this paper, we discuss some of the theories that
have been put forth regarding the nature of reality and of our perceived
universe. We develop an abstract mathematical model, whereby, several theories
that have been proposed so, ranging from modern physics to ancient Indian
philosophy can be brought under a common umbrella. We also discuss a specific
case, which emerges from our more general model, which has an interesting
consequence upon the way we view our world.",94,5,578,39.16
3272,philosophy,"We review the history of the road to a manifestly covariant perturbative
calculus within quantum electrodynamics from the early semi-classical results
of the mid-twenties to the complete formalism of Stueckelberg in 1934. We chose
as our case study the calculation of the cross-section of the Compton effect.
We analyse Stueckelberg's paper extensively. This is our first contribution to
a study of his fundamental contributions to the theoretical physics of
twentieth century.",71,5,477,28.03
3273,philosophy,"In recent years, a change in attitude in particle physics has led to our
understanding current quantum field theories as effective field theories
(EFTs). The present paper is concerned with the significance of this EFT
approach, especially from the viewpoint of the debate on reductionism in
science. In particular, it is a purpose of this paper to clarify how EFTs may
provide an interesting case-study in current philosophical discussion on
reduction, emergence and inter-level relationships in general.",77,4,505,28.47
3274,philosophy,"Starting with Einstein's famous papers of 1905, we review some of the ensuing
developments and their impact on present-day physics. We attempt to cover
topics that are of interest to historians and philosophers of science as well
as to physicists. This paper will appear in ``2005: The Centenary of Einstein's
Annus Mirabilis'', the special March 2006 issue of Studies in History and
Philosophy of Modern Physics.",66,4,413,49.15
3275,philosophy,"Multiverse scenarios are common place in contemporary high energy physics and
cosmology, although many consider them simply as bold speculations. In any case
there is nothing like a single theory or a unified model of the multiverse.
Instead, there are innumerable theoretical proposals often reciprocally
incompatible. What is common to all these scenarios is the postulated existence
of many causally disjointed regions of space/time (if not completely separated
space-times) and the consideration of the observable universe as atypical in a
global perspective. This paper examines the history of modern cosmology
focusing on the forerunners of current ideas, and shows how some fundamental
issues tend to present themselves on increasingly deeper levels of physical
knowledge.",114,6,779,22.95
3276,philosophy,"In this manuscript various components of research are listed and briefly
discussed. The topics considered in this write-up cover a part of the research
methodology paper of Master of Philosophy (M.Phil.) course and Doctor of
Philosophy (Ph.D.) course. The manuscript is intended for students and research
scholars of science subjects such as mathematics, physics, chemistry,
statistics, biology and computer science. Various stages of research are
discussed in detail. Special care has been taken to motivate the young
researchers to take up challenging problems. Ten assignment works are given.
For the benefit of young researchers a short interview with three eminent
scientists is included at the end of the manuscript.",109,12,722,49.21
3277,philosophy,"The goal of this report is to provide an up to date account of results on the
quantum nature of the big bang, obtained in loop quantum cosmology. They
suggest a radical modification of the paradigm provided by general relativity
for the issue of the Beginning. The article is addressed primarily to
historians and philosophers of science.",57,4,338,43.73
3278,philosophy,"The development of Quantum Electrodynamics (QED) is sketched from its
earliest beginnings until the formulations of 1949, using the example of the
divergent self-energy of the electron as a quintessential problem of the
1930's-40's. The lack of progress towards solving this problem led researchers
to believe that after the conceptual revolution of quantum mechanics a new
conceptual change was needed. It took a war and a new generation of
algorithmically inclined physicists to pursue the conventional route of
regularization and renormalization that led to the solution in 1947-1949. Some
remarks on contemporary high energy physics are made.",97,5,646,29.89
3279,philosophy,"The concept of typicality refers to properties holding for the ""overwhelming
majority"" of cases and is a fundamental idea of the qualitative approach to
dynamical problems. We argue that measure-theoretical typicality would be the
adequate viewpoint of the role of probability in classical statistical
mechanics, particularly in understanding the micro to macroscopic change of
levels of description.",57,3,400,0.25
3280,philosophy,"We investigate a new class of entangled states, which we call
'hyperentangled',that have EPR correlations identical to those in the vacuum
state of a relativistic quantum field. We show that whenever hyperentangled
states exist in any quantum theory, they are dense in its state space. We also
give prescriptions for constructing hyperentangled states that involve an
arbitrarily large collection of systems.",61,4,408,42.41
3281,philosophy,"We apply the machinery of projection lattices and von Neumann algebras to
analyze the question of how modal interpretations can (and do) circumvent von
Neumann's infamous 'no-hidden-variables' theorem.",28,2,201,9.22
3282,philosophy,"`Philosophy' was speakable for John Bell but is not for many physicists. The
border between philosophy and physics is here illustrated through Brownian
motion and Bell experiments. `Measurement', however, was unspeakable for Bell.
His insistence that the physics of quantum measurement should not be confined
to the laboratory and that physics is concerned with the big world outside
leads us to examples from zoology, meteorology and cosmology.",67,5,445,45.96
3283,philosophy,"It is argued that local realism is a fundamental principle, which might be
rejected only if experiments clearly show that it is untenable. A critical
review is presented of the derivations of Bell's inequalities and the performed
experiments, with the conclusion that no valid, loophole-free, test exists of
local realism vs. quantum mechanics. It is pointed out that, without any
essential modification, quantum mechanics might be compatible with local
realism. This suggests that the principle may be respected by nature.",80,6,523,34.26
3284,philosophy,"A version of Bohm's model incorporating retrocausality is presented, the aim
being to explain the nonlocality of Bell's theorem while maintaining Lorentz
invariance in the underlying ontology. The strengths and weaknesses of this
alternative model are compared with those of the standard Bohm model.",44,3,299,23.77
3285,philosophy,"According to Bell's theorem a large class of hidden-variable models obeying
Bell's notion of local causality conflict with the predictions of quantum
mechanics. Recently, a Bell-type theorem has been proven using a weaker notion
of local causality, yet assuming the existence of perfectly correlated event
types. Here we present a similar Bell-type theorem without this latter
assumption. The derived inequality differs from the Clauser-Horne inequality by
some small correction terms, which render it less constraining.",75,5,520,35.47
3286,philosophy,"Bohmian mechanics is an alternative interpretation of quantum mechanics. We
outline the main characteristics of its non-relativistic formulation. Most
notably it does provide a simple solution to the infamous measurement problem
of quantum mechanics. Presumably the most common objection against Bohmian
mechanics is based on its non-locality and its apparent conflict with
relativity and quantum field theory. However, several models for a quantum
field theoretical generalization do exist. We give a non-technical account of
some of these models.",78,7,548,24.44
3287,philosophy,"We argue about a possible scenario of physical reality based on the
parallelism between Poincare group and the sunyata philosophy of Nagarjuna. The
notion of ""relational"" is the common denominator of two views. We have
approached the relational concept in third-person perspective (ontic level). It
is possible to deduce different physical consequence and interpretation through
first-person perspective approach. This relational interpretation leave open
the questions: i)we must abandon the idea for a physical system the possibility
to extract completeness information? ii)we must abandon the idea to infer a
possible structure of physical reality?",93,5,651,21.9
3288,philosophy,"We discuss a number of fundamental aspects of modern cosmological concepts,
from the phenomenological, observational, theoretical and epistemic points of
view. We argue that the modern cosmology, despite a great advent, in particular
in the observational sector, is yet to solve important problems, posed already
by the classical times. In particular the stress is put on discerning the
scientific features of modern cosmological paradigms from the more speculative
ones, with the latter immersed in some aspects deeply into mythological world
picture. We finally discuss the principal paradigms, which are present in the
modern cosmological studies and evaluate their epistemic merits.
  KEY WORDS: cosmology, epistemology, methodology, mythology, philosophy of
science",109,5,770,15.51
3289,philosophy,"This is a preliminary version of an article to appear in the forthcoming
Ashgate Companion to the New Philosophy of Physics. I don't advocate any
particular approach to the measurement problem (not here, at any rate!) but I
do focus on the importance of decoherence theory to modern attempts to solve
the measurement problem, and I am fairly sharply critical of some aspects of
the ""traditional"" formulation.",67,3,408,40.38
3290,philosophy,"The direct and indirect relationship between the British physicist originally
from Austria, Sir Hermann Bondi, and Venezuelan physics are presented. Special
emphasis is made of his more remarkable human qualities, nobility and
humbleness, besides his important contribution to General Relativity and to the
European science agencies. Self--declared as a staunch disciple of Popperian
philosophy, Bondi defended the ""hard and dirty"" physics against the ""inmaculate
and beauty"" physics. Attention is focused on two cornerstones of Bondi's work,
followed thoroughly by Luis Herrera and disciples in Venezuela.",85,5,606,24.48
3291,philosophy,"This article presents a discussion of the notion of quantum ontological
excess baggage, first proposed by Hardy. It is argued here that this idea does
not have the significance as suggested in his paper. It is shown here that if
this concept is properly analyzed, it fails to pose any threat to the ontic
approaches of quantum theory in general.",60,4,345,51.18
3292,philosophy,"Reductionism has dominated science and philosophy for centuries. Complexity
has recently shown that interactions---which reductionism neglects---are
relevant for understanding phenomena. When interactions are considered,
reductionism becomes limited in several aspects. In this paper, I argue that
interactions imply non-reductionism, non-materialism, non-predictability,
non-Platonism, and non-nihilism. As alternatives to each of these, holism,
informism, adaptation, contextuality, and meaningfulness are put forward,
respectively. A worldview that includes interactions not only describes better
our world, but can help to solve many open scientific, philosophical, and
social problems caused by implications of reductionism.",88,7,729,-2.68
3293,philosophy,"I offer one possible explanation of why inertial and gravitational mass are
equal in Newtonian gravitation. I then argue that this is an example of a kind
of explanation that is not captured by standard philosophical accounts of
scientific explanation. Moreover, this form of explanation is particularly
important, at least in physics, because demands for this kind of explanation
are used to motivate and shape research into the next generation of physical
theories. I suggest that explanations of the sort I describe reveal something
important about one way in which physical theories can be related
diachronically.",96,5,617,30.2
3294,philosophy,"Starting from Bunge's (1977) scientific ontology, we expose a materialistic
relational theory of space-time, that carries out the program initiated by
Leibniz, and provides a protophysical basis consistent with any rigorous
formulation of General Relativity. Space-time is constructed from general
concepts which are common to any consistent scientific theory and they are
interpreted as emergent properties of the greatest assembly of things, namely,
the world.",65,3,462,4.65
3295,philosophy,"In contemporary theoretical physics, the powerful notion of symmetry stands
for a web of intricate meanings among which I identify four clusters associated
with the notion of transformation, comprehension, invariance and projection.
While their interrelations are examined closely, these four facets of symmetry
are scrutinised one after the other in great detail. This decomposition allows
us to examine closely the multiple different roles symmetry plays in many
places in physics. Furthermore, some connections with others disciplines like
neurobiology, epistemology, cognitive sciences and, not least, philosophy are
proposed in an attempt to show that symmetry can be an organising principle
also in these fields.",103,5,718,19.91
3296,philosophy,"Arising out of an attempt at a new foundations of mathematics, in which
relations are more primitive than sets, and out of the theoretical physicists'
concept of underlying causes of empirical phenomena, the idea of a purely
mathematical possible world (of underlying causes) is developed. It is shown
that at least one, and at most one, possible world is actual, and that the one
that is actual is the best (as in the philosophy of Leibniz), and therefore
requires the cosmic coincidences to exist. This best is actual necessarily
because of having a higher level top relation than any other possible world,
and because of this top relation possessing the property of intrinsic necessary
existence.",115,4,699,24.14
3297,philosophy,"Software design is gradually becoming open, distributed, pervasive, and
connected. It is a sad statistical fact that software projects are
scientifically fragile and tend to fail more than other engineering fields.
Agile development is a philosophy. And agile methods are processes that support
the agile philosophy. XP places a strong emphasis on technical practices in
addition to the more common teamwork and structural practices. In this paper,
we elaborate how XP practices can be used to thinking, collaborating,
releasing, planning, developing. And the state that make your team and
organization more successful.",92,8,619,41.26
3298,philosophy,"Quantum gravity is known to be mostly a kind of metaphysical speculation. In
this brief essay, we try to argue that, although still extremely difficult to
reach, observational signatures can in fact be expected. The early universe is
an invaluable laboratory to probe ""Planck scale physics"". With the example of
Loop Quantum Gravity, we detail some expected features.",58,5,367,48.3
3299,philosophy,"Physical cosmology tries to understand the Universe at large with its origin
and evolution. Observational and experimental situations in cosmology do not
allow us to proceed purely based on the empirical means. We examine in which
sense our cosmological assumptions in fact have shaped our current cosmological
worldview with consequent inevitable limits. Cosmology, as other branches of
science and knowledge, is a construct of human imagination reflecting the
popular belief system of the era. The question at issue deserves further
philosophic discussions. In Whitehead's words, ""philosophy, in one of its
functions, is the critic of cosmologies"". (Whitehead 1925)",98,7,667,29.55
3300,philosophy,"A Hegelian version of the concept of problematic is used to investigate the
underlying theoretical unity and structure of Arabic physical science (physics,
astronomy and chemistry). A contradictory triad (associated with Platonism,
Aristotelian philosophy and Ptolemaic science) is identified at the heart of
the Arabic project for physical science. The paper focuses on the valiant
attempts made by leading Arabic scientists to overcome these contradictions
without transcending or tearing apart the prevailing problematic. The following
question is then addressed: why was Arabic physical science reformist, rather
than revolutionary, unlike Renaissance European physical science? An answer is
proposed in terms of the history, nature and decline of Arabic rationalism.",108,5,771,24.17
3301,philosophy,"This paper explores the issue of the unification of three languages of
physics, the geometric language of forces, geometric language of fields or
4-dimensional space-time, and probabilistic language of quantum mechanics. On
the one hand, equations in each language may be derived from the Principle of
Least Action (PLA). On the other hand, Feynman's path integral method could
explain the physical meaning of PLA. The axioms of classical and relativistic
mechanics can be considered as consequences of Feynman's formulation of quantum
mechanics.",82,5,546,42.21
3302,philosophy,"We discuss the photograph procured from the archives of the V. Stefanyk Lviv
National Scientific Library of Ukraine dated by 1904 which shows Marian
Smoluchowski together with professors and graduate students of the Philosophy
department of the Lviv University. The personalia includes both the professors
and the graduates depicted on the photograph with the emphasis on the graduates
as being much less known and studied. The photograph originates from the
collection of the Shevchenko Scientific Society, therefore a brief historical
background on the activities of physicists in this society around that period
of time is provided as well.",98,5,643,29.69
3303,philosophy,"This article deals with the coherence of the model given by the Cohen-Lenstra
heuristic philosophy for class groups and also for their generalizations to
Tate-Shafarevich groups. More precisely, our first goal is to extend a previous
result due to E. Fouvry and J. Kl\""uners which proves that a conjecture
provided by the Cohen-Lenstra philosophy implies another such conjecture. As a
consequence of our work, we can deduce, for example, a conjecture for the
probability laws of $p^j$-ranks of Selmer groups of elliptic curves. This is
compatible with some theoretical works and other classical conjectures.",94,7,607,47.08
3304,philosophy,"This brief article presents the introduction and draft of the fundamental
ideas developed at length in the book of the same title, which gives a
challenging point of view about science and its history/philosophy/sociology.
Science is in decline. After centuries of great achievements, the exhaustion of
new forms and fatigue have reached our culture in all of its manifestations
including the pure sciences. Our society is saturated with knowledge which does
not offer people any sense in their lives. There is a loss of ideals in the
search for great truths and a shift towards an anodyne specialized industry.",99,6,611,59.84
3305,philosophy,"In nature there are various pairs of observed phenomena and observing
scientific techniques which are elegantly coupled with each other. A very
general and well known example is the fact that the metal we use to build
telescopes were once built in stars by nuclear fusion. Hence in a fundamental
sense, stars themselves have helped us indirectly in observing them in great
detail. In this article I mention a bit more scientifically subtle and an even
more interesting example of such a pair which raises interesting thoughts about
an old experiment, its beauty and relevance in a very modern tool for
astronomy.",102,5,612,45.59
3306,philosophy,"It is argued that the problem of interpreting quantum mechanics, and the
philosophical problem of consciousness, both have their roots in the same set
of misguided Cartesian assumptions. The confusions underlying those assumptions
are analyzed in detail. It is sometimes suggested that quantum mechanics might
explain consciousness. That is not the suggestion here. Rather it is suggested
that an adequate non-Cartesian philosophy would transform our understanding of
both quantum mechanics and consciousness. Consequently, it would change our
ideas as to just what it is that we are trying to explain.",90,7,602,47.79
3307,philosophy,"I discuss singular spacetimes in the context of the geometrized formulation
of Newtonian gravitation. I argue first that geodesic incompleteness is a
natural criterion for when a model of geometrized Newtonian gravitation is
singular, and then I show that singularities in this sense arise naturally in
classical physics by stating and proving a classical version of the
Raychaudhuri-Komar singularity theorem.",60,3,410,7.19
3308,philosophy,"Recent work in psychology and experimental philosophy has shown that
judgments of actual causation are often influenced by consideration of
defaults, typicality, and normality. A number of philosophers and computer
scientists have also suggested that an appeal to such factors can help deal
with problems facing existing accounts of actual causation. This paper develops
a flexible formal framework for incorporating defaults, typicality, and
normality into an account of actual causation. The resulting account takes
actual causation to be both graded and comparative. We then show how our
account would handle a number of standard cases.",95,6,639,18.35
3309,philosophy,"The research in quantum gravity has jauntily grown in the recent years,
intersecting with conceptual and philosophical issues that have a long history.
In this paper I analyze the conceptual basis on which Loop Quantum Gravity has
grown, the way it deals with some classical problems of philosophy of science
and the main methodological and philosophical assumptions on which it is based.
In particular, I emphasize the importance that atomism (in the broadest sense)
and relationalism have had in the construction of the theory.",84,4,529,34.6
3310,philosophy,"Why do gases reach equilibrium when left to themselves? The canonical answer,
originally proffered by Boltzmann, is that the systems have to be ergodic. This
answer is now widely regarded as flawed. We argue that some of the main
objections, in particular, arguments based on the KAM-theorem and the
Markus-Meyer theorem, are beside the point. We then argue that something close
to Boltzmann's proposal is true: gases behave thermodynamic-like if they are
epsilon-ergodic, i.e., ergodic on the phase space except for a small region of
measure epsilon. This answer is promising because there is evidence that
relevant systems are epsilon-ergodic.",100,8,645,48.5
3311,philosophy,"Is our world just information? We argue that our current notion of
information has one serious shortcoming: It is quite literally meaningless. We
suggest a meaningful extension of the notion of information that is dynamic,
internal, approximate, contains an element of randomness, and is layered. This
new notion of information derives from the interactions of material objects.
Our answer to the essay question then is Bit from It or, more appropriately,
Bit++ from It. We discuss how our new notion of information sheds light on the
measurement problem in quantum mechanics and how it can be applied in
philosophy and computer science.",102,6,637,37.3
3312,philosophy,"We discuss two research projects in material science in which the results
cannot be stated with an estimation of the error: a spectro- scopic
ellipsometry study aimed at determining the orientation of DNA molecules on
diamond and a scanning tunneling microscopy study of platinum-induced nanowires
on germanium. To investigate the reliability of the results, we apply ideas
from the philosophy of models in science. Even if the studies had reported an
error value, the trustworthiness of the result would not depend on that value
alone.",85,4,536,25.83
3313,philosophy,"The example of the calculus is used to explain how simple, practical math was
made enormously complex by imposing on it the Western religiously-colored
notion of mathematics as ""perfect"". We describe a pedagogical experiment to
make math easy by teaching ""calculus without limits"" using the new realistic
philosophy of zeroism, different from Platonic idealism or formalist
metaphysics. Despite its demonstrated advantages, it is being resisted because
of the existing colonial hangover.",71,4,487,13.58
3314,philosophy,"A brief review is given of some recent positive developments regarding the
reception of archaeoastronomy by the archaeological institutions in Italy.
Discussions and problems that are currently going on in this field are also
mentioned, such as the separation of the scientific and humanistic disciplines
(i.e. the two cultures problem). Suggestions based on contemporary philosophy
are also reported. Finally, sky-gazing is proposed as the place where the two
cultures could meet, since, taking Plato into account, sky-gazing could be
considered the mom of the human knowledge, and of the scientific and humanistic
disciplines.",93,7,628,35.68
3315,philosophy,"In this paper we attempt to physically interpret the Modal Kochen- Specker
(MKS) theorem. In order to do so, we analyze the features of the possible
properties of quantum systems arising from the elements in an orthomodular
lattice and distinguish the use of ""possibility"" in the classical and quantum
formalisms. Taking into account the modal and many worlds non-collapse
interpretation of the projection postulate, we discuss how the MKS theorem
rules the constraints to actualization, and thus, the relation between actual
and possible realms.",84,4,546,26.14
3316,philosophy,"This is a discussion of some themes in Max Tegmark's recent book, Our
Mathematical Universe. It was written as a review for Plus Magazine, the online
magazine of the UK's national mathematics education and outreach project, the
Mathematics Millennium Project. Since some of the discussion (about symmetry
breaking, and Pythagoreanism in the philosophy of mathematics) went beyond
reviewing Tegmark's book, the material was divided into three online articles.
This version combines those three articles, and adds some other material, in
particular a brief defence of quidditism about properties. It also adds some
references, to other Plus articles as well as academic articles. But it retains
the informal style of Plus.",110,7,720,44.44
3317,philosophy,"The Doomsday argument and anthropic reasoning are two puzzling examples of
probabilistic confirmation. In both cases, a lack of knowledge apparently
yields surprising conclusions. Since they are formulated within a Bayesian
framework, they constitute a challenge to Bayesianism. Several attempts, some
successful, have been made to avoid these conclusions, but some versions of
these arguments cannot be dissolved within the framework of orthodox
Bayesianism. I show that adopting an imprecise framework of probabilistic
reasoning allows for a more adequate representation of ignorance in Bayesian
reasoning and explains away these puzzles.",90,6,640,36.28
3318,philosophy,"I address a question recently raised by Simon Saunders [Phil. Sci. 80(2):
22-48 (2013)] concerning the relationship between the spacetime structure of
Newton-Cartan theory and that of what I will call ""Maxwell-Huygens spacetime"".
This discussion will also clarify a connection between Saunders' work and a
recent paper by Eleanor Knox [Brit. J. Phil. Sci. 65(4): 863-880 (2014)].",57,9,379,56.96
3319,philosophy,"This article surveys recent literature by Parsons, McGee, Shapiro and others
on the significance of categoricity arguments in the philosophy of mathematics.
After discussing whether categoricity arguments are sufficient to secure
reference to mathematical structures up to isomorphism, we assess what exactly
is achieved by recent `internal' renditions of the famous categoricity
arguments for arithmetic and set theory.",58,3,420,-0.27
3320,philosophy,"I consider two usages of the expression ""gauge theory"". On one, a gauge
theory is a theory with excess structure; on the other, a gauge theory is any
theory appropriately related to classical electromagnetism. I make precise one
sense in which one formulation of electromagnetism, the paradigmatic gauge
theory on both usages, may be understood to have excess structure, and then
argue that gauge theories on the second usage, including Yang-Mills theory and
general relativity, do not generally have excess structure in this sense.",84,4,532,26.14
3321,philosophy,"The Weltanschauung emerging from quantum theory clashes profoundly with our
classical concepts. Quantum characteristics like superposition, entanglement,
wave-particle duality, nonlocality, contextuality are difficult to reconcile
with our everyday intuition. In this article I survey some aspects of quantum
foundations and discuss intriguing connections with the foundations of
mathematics.",48,4,392,-3.99
3322,philosophy,"In the Nietzschean philosophy, the concept of force from physics is important
to build one of its main concepts: the will to power. The concept of force,
which Nietzsche found out in the Classical Mechanics, almost disappears in the
physics of the XX century with the Quantum Field Theory and General Relativity.
Is the Nietzschean world as contending forces, a Dionysian cosmology, possible
in the current science?",67,3,415,48.84
3323,philosophy,"The application of quantum theory to cosmology raises a number of conceptual
questions, such as the role of the quantum-mechanical notion of ""observer"" or
the absence of a time variable in the Wheeler-DeWitt equation. I point out that
a relational formulation of quantum mechanics, and more in general the
observation that evolution is always relational, provides a coherent solution
to this tangle of problems.",64,3,411,13.62
3324,philosophy,"For four decades it has been argued that we need to adopt a new conception of
science called aim-oriented empiricism. This has far-reaching implications and
repercussions for science, the philosophy of science, academic inquiry in
general, the conception of rationality, and how we go about attempting to make
progress towards as good a world as possible. Despite these far-reaching
repercussions, aim-oriented empiricism has so far received scant attention from
philosophers of science. Here, sixteen objections to the validity of the
argument for aim-oriented empiricism are subjected to critical scrutiny.",89,5,608,31.92
3325,philosophy,"I point out a radical indeterminism in potential-based formulations of
Newtonian gravity once we drop the condition that the potential vanishes at
infinity (as is necessary, and indeed celebrated, in cosmological
applications). This indeterminism, which is well known in theoretical cosmology
but has received little attention in foundational discussions, can be removed
only by specifying boundary conditions at all instants of time, which
undermines the theory's claim to be fully cosmological, i.e., to apply to the
Universe as a whole. A recent alternative formulation of Newtonian gravity due
to Saunders (Philosophy of Science 80 (2013) pp.22-48) provides a conceptually
satisfactory cosmology but fails to reproduce the Newtonian limit of general
relativity in homogenous but anisotropic universes. I conclude that Newtonian
gravity lacks a fully satisfactory cosmological formulation.",127,8,892,7.66
3326,philosophy,"This is a systematic review of the concept of indistinguishability in both
classical and quantum mechanics, with particular attention to Gibbs' paradox.
Section 1 is on the Gibbs paradox; section 2 is a defense of the concept of
classical indistinguishability, that addresses (and refutes) the view that
classical particles can always be distinguished by their trajectories so are
distinguishable. Section 3 is on the notion of object more generally, and on
whether indistinguishables should be thought of as objects at all",81,3,523,27.15
3327,philosophy,"It is widely accepted that the notion of an inertial frame is central to
Newtonian mechanics and that the correct space-time structure underlying
$\text{Newton's}$ methods in $\textit{Principia}$ is neo-Newtonian or Galilean
space-time. I argue to the contrary that inertial frames are not needed in
$\text{Newton's}$ theory of motion, and that the right space-time structure for
$\text{Newton's}$ $\textit{Principia}$ requires the notion of parallelism of
spatial directions at different times and nothing more.",71,3,512,18.52
3328,philosophy,"The well-known equation for hydrostatic equilibrium in a static spherically
symmetric spacetime supported by an isotropic perfect fluid is referred to as
the Oppenheimer-Volkoff (OV) equation or the Tolman-Oppenheimer-Volkoff (TOV)
equation in various General Relativity textbooks or research papers. We
scrutinize the relevant original publications to argue that the former is the
more appropriate terminology.",55,3,411,1.26
3329,philosophy,"A notion of delegated causality is introduced. This subtle kind of causality
is dual to interventional causality. Delegated causality elucidates the causal
role of dynamical systems at the ""edge of chaos"", explicates evident cases of
downward causation, and relates emergent phenomena to Godel's incompleteness
theorem. Apparently rich implications are noticed in biology and Chinese
philosophy.",55,5,395,15.17
3330,philosophy,"This is the introduction I wrote for the multi-authored book ""From Riemann to
differential geometry and relativity"", edited by L. Ji, A. Papadopoulos and S.
Yamada (Berlin, Springer verlag, 2017). The book consists of twenty chapters,
written by various authors. This introduction, besides giving the information
on the content of the book, is a quick review of the topics on which Riemann
worked and of the impact of this work on mathematics (topology, complex
geometry, algebraic geometry, integration, trigonometric series, Riemannian
geometry, etc.), philosophy and physics.",86,8,578,40.04
3331,philosophy,"In metaphysics, there are a number of distinct but related questions about
the existence of ""further facts"" -- facts that are contingent relative to the
physical structure of the universe. These include further facts about qualia,
personal identity, and time. In this article I provide a sequence of examples
involving computer simulations, ranging from one in which the protagonist can
clearly conclude such further facts exist to one that describes our own
condition. This raises the question of where along the sequence (if at all) the
protagonist stops being able to soundly conclude that further facts exist.",97,5,613,47.12
3332,philosophy,"It seems natural to ask why the universe exists at all. Modern physics
suggests that the universe can exist all by itself as a self-contained system,
without anything external to create or sustain it. But there might not be an
absolute answer to why it exists. I argue that any attempt to account for the
existence of something rather than nothing must ultimately bottom out in a set
of brute facts; the universe simply is, without ultimate cause or explanation.",80,5,462,59.64
3333,philosophy,"We provide a novel perspective on ""regularity"" as a property of
representations of the Weyl algebra. In Part I, we critiqued a proposal by
Halvorson [2004, ""Complementarity of representations in quantum mechanics"",
Studies in History and Philosophy of Modern Physics 35(1), pp. 45--56], who
advocates for the use of the non-regular ""position"" and ""momentum""
representations of the Weyl algebra. Halvorson argues that the existence of
these non-regular representations demonstrates that a quantum mechanical
particle can have definite values for position or momentum, contrary to a
widespread view. In this sequel, we propose a justification for focusing on
regular representations, pace Halvorson, by drawing on algebraic methods.",106,6,730,16.12
3334,philosophy,"Using the example of classical electrodynamics, I argue that the concept of
fields as mediators of particle interactions is fundamentally flawed and
reflects a misguided attempt to retrieve Newtonian concepts in relativistic
theories. This leads to various physical and metaphysical problems that are
discussed in detail. In particular, I emphasize that physics has not found a
satisfying solution to the self-interaction problem in the context of the
classical field theory. To demonstrate the superiority of a pure particle
ontology, I defend the direct interaction theory of Wheeler and Feynman against
recent criticism and argue that it provides the most cogent formulation of
classical electrodynamics.",104,5,707,11.25
3335,philosophy,"A telephone sender following the design of Johann Philipp Reis made by W
Ladd, London 1863, in the Natural Philosophy Collection of the University of
Aberdeen is illustrated and described. How Reis came to invent a telephone some
15 years before Graham Bell's patent is discussed, with 19th century
illustrations. The method employed by Reis is outlined and contemporary letters
by Reis are reproduced, including an extensive letter to the instrument maker
William Ladd. The origin of the Aberdeen instrument is given and some of the
reasons why Bell was granted his patent in spite of the existence of Reis's
instrument are suggested. The monument to Reis erected after his early death is
shown.",114,6,696,48.33
3336,philosophy,"By mass-energy equivalence, the gravitational field has a relativistic mass
density proportional to its energy density. I seek to better understand this
mass of the gravitational field by asking whether it plays three traditional
roles of mass: the role in conservation of mass, the inertial role, and the
role as source for gravitation. The difficult case of general relativity is
compared to the more straightforward cases of Newtonian gravity and
electromagnetism by way of gravitoelectromagnetism, an intermediate theory of
gravity that resembles electromagnetism.",83,4,568,17.98
3337,philosophy,"Although general relativity is a predictively successful theory, it treats
matter as classical rather than as quantum. For this reason, it will have to be
replaced by a more fundamental quantum theory of gravity. Attempts to formulate
a quantum theory of gravity suggest that such a theory may have radical
consequences for the nature, and indeed the fate, of spacetime. The present
article articulates what this problem of spacetime is and traces it through
three approaches to quantum gravity taking general relativity as their vantage
point: semi-classical gravity, causal set theory, and loop quantum gravity.",95,5,613,30.4
3338,philosophy,"This paper introduces and defends an account of model-based science that I
dub model pluralism. I argue that despite a growing awareness in the philosophy
of science literature of the multiplicity, diversity, and richness of models
and modeling-practices, more radical conclusions follow from this recognition
than have previously been inferred. Going against the tendency within the
literature to generalize from single models, I explicate and defend the
following two core theses: (i) any successful analysis of models must target
sets of models, their multiplicity of functions within science, and their
scientific context and history and (ii) for almost any aspect x of phenomenon
y, scientists require multiple models to achieve scientific goal z.",113,4,752,7.83
3339,philosophy,"Theory testing in the physical sciences has been revolutionized in recent
decades by Bayesian approaches to probability theory. Here, I will consider
Bayesian approaches to theory extensions, that is, theories like inflation
which aim to provide a deeper explanation for some aspect of our models (in
this case, the standard model of cosmology) that seem unnatural or fine-tuned.
In particular, I will consider how cosmologists can test the multiverse using
observations of this universe.",74,4,488,29.48
3340,philosophy,"We study the Johansen-Ledoit-Sornette (JLS) model of financial market crashes
(Johansen, Ledoit, and Sornette [2000] ""Crashes as Critical Points."" Int. J.
Theor. Appl. Finan. 3(2) 219-255). On our view, the JLS model is a curious case
from the perspective of the recent philosophy of science literature, as it is
naturally construed as a ""minimal model"" in the sense of Batterman and Rice
(Batterman and Rice [2014] ""Minimal Model Explanations."" Phil. Sci. 81(3):
349-376) that nonetheless provides a causal explanation of market crashes, in
the sense of Woodward's interventionist account of causation (Woodward [2003].
Making Things Happen. Oxford:Oxford University Press).",99,14,675,42.92
3341,philosophy,"This paper examines two cosmological models of quantum gravity (from string
theory and loop quantum gravity) to investigate the foundational and conceptual
issues arising from quantum treatments of the big bang. While the classical
singularity is erased, the quantum evolution that replaces it may not
correspond to classical spacetime: it may instead be a non-spatiotemporal
region, which somehow transitions to a spatiotemporal state. The different
kinds of transition involved are partially characterized, the concept of a
physical transition without time is investigated, and the problem of empirical
incoherence for regions without spacetime is discussed.",94,4,660,14.33
3342,philosophy,"According to the received view Feynman diagrams are a bookkeeping device in
complex perturbative calculations. Thus, they do not provide a representation
or model of the underlying physical process. This view is in apparent tension
with scientific practice in high energy physics, which analyses its data in
terms of `channels'. For example the Higgs discovery was based on the
observation of the decay $H \rightarrow \gamma\gamma$ -- a process which can be
easily represented by the corresponding Feynman diagrams. I take issue with
this tension and show that on closer analysis the story of the Higgs discovery
should be told differently.",101,6,640,42.72
3343,philosophy,"On the basis of what I call physico-formalist philosophy of mathematics, I
will develop an amended account of the Kantian--Reichenbachian conception of
constitutive a priori. It will be shown that the features (attributes,
qualities, properties) attributed to a real object are not possessed by the
object as a ""thing-in-itself""; they require a physical theory by means of which
these features are constituted. It will be seen that the existence of such a
physical theory implies that a physical object can possess a property only if
other contingently existing physical objects exist; therefore, the
intrinsic--extrinsic distinction is flawed.",97,4,644,21.77
3344,philosophy,"In 1687 Isaac Newton published PHILOSOPHI\AE \ NATURALIS PRINCIPIA
MATHEMATICA, where the classical analytic dynamics was formulated. But Newton
also formulated a discrete dynamics, which is the central difference algorithm,
known as the Verlet algorithm. In fact Newton used the central difference to
derive his second law. The central difference algorithm is used in computer
simulations,where almost all Molecular Dynamics simulations are performed with
the Verlet algorithm or other reformulations of the central difference
algorithm. Here we show, that the discrete dynamics obtained by Newtons
algorithm for Kepler's equation has the same solutions as the analytic
dynamics. The discrete positions of a celestial body are located on an ellipse,
which is the exact solution for a shadow Hamiltonian nearby the Hamiltonian for
the analytic solution.",125,7,853,25.08
3345,philosophy,"The Everett interpretation of quantum mechanics divides naturally into two
parts: first, the interpretation of the structure of the quantum state, in
terms of branching, and second, the interpretation of this branching structure
in terms of probability. This is the second of two reviews of the Everett
interpretation, and focuses on probability. Branching processes are identified
as chance processes, and the squares of branch amplitudes are chances. Since
branching is emergent, physical probability is emergent as well.",77,5,523,34.97
3346,philosophy,"Quantum gravity--the marriage of quantum physics with general relativity--is
bound to contain deep and important lessons for the nature of physical time.
Some of these lessons shall be canvassed here, particularly as they arise from
quantum general relativity and string theory and related approaches. Of
particular interest is the question of which of the intuitive aspects of time
will turn out to be fundamental, and which 'emergent' in some sense.",70,4,451,39.37
3347,philosophy,"In elementary particle physics the philosophy of virtual particles is widely
used. We use this philosophy to obtain the famous inverse square law of
classical physics. We define a formal model without fields or forces, but with
virtual particle - information transmitter. This formal model admits very
simple (school level) interpretation with two classical particles and one
virtual. Then we prove (in a mathematically rigorous way) that the trajectories
in our model converge to standard Newtonian trajectories of classical physics.",80,6,534,30.06
3348,philosophy,"The analytic philosophy of Robert Brandom, based on the ideas of pragmatism,
paints a picture of sapience, through inferentialism. In this paper, we present
a theory, that utilizes essential elements of Brandom's philosophy, towards the
objective of achieving strong-AI. We do this by connecting the constitutive
elements of reinforcement learning and the Game Of Giving and Asking For
Reasons. Further, following Brandom's prescriptive thoughts, we restructure the
popular reinforcement learning algorithm A3C, and show that RL algorithms can
be tuned towards the objective of strong-AI.",85,5,588,32.94
3349,philosophy,"Philosophical thinking has a side effect: by aiming to find the essence of a
diverse set of phenomena, it often makes it difficult to see the differences
between them. This can be the case with Mathematics, Programming, Writing and
Philosophy itself. Their unified essence is having a shared understanding of
the world helped by off-loading our cognitive efforts to suitable languages.",61,4,385,50.87
3350,philosophy,"The paper discusses from a metaphysical standpoint the nature of the
dependence relation underpinning the talk of mutual action between material and
spatiotemporal structures in general relativity. It is shown that the standard
analyses of dependence in terms of causation or grounding are ill-suited for
the general relativistic context. Instead, a non-standard analytical framework
in terms of structural equation modeling is exploited, which leads to the
conclusion that the kind of dependence encoded in the Einstein field equations
is a novel one.",82,4,552,18.39
3351,philosophy,"In this work we show the equivalence between Hamiltonian mechanics and
conservation of information entropy. We will show that distributions with
coordinate independent values for information entropy require that the manifold
on which the distribution is defined is charted by conjugate pairs (i.e. it is
a symplectic manifold). We will also show that further requiring that the
information entropy is conserved during the evolution yields Hamilton's
equations.",67,6,460,37.5
3352,philosophy,"Many attempts have been made to provide Quantum Field Theory with
conceptually clear and mathematically rigorous foundations; remarkable examples
are the Bohmian and the algebraic perspectives respectively. In this essay we
introduce the dissipative approach to QFT, a new alternative formulation of the
theory explaining the phenomena of particle creation and annihilation starting
from nonequilibrium thermodynamics. It is shown that DQFT presents a rigorous
mathematical structure, and a clear particle ontology, taking the best from the
mentioned perspectives. Finally, after the discussion of its principal
implications and consequences, we compare it with the main Bohmian QFTs
implementing a particle ontology.",100,5,717,12.26
3353,philosophy,"When a physicist says that a theory is fine-tuned, they mean that it must
make a suspiciously precise assumption in order to explain a certain
observation. This is evidence that the theory is deficient or incomplete. One
particular case of fine-tuning is particularly striking. The data in question
are not the precise measurements of cosmology or particle physics, but a more
general feature of our universe: it supports the existence of life. This
chapter reviews this Fine-Tuning of the Universe for Life.",82,6,508,46.37
3354,philosophy,"I argue that the many worlds explanation of quantum computation is not
licensed by, and in fact is conceptually inferior to, the many worlds
interpretation of quantum mechanics from which it is derived. I argue that the
many worlds explanation of quantum computation is incompatible with the
recently developed cluster state model of quantum computation. Based on these
considerations I conclude that we should reject the many worlds explanation of
quantum computation.",72,4,469,30.2
3355,philosophy,"Theories in physics usually do not address ``the present''or ``the now''.
However, they usually have a precise notion of an ``instant'' (or state). I
review how this notion appears in relational point mechanics and how it
suffices to determine durations - a fact that is often ignored in modern
presentations of analytical dynamics. An analogous discussion is attempted for
General Relativity. Finally I critically remark on the difference between
relationalism in point mechanics and field theory and the problematic
foundational dependencies between fields and spacetime.",85,6,573,29.04
3356,philosophy,"This paper tries to justify the relevance of an introductory course in
Mathematical Logic in the Philosophy curriculum for analyzing philosophical
arguments in natural language. It is argued that the representation of the
structure of natural language arguments in Freeman's diagramming system can
provide an intuitive foundation for the inferential processes involved in the
use of First Order Logic natural deduction rules.",62,3,425,6.17
3357,philosophy,"An ontology of Leibnizian relationalism, consisting in distance relations
among sparse matter points and their change only, is well recognized as a
serious option in the context of classical mechanics. In this paper, we
investigate how this ontology fares when it comes to general relativistic
physics. Using a Humean strategy, we regard the gravitational field as a means
to represent the overall change in the distance relations among point particles
in a way that achieves the best combination of being simple and being
informative.",84,4,535,34.6
3358,philosophy,"I address the problem of explaining why wave functions for identical
particles must be either symmetric or antisymmetric (the symmetry dichotomy)
within two interpretations of quantum mechanics which include particles
following definite trajectories in addition to, or in lieu of, the wave
function: Bohmian mechanics and Newtonian quantum mechanics (a.k.a. many
interacting worlds). In both cases I argue that, if the interpretation is
formulated properly, the symmetry dichotomy can be derived and need not be
postulated.",76,6,523,20.42
3359,philosophy,"This chapter, from the Routledge Companion to the Philosophy of Physics
(Eleanor Knox and Alastair Wilson, eds., 2021), is an overview of the
constraints that relativity places on interpretations of quantum theory. It
focuses on four main avenues of approach: (i) additional beables theories,
which include ""hidden-variables"" theories and modal interpretations, (ii)
dynamical collapse theories, (iii) Everettian, or ""many-worlds""
interpretations, and (iv) non-realist interpretations, which deny that quantum
states represent anything in physical reality independent of considerations of
agents and their beliefs.",82,4,614,9.93
3360,philosophy,"Computational complexity has often been ignored in philosophy of mind, in
philosophical artificial intelligence studies. The purpose of this paper is
threefold. First and foremost, to show the importance of complexity rather than
computability in philosophical and AI problems. Second, to rephrase the notion
of computability in terms of solvability, i.e. treating computability as
non-sufficient for establishing intelligence. The Church-Turing thesis is
therefore revisited and rephrased in order to capture the ontological
background of spatial and temporal complexity. Third, to emphasize ontological
differences between different time complexities, which seem to provide a solid
base towards better understanding of artificial intelligence in general.",102,9,756,14.36
3361,philosophy,"The extravagances of quantum mechanics never fail to enrich daily the debate
around natural philosophy. Entanglement, non-locality, collapse, many worlds,
many minds, and subjectivism have challenged generations of thinkers. Its
approach can perhaps be placed in the stream of quantum logic, in which the
""strangeness"" of quantum mechanics is ""measured"" through the violation of
Bell's inequalities and, from there, attempts an interpretative path that
preserves realism yet ends up overturning it, restating the fundamental
mechanisms of QM as a logical necessity for a strong realism.",85,4,586,25.83
3362,philosophy,"We undertake a reconstruction of the epistemic significance of research on
operational theories in quantum foundations. We suggest that the space of
operational theories is analogous to the space of possible worlds employed in
the possible world semantics for modal logic, so research of this sort can be
understood as probing modal structure. Thus we argue that operational
axiomatisations of quantum mechanics may be interpreted as a novel form of
structural realism; we discuss the consequences of this interpretation for the
philosophy of structural realism and the future of operational theories.",91,4,601,23.8
3363,philosophy,"In this paper, we situate the educational movement of ""Ethics in
Mathematics,"" as outlined by the Cambridge University Ethics in Mathematics
Project, in the wider area of mathematics ethics education. By focusing on the
core message coming out of Ethics in Mathematics, its target group, and
educational philosophy, we set it into relation with ""Mathematics for Social
Justice"" and Paul Ernest's recent work on ethics of mathematics. We conclude
that, although both Ethics in Mathematics and Mathematics for Social Justice
appear antagonistic at first glance, they can be understood as complementary
rather than competing educational strategies.",96,4,645,22.08
3364,philosophy,"Carnap's conception of linguistic frameworks is widespread; however, it is
not entirely clear nor consensual to pinpoint what is the influence in his
stance within the traditional realist/anti-realist debate. In this paper, we
place Carnap as a proponent of a scientific realist stance, by presenting what
he called ""linguistic realism"". Some possible criticisms are considered, and a
case study is offered with wave function realism, a popular position in the
philosophy of quantum mechanics.",74,4,493,21.02
3365,philosophy,"This paper introduces the logics of super-strict implications that are based
on C.I. Lewis' non-normal modal logics S2 and S3. The semantics of these logics
is based on Kripke's semantics for non-normal modal logics. This solves a
question we left open in a previous paper by showing that these logics are
weakly connexive.",53,6,323,57.98
3366,philosophy,"Recent work on the status of astrophysical modeling in the wake of quantum
gravity indicates that a 'fauxrizon' (portmanteau of 'faux horizon'), such as
is relevant to understanding astrophysical black holes according to the
fuzzball proposal within string theory, might ultimately solve the familiar
black hole evaporation paradox. I clarify, with general upshots for the
foundations of quantum gravity research, some of what this suggestion would
amount to: identification of intertheoretic constraints on global spacetime
structure in (observer-relative) semiclassical models of fuzzballs.",82,3,592,4.48
3367,philosophy,"Much has been discussed in the philosophy of science about how we should
understand the scientific enterprise. On the one hand, scientific realists
believe that empirically adequate theories can be supplemented by
interpretations that can mirror reality-as-it-is; on the other hand,
anti-realists argue that this is not the case, as long as scientific theories
make sufficiently accurate experimental predictions the addition of narratives
is irrelevant for the scientific enterprise, and regarding narratives, it is
preferable to remain agnostic. In this paper, we argue that realism was never
really at stake in this debate.",93,4,626,14.63
3368,philosophy,"The home is often the most private space in people's lives, and not one in
which they expect to be surveilled. However, today's market for smart home
devices has quickly evolved to include products that monitor, automate, and
present themselves as human. After documenting some of the more unusual
emergent problems with contemporary devices, this body of work seeks to develop
a design philosophy for intelligent agents in the smart home that can act as an
alternative to the ways that these devices are currently built. This is then
applied to the design of privacy empowering technologies, representing the
first steps from the devices of the present towards a more respectful future.",112,5,687,43.06
3369,philosophy,"We discuss in this work the contradictory position in modern Physics between
the existence of a microphysical quantum Reality and macrophysical classical
one. After discussing some basic concepts in Philosophy, we revisit the
situation of Quantum Mechanics results, particularly after the confirmation of
violations of Bell's Theorem, and its significance to create a tension between
the micro and the macro world, which is very fundamental and unsolved.",67,3,454,3.63
3370,philosophy,"Conventional wisdom holds that the von Neumann entropy corresponds to
thermodynamic entropy, but Hemmo and Shenker (2006) have recently argued
against this view by attacking von Neumann (1955) and his argument. I argue
that Hemmo and Shenker's arguments fail due to several misunderstandings: about
statistical-mechanical and thermodynamic domains of applicability, about the
nature of mixed states, and about the role of approximations in physics. As a
result, their arguments fail in all cases: in the single-particle case, the
finite particles case, and the infinite particles case.",86,4,585,25.42
3371,philosophy,"We consider some of the epistemic benefits of exploring ""theory space"" in the
context of modifications of general relativity with intended applications in
cosmology. We show how studying modifications of general relativity can help in
assessing the robustness of empirical inferences, particularly in inaccessible
regimes. We also discuss challenges to sharply distinguishing apparently
distinct directions in theory space.",58,4,423,1.13
3372,philosophy,"We consider the duality between General Relativity and the theory of Einstein
algebras, in the extended setting where one permits non-Hausdorff manifolds. We
show that the duality breaks down, and then go on to discuss a sense in which
general relativity, formulated using non-Hausdorff manifolds, exhibits excess
structure when compared to Einstein algebras. We discuss how these results bear
on a class of algebraically-motivated deflationist views about spacetime
ontology. We conclude with a conjecture concerning non-Hausdorff spacetimes
with no bifurcate curves.",81,5,568,25.49
3373,philosophy,"Neuroscience and artificial intelligence are closely intertwined, but so are
the physics of dynamical system, philosophy and psychology. Each of these
fields try in their own way to relate observations at the level of molecules,
synapses, neurons or behavior, to a function. An influential conceptual
approach to this end was popularized by David Marr, which focused on the
interaction between three theoretical 'levels of analysis'. With the
convergence of simulation-based approaches, algorithm-oriented Neuro-AI and
high-throughput data, we currently see much research organized around four
levels of analysis: observations, models, algorithms and functions.
Bidirectional interaction between these levels influences how we undertake
interdisciplinary science.",103,6,763,16.73
3374,philosophy,"The precise definition of causality is currently an open problem in
philosophy and statistics. We believe causality should be defined as functions
(in mathematics) that map causes to effects. We propose a reductive definition
of causality based on Structural Functional Model (SFM). Using delta
compression and contrastive forward inference, SFM can produce causal
utterances like ""X causes Y"" and ""X is the cause of Y"" that match our
intuitions. We compile a dataset of causal scenarios and use SFM in all of
them. SFM is compatible with but not reducible to probability theory. We also
compare SFM with other theories of causation and apply SFM to downstream
problems like free will, causal explanation, and mental causation.",116,8,727,46.17
3375,philosophy,"Laws of motion given in terms of differential equations can not always be
derived from an action principle, at least not without introducing auxiliary
variables. By allowing auxiliary variables, e.g. in the form of Lagrange
multipliers, an action is immediately obtained. Here, we consider some ways how
this can be done, drawing examples from the literature, and apply this to
Bohmian mechanics. We also discuss the possible metaphysical status of these
auxiliary variables. A particularly interesting approach brings the theory in
the form of a gauge theory, with the auxiliary variables as gauge degrees of
freedom.",96,8,618,38.32
3376,philosophy,"According to one possible diagnosis of the quantum measurement problem, it is
a consequence of quantum fundamentalism claiming that ontology and epistemology
of the world are exclusively quantum, and classical physics is only an
approximation. For N. Bohr, the measurement problem is a pseudo-problem because
any quantum phenomenon presupposes the classical context of an experimental
setup and the use of classical concepts to describe it. We consider Bohr's
position from the point of view of our contextual quantum realism (CQR),
inspired by the later Wittgenstein philosophy. Our approach is consistent with
H. Zinkernagel's interpretation, according to which Bohr's position is not only
epistemological anti-fundamentalism, but also ontological anti-fundamentalism.",108,7,770,7.25
3377,philosophy,"Weyl famously argued that if space were discrete, then Euclidean geometry
could not hold even approximately. Since then, many philosophers have responded
to this argument by advancing alternative accounts of discrete geometry that
recover approximately Euclidean space. However, they have missed an importantly
flawed assumption in Weyl's argument: physical geometry is determined by
fundamental spacetime structures independently from dynamical laws. In this
paper, I aim to show its falsity through two rigorous examples: random walks in
statistical physics and quantum mechanics.",81,5,582,25.49
3378,philosophy,"Modern computational natural philosophy conceptualizes the universe in terms
of information and computation, establishing a framework for the study of
cognition and intelligence. Despite some critiques, this computational
perspective has significantly influenced our understanding of the natural
world, leading to the development of AI systems like ChatGPT based on deep
neural networks. Advancements in this domain have been facilitated by
interdisciplinary research, integrating knowledge from multiple fields to
simulate complex systems. Large Language Models (LLMs), such as ChatGPT,
represent this approach's capabilities, utilizing reinforcement learning with
human feedback (RLHF). Current research initiatives aim to integrate neural
networks with symbolic computing, introducing a new generation of hybrid
computational models.",108,6,836,-1.22
3379,philosophy,"There is wide agreement that ethical considerations are a valuable aspect of
a data science curriculum, and to that end, many data science programs offer
courses in data science ethics. There are not always, however, explicit
connections between data science ethics and the centuries-old work on ethics
within the discipline of philosophy. Here, we present a framework for bringing
together key data science practices with ethical topics. The ethical topics
were collated from sixteen data science ethics courses with public-facing
syllabi and reading lists. We encourage individuals who are teaching data
science ethics to engage with the philosophical literature and its connection
to current data science practices, which is rife with potentially morally
charged decision points.",116,6,782,31.01
3380,philosophy,"No, but the paper argues that Bohr understood his correspondence principle,
or at least an aspect of that principle expressed by the notion of rational
generalization, as grounded in Hankel's principle of permanence, adapted to new
historical and theoretical contexts. This is shown to illuminate some otherwise
obscure aspects of Bohr's approach to quantum theory, as well as a seemingly
strange criticism against this approach, due to Feyerabend and Bohm.",70,3,457,19.03
3381,philosophy,"We examine the justification for taking the Event Horizon Telescope's famous
2019 image to be a reliable representation of the region surrounding a black
hole. We argue that it takes the form of a robustness argument, with the
resulting image being robust across variation in a range of data-analysis
pipelines. We clarify the sense of ""robustness"" operating here and show how it
can account for the reliability of astrophysical inferences, even in cases --
like the EHT -- where these inferences are based on experiments that are (for
all practical purposes) unique. This has consequences far beyond the 2019
image.",100,5,616,38.15
3382,philosophy,"Highly personalysed and subjective review of studies of the equilibrium,
pulsations and stability of stars with the first-order phase transition.",20,2,145,25.8
3383,philosophy,"The evolution of the conception of motion as composed by circular uniform
motions is analyzed, stressing its continuity from antiquity to our days.",23,2,147,31.21
3384,philosophy,"Editorial of the International Conference (NEXT 2003): News and expectations
in Thermostatistics, Sardinia 21-28 Sept. 2003",16,2,123,12.94
3385,philosophy,"A survey of the approach to Statistical Mechanics following Boltzmann's
theory of ensembles and ergodic hypothesis leading to chaoticity as a unifying
principle of equilibrium and nonequilibrium Statistical Mechanics.",29,2,217,-17.19
3386,philosophy,"The relationship between modern philosophy and physics is discussed. It is
shown that the latter develops some need for a modernized metaphysics which
shows up as an ultima philosophia of considerable heuristic value, rather than
as the prima philosophia in the Aristotelian sense as it had been intended, in
the first place. It is shown then, that it is the philosophy of Spinoza in
fact, that can still serve as a paradigm for such an approach. In particular,
Spinoza's concept of infinite substance is compared with the philosophical
implications of the foundational aspects of modern physical theory. Various
connotations of sub-stance are discussed within pre-geometric theories,
especially with a view to the role of spin networks within quantum gravity. It
is found to be useful to intro-duce a separation into physics then, so as to
differ between foundational and empirical theories, respectively. This leads to
a straightforward connection bet-ween foundational theories and speculative
philosophy on the one hand, and between empirical theories and sceptical
philosophy on the other. This might help in the end, to clarify some recent
problems, such as the absence of time and causality at a fundamental level. It
is implied that recent results relating to topos theory might open the way
towards eventually deriving logic from physics, and also towards a possible
transition from logic to hermeneutic.",221,10,1413,38.05
3387,philosophy,"Based on new experiments about the ""macroscopic Schrodinger's cat state""
etc., a self-consistent interpretation on quantum mechanics is presented from
the new point of view combining physics, philosophy and mathematics together.",31,3,228,30.36
3388,philosophy,The present-day crisis in quantum field theory is described.,9,2,60,53.88
3389,philosophy,"I recall my collaboration with David Gross. A result about descendants of the
chiral anomaly is presented: Chern-Simons terms can be written as total
derivatives.",25,3,162,41.87
3390,philosophy,"Dirac's quantization of magnetic monopole strength is derived without
reference to a (singular, patched) vector potential.",16,2,122,29.86
3391,philosophy,"The Bordelaise philosophy, or rather a juvenile version of it, is used to
enumerate self avoiding walks in a $[0,1] \times (- \infty, \infty)$.",24,2,143,48.13
3392,philosophy,"Neutrosophy is a new branch of philosophy which studies the origin, nature,
and scope of neutralities, as well as their interactions with different
ideational spectra.",25,2,167,29.18
3393,philosophy,"Here we review a kind of post-World-War-II ""Nachtrag"" to H. Weyl's
philosophical comments on mathematics and the natural sciences published in the
middle of the 1920s. In a talk given at Z\""urich in the late 1940s, Weyl
discussed F.Gonseth's dialectical epistemology and considered it as being
restricted too strictly to aspects of historical change. His own experiences
with post-Kantian dialectical philosophy, in particular J.G. Fichte's
derivation of the concept of space and matter, had been a stronger dialectical
background for his own 1918 studies in purely infintitesimal geometry and the
early geometrically unified field theory of matter (extending the Mie-Hilbert
program). Although now Weyl distantiated himself from the speculative features
of his youthful philosophizing and in particular from his earlier enthusiasm
for Fichte, he again had deep doubts as to the cultural foundations of modern
mathematical sciences and its role in material culture of high modernity. For
Weyl, philosophical ""reflection"" was a cultural necessity; he now turned
towards K. Jasper's and M. Heidegger's existentialism to find deeper grounds,
similar to his turn towards Fichte's philosophy after World War I.",179,12,1205,36.39
3394,philosophy,"A discussion of different criteria of consistency of quantum field theory
from the point of view of physics and mathematics.",20,2,124,34.26
3395,philosophy,"We describe the physics opportunities and technical challenges of a muon
collider as a tool for exploring high energy physics phenomena.",21,2,136,33.24
3396,philosophy,"This paper has been translated into German and will be included, in a
somewhat altered form, in a book Sterne der Zertrummerung, Marietta Blau,
Wegbereiterin der Moderne Teilchenphysik, Brigitte Strohmaier and Robert
Rosner, eds., Boehlau Verlag, Wien.",37,3,252,52.7
3397,philosophy,"Since 1945 Canada has had a nuclear power industry based on reactor design
which uses natural uranium and heavy water. The tortuous and improbable
sequence of events which led to this situation is examined.",34,3,206,37.3
3398,philosophy,"I will describe some of the events that led to the creation of General
Atomic, a research and development organization founded in San Diego in 1956.",26,2,148,53.55
3399,philosophy,"While similarities do naturally exist between tao and other philosophical
systems, for the specific case of Democritus we can argue also the
chronological parallels, the parallels in the posterior development (alchemy
and mathematics) and the textual parallelism.",37,2,263,-8.39
3400,philosophy,"This note is about three interesting 15th and 16th century sightings of
comets in Kashmiri chronicles. We provide reasons for their identification as
the 1468 S1, 1531 (Halley's), and 1533 M1 comets.",32,3,199,63.7
3401,philosophy,"This note presents reasons why Mendeleev chose Sanskrit names (now
superseded) for eight elements in the periodic table.",18,2,120,53.21
3402,philosophy,"Some erroneous and misleading statements in an article by J. Bernstein on
Heisenberg's visit to Cracow during the war are corrected.",21,3,132,52.36
3403,philosophy,"The beliefs of physicists can bias their results towards their expectations
in a number of ways. We survey a variety of historical cases of expectation
bias in observations, experiments, and calculations.",31,3,204,30.36
3404,philosophy,"In this note I shall review the Japan-Italy cooperative work in high energy
collider experiments, in particular OPAL at LEP, CDF at Fermilab, ZEUS at HERA
and ATLAS at the future LHC.",32,2,183,30.54
3405,philosophy,"This is an ""Essay-Review"" of a book with the same title, by Jeffrey Bub
(Cambridge University Press, 1997).",18,2,107,70.13
3406,philosophy,"We give two simple Kochen-Specker arguments for complementary between the
position and momentum components of spinless particles, arguments that are
identical in structure to those given by Peres and Mermin for spin-1/2
particles.",33,2,230,21.06
3407,philosophy,"This colloquium summarizes Dirac's contributions to the discovery of quantum
mechanics before he invented his relativistic wave equation.",18,2,137,10.91
3408,philosophy,"In recent papers, Zurek has objected to the decision-theoretic approach of
Deutsch and Wallace to deriving the Born rule for quantum probabilities on the
grounds that it courts circularity. Deutsch and Wallace assume that the many
worlds theory is true and that decoherence gives rise to a preferred basis.
However, decoherence arguments use the reduced density matrix, which relies
upon the partial trace and hence upon the Born Rule for its validity. Using the
Heisenberg Picture and quantum Darwinism - the notion that classical
information is quantum information that can proliferate in the environment
pioneered by Olliver et al - I show that measurement interactions between two
systems only create correlations between a specific set of commuting
observables of system 1 and a specific set of commuting observables of system
2. This argument picks out a unique basis in which information flows in the
correlations between those sets of commuting observables. I then derive the
Born rule for both pure and mixed states and answer some other criticisms of
the decision theoretic approach to quantum probability.",176,7,1116,25.12
3409,philosophy,"The historical significance of the problem of relativistic rigid rotation is
reviewed in light of recently published correspondence between Einstein and the
mathematician Vladimir Varicak from the years 1909 to 1913.",31,2,216,14.63
3410,philosophy,"The present work is a brief review of the progressive search of improper
delta-functions which are of interest in Quantum Mechanics and in the problem
of motion in General Relativity Theory.",31,2,190,31.55
3411,philosophy,"The interpretation of an experimental realization of Wheeler's delayed-choice
gedanken experiment is discussed and called into question.",17,2,136,3.46
3412,philosophy,"This is a philosophy paper rather than mathematical physics work. I will
publish it in some other place.",18,3,104,62.34
3413,philosophy,"These notes are based on lectures given in Wuhan (China) in July 2007. Their
aim is to provide an introduction to Langlands philosophy.",23,3,135,68.26
3414,philosophy,"This submission has been withdrawn by arXiv admins because there was an
erroneous author included in the original version.",19,2,122,43.73
3415,philosophy,"A few recollections and afterthoughts on the development of the string
picture of fundamental interactions out of the S-matrix program.",20,2,135,25.8
3416,philosophy,"The rise of quantum mechanics is reviewed with special attention to the
development between June 1925 and October 1927 when the Copenhagen
interpretation was proposed.",25,2,167,29.18
3417,philosophy,"This is a review of the four-volume set entitled The Genesis of General
Relativity edited by Juergen Renn, Springer, Dordrecht (2007)",21,1,133,33.24
3418,philosophy,"This article discusses epistemological problems in the philosophy of
mathematics and issues concerning the reliability of the mathematical
literature.",19,2,150,-32.42
3419,philosophy,We review the life and remarkable contributions to Physics of Gregor Wentzel.,12,2,77,59.3
3420,philosophy,"According to the philosopher Kant, Mathematics is an ""a priori cognition"".
Kant's assumption, together with the unsolvability of Hilbert's 10th problem,
implies an astonishing result.",25,3,183,33.41
3421,philosophy,"Invited contribution to the collection of articles: `The Birth of String
Theory', edited by Andrea Cappelli, Elena Castellani, Filippo Colomo and Paolo
Di Vecchia.",24,2,163,21.74
3422,philosophy,"On october 21st 1983 took place in S\`evres on the western outskirts of Paris
the official funeral of the meter. With it the notion of distance as a physical
observable was buried.",32,3,180,63.7
3423,philosophy,"We concisely review the history, physics and significance of coherent states.",11,2,77,34.93
3424,philosophy,"We review some approaches and philosophies of causal inference coming from
sociology, economics, computer science, cognitive science, and statistics",19,1,148,9.89
3425,philosophy,"A dissertation submitted to the University of Bristol in accordance with the
requirements of the degree of Doctor of Philosophy (PhD) in the Faculty of
Engineering, Department of Computer Science, July 2009.",32,2,207,13.62
3426,philosophy,"As a material property and as a metaphor, thermal conductivity occupies an
important position in physical, biological and geological sciences. Yet, its
precise measurement is dependent on using electricity as a proxy because
flowing heat cannot directly be measured.",39,3,266,9.38
3427,philosophy,"A substantial school in the philosophy of science identifies Bayesian
inference with inductive inference and even rationality as such, and seems to
be strengthened by the rise and practical success of Bayesian statistics. We
argue that the most successful forms of Bayesian statistics do not actually
support that particular philosophy but rather accord much better with
sophisticated forms of hypothetico-deductivism. We examine the actual role
played by prior distributions in Bayesian models, and the crucial aspects of
model checking and model revision, which fall outside the scope of Bayesian
confirmation theory. We draw on the literature on the consistency of Bayesian
updating and also on our experience of applied work in social science.
  Clarity about these matters should benefit not just philosophy of science,
but also statistical practice. At best, the inductivist view has encouraged
researchers to fit and compare models without checking them; at worst,
theorists have actively discouraged practitioners from performing model
checking because it does not fit into their framework.",163,7,1098,26.95
3428,philosophy,"The aim of this short note is to realize that the main reason for
non-mechanistic explanation of Newton's gravitational attraction, is explicitly
encapsulated in his famous General Scholium of the second Edition of Principia
Mathematica (1713).",36,2,244,1.1
3429,philosophy,"We trace the origin of the concept which was named by the High Energy Physics
Community ""The Cabibbo angle""",19,1,107,60.65
3430,philosophy,"A brief description and results of A.M. Mathai's research programme on
statistics and probability, initiated in the 1970s, and its relation to physics
is given.",25,4,160,50.33
3431,philosophy,"I write about H\'ector, his contributions to the early work in the quark
model, and a general discussion of quantum statistics",21,1,126,50.16
3432,philosophy,"In the present article we provide a brief introduction to the Life and Works
of Indian astronomer R. G. Chandra.",20,4,112,59.64
3433,philosophy,"Many see modern science as having serious defects, intellectual, social,
moral. Few see this as having anything to do with the philosophy of science. I
argue that many diverse ills of modern science are a consequence of the fact
that the scientific community has long accepted, and sought to implement, a bad
philosophy of science, which I call standard empiricism. This holds that the
basic intellectual aim is truth, the basic method being impartial assessment of
claims to knowledge with respect to evidence. Standard empiricism is, however,
untenable. Furthermore, the attempt to put it into scientific practice has many
damaging consequences for science. The scientific community urgently needs to
bring about a revolution in both the conception of science, and science itself.
It needs to be acknowledged that the actual aims of science make metaphysical,
value and political assumptions and are, as a result, deeply problematic.
Science needs to try to improve its aims and methods as it proceeds. Standard
empiricism needs to be rejected, and the more rigorous philosophy of science of
aim-oriented empiricism needs to be adopted and explicitly implemented in
scientific practice instead. The outcome would be the emergence of a new kind
of science, of greater value in both intellectual and humanitarian terms.",207,12,1319,43.93
3434,philosophy,"In the present Note we have presented some documents to reveal the
longstanding relationship of Indian amateur astronomer R. G. Chandra with
British Astronomical Association.",25,4,174,24.95
3435,philosophy,"I contemplate the idea that the subjective world and quantum state reductions
are one and the same. If true, this resolves with one stroke both the quantum
mechanical measurement problem and the hard problem of consciousness.",36,3,225,61.67
3436,philosophy,"Masses and mixings of quarks and leptons differ wildly from one another. Thus
it is all the more challenging to search for some hidden attribute that they
may share.",29,3,165,73.68
3437,philosophy,"This note is an extended review of the book Error and Inference, edited by
Deborah Mayo and Aris Spanos, about their frequentist and philosophical
perspective on testing of hypothesis and on the criticisms of alternatives like
the Bayesian approach.",39,2,249,23.43
3438,philosophy,"We give a short introduction to category theory aimed at philosophers. We
emphasize methodological issues and philosophical ramifications.",18,3,138,11.58
3439,philosophy,"The mechanism of spontaneous symmetry breaking in quantum systems is briefly
reviewed, rectifying part of the standard wisdom on logical and mathematical
grounds. The crucial role of the localization properties of the time evolution
for the conclusion of the Goldstone theorem is emphasized.",43,3,291,32.73
3440,philosophy,"Professor Sir Karl Popper (1902-1994) was one of the most influential
philosophers of science of the twentieth century. However, in his most famous
work he displays misunderstandings of science and mathematics at a basic level.",35,3,227,45.25
3441,philosophy,"Translation of a popular article on MOND vs. dark matter that appeared, in
Hebrew, in the Israeli magazine ""Odyssea"", dedicated to ""thoughts and ideas in
the forefront of science and philosophy"".",31,3,195,55.74
3442,philosophy,"We present two unusual observations of Saturn recorded during the early years
of the twentieth century",16,1,102,38.32
3443,philosophy,"This is a former PhD student's take on his teacher's scientific philosophy. I
describe a set of 'principles' that I believe are conducive to good applied
mathematics, and that I have learnt myself from observing Hans van Duijn in
action.",40,3,237,51.18
3444,philosophy,"This survey tries to investigate the truths and deficiencies of prevalent
philosophy about Uncertainty Relations (UR) and Quantum Measurements (QMS). The
respective philosophy, known as being eclipsed by unfinished controversies, is
revealed to be grounded on six basic precepts. But one finds that all the
respective precepts are discredited by insurmountable deficiencies. So, in
regard to UR, the alluded philosophy discloses oneself to be an unjustified
mythology. Then UR appear either as short-lived historical conventions or as
simple and limited mathematical formulas, without any essential significance
for physics. Such a finding reinforces the Dirac's prediction that UR ""`in
their present form will not survive in the physics of future""'. The noted
facets of UR motivate reconsiderations of associated debates on QMS. Mainly one
reveals that, properly, UR have not any essential connection with genuine
descriptions of QMS. For such descriptions, it is necessary that,
mathematically, the quantum observables to be considered as random variables.
The measuring scenarios with a single sampling, such are wave function collapse
or Schrodinger's cat thought experiment, are revealed as being useless
exercises. We propose to describe QMS as transmission processes for stochastic
data. Note that the above-announced revaluation of UR and QMS philosophy does
not disturb in any way the practical framework of the usual quantum mechanics.",212,13,1445,36.59
3445,philosophy,"The general philosophy for bootstrap or permutation methods for testing
hypotheses is to simulate the variation of the test statistic by generating the
sampling distribution which assumes both that the null hypothesis is true, and
that the data in the sample is somehow representative of the population. This
philosophy is inapplicable for testing hypotheses for a single parameter like
the population mean, since the two assumptions are contradictory (e.g., how can
we assume both that the mean of the population is $\mu_0,$ and that the
individuals in the sample with a mean $M \ne \mu_0$ are representative of the
population?). The Mirror Bootstrap resolves that conundrum. The philosophy of
the Mirror Bootstrap method for testing hypotheses regarding one population
parameter is that we assume both that the null hypothesis is true, and that the
individuals in our sample are as representative as they could be without
assuming more extreme cases than observed. For example, the Mirror Bootstrap
method for testing hypotheses of one mean uses a generated symmetric
distribution constructed by reflecting the original sample around the
hypothesized population mean $\mu_0$. Simulations of the performance of the
Mirror Bootstrap for testing hypotheses of one mean show that, while the method
is slightly on the conservative side for very small samples, its validity and
power quickly approach that of the widely used t-test. The philosophy of the
Mirror Bootstrap is sufficiently general to be adapted for testing hypotheses
about other parameters; this exploration is left for future research.",247,10,1598,23.19
3446,philosophy,"Here a discussion on the Loulan Kingdom, an ancient kingdom along the Silk
Road, and some observations based on satellite images.",21,2,129,58.62
3447,philosophy,"The article gives an overview on early cosmic-ray work, published in German
in the period from around 1910 to about 1940.",21,2,121,58.62
3448,philosophy,"This is an article for a special edition of ""European Review"" with a focus on
the topic ""Causality"".",18,2,100,53.21
3449,philosophy,"In this very brief note, we only wish to identify a simple but notable
epistemological basis, concerning the Karl R. Popper philosophy of science
thought, into the realm of the experimental proves of Fundamental Physics.",35,3,220,45.25
3450,philosophy,"We seek to elucidate the philosophical context in which one of the most
important conceptual transformations of modern mathematics took place, namely
the so-called revolution in rigor in infinitesimal calculus and mathematical
analysis. Some of the protagonists of the said revolution were Cauchy, Cantor,
Dedekind, and Weierstrass. The dominant current of philosophy in Germany at the
time was neo-Kantianism. Among its various currents, the Marburg school (Cohen,
Natorp, Cassirer, and others) was the one most interested in matters scientific
and mathematical. Our main thesis is that Marburg neo-Kantian philosophy
formulated a sophisticated position towards the problems raised by the concepts
of limits and infinitesimals. The Marburg school neither clung to the
traditional approach of logically and metaphysically dubious infinitesimals,
nor whiggishly subscribed to the new orthodoxy of the ""great triumvirate"" of
Cantor, Dedekind, and Weierstrass that declared infinitesimals conceptus
nongrati in mathematical discourse. Rather, following Cohen's lead, the Marburg
philosophers sought to clarify Leibniz's principle of continuity, and to
exploit it in making sense of infinitesimals and related concepts.",169,8,1215,21.63
3451,philosophy,"Kenneth G. Wilson made deep and insightful contributions to statistical
physics, particle physics, and related fields. He was also a helpful and
thoughtful human being.",25,4,168,41.87
3452,philosophy,"This paper describes the history of experimental neutrino physics in the
physics department of Rome Sapienza University",17,1,119,28.84
3453,philosophy,"It is shown how the study of blackbody radiation in the early twentieth
century by the German physicist Max Planck gave rise to the quantum theory.",26,2,147,53.55
3454,philosophy,"This paper explains genetic algorithm for novice in this field. Basic
philosophy of genetic algorithm and its flowchart are described. Step by step
numerical computation of genetic algorithm for solving simple mathematical
equality problem will be briefly explained",38,3,265,33.2
3455,philosophy,"It is shown as experiments and theories about the nature of light led to the
special theory of relativity. The most important facts for the emergence of the
theory proposed by Einstein in 1905 are presented.",36,3,207,53.21
3456,philosophy,"I argue that the Carroll-Chen cosmogenic model does not provide a plausible
scientific explanation of our universe's initial low-entropy state.",20,2,143,25.8
3457,philosophy,"This short note describes the observatory of the pioneering spectroscopist,
Frank McClean (1837-1907), at Tunbridge Wells in England",18,1,132,44.75
3458,philosophy,"The QBist view of science, first put forth to dispel the fog from quantum
foundations, also clears up a longstanding puzzle in classical physics.",24,2,145,55.58
3459,philosophy,"A personal and subjective recollection, concerning mainly Wilson's lectures
delivered over the spring of 1972 at Princeton University (summary of a talk at
Cornell University on November 16, 2013 at the occasion of the memorial Kenneth
G. Wilson conference).",39,3,258,14.97
3460,philosophy,"Current thinking on the interpretation of quantum physics is reviewed, with
special detail given to the Copenhagen and Everett many-worlds interpretations.",21,2,155,24.78
3461,philosophy,"The principle of classification of macroprocesses is offered, which allows to
avoid some methodological mistakes of modern natural sciences. The content and
the nearest consequences of this principle is open and its conformity of a
classical line of physics developments is shown.",42,3,280,33.24
3462,philosophy,"The highlights of the conference: The Legacy of Bruno Pontecorvo: the
Scientist and the Man, held in Roma, Universit\`a La Sapienza, 11-12 September,
2013, are summarised and illustrated.",28,2,187,34.6
3463,philosophy,"An essay on Jyant Narlikar in the Living Legends of Indian Science series of
the journal Current Science.",18,2,105,53.21
3464,philosophy,"In this article, we explain the main philosophy of 2-representation theory
and quantum affine Schur-Weyl duality. The Khovanov-Lauda-Rouquier algebras
play a central role in both themes.",26,3,186,41.36
3465,philosophy,"This article is a brief Retrospective on the life and work of Robert W.
Zwanzig, who formulated nonequilibrium statistical mechanics and who passed
away in May of this year.",29,3,173,56.76
3466,philosophy,"Reinhard Werner authored a comment on my paper ""What Bell Did"", disputing the
conclusion and argumentation of the paper. This is my reply.",23,3,138,51.34
3467,philosophy,"A Thesis Submitted to the Tata Institute of Fundamental Research, Mumbai for
the degree of Doctor of Philosophy in Physics (supervisor: Prof. A. R. Rao)",25,4,152,37.64
3468,philosophy,"Translation of Denis Diderot's `Cinqui\`eme M\'emoire ou Lettre sur la
R\'esitance de L'Air ou Mouvement des Pendules.'",17,2,119,45.76
3469,philosophy,"A review of the book ""A Brief History of String Theory: From Dual Models to
M-Theory"" by Dean Rickles",19,1,101,60.65
3470,philosophy,"Pioneering works and stimulation by S. Hayakawa for the development of
high-energy astrophysics in Japan.",15,3,105,38.48
3471,philosophy,"From the analysis of the quantum and relativistic properties of the particles
it results the unified quantum-relativistic dynamics of the physical reality
(Universe).",23,2,166,5.83
3472,philosophy,"Aboriginal stories dating back many thousands of years talk of a fire from
the sky in an area now home to the Henbury meteorite craters, in the Northern
Territory",29,1,162,58.96
3473,philosophy,"This short note discusses the role of syntax vs. semantics and the interplay
between logic, philosophy, and language in computer science and game theory.",24,3,153,42.38
3474,philosophy,"""All men by nature desire to know,"" states Aristotle in the famous first
sentence of his Metaphysics. Knowledge about fundamental particles and
interactions, that is, knowledge about the deepest aspects of matter, is
certainly high if not top on the priority list, not only for physicists and
philosophers. The goal of the present book is to contribute to this knowledge
by going beyond the usual presentations of quantum field theory in physics
textbooks, both in mathematical approach and by critical reflections inspired
by epistemology, that is, by the branch of philosophy also referred to as the
theory of knowledge.
  Hopefully, the present book motivates physicists to appreciate philosophical
ideas. Epistemology and the philosophy of the evolution of science often seem
to lag behind science and to describe the developments a posteriori. As
philosophy here has a profound influence on the actual shaping of an image of
fundamental particles and their interactions, our development should stimulate
the curiosity and imagination of physicists.
  This book can be used as a textbook on quantum field theory for students of
physics or as a monograph for philosophers and physicists interested in the
epistemological foundations of particle physics. The benefits of an approach
resting on philosophical foundations is twofold: the reader is stimulated to
critical thinking and the entire story flows very naturally, thus removing all
the mysteries from quantum field theory.",227,9,1481,25.73
3475,philosophy,"Conway and Kochen's Free Will Theory is examined as an important foundational
element in a new area of activity in computer science - developing protocols
for quantum computing",28,1,176,10.23
3476,philosophy,"We review some prominent results of ITEP theorists obtained in the first 70
years of the Institute operation",18,1,108,44.75
3477,philosophy,"DGRAV News:
  DGRAV
  we hear that....
  Research Briefs:
  GW150914
  Obituaries:
  Remembering Felix Pirani
  Remembering David Finkelstein
  Steve, the physicist
  Remembering Sergio Dain
  Editorial:
  Gravitational physics in the modern university",29,5,252,22.92
3478,philosophy,"There exist limits of self-inspection due to self-referential paradoxes,
incompleteness and fixed point theorems. As quantum mechanics dictates the
exchange of discrete quanta, measurements and self-inspection of quantized
systems are fundamentally limited.",32,3,257,4.47
3479,philosophy,"Dmitri Ivanenko, professor of Moscow State University, was one of the great
theoreticians of XX century, an author of the proton-neutron model of atomic
nucleus. In honor of the 110th Year Anniversary.",32,3,201,46.78
3480,philosophy,"In memory of Guido Altarelli I present my personal recollections of the early
times and his major role played in the development of QCD.",24,2,136,47.12
3481,philosophy,"The liar paradox is widely seen as not a serious problem. I try to explain
why this view is mistaken.",20,3,101,78.25
3482,philosophy,"The goal of this paper is to explain how the views of Albert Einstein, John
Bell and others, about nonlocality and the conceptual issues raised by quantum
mechanics, have been rather systematically misunderstood by the majority of
physicists.",38,2,242,24.45
3483,philosophy,"I use Supergravity as a test case to study the role and uses of
elegance/simplicity in formulating and evaluating physical models, whose sole
criterion is of course truth: an observationally verified description of Nature
within a certain range of scales.",40,2,255,5.5
3484,philosophy,"I provide an alternative characterization of a ""standard of rotation"" in the
context of classical spacetime structure that does not refer to any covariant
derivative operator.",26,2,175,11.25
3485,philosophy,"These are reminiscences of my interactions with Julian Schwinger from 1968
through 1981 and beyond.",15,2,99,64.71
3486,philosophy,"Can we increase chances for a scientific breakthrough by get trained in
discovery-oriented thinking?",14,1,100,40.35
3487,philosophy,"We will establish a nearby and vanishing cycle formalism for the arithmetic
$\mathscr{D}$-module theory following Beilinson's philosophy. As an
application, we define smooth objects in the framework of arithmetic
$\mathscr{D}$-modules whose category is equivalent to the category of
overconvergent isocrystals.",40,3,310,8.88
3488,philosophy,"The purpose of this paper is to describe and elaborate the philosophical
ideas behind hyperstructures and structure formation in general and emphasize
the key ideas of the Hyperstructure Program.",29,2,195,25.12
3489,philosophy,"A non-relativistic theory of inertia based on Mach's principle is presented
as has been envisaged but not achieved by Ernst Mach in 1872. Central feature
is a space-dependent, anisotropic, symmetric inert mass tensor.",33,3,217,37.81
3490,philosophy,"Notwithstanding its great influence in modern physics, the EPR
thought-experiment has been explained incorrectly a surprising number of times.",19,2,142,26.81
3491,philosophy,"This short review is dedicated to academician Yakov Borisovich Zeldovich, the
science of his epoch and the creation of modern accretion theory.",22,2,143,40.69
3492,philosophy,"Brief recollections of two giants of physics, their origins, similarities and
differences.",12,2,90,33.92
3493,philosophy,"It is an expanded form of Drasin's work on normality of family of meromorphic
functions given in his seminal paper titled ""Normal Families and the Nevanlinna
Theory"".",27,2,166,27.15
3494,philosophy,"This is an expository survey of the Jacobian problem for the class of
Pluriharmonic functions.",15,2,94,39.33
3495,philosophy,"arXiv admin note: This submission has been withdrawn by arXiv administrators
due to inflammatory content and unprofessional language",18,1,132,10.91
3496,philosophy,"arXiv admin note: This submission has been withdrawn by arXiv administrators
due to inflammatory content and unprofessional language",18,1,132,10.91
3497,philosophy,"After a discussion of the Frauchiger-Renner argument that no 'single- world'
interpretation of quantum mechanics can be self-consistent, I propose a
'Bohrian' alternative to many-worlds or QBism as the rational option.",31,2,218,14.63
3498,philosophy,"The present short essay, of essentially historical nature, aims at describing
the transition from the Euclidean-Newtonian space-time geometry of Classical
Physics to the Pseudoriemannian geometry of General Relativity, including the
Minkowskian geometry of Special Relativity as an intermediate step.",39,2,300,-27.34
3499,philosophy,"This paper is based on a talk delivered on 16 November, 2015 in Osaka at the
Nambu's Century: International Symposium on Yoichiro Nambu's Physics",24,1,145,30.2
3500,philosophy,"I present a simple variant of the Schr\""odinger cat meets Wigner's friend
thought experiment. If you are shocked by it, you have not understood quantum
physics (no words are missing from this sentence).",33,3,202,71.65
3501,philosophy,"Contributed paper to the Conference ""Francesco's Legacy: Star Formation in
Space and Time"", in memory of Francesco Palla (1954-2016), held in Florence,
June 5-9, 2017",25,1,166,54.56
3502,philosophy,"This is an annotated translation of Euler's 1777 manuscript ""De Figura Quam
Ventus Fluido Stagnanti Inducere Valet"", where Euler models the shape which the
wind gives to a still liquid surface.",31,2,193,40.01
3503,philosophy,"We argue that computation is an abstract algebraic concept, and a computer is
a result of a morphism (a structure preserving map) from a finite universal
semigroup.",27,2,164,35.61
3504,philosophy,"I document 32 students who graduated to receive PhDs under Feynman's
supervision. I provide links to their doctoral dissertations.",19,3,130,36.45
3505,philosophy,"The history of astronomy in Odessa is briefly discussed with a special
emphasis on the scientific school of variable star researches founded by Prof.
V.P.Tsesevich.",25,5,164,29.18
3506,philosophy,"I present some reminiscences, both personal and scientific, over a lifetime
of admiration of, and friendship with, one of the Grandmasters of our subject.",24,2,154,38.66
3507,philosophy,"arXiv admin note: This submission has been withdrawn by arXiv administrators
due to inflammatory content and unprofessional language",18,1,132,10.91
3508,philosophy,"Ennackal Chandy George Sudarshan was born on 16 September 1931 in Pallam, a
small village in the Kottayam District of Kerala State, South India.",24,2,144,55.58
3509,philosophy,"In this invited talk, I discuss four important contributions of E.C.G.
Sudarshan, among many. They are the V-A theory of weak interaction, Sudarshan -
Glauber representation, tachyons and the quantum zeno effect.",32,6,212,52.56
3510,philosophy,"The relationship between the chemical picture of an isolated molecule and
that arising from the eiegenfunctions of the Schrodinger Coulomb Hamiltonian
ror the isolated molecule are examined and discussed.",29,2,204,16.66
3511,philosophy,"The assertion that an experiment by Afshar et al. demonstrates violation of
Bohr's Principle of Complementarity is based on the faulty assumption that
which-way information in a double-slit interference experiment can be
retroactively determined from a future measurement.",38,3,272,18.35
3512,philosophy,"We review the special theory of relativity kinematics and dynamics as well as
the general theory of relativity under the aspect of logic.",23,2,137,14.29
3513,philosophy,"This paper collects into one place (most of) my answers to the questions
Maximilian Schlosshauer posed in his interview volume, ""Elegance and Enigma:
The Quantum Interviews"" (Springer, Frontiers Collection, 2011).",30,2,213,32.57
3514,philosophy,"In this article, I discuss how the AI community views concerns about the
emergence of superintelligent AI and related philosophical issues.",21,2,139,24.78
3515,philosophy,"The answer will be a ""yes"" (despite looking like a violation of the
Uncertainty Principle).",15,2,91,47.79
3516,philosophy,"The sixteen years old Albert Einstein made friend with Ernestina Marangoni in
the summer of 1895 in Pavia. We discuss in this article the unacknowledged link
between Albert Einstein and the physicist and professor Carlo Marangoni,
Ernestina's uncle, a specialist of capillarity effects.",43,3,286,41.19
3517,philosophy,"The emergence of the new, non-Euclidean geometry of Bolyai, Gauss, and
Lobachevskii (BGL) and its impact on modern sciences is the subject of a series
of biennial conferences. Below, I briefly review the history.",34,3,212,54.22
3518,philosophy,We present an English translation of a 1918 paper by Felix Klein.,12,2,65,76.22
3519,philosophy,"Before they met, David Bohm and Roger Penrose each puzzled over the paradox
of the arrow of time. After they met, the case for projective physical space
became clearer.",29,3,168,73.68
3520,philosophy,"We propose that the Jungian psychological type of an individual is naturally
modelled as a quantum state: a maximally entangled two-qubit state, one of
whose qubits is undergoing quantum teleportation.",30,2,201,15.65
3521,philosophy,"The article below is based on lectures delivered to new students remotely in
the course of orientation. It presents the quantum theory tree from its
inception a century ago till today. The main focus is on the nuclear physics -
HEP branch.",42,4,239,57.57
3522,philosophy,"As a neuroscientist and a theoretical physicist, both working on time, we
have decided to open a direct dialogue to examine if the apparent discrepancies
regarding the nature of time can be composed.",33,2,199,21.06
3523,philosophy,"In this paper, we will explain a successfully proven lecturing method based
entirely on system design. Wireless communications will be used as an example
to explain this new teaching philosophy.",30,3,194,39.33
3524,philosophy,"Biographical essay at the occasion of the first death anniversary of Manfred
Bonitz",13,1,83,41.36
3525,philosophy,"There is no mysterious link between mathematics and physics, because both of
them are human inventions designed to study the world.",21,2,131,50.16
3526,philosophy,"I describe the contributions of Guido Altarelli to the development of Quantum
Chromodynamics from the discovery of asymptotic freedom until the end of the
S$p\bar{p}$S collider era, 1973-1985.",28,2,192,17.68
3527,philosophy,"This article presents a survey of computability logic: its philosophy and
motivations, main concepts and most significant results obtained so far. A
continuously updated online version of this article is maintained at
http://www.csc.villanova.edu/~japaridz/CL/ .",34,6,262,12.43
3528,philosophy,"A biographical profile of the theoretical physicist, Julian Schwinger, and a
discussion of ""The Memories of Julian"" Centennial Celebration (held at Harvard
University on February 12, 2018) is presented herein.",30,2,209,7.19
3529,philosophy,"A concise story of the rise of the four fermion theory of the universal weak
interaction and its experimental confirmation, with a special emphasis on the
problems related to parity violation.",31,2,192,14.63
3530,philosophy,"I briefly summarize my personal opinions on the current status of HEP theory
and comment on the so-called ""non-empiric confirmation.""",20,2,133,34.26
3531,philosophy,"The familiar ""modulus squared"" form of all quantum mechanical probabilities
is derived from an assumption of equal a priori probabilities concerning the
final states available.",25,2,176,12.26
3532,philosophy,"The famous school case of Schrodinger is quickly reviewed and evaluated in
the light of recent experimental and formal developments, and conclusions are
proposed at theoretical, epistemological and philosophical points of view.",32,2,227,5.16
3533,philosophy,"This addendum addresses several objections regarding accelerating cavities in
the paper by Boughn and Rothman, ""Hasen\""ohrl and the Equivalence of Mass and
Energy,"" arXiv:1108.2250.",24,3,181,13.28
3534,philosophy,"Mike Lockwood and Mathew Owens discuss how eclipse observations are aiding
the development of a climatology of near-Earth space",19,1,127,43.73
3535,philosophy,"This three-part paper comprises: (i) a critique by Halvorson of Bell's (1973)
paper ""Subject and Object""; (ii) a comment by Butterfield; (iii) a reply by
Halvorson. An Appendix gives the passage from Bell that is the focus of
Halvorson's critique.",40,3,247,59.64
3536,philosophy,"A recent paper by Mucino, Okon and Sudarsky attempts an assessment of the
Relational Interpretation of quantum mechanics. The paper presupposes
assumptions that are precisely those questioned in the Relational
Interpretation, thus undermining the value of the assessment.",38,3,271,9.89
3537,philosophy,"Starting from general considerations, some ideas of the philosopher Derek
Parfit on consciousness, self-awareness, and reductionism are briefly reviewed
and critically examined from the standpoint of physics.",27,2,208,27.15
3538,philosophy,"Explaining the emergence of stochastic irreversible macroscopic dynamics from
time-reversible deterministic microscopic dynamics is one of the key problems
in philosophy of physics. The Mori-Zwanzig projection operator formalism, which
is one of the most important methods of modern nonequilibrium statistical
mechanics, allows for a systematic derivation of irreversible transport
equations from reversible microdynamics and thus provides a useful framework
for understanding this issue. However, discussions of the Mori-Zwanzig
formalism in philosophy of physics tend to focus on simple variants rather than
on the more sophisticated ones used in modern physical research. In this work,
I will close this gap by studying the problems of probability and
irreversibility using the example of Grabert's time-dependent projection
operator formalism. This allows to give a more solid mathematical foundation to
various concepts from the philosophical literature, in particular Wallace's
simple dynamical conjecture and Robertson's theory of autonomous macrodynamics.
Moreover, I will explain how the Mori-Zwanzig formalism allows to resolve the
tension between epistemic and ontic approaches to probability in statistical
mechanics. Finally, I argue that the debate which interventionists and
coarse-grainers should really be having is related not to the question why
there is equilibration at all, but why it has the quantitative form it is found
to have in experiments.",207,8,1468,16.05
3539,philosophy,"I provide the backstory on how a historical error in the Feynman Lectures on
Physics was corrected.",17,2,99,54.22
3540,philosophy,Celebrating fifty years of collaboration and friendship with Chris Isham.,10,2,73,44.41
3541,philosophy,"The physics at Frascati in the years 60's - 70's is reviewed together with
the role played by Bruno Touschek",20,1,108,77.57
3542,philosophy,"The author reflects on the significance of Einstein's brain and the search
for what makes it distinct.",17,2,102,71.14
3543,philosophy,"This article focuses on the connection between the possibility of quantum
computers, the predictability of complex quantum systems in nature, and the
issue of free will.",26,2,169,28.17
3544,philosophy,"In this work we develop a model based on the double solution theory of de
Broglie in order to reproduce the famous Landau levels splitting in a constant
magnetic field.",30,2,168,41.03
3545,philosophy,"A recent phase transition in the relational interpretation of quantum
mechanics (RQM) is situated in its historical context, and the novelty of the
post-transition viewpoint is questioned.",27,2,188,10.23
3546,philosophy,"A room, a teacher and many friends.",7,2,35,106.67
3547,philosophy,"Foreword to Michael Janas, Michael E. Cuffaro, Michel Janssen, Understanding
Quantum Raffles. Quantum Mechanics on an Informational Approach: Structure and
Theory (Boston Studies in the Philosophy and History of Science, 340)
(Springer, 2022).",33,4,243,43.39
3548,philosophy,"In this paper, I review the book: Gary S. Berger, Michael DiRuggiero.
""Einstein: The Man and His Mind."" Bologna: Damiani, 2022. Illustrations. 209
pp. $70.00, cloth, ISBN 978-88-6208-784-1.",28,9,189,82.71
3549,philosophy,"This entry reviews Rudolf Carnap's philosophical views on the quantum
mechanics of his time. It also offers some thoughts on how Carnap might have
reacted to some recent developments in the foundations of quantum mechanics.",35,3,223,45.25
3550,philosophy,"A brief account of the development of the concept of the gravitational
constant and the debate around in in Britain at the end of the 19th century.",27,2,147,52.53
3551,philosophy,"A short account of the life of Amy Ogle, who, in 1876, was the first woman to
come top of the Natural Sciences Tripos at Cambridge.",26,2,131,70.47
3552,philosophy,"Alex, the main discoverer of high Tc superconductivity, was also a dear
friend. Here I offer a few frank anecdotes, possibly inaccurate in some details
but heartfelt and accurate in the substance, as a personal tribute to our
friendship.",39,3,237,43.22
3553,philosophy,"L. E. Ballentine's remarks in Physics Today about the QBist interpretation of
quantum mechanics are generally wide of the mark.",20,4,127,42.72
3554,philosophy,"The assumption that the system Hamiltonian for entangled states is additive
is widely used in orthodox quantum no-signalling arguments. It is shown that
additivity implies a contradiction with the assumption that the system being
studied is entangled.",37,3,251,35.78
3555,philosophy,"Theoretical physics suffered a major loss with the death of my dear friend
Jan Zaanen on January 18. This note is my remembrance of him.",25,3,136,67.25
3556,philosophy,"Comment on Herbert Bruderer's recent CACM contribution, providing additional
citations to recent publications on Ada Lovelace and suggesting a correction to
his conclusions.",23,2,173,5.83
3557,philosophy,"Yuri L'vovich Klimontovich (28.09.1924--26.10.2002) was an outstanding
theoretical physicist who made major contributions to kinetic theory. On the
occasion of his 100th birthday we recall his main scientific achievements.",29,7,222,44.71
3558,philosophy,"The hitherto unknown author of a citation by Goethe in his History of Colours
is identified as J. E. Montucla and the context of Montucla's quotation is
discussed.",28,4,163,57.27
3559,philosophy,"This is an English (annotated) translation of the Thesis report (in German)
of Max Planck at the University of Munich (1879)",21,1,124,50.16
3560,philosophy,"This is an English (annotated) translation of the Habilitation-Thesis report
(in German) of Max Planck at the University of Munich (1880)",21,1,137,24.78
3561,philosophy,"This is an English (annotated) translation of the German paper by Max Planck
(1887) about ""The principle of the conservation of energy""",22,1,135,40.69
3562,philosophy,"This is an English (annotated) translation of the German paper by Max Planck
(1943) about ""The history of the discovery of the physical quantum of action""",26,1,154,45.09
3563,philosophy,"A short essay presenting the State-Effect Interpretation of natural deduction
rules as an explanatory framework for recent developments in proof-theoretic
semantics.",21,2,165,-9.07
3564,philosophy,"This report enlists 13 functional conditions cashed out in computational
terms that have been argued to be constituent of conscious valenced experience.
These are extracted from existing empirical and theoretical literature on,
among others, animal sentience, medical disorders, anaesthetics, philosophy,
evolution, neuroscience, and artificial intelligence.",45,3,358,-2.13
3565,philosophy,"The science of complexity is based on a new way of thinking that stands in
sharp contrast to the philosophy underlying Newtonian science, which is based
on reductionism, determinism, and objective knowledge. This paper reviews the
historical development of this new world view, focusing on its philosophical
foundations. Determinism was challenged by quantum mechanics and chaos theory.
Systems theory replaced reductionism by a scientifically based holism.
Cybernetics and postmodern social science showed that knowledge is
intrinsically subjective. These developments are being integrated under the
header of ""complexity science"". Its central paradigm is the multi-agent system.
Agents are intrinsically subjective and uncertain about their environment and
future, but out of their local interactions, a global organization emerges.
Although different philosophers, and in particular the postmodernists, have
voiced similar ideas, the paradigm of complexity still needs to be fully
assimilated by philosophy. This will throw a new light on old philosophical
issues such as relativism, ethics and the role of the subject.",160,11,1122,29.86
3566,philosophy,"We prove that for any two commuting von Neumann algebras of infinite type,
the open set of Bell correlated states for the two algebras is norm dense. We
then apply this result to algebraic quantum field theory -- where all local
algebras are of infinite type -- in order to show that for any two spacelike
separated regions, there is an open dense set of field states that dictate Bell
correlations between the regions. We also show that any vector state cyclic for
one of a pair of commuting nonabelian von Neumann algebras is entangled (i.e.,
nonseparable) across the algebras -- from which it follows that every field
state with bounded energy is entangled across any two spacelike separated
regions.",120,6,703,41.74
3567,philosophy,"Conceptual consequences of recent results in loop quantum gravity are
collected and discussed here in view of their implications for a modern
philosophy of science which is mainly understood as one that totalizes
scientific insight so as to eventually achieve a consistent model of what may
be called fundamental heuristics on an onto-epistemic background which is part
of recently proposed transcendental materialism. This enterprise is being
understood as a serious attempt of answering recent appeals to philosophy so as
to provide a conceptual foundation for what is going on in modern physics, and
of bridging the obvious gap between physics and philosophy. This present first
part of the paper deals with foundational aspects of this enterprise, a second
part will deal with its holistic aspects.",125,4,802,20.69
3568,philosophy,"Sir Arthur Eddington is considered one of the greatest astrophysicist of the
twentieth century and yet he gained a stigma when, in the 1930s, he embarked on
a quest to develop a unified theory of gravity and quantum mechanics. His
attempts ultimately proved fruitless and he was unfortunately partially shunned
by some physicists in the latter portion of his career. In addition some
historians have been less than kind to him regarding this portion of his work.
However, detailed analysis of how this work got started shows that Eddington's
theories were not as outlandish as they are often purported to be. His entire
theory rested on the use of quantum mechanical methods of uncertainty in the
reference frames of relativity. Though the work was ultimately not fruitful, in
hindsight it did foreshadow several later results in physics and his methods
were definitely rigorous. In addition, his philosophy regarding determinism and
uncertainty was actually fairly orthodox for his time. This work begins by
looking at Eddington's life and philosophy and uses this as a basis to explore
his work with uncertainty.",180,9,1114,40.18
3569,philosophy,"Landauer erasure seems to provide a powerful link between thermodynamics and
information processing (logical computation). The only logical operations that
require a generation of heat are logically irreversible ones, with the minimum
heat generation being $kT \ln 2$ per bit of information lost. Nevertheless, it
will be shown logical reversibility neither implies, nor is implied by
thermodynamic reversibility. By examining thermodynamically reversible
operations which are logically irreversible, it is possible to show that
information and entropy, while having the same form, are conceptually
different.",84,5,609,7.86
3570,philosophy,"Given a state on an algebra of bounded quantum-mechanical observables (the
self-adjoint part of a C*-algebra), we investigate those subalgebras that are
maximal with respect to the property that the given state's restriction to the
subalgebra is a mixture of dispersion-free states---what we call maximal
""beable"" subalgebras (borrowing a terminology due to J. S. Bell). We also
extend our investigation to the theory of algebras of unbounded observables (as
developed by R. Kadison), and show how our results articulate a solid
mathematical foundation for central tenets of the orthodox Copenhagen
interpretation of quantum theory (such as the joint indeterminacy of
canonically conjugate observables, and Bohr's defense of the completeness of
quantum theory against the argument of Einstein, Podolsky, and Rosen).",120,6,815,5.5
3571,philosophy,"It was recently shown that the nonseparable density operators for a bipartite
system are trace norm dense if either factor space has infinite dimension. We
show here that non-local states -- i.e., states whose correlations cannot be
reproduced by any local hidden variable model -- are also dense. Our
constructions distinguish between the cases where both factor spaces are
infinite-dimensional, where we show that states violating the CHSH inequality
are dense, and the case where only one factor space is infinite-dimensional,
where we identify open neighborhoods of nonseparable states that do not violate
the CHSH inequality but show that states with a subtler form of non-locality
(often called ""hidden"" non-locality) remain dense.",112,6,737,26.64
3572,philosophy,"With his General Theory of Relativity, Albert Einstein produced a revolution
in our conception of reality and of the knowledge we can obtain from it. This
revolution can be viewed from philosophy as leading to one of the great
paradigms in the history of thought which, together with the Aristotelian and
the Newtonian paradigms, embodied the different ways of conceiving the universe
and our access to it. The comparison among these three paradigms allows us to
understand how the human being has progressively lost his central place in the
cosmos, not only in physical terms, but also in an epistemic sense, regarding
his power of knowledge about reality.",108,4,657,26.48
3573,philosophy,"I discuss the idea of relativistic causality, i.e. the requirement that
causal processes or signals can propagate only within the light-cone. After
briefly locating this requirement in the philosophy of causation, my main aim
is to draw philosophers' attention to the fact that it is subtle, indeed
problematic, in relativistic quantum physics: there are scenarios in which it
seems to fail.
  I consign to an Appendix two such scenarios, which are familiar to
philosophers of physics: the pilot-wave approach, and the Newton-Wigner
representation. I instead stress two unfamiliar scenarios: the
Drummond-Hathrell and Scharnhorst effects. These effects also illustrate a
general moral in the philosophy of geometry: that the mathematical structures,
especially the metric tensor, that represent geometry get their geometric
significance by dint of detailed physical arguments.",127,8,876,33.04
3574,philosophy,"String theory has been the dominating research field in theoretical physics
during the last decades. Despite the considerable time elapse, no new testable
predictions have been derived by string theorists and it is understandable that
doubts have been voiced. Some people have argued that it is time to give up
since testability is wanting. But the majority has not been convinced and they
continue to believe that string theory is the right way to go. This situation
is interesting for philosophy of science since it highligts several of our
central issues. In this paper we will discuss string theory from a number of
different perspectives in general methodology. We will also relate the
realism/antirealism debate to the current status of string theory. Our goal is
two-fold; both to take a look at string theory from philosophical perspectives
and to use string theory as a test case for some philosophical issues.",150,9,919,52.39
3575,philosophy,"We make a first attempt to axiomatically formulate the Montevideo
interpretation of quantum mechanics. In this interpretation environmental
decoherence is supplemented with loss of coherence due to the use of realistic
clocks to measure time to solve the measurement problem. The resulting
formulation is framed entirely in terms of quantum objects without having to
invoke the existence of measurable classical quantities like the time in
ordinary quantum mechanics. The formulation eliminates any privileged role to
the measurement process giving an objective definition of when an event occurs
in a system.",90,5,609,23.26
3576,philosophy,"Analytic QCD models are those versions of QCD in which the running coupling
parameter a(Q^2) has the same analytic properties as the spacelike physical
quantities, i.e., no singularities in the complex Q^2 plane except on the
timelike semiaxis. In such models, a(Q^2) usually differs from its perturbative
analog by power terms ~(Lambda^2/Q^2)^k for large momenta, introducing thus
nonperturbative terms in spacelike physical quantities whose origin is the UV
regime. Consequently, it contradicts the ITEP-OPE philosophy which states that
such terms can come only from the IR regimes. We investigate whether it is
possible to construct analytic QCD models which respect the ITEP-OPE philosophy
and, at the same time, reproduce not just the high-energy QCD observables, but
also the low-energy ones, among them the well-measured semihadronic tau decay
ratio.",128,7,857,37.03
3577,philosophy,"The hypothesis that philosophy is driven by difference/innovation is checked
in a quantitative manner. This was performed by assigning grades to eight main
philosophical features with respect to seven prominent philosophers, which
allowed sound concepts from multivariate statistics and pattern recognition to
be applied. A number of insights could then be inferred about the way in which
philosophy has been developed. For instance, the evolution of philosophy can be
represented as a trajectory on a plane (two instead of the eight original
dimensions) whose axes are defined by a linear combination of the philosophical
characteristics considered. In addition, all the philosophical moves have been
verified to oppose the prevailing philosophical state. We also identified an
intense and progressive trend toward dialectics.",121,7,827,34.05
3578,philosophy,"Henri Poincare's work on mathematical features of the Lorentz transformations
was an important precursor to the development of special relativity. In this
paper I compare the approaches taken by Poincare and Einstein, aiming to come
to an understanding of the philosophical ideas underlying their methods. In
section (1) I assess Poincare's contribution, concluding that although he
inspired much of the mathematical formalism of special relativity, he cannot be
credited with an overall conceptual grasp of the theory. In section (2) I
investigate the origins of the two approaches, tracing differences to a
disagreement about the appropriate direction for explanation in physics; I also
discuss implications for modern controversies regarding explanation in the
philosophy of special relativity. Finally, in section (3) I consider the links
between Poincare's philosophy and his science, arguing that apparent
inconsistencies in his attitude to special relativity can be traced back to his
acceptance of a `convenience thesis' regarding conventions.",153,6,1051,6.58
